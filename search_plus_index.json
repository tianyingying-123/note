{"./":{"url":"./","title":"Introduction","keywords":"","body":"个人学习笔记 算法与数据结构 / 操作系统 / 数据库 / 计算机系统 / 网络 / 中间件 / Java / 软件工程 / 前端 / 运维 / 网络安全 在线阅读:https://note.ismy.wang https://b.ismy.wang(国内服务器) note-mind 笔记思维导图: https://github.com/0xcaffebabe/note-mind 相关计划：https://github.com/0xcaffebabe?tab=projects 参考文献 统计： 算法与数据结构 leetcode 基本数据结构 算法策略 排序 堆 查找 并查集 图 字符串 数据库系统 leetcode -关系数据库- 形式化关系查询语言 -数据库设计- 数据库设计和ER模型 关系数据库设计 -数据存储和查询- 存储和文件结构 索引与散列 查询处理 查询优化 ORM -事务管理- 事务 并发控制 恢复系统、 -系统体系结构- 数据库系统体系结构 并行数据库 分布式数据库 -数据仓库、数据挖掘与信息检索- 数据仓库与数据挖掘 信息检索 -特殊数据库- 对象数据库 -高级主题- 数据库优化 高级应用开发 时空数据和移动性 高级事务处理 操作系统 进程与线程 内存管理 文件管理 输入/输出 死锁 虚拟化与云 多处理机系统 安全 虚拟化 软件工程 软件过程 软件需求 结构化分析方法 结构化设计方法 UML 面向对象 领域驱动设计 面向对象范式 敏捷软件开发 软件工艺 软件测试 项目管理 人月神话 CMM -软件工程落地- DevOps ServiceComb 编码 代码重构 代码审查 整洁代码 编码规范 设计模式 创建型模式 结构型模式 行为模式 MVC 服务计算 架构 编程范式 设计原则 系统设计 分布式 分布式理论 分布式系统 分布式事务 集群 缓存 静态化 资源隔离 服务限流 服务降级 网关 开放平台设计 SSO 支付系统设计 组件构建原则 软件架构 实现细节 网站架构演进 前后端分离 前端工程化 架构模式 概览 领域逻辑模式 数据源架构模式 对象关系行为模式 对象关系结构模式 对象关系元数据映射模式 web表现模式 分布模式 离线并发模式 会话模式 基本模式 微服务 服务建模 集成 分解单块系统 部署 测试 监控 安全 规模化 分布式日志 SpringCloud 注册中心 服务提供与调用 熔断器与熔断监控 配置中心 消息总线 消息驱动 服务网关 链路追踪 开放平台 SpringCloudAlibaba 计算机系统 -程序结构和执行- 数据的表示 运算方法与运算器 汇编 处理器体系架构 优化程序性能 存储器层次结构 指令系统 总线 -在系统上运行程序- 链接 异常控制流 虚拟内存 -程序间的交互和通信- 输入输出系统 系统级IO 网络编程 数字逻辑电路 数字逻辑电路基础 逻辑门电路 组合逻辑电路 时序逻辑电路 时序逻辑功能模块 半导体存储器 可编程逻辑器件 可编程逻辑器件 数模与模数转换 网络安全 网络协议安全 网络安全隔离技术 网络安全技术 安全协议技术 踩点 扫描 查点 攻击Windows 攻击Unix APT 拨号攻击 无线攻击 硬件攻击 web与数据库攻击 移动设备攻击 -KALI渗透测试- 渗透测试方法论 信息收集 目标识别 服务枚举 漏洞映射 社会工程 漏洞利用 权限提升 访问维护 Web安全 -客户端脚本安全- 浏览器安全 XSS攻击 CSRF 点击劫持 HTML5安全 -服务端安全- 注入攻击 文件上传漏洞 认证与会话管理 加密算法与随机数 Web框架安全 应用层拒绝服务攻击 web服务器配置安全 -运营安全- 业务安全 安全开发与安全运营 密码学 计算机网络 应用层 rpc HTTP RESTful 运输层 网络层 链路层 无线网络 网络安全 多媒体网络 云计算 编程语言 C语言 类型运算符与表达式 函数与程序结构 指针与数组 结构 输入与输出 UNIX系统接口 JAVA 语言基础 Java谜题 JAVA编程规范 常用API 继承与多态 嵌套类 集合 异常 日志 IO 泛型 注解 反射 JAVA并发编程 leetcode 基础概念 并发工具类 并发集合 线程池 Disruptor 网络编程 NIO 网络爬虫 Netty 概念及体系结构 传输 ByteBuf Channel相关 引导 编解码器 Lambda表达式 Stream流 JAVA模块化 JDBC 语法糖 编译器API JAVA运行管理 JAVA源码解析 基础 集合 List Map Set 并发集合 队列 线程 锁 线程池 JVM 字节码 运行参数 内存结构 垃圾回收 类加载机制 JAVA内存模型 Jakara EE Servlet JSP Cookie&Session Filter&Listener JNDI JPA Freemarker -框架- Mybatis CURD操作 连接池与事务 多表操作 缓存 注解开发 分页插件 Mybatis-Plus Hibernate Dubbo JUnit JavaScript DOM 事件 BOM 面向对象 函数 正则表达式 AJAX ES5 ES6 NodeJS art-template Express 模块化 -第三方库/框架- jQuery Vue 数据渲染 属性操作 系统指令 组件 动画 前端路由 Vuex ReactJS python go typescript HasKell Spring spring概览 装配Bean 高级装配 AOP 事务 源码解析 SpringMVC 渲染WEB视图 SpringMVC高级特性 SpringData ORM 缓存数据 Elasticsearch SpringSecurity 用户认证 RBAC Spring集成 使用远程服务 SpringBoot SpringWebFlux DSL HTML CSS 选择器 字体样式 复合选择器 标签显式模式 行高 背景 盒子模型 浮动 定位 高级技巧 CSS3 Less Bootstrap xml GraphQL SQL 中间件 数据库 MySQL 基本使用 数据类型 视图和存储程序 存储引擎 索引 管理 优化 performance schema schema与数据类型优化 执行计划 查询优化 分区表 Oracle Redis MongoDB 消息队列 ActiveMQ RabbitMQ RocketMQ Kafka web容器/服务器 Tomcat Nginx 全文检索 Lucene ElasticSearch 缓存中间件 EhCache 分布式中间件 Zookeeper xxl-job Apollo 数据库中间件 MyCat ShardingJDBC 文件服务器 FastDFS 移动开发 安卓 Activity Intent RecyclerView Handler IPC机制 通知栏 数据绑定 屏幕适配 Fragment 移动web开发 小程序开发 uniapp 开发工具 Linux VIM GIT SVN idea -构建工具- Gradle Maven 分模块构建 NPM WebPack 运维 持续集成 Docker K8s 容器管理 通识 技术与世界 专业素养 编程思想 测试与思维 学习方法论 区块链 markdown写作 概率论与数理统计 项目开发 参考文献 个人简历 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-20 05:45:30 "},"算法与数据结构/算法与数据结构.html":{"url":"算法与数据结构/算法与数据结构.html","title":"算法与数据结构","keywords":"","body":"算法与数据结构 算法 有穷性 确定性 可行性 输入输出 好的算法 正确性 易读性 健壮性 高效性 低存储性 时间复杂度 常数 多项式 n^2 n^3 指数 2^n n! 对数 logn 空间复杂度 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-07 05:02:08 "},"算法与数据结构/leetcode/leetcode.html":{"url":"算法与数据结构/leetcode/leetcode.html","title":"leetcode","keywords":"","body":"leetcode 两数之和 给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那两个整数，并返回他们的数组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍 给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1] 解法1 暴力求解，双重循环求得数组的两个项等于target的组合 class Solution { public int[] twoSum(int[] nums, int target) { int[] ret =new int[2]; for(int i=0;i 耗时:60-100ms 解法2 使用map存储(target-数组的item,index) 遍历数组，根据数组的item查找到index， 如果找到的index不与当前遍历的index相同， 则结果就是当前的index与查找的index class Solution { public int[] twoSum(int[] nums, int target) { int[] result = new int[2]; Map map = new HashMap<>(); for (int i=0;i 耗时:3-4ms 翻转32位整数 123 -> 321 解法1 转换成字符串翻转 class Solution { public int reverse(int x) { boolean f = false; if (x=0;i--){ sb.append(s.charAt(i)); } if (sb.toString().charAt(sb.length()-1) == '-'){ sb = sb.replace(sb.length()-1,sb.length(),\"\"); } long ret = Long.parseLong(sb.toString()); if (f){ ret = -ret; } if (ret > Integer.MAX_VALUE || ret 耗时：28ms 解法2 将这个数通过区域拆解成n个个位数 再倒序n个个位数相加 class Solution { public int reverse(int x) { int i; long result = 0; LinkedList list = new LinkedList<>(); long f =1; while (x!=0){ i = x%10; x/=10; if (x!=0){ f*=10; } list.offer(i); } while(list.size() != 0){ result +=list.poll()*f; f/=10; } // 判断溢出 return (int)result == result ? (int)result:0; } } 使用队列解决正序转倒序问题 耗时：3ms 判断回文数 判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数 解法1 转为字符串，生成该字符串的倒序字符串，进行判断 class Solution { public boolean isPalindrome(int x) { String s = String.valueOf(x); StringBuilder sb = new StringBuilder(); for (int i=s.length()-1;i>=0;i--){ sb.append(s.charAt(i)); } if (sb.toString().equals(s)){ return true; } return false; } } 耗时：146ms 解法2 过滤负数，逐一拆分为n个个位数倒序加入队列 将队列元素出队，还原为倒序的整数，判断是否相等 class Solution { public boolean isPalindrome(int x) { int x1 = x; if (x queue = new LinkedList<>(); int f =1; while(x !=0){ queue.add(x%10); x = x/10; if (x != 0) { f *=10; } } int ret = 0; while (queue.size()!=0) { ret+=queue.poll()*f; f/=10; } return ret == x1; } } 耗时：13ms 罗马数字转整数 V -> 5 IV -> 4 准备(字符,整数)，从下表1-结束扫描字符串 找到罗马字符代表的整数， 如果当前扫码的罗马字符比index-1的罗马字符还要小， 则将该罗马字符代表的整数累加到结果 否则减去两倍index-1位置的值（因为你前已经加了一遍） import java.util.*; class Solution { public int romanToInt(String s) { Map map = new HashMap<>(); map.put('I',1); map.put('V',5); map.put('X',10); map.put('L',50); map.put('C',100); map.put('D',500); map.put('M',1000); int ret = 0; for(int i =0;i previous){ ret -=2*previous; } } } return ret; } } 耗时：8ms 字符串数组最长公共前缀 暴力解法 取字符串数组第一个作为src 分别求得src的所有前缀 判断数组其他项是否都有这个前缀，如果没有，最长前缀及当前src的前缀 class Solution { public String longestCommonPrefix(String[] strs) { if (strs.length == 0) { return \"\"; } String prefix = \"\"; String src = strs[0]; for (int i =0;i 耗时：4ms 括号匹配问题 输入\"()\" -> true \"[)\" -> false 使用栈 左括号是入栈，右括号出栈 如果发现出栈的与入栈不匹配，则不匹配 或者发现输入右括号时，栈为空，也是不匹配 字符串扫描完成时，栈为空，表明匹配 class Solution { public boolean isValid(String s) { LinkedList stack = new LinkedList<>(); Map map = new HashMap<>(); map.put('{','}'); map.put('[',']'); map.put('(',')'); for (int i=0;i 耗时：2ms 合并两个有序链表 输入：1->2->4, 1->3->4 输出：1->1->2->3->4->4 解法 当两个指针都不为空时，则判断哪个指针的值比较小， 将较小的值存入结果，结果的指针与比较小的指针后移 如果只有一个指针不为空，则不断对该指针存入结果，并且将结果与该指针后移 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode mergeTwoLists(ListNode l1, ListNode l2) { if (l1 == null && l2 == null) { return null; } ListNode node = new ListNode(); ListNode ret = node; while(l1 != null && l2 != null) { if (l1.val 耗时：1ms 删除排序数组中的重复项 给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 解法1 从左向右扫描数组 如果发现被扫描元素等于左边元素 则将该元素往后的所有元素往前移动一位 class Solution { public int removeDuplicates(int[] nums) { int length = nums.length; for (int i=1;i 耗时：86ms 解法2 双指针解法 定义一个指针i，默认指向0 从1-n扫描数组，如果发现右边不等于左边 则i++，然后让数组i的位置内容替换为扫描位置的内容 由于i代表的是下标，所以最后需要i+1转为长度 class Solution { public int removeDuplicates(int[] nums) { if (nums.length == 0) return 0; int i = 0; for (int j = 1; j 耗时：1ms 移除元素 给定 nums = [3,2,2,3], val = 3, 函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。 你不需要考虑数组中超出新长度后面的元素 解法1 这道题跟上一道题很像，同样可以扫描元素，等于val时就将后面的元素全部向前移动一位 耗时：5ms 解法2 维护一个指针i=0 从左向右扫描元素，如果发现扫描的值不等于要被移除的值 则将扫描的值转移到数组i的位置，然后i向后移动一位 class Solution { public int removeElement(int[] nums, int val) { int i = 0; for (int j=0; j 耗时：0ms IP地址无效化 给你一个有效的 IPv4 地址 address，返回这个 IP 地址的无效化版本。 所谓无效化 IP 地址，其实就是用 \"[.]\" 代替了每个 \".\"。 解法 从左至右扫描字符，遇到“.”就改为\"[.]\"否则原样输出 为了效率，这里使用了StringBuffer class Solution { public String defangIPaddr(String address) { StringBuffer sb = new StringBuffer(); for(int i =0;i 合并两个有序数组 输入: nums1 = [1,2,3,0,0,0], m = 3 nums2 = [2,5,6], n = 3 输出: [1,2,2,3,5,6] 跟合并两个有序链表类似 class Solution { public void merge(int[] nums1, int m, int[] nums2, int n) { LinkedList list1 = new LinkedList<>(); for (int i=0;i list2 = new LinkedList<>(); for (int i=0;i list; if (list1.isEmpty()){ list=list2; }else { list = list1; } while(!list.isEmpty()){ nums1[index++]=list.remove(); } } } 耗时：2ms 最后一个单词的长度 https://leetcode-cn.com/problems/length-of-last-word/ 输入: \"Hello World\" 输出: 5 解法 从后往前扫描文本 发现字符为非空格，长度+1 发现字符是空格，并且长度不等于0，则已经查找到最后一个单词的长度 class Solution { public int lengthOfLastWord(String s) { int length =0; for (int i=s.length()-1;i>=0;i--){ if (s.charAt(i) == ' ' && length != 0) { break; }else if (s.charAt(i) != ' '){ length ++; } } return length; } } 耗时：0ms 删除排序链表中的重复元素 https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list/ 给定一个排序链表，删除所有重复的元素，使得每个元素只出现一次 解法 遍历链表，如果发现当前节点等于后继节点，则将当前节点的后继修改为后继节点的后继 当当前节点或者后继节点为null，停止遍历 class Solution { public ListNode deleteDuplicates(ListNode head) { ListNode origin = head; while(head != null && head.next != null) { if (head.val == head.next.val) { head.next = head.next.next; continue; } head = head.next; } return origin; } } 耗时：0ms 相同的树 给定两个二叉树，编写一个函数来检验它们是否相同 https://leetcode-cn.com/problems/same-tree/ 解法 对两棵树做前序遍历，结果存到两个list，比较两个lsit即可 需要注意的是，需要特别处理左树为空，但右树不为空的情况 class Solution { public boolean isSameTree(TreeNode p, TreeNode q) { ArrayList list1 = new ArrayList<>(); ArrayList list2 = new ArrayList<>(); preWalk(p,list1); preWalk(q,list2); return list1.equals(list2); } public void preWalk(TreeNode p, List list){ if (p == null){ return ; } list.add(p.val); if (p.left == null && p.right != null) { list.add(null); } preWalk(p.left,list); preWalk(p.right,list); } } 耗时:0ms 二叉树的最大深度 给定一个二叉树，找出其最大深度。 https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/ 解法 同上题，传入根节点，如果根节点为空，返回0 否则i++ 接下来递归获取左右子树的深度，获取最大深度，累加到i即可 class Solution { public int maxDepth(TreeNode root) { return getDepth(root,0); } public int getDepth(TreeNode root,int i) { if (root == null) { return 0; } i++; int left = getDepth(root.left,0); int right = getDepth(root.right,0); if (left > right) { return i + left; }else { return i + right; } } } 耗时：0ms 求1+2+…+n 求 1+2+...+n ，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。 https://leetcode-cn.com/problems/qiu-12n-lcof/ 解法 等差数列求和公式 return (n+1)*n/2; 验证回文串 给定一个字符串，验证它是否是回文串，只考虑字母和数字字符，可以忽略字母的大小写 https://leetcode-cn.com/problems/valid-palindrome/ 解法 类似于前面的验证回文数字，分别正序与逆序将字符串入栈，比较两个栈 class Solution { public boolean isPalindrome(String s) { s = s.toLowerCase(); LinkedList stack1 = new LinkedList<>(); LinkedList stack2 = new LinkedList<>(); for (int i=s.length()-1;i>=0;i--){ char c =s.charAt(i); if ((c >=48 && c =97 && c 环形链表 给定一个链表，判断链表中是否有环。 https://leetcode-cn.com/problems/linked-list-cycle/ 解法 使用map存储遍历过的node 对List进行遍历，发现存在过的node即存在环 public class Solution { public boolean hasCycle(ListNode head) { Map map = new HashMap(); while(head != null){ if (map.containsKey(head)){ return true; } map.put(head,true); head = head.next; } return false; } } 耗时：5ms 二叉树的层次遍历 给定一个二叉树，返回其节点值自底向上的层次遍历。 （即按从叶子节点所在层到根节点所在的层，逐层从左向右遍历） https://leetcode-cn.com/problems/binary-tree-level-order-traversal-ii/ 解法 对树做前序遍历，将结果写到list里，再对list进行reverse class Solution { public List> levelOrderBottom(TreeNode root) { ArrayList> list = new ArrayList<>(); walk(root,list,0); Collections.reverse(list); return list; } public void walk(TreeNode root,ArrayList> list,int p) { if (root == null) { return; } if (list.size()()); } list.get(p).add(root.val); walk(root.left,list,p+1); walk(root.right,list,p+1); } } 耗时：1ms 一维数组的动态和 输入：nums = [1,2,3,4] 输出：[1,3,6,10] 解释：动态和计算过程为 [1, 1+2, 1+2+3, 1+2+3+4] 。 https://leetcode-cn.com/problems/running-sum-of-1d-array/ 解法 求出nums的和，设置ret的最后一个元素为sum 遍历ret数组倒数第二个至第一个，ret元素内容为后一个下标元素-nums对应的数 class Solution { public int[] runningSum(int[] nums) { if (nums.length == 0) { return new int[]{}; } int[] ret = new int[nums.length]; int sum = 0; for (int i:nums){ sum+=i; } ret[ret.length-1]=sum; for(int i=nums.length-2;i>=0;i--){ ret[i] = ret[i+1]-nums[i+1]; } return ret; } } 斐波那契数 给定 N，计算 F(N)。 https://leetcode-cn.com/problems/fibonacci-number/submissions/ 解法1 递归 class Solution { public int fib(int N) { if (N == 0 || N == 1) { return N; } return fib(N-1) + fib(N-2); } } 耗时:9ms 解法2 使用缓存避免重复的计算 class Solution { private int[] cache = new int[100]; public int fib(int N) { return fib0(N); } private int fib0(int N){ if (N == 0 || N == 1) { return N; } if (cache[N] == 0){ cache[N] = fib1(N); } return cache[N]; } private int fib1(int N){ if (N == 0 || N == 1) { return N; } return fib0(N-1) + fib0(N-2); } } 耗时:0ms 反转字符串 https://leetcode-cn.com/problems/reverse-string/ 使用前后双指针 两个指针往中间靠 交换元素 class Solution { public void reverseString(char[] s) { if (s.length 只出现一次的数字 https://leetcode-cn.com/problems/single-number/ 使用异或去除相同数字 class Solution { public int singleNumber(int[] nums) { int base = nums[0]; for(int i=1;i 耗时:1ms 完全平方数 https://leetcode-cn.com/problems/valid-perfect-square/submissions/ 从1扫描到num/2+1 每次递增1 class Solution { public boolean isPerfectSquare(int num) { int N = num/2+1; for (int i=1;i 耗时:1449ms 两数之和 https://leetcode-cn.com/problems/sum-of-two-integers/submissions/ class Solution { public int getSum(int a, int b) { if (b >0){ while(b>0){ a++; b--; } }else if (b 耗时:946 猜数字大小 https://leetcode-cn.com/problems/guess-number-higher-or-lower/submissions/ public class Solution extends GuessGame { public int guessNumber(int n) { int low = 1; int high = n; while(low 多数元素 https://leetcode-cn.com/problems/majority-element/submissions/ class Solution { public int majorityElement(int[] nums) { int n = nums.length/2; Map map = new HashMap<>(); for(int i :nums){ if (map.containsKey(i)){ map.put(i,map.get(i)+1); }else{ map.put(i,1); } } for(int i:map.keySet()){ if (map.get(i)>n){ return i; } } return -1; } } 耗时：16ms 路径总和 https://leetcode-cn.com/problems/path-sum/submissions/ class Solution { public boolean hasPathSum(TreeNode root, int sum) { if (root == null){ return false; } if (root.left == null && root.right == null){ return root.val == sum; }else if(root.left == null){ return hasPathSum(root.right,sum-root.val); }else if(root.right == null){ return hasPathSum(root.left,sum-root.val); }else { return hasPathSum(root.right,sum-root.val) || hasPathSum(root.left,sum-root.val); } } } 耗时:0 魔术索引 https://leetcode-cn.com/problems/magic-index-lcci/submissions/ class Solution { public int findMagicIndex(int[] nums) { for(int i=0;i 耗时:1 左叶子之和 https://leetcode-cn.com/problems/sum-of-left-leaves/submissions/ class Solution { public int sumOfLeftLeaves(TreeNode root) { return sum(root,false); } public int sum(TreeNode root,boolean isLeft){ if (root == null){ return 0; } if (root.left == null && root.right == null){ if (isLeft){ return root.val; }else { return 0; } } return sum(root.left,true)+sum(root.right,false); } } 耗时:0 汉明距离 https://leetcode-cn.com/problems/hamming-distance/submissions/ class Solution { public int hammingDistance(int x, int y) { // 异或：相同为0 不同为1 int z = x^y; int ret = 0; // 计算二进制有多少1 while(z!=0){ int t = z%2; z/=2; if (t == 1){ ret++; } } return ret; } } 耗时：0 从尾到头打印链表 https://leetcode-cn.com/problems/cong-wei-dao-tou-da-yin-lian-biao-lcof class Solution { public int[] reversePrint(ListNode head) { List list = new ArrayList<>(); walk(head,list); int [] ret = new int[list.size()]; for (int i=0;i list){ if (head == null){ return; } walk(head.next,list); list.add(head.val); } } 耗时：1 Excel 表列序号 https://leetcode-cn.com/problems/excel-sheet-column-number/submissions/ class Solution { public int titleToNumber(String s) { int ret = 0; int N = s.length(); for(int i=0;i 耗时：2 二叉树的最小深度 https://leetcode-cn.com/problems/minimum-depth-of-binary-tree/submissions/ class Solution { public int minDepth(TreeNode root) { if (root == null) return 0; if (root.left == null && root.right == null) return 1; int l = minDepth(root.left)+1; int r = minDepth(root.right)+1; if (root.left == null || root.right == null){ return Math.max(l,r); }else{ return Math.min(l,r); } } } 耗时：0 移动零 https://leetcode-cn.com/problems/move-zeroes/submissions/ class Solution { public void moveZeroes(int[] nums) { int numOf0 = 0; int passOf0 =0; for(int i=0;i=nums.length-numOf0;i--){ nums[i]=0; } } } 耗时：0 剑指 Offer 22. 链表中倒数第k个节点 https://leetcode-cn.com/problems/lian-biao-zhong-dao-shu-di-kge-jie-dian-lcof/ 递归到尾不断对计数器+1 判断计数器等于目标值 就返回当前遍历节点 class Solution { private ListNode ret; public ListNode getKthFromEnd(ListNode head, int k) { getKthFromEnd0(head,k,new int[]{0}); return ret; } private void getKthFromEnd0(ListNode head, int k,int[] arr) { if (head == null){ return; } getKthFromEnd0(head.next,k,arr); arr[0]=arr[0]+1; if (arr[0] == k){ ret = head; } } } 耗时：0 LCP 06. 拿硬币 https://leetcode-cn.com/problems/na-ying-bi/ class Solution { public int minCount(int[] coins) { int count = 0; for (int i:coins){ count+=i/2; if (i % 2!= 0){ count+=1; } } return count; } } 耗时:0 剑指 Offer 50. 第一个只出现一次的字符 https://leetcode-cn.com/problems/di-yi-ge-zhi-chu-xian-yi-ci-de-zi-fu-lcof/ class Solution { public char firstUniqChar(String s) { int[] map = new int[128]; for(char c : s.toCharArray()){ map[c] = map[c] + 1; } for(int i=0;i 耗时：6 1486. 数组异或操作 https://leetcode-cn.com/problems/xor-operation-in-an-array/ class Solution { public int xorOperation(int n, int start) { int ret=start; for(int i=1;i 耗时：0 剑指 Offer 58 - II. 左旋转字符串 https://leetcode-cn.com/problems/zuo-xuan-zhuan-zi-fu-chuan-lcof/submissions/ class Solution { public String reverseLeftWords(String s, int n) { StringBuffer sb = new StringBuffer(); for(int i = n;i 耗时：5 剑指 Offer 53 - II. 0～n-1中缺失的数字 https://leetcode-cn.com/problems/que-shi-de-shu-zi-lcof/submissions/ class Solution { public int missingNumber(int[] nums) { int ret = nums[nums.length-1]; for(int i=0;i 耗时：0 剑指 Offer 05. 替换空格 https://leetcode-cn.com/problems/ti-huan-kong-ge-lcof/ class Solution { public String replaceSpace(String s) { StringBuffer sb = new StringBuffer(); for(int i=0;i 耗时：0 剑指 Offer 03. 数组中重复的数字 https://leetcode-cn.com/problems/shu-zu-zhong-zhong-fu-de-shu-zi-lcof/ class Solution { public int findRepeatNumber(int[] nums) { int[] map = new int[nums.length]; for(int i:nums){ map[i] = map[i] + 1; } for(int i=0;i1){ return i; } } return -1; } } 耗时：1 剑指 Offer 17. 打印从1到最大的n位数 https://leetcode-cn.com/problems/da-yin-cong-1dao-zui-da-de-nwei-shu-lcof/ class Solution { public int[] printNumbers(int n) { if (n == 0) return new int[]{}; int[] ret = new int[(int)Math.pow(10,n)-1]; for(int i=0;i 耗时：1 有效的字母异位词 https://leetcode-cn.com/problems/valid-anagram/ class Solution { public boolean isAnagram(String s, String t) { int[] map1 = new int[128]; int[] map2 = new int[128]; for(int i=0;i 耗时：4 二叉树的中序遍历 https://leetcode-cn.com/problems/binary-tree-inorder-traversal/ class Solution { public List inorderTraversal(TreeNode root) { List list = new ArrayList<>(); walk(root, list); return list; } private void walk(TreeNode root, List list){ if (root == null) return; walk(root.left, list); list.add(root.val); walk(root.right, list); } } 耗时：0 反转链表 https://leetcode-cn.com/problems/reverse-linked-list/ class Solution { public ListNode reverseList(ListNode head) { if (head == null) return null; LinkedList stack = new LinkedList<>(); while(head != null){ stack.push(head.val); head = head.next; } ListNode root = new ListNode(); ListNode origin = root; while(!stack.isEmpty()){ root.val = stack.pop(); if (!stack.isEmpty()){ root.next = new ListNode(); root = root.next; } } return origin; } } 耗时：0 226. 翻转二叉树 https://leetcode-cn.com/problems/invert-binary-tree/ class Solution { public TreeNode invertTree(TreeNode root) { invertTree0(root); return root; } private void invertTree0(TreeNode root){ if (root == null) return; TreeNode t = root.left; root.left = root.right; root.right = t; if (root.left !=null) invertTree0(root.left); if (root.right !=null) invertTree0(root.right); } } 耗时：０ 389. 找不同 https://leetcode-cn.com/problems/find-the-difference/ class Solution { public char findTheDifference(String s, String t) { int[] map = new int[128]; for(int i =0;i 耗时：4 412. Fizz Buzz https://leetcode-cn.com/problems/fizz-buzz/ class Solution { public List fizzBuzz(int n) { List list = new ArrayList<>(); for(int i=1;i 耗时：6 173. 二叉搜索树迭代器 https://leetcode-cn.com/problems/binary-search-tree-iterator/ class BSTIterator { private LinkedList list = new LinkedList<>(); public BSTIterator(TreeNode root) { midVisist(root); } private void midVisist(TreeNode root){ if (root == null) return; midVisist(root.left); list.add(root.val); midVisist(root.right); } /** @return the next smallest number */ public int next() { return list.removeFirst(); } /** @return whether we have a next smallest number */ public boolean hasNext() { return !list.isEmpty(); } } 耗时：24 290. 单词规律 https://leetcode-cn.com/problems/word-pattern/ class Solution { public boolean wordPattern(String pattern, String s) { Map map1 = new HashMap<>(); Map map2 = new HashMap<>(); String[] strs = s.split(\" \"); if (strs.length != pattern.length()) return false; for(int i = 0;i 耗时：1 709. 转换成小写字母 https://leetcode-cn.com/problems/to-lower-case/ class Solution { public String toLowerCase(String str) { StringBuffer sb = new StringBuffer(); for(int i =0;i= 65 && c 耗时：0 66. 加一 https://leetcode-cn.com/problems/plus-one/ class Solution { public int[] plusOne(int[] digits) { int[] ret = new int[digits.length+1]; for(int i=0;i=0;i--){ if (ret[i] == 10) { ret[i] = 0; f = true; continue; } if (f) { if (ret[i] == 9) { ret[i] = 0; f = true; }else { ret[i]++; f= false; } } } if (ret[0] == 0) { int[] trimArr = new int[ret.length-1]; System.arraycopy(ret,1,trimArr,0,trimArr.length); return trimArr; } return ret; } } 耗时：0 110. 平衡二叉树 https://leetcode-cn.com/problems/balanced-binary-tree/ class Solution { public boolean isBalanced(TreeNode root) { if (root == null) return true; if (root.left == null && root.right == null) return true; if (Math.abs(treeHeight(root.left, 0) - treeHeight(root.right, 0)) > 1) return false; return isBalanced(root.left) && isBalanced(root.right); } private int treeHeight(TreeNode root, int i){ if (root == null) return i; i++; int l = treeHeight(root.left, i); int r = treeHeight(root.right, i); return l > r ? l : r; } } 耗时：1 349. 两个数组的交集 https://leetcode-cn.com/problems/intersection-of-two-arrays/ class Solution { public int[] intersection(int[] nums1, int[] nums2) { HashSet s1 = new HashSet<>(); HashSet s2 = new HashSet<>(); for(int i : nums1) { s1.add(i); } for(int i : nums2) { s2.add(i); } if (s1.size() it = s1.iterator(); while(it.hasNext()){ var e = it.next(); if (!s2.contains(e)) it.remove(); } int[] ret = new int[s1.size()]; int count = 0; for(int i :s1){ ret[count] = i; count++; } return ret; } } 耗时：3 557. 反转字符串中的单词 III https://leetcode-cn.com/problems/reverse-words-in-a-string-iii/ class Solution { public String reverseWords(String s) { if (s.length() == 0) return \"\"; StringBuffer sb = new StringBuffer(); for(int i =s.length()-1;i>=0;i--){ sb.append(s.charAt(i)); } String[] strs = sb.toString().split(\" \"); sb = new StringBuffer(); for(int i = strs.length-1;i>=0;i--){ sb.append(strs[i]); if (i != 0) sb.append(\" \"); } return sb.toString(); } } 耗时：10 145. 二叉树的后序遍历 https://leetcode-cn.com/problems/binary-tree-postorder-traversal/ class Solution { public List postorderTraversal(TreeNode root) { List list = new ArrayList<>(); postOrder(root, list); return list; } private void postOrder(TreeNode root, List list){ if (root == null) return; postOrder(root.left, list); postOrder(root.right, list); list.add(root.val); } } 耗时：0 230. 二叉搜索树中第K小的元素 https://leetcode-cn.com/problems/kth-smallest-element-in-a-bst/ class Solution { public int kthSmallest(TreeNode root, int k) { return getKMin(root,k,new int[]{0}); } public int getKMin(TreeNode root,int k,int[] i){ if (root == null) return -1; int l = getKMin(root.left, k,i); i[0]++; if (i[0] == k) { return root.val; } int r = getKMin(root.right, k,i); if (l != -1) { return l; } if (r != -1) { return r; } return -1; } } 耗时：0 811. 子域名访问计数 https://leetcode-cn.com/problems/subdomain-visit-count/ class Solution { public List subdomainVisits(String[] cpdomains) { Map map = new HashMap<>(256); for (String s : cpdomains){ String[] a = s.split(\" \"); int count = Integer.valueOf(a[0]); String domain = a[1]; for(int i=domain.length()-1;i>=0;i--){ char c = domain.charAt(i); if (c == '.') { String subDomain = domain.substring(i+1,domain.length()); Integer oldCount = map.get(subDomain); if (oldCount == null){ map.put(subDomain, count); }else { map.put(subDomain, oldCount + count); } } if (i == 0){ Integer oldCount = map.get(domain); if (oldCount == null){ map.put(domain, count); }else { map.put(domain, oldCount + count); } } } } List ret = new ArrayList<>(); for (String s: map.keySet()){ ret.add(map.get(s) + \" \" + s); } return ret; } } 耗时：21 876. 链表的中间结点 https://leetcode-cn.com/problems/middle-of-the-linked-list/ class Solution { public ListNode middleNode(ListNode head) { ListNode[] map = new ListNode[101]; int i = 1; while(head != null){ map[i]=head; i++; head = head.next; } if (i % 2 !=0) return map[i/2+1]; else return map[i/2]; } } 耗时：0 118. 杨辉三角 https://leetcode-cn.com/problems/pascals-triangle/ class Solution { public List> generate(int numRows) { List> list = new ArrayList<>(); for(int i=0;i seq = new ArrayList<>(); for(int j = 0;j 耗时：1 231. 2的幂 https://leetcode-cn.com/problems/power-of-two/ class Solution { public boolean isPowerOfTwo(int n) { int k = 1; while (true){ if (n == k) return true; if (k > n) return false; if (k 耗时：1 844. 比较含退格的字符串 https://leetcode-cn.com/problems/backspace-string-compare/ class Solution { public boolean backspaceCompare(String S, String T) { LinkedList s1 = new LinkedList<>(); LinkedList s2 = new LinkedList<>(); for(int i = 0;i 耗时：2 222. 完全二叉树的节点个数 https://leetcode-cn.com/problems/count-complete-tree-nodes/ class Solution { public int countNodes(TreeNode root) { if (root == null) return 0; if (root.left == null && root.right == null) return 1; int l = countNodes(root.left); int r = countNodes(root.right); return l + r + 1; } } 耗时：0 747. 至少是其他数字两倍的最大数 https://leetcode-cn.com/problems/largest-number-at-least-twice-of-others/ class Solution { public int dominantIndex(int[] nums) { int maxIndex = 0; for(int i = 0;i nums[maxIndex]) maxIndex = i; } for(int i = 0;i nums[maxIndex] && i != maxIndex) return -1; } return maxIndex; } } 耗时：0 234. 回文链表 https://leetcode-cn.com/problems/palindrome-linked-list/ class Solution { private ListNode origin; public boolean isPalindrome(ListNode head) { origin = head; return travel(head); } private boolean travel(ListNode head){ if (head == null) return true; if (!travel(head.next)){ return false; } if (head.val == origin.val){ origin = origin.next; return true; }else { return false; } } } 耗时：2 938. 二叉搜索树的范围和 https://leetcode-cn.com/problems/range-sum-of-bst/ class Solution { public int rangeSumBST(TreeNode root, int L, int R) { int[] sum = new int[]{0}; midTravel(root,sum,L,R); return sum[0]; } private void midTravel(TreeNode root,int[] sum,int l,int r){ if (root == null) return; midTravel(root.left, sum,l,r); if (root.val >=l && root.val 耗时：1 929. 独特的电子邮件地址 https://leetcode-cn.com/problems/unique-email-addresses/ class Solution { public int numUniqueEmails(String[] emails) { List list = new ArrayList<>(); for(String s: emails){ String[] a = s.split(\"@\"); String name = a[0]; String domain = a[1]; StringBuilder sb = new StringBuilder(); for(int i = 0;i 耗时：12 744. 寻找比目标字母大的最小字母 https://leetcode-cn.com/problems/find-smallest-letter-greater-than-target/ class Solution { public char nextGreatestLetter(char[] letters, char target) { for(int i = 0;i target) return letters[i]; } return letters[0]; } } 耗时：0 144. 二叉树的前序遍历 https://leetcode-cn.com/problems/binary-tree-preorder-traversal/ class Solution { public List preorderTraversal(TreeNode root) { List list = new ArrayList<>(); preTravel(root,list); return list; } private void preTravel(TreeNode root, List list){ if (root == null) return; list.add(root.val); preTravel(root.left, list); preTravel(root.right, list); } } 耗时：0 191. 位1的个数 https://leetcode-cn.com/problems/number-of-1-bits/ int hammingWeight(uint32_t n) { int count = 0; while(n != 0){ if (n % 2 != 0) count++; n >>= 1; } return count; } 耗时：4 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-08 08:53:12 "},"算法与数据结构/基本数据结构.html":{"url":"算法与数据结构/基本数据结构.html","title":"基本数据结构","keywords":"","body":"基本数据结构 数据结构的使用要根据场景及数据量来决定 线性结构 线性表 n个数据元素的有限序列。可以看做数组 链表 循环链表 双向链表 栈 LIFO 结构 使用数组实现 使用链表实现 队列 先进先出（FIFO）的线性表，只允许在表的一段进行插入，另一端删除 循环队列 链表实现 树结构 有层次的非线性结构 图结构 哈希结构 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-21 02:21:55 "},"算法与数据结构/算法策略.html":{"url":"算法与数据结构/算法策略.html","title":"算法策略","keywords":"","body":"算法策略 贪心算法 一个贪心算法总是做出当前最好的选择，也就是说，它期望通过局部最优选择从而得到全局最优的解决方案。 做出选择 不可反悔 可能得不到最优解 贪心策略决定算法好坏 确定贪心策略 选择当前看上去最好的方案 一步一步得到局部最优解 将所有局部最优解合并称为一个原来问题的最优解 冒泡排序就使用了贪心算法 原则 贪心原则 所谓贪心选择性质是指原问题的整体最优解可以通过一系列局部最优的选择得到 最优子结构 当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构性质 背包问题 选择一个最好的贪心策略 物品可分割称为背包问题 物品不可分割称为0-1背包问题 会议安排问题 最短路径问题 哈夫曼编码 最小生成树 分治法 其本质就是将一个大规模的问题分解为若干个规模较小的相同子问题，分而治之 递归 分支算法要素 原问题可以分解为若干个规模较小的相同子问题 子问题相互独立 子问题解可以合并为原问题的解 二分查找 归并排序 快速排序 大整数乘法 动态规划 基础 动态规划的思想类似于分治法 不过动态规划是从最小子问题求起 将小问题的解存储起来 求解大问题时 如果需要用到小问题的解 直接使用即可 无需再重复计算 要素 最优子结构 问题的最优解包含其子问题的最优解 子问题重叠 不是必要条件 但是是动态规划的优势 兔子序列 最长公共子串 回溯法 回溯法是一种选优搜索法，按照选优条件深度优先搜索，以达到目标。当搜索到某一步时，发现原先选择并不是最优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术称为回溯法，而满足回溯条件的某个状态称为“回溯点”。 要素 解空间 由所有可能解组成的空间 将这些解按一定结构组织起来：解空间树 隐约束 不满足隐元素的分支无需搜索 直接剪掉 也称为剪枝函数 0-1背包 最大图 地图着色 n皇后 分支限界法 广度优先 回溯法找出所有解 分支限界法找出一个接 回溯法深度优先 分支限界法广度优先 回溯法搜索一次生成一个孩子节点 分支限界法一次生成所有节点 线性规划网络流 解决 确定决策变量 哪些变量对模板有影响 确定目标函数 含有决策变量的线性函数 找出约束条件 将对决策变量的约束表示为方程或者不等式 求最优解 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-04 08:01:17 "},"算法与数据结构/排序.html":{"url":"算法与数据结构/排序.html","title":"排序","keywords":"","body":"排序 为什么要学习O(N^2)的排序算法 是其他算法的基础 编码简单 作为子过程，用于改进复杂的排序算法 排序算法的稳定性 对于相等的元素，在排序后，相对位置没有发生改变 选择排序 每一轮循环找到数组中最小的元素，第一次找到的最小元素将它与第一个元素交换位置，第二次找到的最小元素交换将它与第二个位置交换，以此类推 for (int i = 0; i 插入排序 插入排序是从后往前扫描的 第一次从后到前逐个扫描下标1-0的元素，如果发现后面一个比前面小，则两个交换位置，否则就开始下一次扫描 第二次从后到前逐个扫描下标2-0的元素，如果发现后面一个比前面小，则两个交换位置 ，否则就开始下一次扫描 依此类推 插入排序对近乎有序的数组性能很强 for (int i = 1; i 0; j--) { if (less(a[j], a[j - 1])) { swap(a, j, j - 1); }else { break; } } } // 改进后的插入排序 for (int i = 1; i 0 && greater(a[j - 1], e); j--) { // 将 a[j]=a[j-1]; } a[j]=e; } 冒泡排序 第一次扫描下标为0的元素到最后一个元素 第二次扫描下标为0的元素到倒数第二个元素 每次扫描如果发现右边比左边小 则两个交换位置 以此类推 for (int i = 1; i 希尔排序 希尔排序是将插入排序中的交换相邻元素改为交换不相邻元素 选择一个增量序列t1，t2，…，tk 按增量序列个数k，对序列进行k 趟排序 int h = 1; // 计算增长序列，1,4，13,40... while (h =1){ for (int i = h; i h && less(a[j - h], e); j-=h) { a[j]=a[j-h]; } a[j]=e; } h/=3; } 归并排序 把长度为n的输入序列分成两个长度为n/2的子序列； 对这两个子序列分别采用归并排序； 将两个排序好的子序列合并成一个最终的排序序列 对两个有序子序列进行合并，得到一个更大的有序子序列，以此类推，直到只剩下一个序列 但是一个缺点是需要额外的O(N)空间 private void mergeSort(Comparable[] a, int l, int r) { if (l >= r) { return; } int mid = (l + r) / 2; mergeSort(a, l, mid); // 对左边排序 mergeSort(a, mid + 1, r); // 对右边排序 merge(a, l, mid, r); // 对两个数组进行归并 } private void merge(Comparable[] a, int l, int mid, int r) { // 开辟一块新空间给l-r之间的元素 Comparable[] aux = new Comparable[r - l + 1]; for (int i = l; i mid) { // 如果左指针已经跑过了mid，那此时让右指针去跑 a[k] = aux[j - l]; j++; } else if (j > r) { // 如果右指针已经跑完了，则此时让左指针去跑 a[k] = aux[i - l]; i++; } else if (less(a[i - l], a[j - l])) { // 否则就比较左右两指针谁的值比较小，谁小就把谁的值复制到结果里，然后该指针往后移动 a[k] = aux[i - l]; i++; } else { a[k] = aux[j - l]; j++; } } } 优化 当mid+1位置的元素大于mid位置的元素时，就没有必要进行归并了 if (greater(a[mid],a[mid+1])){ merge(a, l, mid, r); } 也可以当被归并排序的数组数量小于某一数量级时，使用其他排序算法，来提高性能 自底向上的归并排序 // 每次归并的数组大小依次为1 2 4 ... for (int sz = 1; sz 快速排序 选定一个元素，将比该元素小的元素放其左边，比它大的放在其右边，并递归地对它左右两边的子序列进行排序 快速排序在最差的情况下，会退化为O(N^2) private void quickSort(Comparable[] a, int l, int r) { if (l >= r) { return; } int p = partition(a, l, r); quickSort(a, l, p - 1); quickSort(a, p + 1, r); } /** * 返回一个p，使得a[l...p-1] a[p] */ private int partition(Comparable[] a, int l, int r) { var v = a[l]; int j = l; // 从左到右扫描（一） for (int i = l + 1; i 一 二 三 优化 当数组里有大量相同的元素，快速排序的时间复杂度为退化到N^2,解决方法是在两侧使用双指针向中间扫描 双路快速排序 private int partition(Comparable[] a, int l, int r) { var v = a[l]; // i:a[l+1...i] =v int i = l + 1, j = r; while (true) { while (i = l + 1 && greater(a[j], v)) j--; if (i > j) { break; } else { swap(a, i, j); i++;j--; } } swap(a,l,j); return j; } 三路快速排序 private void quickSort(Comparable[] a, int l, int r) { if (l >= r) { return; } // partition var v = a[l]; int lt = l; // a[l+1...lt] v int i = l + 1; // a[lt+1...i) == v while (i 0) { swap(a, i, gt - 1); gt--; }else { i++; } } swap(a,i,lt); quickSort(a, l, lt - 1); quickSort(a, gt, r); } 归并排序与快速排序的背后 两个算法都使用了分治算法 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-05 00:55:06 "},"算法与数据结构/堆.html":{"url":"算法与数据结构/堆.html","title":"堆","keywords":"","body":"堆 应用 优先级队列 堆的存储 二叉堆 是一棵完全二叉树（最大堆） 用数组存储二叉堆 操作 shift up 新加入的元素与其父元素判断，是否比父元素大，如果是，交换两个元素，以此类推，直到小于其父亲 while (less(data,i/2,i)) { swap(data,i/2,i); i/=2; } shift down 只能取出根节点的元素，取出后，使用堆中的最后一个元素填补空缺 填补后，跟左右两个孩子比较，哪个孩子大就跟谁交换...以此类推，直至自己比两个孩子都大 while (2 * k 堆排序 MaxHeap> heap = new MaxHeap<>(a.length+1); for (int i = 0; i Heapify（堆化【将数组转为堆】） 对于一棵完全二叉树，其最后一个非叶子节点是元素个数除二取整 所以要把一个数组堆化，只需要对其非叶子结点进行shift down for (int i = 0; i = 1; i--) { shiftDown(i); } 原地堆排序 int n = a.length; // 先将整个数组构造成一个最大堆 for (int i = (n - 2) / 2; i >= 0; i--) { shiftDown(a, n, i); } // 将堆中的第一大元素移到末尾，再次构造最大堆(排除末尾排好序的元素) // 然后下一次循环再将第一大元素移到倒数第二个...以此类推，直至只剩一个元素 for (int i = n - 1; i > 0; i--) { swap(a, 0, i); shiftDown(a, i, 0); } 索引堆 引入一个index数组，在增删改查的时候，提供一个index 索引堆根据这个index找到数据在data中的位置 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-09 04:10:30 "},"算法与数据结构/查找.html":{"url":"算法与数据结构/查找.html","title":"查找","keywords":"","body":"查找 顺序查找 按照顺序一个个比较，直到序列末尾 int seq_search(int array[], int n, int key) { int i; for(i = 0; i 二分查找 通过对一个有序数组中对元素依次比较，从而能实现对数级别时间复杂度的查找 根据左右指针计算出一个mid指针 如果mid指针处的元素等于目标值 则要查找的目标就是在这里 否则如果mid处的指针比目标值大 则右指针等于mid-1 否则左指针等于mid+1 然后重复上述操作 直到左指针大于右指针 int l = 0, r = a.length - 1; while (l 二叉查找树 高效 特点 每个结点的键值大于左孩子，小于右孩子 每个孩子又是二叉查找树 二分查找树不一定是完全二叉树 插入 if (root == null) { count++; return new Node(key, value); // 当前节点为null，则创建一个节点返回 } if (key.equals(root.key)) { //　当前节点等于要插入的节点，则直接覆盖 root.value = value; } else if (less(key, root.key)) { //　当前节点比要插入的大，则向当前节点的左子树插入 root.left = insert(root.left, key, value); } else if (greater(key, root.key)) { //　当前节点比要插入的小，则向当前节点的右子树插入 root.right = insert(root.right, key, value); } 查找 原理同插入，根据左子树比父节点小，右子树比父节点大的条件 if (root == null){ return null; } if (key.equals(root.key)){ return root.value; }else if(less(key,root.key)){ return search(root.left,key); }else { return search(root.right,key); } floor与ceil floor：是最接近key值且小于key的节点 ceil：是最接近key值且大于key的节点 遍历 前序遍历 先访问当前节点，再递归访问左右子树 if (root != null){ consumer.accept(root.key,root.value); preOrder(root.left,consumer); preOrder(root.right,consumer); } 中序遍历 先递归访问左子树，再访问自身，再递归访问右子树 if (root != null){ preOrder(root.left,consumer); consumer.accept(root.key,root.value); preOrder(root.right,consumer); } 后序遍历 先递归访问左右子树，在访问自身 if (root != null){ preOrder(root.left,consumer); preOrder(root.right,consumer); consumer.accept(root.key,root.value); } 广度优先遍历(层序) Queue queue = new LinkedList<>(); queue.add(root); while (!queue.isEmpty()) { var node = queue.remove(); consumer.accept(node.key,node.value); if (node.left != null){ queue.add(node.left); } if (node.right != null){ queue.add(node.right); } } 删除 分为三种情况 删除叶子节点 直接解除父节点对其的引用即可 删除只有一个子节点的 将父节点指向其子节点 private Node removeMax(Node node) { if (node.right == null) { // 代表当前节点就是最大节点，所以返回当前节点的左子树给父节点 count--; return node.left; } // 将删除的节点的左子树作为父节点的右子树 node.right = removeMax(node.right); return node; } 删除有两个子节点的 Hubbard Deletion 使用被删除节点右子树中的最小节点来代替被删除节点 局限性 同样的数据会对应不同的查找树 有可能退化成链表 2-3查找树 插入 2-3树之所以完美平衡，关键在于插入时的维护 节点分裂 插入示例 删除 红黑树 基本操作 旋转 反色 插入 新插入的节点均设为红色 情况１ 对ｂ逆时针旋转 情况2 反色 情况3 进行顺时针旋转,变成情况２ 删除 散列表 根据键（Key）而直接访问在内存存储位置的数据结构,也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度 散列函数 这个过程会讲键转化为数组的索引 把任意长度的输入（又叫做预映射pre-image）通过散列算法变换成固定长度的输出，该输出就是散列值 散列冲突 当不同的输入得到相同的hash值时，称为散列冲突 解决：拉链法 当发生碰撞的时候，拉链法是将碰撞的元素串成一个链表 解决：线性探测 当发生碰撞的时候，直接检查散列表中的下Ｎ个位置（Ｎ可正可负） 在查找的时候，如插入一样一直进行线性探测，直至碰到一个键为空的槽 删除 删除的时候，不能简单地将槽置为空，需要将与该键同散列值的键都往前移动，填补因为该键被删除而造成的空缺 调整大小 当数组大小发生改变，不能直接位置一对一迁移，而是需要对先前的每个元素，重新计算散列(rehash)，重新放入槽 java中的实现 JDK8后，HashMap当冲突列表超过８个之后，会使用红黑树 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-05 01:16:04 "},"算法与数据结构/树.html":{"url":"算法与数据结构/树.html","title":"树","keywords":"","body":"树 一个节点可以只有根节点 也可以是一棵树 ... 每个节点最多有两个子节点的树称为二叉树 平衡二叉树 树及其子树的左右高度差不能超过1 空树及只有根节点的树也是平衡二叉树 二叉查找树 擅长数据的查找 对于任何节点： 左子树上所有节点都小于它 右子树所有节点都大于它 查找树随着数据的不断增加或插入容易失衡 AVL树 在增加和删除节点时通过旋转来保持平衡 右旋：以某个节点为中心 将它沉入当前右子节点的位置 然后让当前左子节点作为新树的根 左旋： 红黑树 红黑树不追求左右子树高度差不超过1 而是保证从根节点到叶尾的最长路径不超过最短路径的2倍 其他约束条件： 节点只能是红色或者黑色 根节点必须是黑色 NIL(Nothing in leaf)节点都是黑色 相连的两个节点不能都是红色 根节点到叶子节点的所有路径黑色节点数量都相同 红黑树的任何旋转至多3次就能完成 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-22 04:17:20 "},"算法与数据结构/并查集.html":{"url":"算法与数据结构/并查集.html","title":"并查集","keywords":"","body":"并查集 并查集是一种树型的数据结构，用于处理一些不交集（Disjoint Sets）的合并及查询问题 连接问题 find find操作返回该节点连接的节点 int find(int p) { return data[p]; } 另外一种实现，通过判断两个节点是否拥有同样的祖先来判断是否相连 while (p != parent[p]) { p = parent[p]; } return p; isConnected 判断两个节点是否连接在一起的（判断这两个节点是否连接了同一个节点） boolean isConnected(int p, int q) { return find(p) == find(q); } union 连接两个节点（将一个节点指向另外一个节点） int pid = find(p); int qid = find(q); if (pid == qid){ return; } for (int i = 0; i 使用另外一种实现的union int qRoot = find(p); int pRoot = find(q); if (qRoot == pRoot){ return; } parent[pRoot]=qRoot; 基于size的优化，维护一个size数组，代表以i为根的集合的元素个数 if (sz[pRoot] 使用rank来决定谁连接谁 if (rank[pRoot] rank[qRoot])) { parent[qRoot] = pRoot; } else { parent[pRoot] = qRoot; rank[qRoot] += 1; } 路径压缩 find while (p != parent[p]) { parent[p]=parent[parent[p]]; p = parent[p]; } return p; MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-11 07:39:47 "},"算法与数据结构/图.html":{"url":"算法与数据结构/图.html","title":"图","keywords":"","body":"图 一些概念 一个图（一般记作{\\displaystyle G}G）由两类元素构成，分别称为顶点（或节点、结点）和边。每条边有两个顶点作为其端点，我们称这条边“连接”了它的两个端点 分类 有向图与无向图 有权图与无权图 表示方法 邻接矩阵 boolean[][] g; // n代表顶点的数量，v代表边的数量 int n, m; // 判断两个顶点是否存在边 boolean hasEdge(int v, int w) { return g[v][w]; } // 给两个顶点增加一条边 void addEdge(int v, int w) { if (hasEdge(v, w)) { return; } g[v][w] = true; if (!directed) { g[w][v] = true; } m++; } // 邻接表 List> g; void addEdge(int v, int w) { g.get(v).add(w); if (!directed && v != w) { g.get(w).add(v); } m++; } boolean hasEdge(int v, int w) { for (int i = 0; i 邻接表适合表示稀疏的图，邻接矩阵适合表示稠密的图 搜索 深度优先 从一个点开始 如果这个点没有被访问过 则选择该点的某个连接点进行深度优先搜索 直到所有能访问的顶点都被访问过 for (int i = 0; i 广度优先 从一个点开始 逐个遍历与该点连接的所有顶点 在遍历某节点时 将该节点的所有连接点入队 每次进行广度搜索的节点就从队列里面拿 两个算法的不同之处只在于获取下一个节点的方式不一样 广度优先下一个节点是最早加入的节点 深度优先下一个节点是最晚加入的节点 连通分量 无向图G的极大连通子图称为G的连通分量 有向图 表示 同样也是使用邻接表表示 可达性 DFS 与　BFS　同样适用于有向图 环 拓扑排序 将所有顶点排序，使得所有的有向边均从排在前面的元素指向后面的元素 强连通性 如果两个顶点互相可达，则称它们是强连通的 有权图 表示 邻接表 邻接表 一副连通加权无向图中一棵权值最小的生成树 最小生成树 贪心算法 找到最小生成树的一条边，不断重复，直到找到所有最小生成树的所有边 Prim算法 每次将一个与树节点连接但不在树中且权值最小的边加入树，直至边数达到节点数-1 kruskal算法 每次将权值最小的且不会构成环的边加入生成树，直至边数达到节点数-1 如何判断环 当边加入之后，使用union find判断从某一节点是否连接它自己，如果是，则就是有环 最短路径 找到从一个顶点到另一个顶点成本最小的路径 Dijkstra算法 前提：图中不能存在负权边 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-05 01:29:56 "},"算法与数据结构/字符串.html":{"url":"算法与数据结构/字符串.html","title":"字符串","keywords":"","body":"字符串 排序 低位优先排序 public static void sort(String[]a,int W) { int N = a.length; int R = 256; String[] aux = new String[N]; //循环W次键索引记数法 for(int d = W-1; d>=0;d--) { int[] count = new int[R+1]; //键索引记数法第一步--频率统计 for(int i=0;i 高位优先排序 public class MSD { private static int R = 256; //字符串中最多可能出现的字符的数量 private static final int M = 15; //当子字符串长度小于M时，用直接插入排序 private static String[] aux; //辅助数组 //实现自己的chatAt()方法 private static int charAt(String s, int d) { if(d 三向字符串快速排序 public class Quick3string { private static int charAt(String s, int d) { if(dv) exch(a,i,gt--); else i++; } sort(a,lo,lt-1,d); if(v>=0) sort(a,lt,gt,d+1); sort(a,gt+1,hi,d); } } 单词查找树 查找 插入 查询所有键　 通过递归的方式，如果有分叉，则生成一个由pre+branch的新字符串 public Interable keys() { return keysWithPrefix(\"\"); } public Interable keysWithPrefix(String pre) { Queue q = new Queue(); collect(get(root, pre, 0), pre, q); return q; } private void collect(Node x, String pre, Queue q) { if (x == null) return; if (x.val != null) q.enqueue(pre); for (char c = 0; c 删除 找到键所对应的结点并将它的值设为空（null）。如果该结点含有一个非空的链接指向某个子结点，那么就不需要在进行其他操作了。如果它的所有链接均为空，那就需要在数据结构中删去这个结点。如果删去它使得它的父结点的所有链接也均为空，就需要继续删除它的父结点，以此类推 public void delete(String key) { root = delete (root, key, 0); } private Node delete(Node x, String key, int d) { if (x == null) return null; if (d == key.length()) x.val = null; else { char c = key.charAt(d); x.next[c] = delete(x.next[c], key, d+1); } if (x.val != null) return x; for (char c = 0; c 三向单词查找树 在三向单词查找树（TST）中，每个结点都含有一个字符、三条链接和一个值。这三条链接分别对应着当前字母小于、等于和大于结点字母的所有键 查找 子字符串查找 暴力查找 public static int search(String pat, String txt) { int M = pat.length(); int N = txt.length(); // 逐个位置匹配模式字符串 for (int i = 0; i 暴力查找(显式回退) public static int searchother(String pat, String txt) { int M = pat.length(); int N = txt.length(); int i; int j; // 逐个位置匹配模式字符串 for (i = 0, j = 0; i KMP算法 根据模式构造一个DFA,使用DFA匹配 BM算法 RK指纹字符查找算法 正则表达式 连接 AB -> {AB} 或 Ａ|B -> {A,B} 闭包 Ｂ* -> 0个或多个Ｂ 构造正则表达式 数据压缩 游程编码 行程编码（Run Length Encoding，RLE), 又称游程编码、行程长度编码、变动长度编码 等，是一种统计编码。主要技术是检测重复的比特或字符序列，并用它们的出现次数取而代之 霍夫曼压缩 用较少的比特表示出现次数多的字符，用较多的比特表示出现频率低的字符 变长前缀 使用单词查找树实现 LZW压缩 LZW编码 (Encoding) 的核心思想其实比较简单，就是把出现过的字符串映射到记号上，这样就可能用较短的编码来表示长的字符串，实现压缩 LZW的一个核心思想，即压缩后的编码是自解释 (self-explaining) 的。什么意思？即字典是不会被写进压缩文件的，在解压缩的时候，一开始字典里除了默认的0->A和1->B之外并没有其它映射，2->AB是在解压缩的过程中一边加入的。这就要求压缩后的数据自己能告诉解码器，完整的字典，例如2->AB是如何生成的，在解码的过程中还原出编码时用的字典 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-06 13:20:51 "},"数据库系统/关系数据库/引言.html":{"url":"数据库系统/关系数据库/引言.html","title":"数据库系统","keywords":"","body":"引言 数据库 数据库是“按照数据结构来组织、存储和管理数据的仓库”。是一个长期存储在计算机内的、有组织的、有共享的、统一管理的数据集合 分类 关系型 非关系型 数据库系统的应用 企业信息、银行和金融、大学、航空业、电信业。 数据库的4个基本概念 数据：描述事物的符号记录 数据库 数据库管理系统 数据库系统数据系统的特点 数据结构化 数据共享性高、冗余度低且易于扩充 数据独立性高 数据由数据库管理系统统一管理和控制数据库系统的目标 文件处理系统的弊端 1.数据冗余和不一致 2.数据访问困难 3.数据孤立 4.完整性问题 5.原子性问题 6.并发访问异常 7.安全性问题 数据库的出现就是为解决这些问题数据视图 数据抽象 物理层->逻辑层->视图层实例和模式 实例：特定时刻存储在数据库中的信息集合 模式：数据库的整体设计 因此，数据库系统通常可以分为几种不同的模式： 物理模式：描述数据库在物理上的设计 逻辑模式：描述在逻辑层数据库的设计 用户模式：数据库用户的视图，是与某一用户有关的数据的逻辑表示 数据模型 定义：数据库结构的基础 关系模型：用表的集合来表示数据和数据间的联系 实体-联系模型：基于对现实世界这样的一种认识，现实世界由一组称为实体的基本对象间的联系构成 基于对象的数据模型：类似JAVA等OOP语言的面向对象特性 半结构化数据模型：如XML数据库语言 数据操纵语言（DML） 过程化DML 声明式DML数据定义语言（DDL） 定义：通过DDL来说明数据库所使用的存储结构和访问方式一致性约束 域约束：属性的约束 参照完整性 断言 授权关系数据库 表 数据库表是一系列二维数组的集合，用来代表和储存数据对象之间的关系数据操纵语言 特点：非过程化（告诉它做说明，而不必告诉它怎么做）SELECT * FROM user where age = 15 # 从user表取出age = 15 的用户所有列 数据定义语言 CREATE TABLE user(id INT,name VARCHAR(255)) # 创建一张user表，这种表有id、name两个字段 应用程序访问数据库 通过提供应用程序接口：如ODBC与JDBC 扩展宿主语言：提供一个预处理，将DML语言转换成宿主的语言调用数据库设计 设计过程 概念设计：进行建模，决定数据库应该要有哪些实体，实体要有哪些属性。比如使用ER模型进行设计。 逻辑设计：将概念设计得到的模型映射到数据所使用的模型上。 物理设计：包括文件组织的形式以及内部的存储结构。实体联系模型 即ER模型 实体 属性 联系 实体集 联系集映射基数 即1:N 1:1 M:N规范化 不好的设计 信息重复 缺乏表达某些信息的能力数据存储和查询 存储管理器 权限及完整性管理器 事务管理器 文件管理器 缓冲区管理器 数据文件 数据字典 索引查询处理器 DDL解释器 DML编译器 查询执行引擎事务管理 特性：A（原子性）C（一致性）I（隔离性）D（持久性）事务 定义：数据库应用中完成单一逻辑功能的操作集合数据库体系结构 两层体系结构：客户端直接与数据进行交互 三层体系结构：客户端通过一个服务端与数据进行交互数据挖掘与信息检索 数据挖掘定义：从数据库中发现知识特种数据库 面向对象数据库 半结构化数据库数据库系统的历史 1950s-1960s：磁带存储 1960s-1970s：硬盘 1980s：关系数据库取代网状数据库 1990s：互联网与数据库 2000s：数据分析与数据库 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-11-25 06:10:39 "},"数据库系统/leetcode.html":{"url":"数据库系统/leetcode.html","title":"leetcode","keywords":"","body":"leetcode 组合两个表 https://leetcode-cn.com/problems/combine-two-tables/ SELECT FirstName, LastName,Address.City,Address.State FROM Person LEFT JOIN Address ON Address.PersonId = Person.PersonId 大的国家 https://leetcode-cn.com/problems/big-countries/ SELECT name,population,area FROM World WHERE area >= 3000000 OR population >= 25000000 查找重复的电子邮箱 https://leetcode-cn.com/problems/duplicate-emails/ SELECT DISTINCT Email FROM Person AS t WHERE EXISTS( SELECT * FROM Person AS t1 WHERE t.Id <> t1.Id AND t.Email = t1.Email) 超过经理收入的员工 https://leetcode-cn.com/problems/employees-earning-more-than-their-managers/ SELECT Name AS Employee FROM Employee t1 WHERE Salary > (SELECT Salary FROM Employee AS t2 WHERE t2.Id = t1.ManagerId) 从不订购的客户 https://leetcode-cn.com/problems/customers-who-never-order/ SELECT Name AS Customers FROM Customers WHERE Customers.Id NOT IN (SELECT CustomerId FROM Orders) 有趣的电影 https://leetcode-cn.com/problems/not-boring-movies/ SELECT * FROM cinema WHERE description <> 'boring' AND id %2 =1 ORDER BY rating DESC 超过5名学生的课 https://leetcode-cn.com/problems/classes-more-than-5-students/ -- 注意对学生姓名去重 SELECT class FROM courses GROUP BY class HAVING COUNT(DISTINCT student) >=5 交换性别 https://leetcode-cn.com/problems/swap-salary/submissions/ UPDATE salary SET sex = CASE sex WHEN 'f' THEN 'm' WHEN 'm' THEN 'f' END 上升的温度 https://leetcode-cn.com/problems/rising-temperature/submissions/ SELECT t2.Id FROM Weather AS t2, Weather AS t1 WHERE DATE_SUB(t2.RecordDate, INTERVAL 1 DAY) = t1.RecordDate AND t2.Temperature > t1.Temperature 部门工资最高的员工 https://leetcode-cn.com/problems/department-highest-salary/submissions/ SELECT Department.Name AS Department, t1.Name AS Employee, Salary FROM Employee AS t1 JOIN Department ON DepartmentId = Department.Id WHERE t1.Salary = ( SELECT Salary FROM Employee AS t2 WHERE t1.DepartmentId = t2.DepartmentId ORDER BY Salary DESC LIMIT 1 ) MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-23 09:06:48 "},"数据库系统/关系数据库/形式化关系查询语言.html":{"url":"数据库系统/关系数据库/形式化关系查询语言.html","title":"形式化关系查询语言","keywords":"","body":"形式化关系查询语言 关系代数 基本运算 选择 (σ)：对应SQL中的WHERE子句 投影 (π)：对应SQL中SELECT 中选择列（加上DISTINCT关键字），因为投影会去除重复结果 并运算：∪ 集合差运算：- 笛卡尔积运算： 表1： name age 小明 15 小红 16 表2： grade school 5 中心小学 6 中心小学 两张表的笛卡尔积是： name age grade school 小明 15 5 中心小学 小红 16 6 中心小学 小明 15 6 中心小学 小红 16 5 中心小学 更名运算 ρ表示更名： ρx(a1,a2,a3..)(E) 表示将表达式E命名为x，并且把各项属性值命名为a1，a2... 关系代数的形式化定义 关系代数中基本的表达式是： 数据库中的一个关系 一个常数关系 常数关系可以理解为（1，2，,3..）常数集合附加的关系代数运算 集合交运算：∩ 自然连接运算：⋈ 赋值运算：←（比如temp1 ← R X S） 外连接运算 左外连接：⟕，保留左边的值 右外连接：⟖，保留右边的值 全外连接：⟗扩展的关系代数运算 广义投影 聚集 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-06-09 15:18:10 "},"数据库系统/数据库设计/数据库设计和ER模型.html":{"url":"数据库系统/数据库设计/数据库设计和ER模型.html","title":"数据库设计和ER模型","keywords":"","body":"数据库设计和ER模型 设计过程概览 设计阶段 需求分析 概念设计 逻辑设计 物理设计 设计选择 在设计时，我们必须确保避免两个主要的缺陷： 冗余 不完整 实体 - 联系模型 实体集 实体：对象 实体集：实体构成的集合 实体通过一组属性来表示，每个属性都有一个值。 联系集 联系是指多个实体间的相互关联 联系集就是相同类型联系的集合 实体在联系中扮演的功能称为实体的角色 联系也可以具有描述性属性 属性 每个属性都有一个可取值的集合，称为该属性的域 属性类型的划分： 简单和复合 单值和多值 派生属性 约束 映射基数 一对一 一对多 多对一 多对多 参与约束 全部参与 部分参与 码 实体的码是一个足以分区每个实体的属性集 同样，码也可以用于唯一标识联系 从实体集中删除冗余属性 当决定好实体集后，必须挑选合适的属性 实体 - 联系 图（ER图） 基本结构 分割成两部分的矩形：实体集 菱形：联系集 未分割的矩形：联系集的属性 线段：实体集与联系集的连接 虚线：联系集到联系集的连接 双线：实体在联系集中的参与度 双菱形：连接到弱实体集的标志性联系集 带箭头的线：代表箭头所指的那方实体映射基数为1 不带箭头的线：代表箭头所指的那方实体映射基数为多 复杂的属性 比如 Address - city - street 角色 通过再菱形和矩形之间的连线上进行标注来表示角色 非二元的联系集 即一个联系连接了两个以上的实体 继承关系 弱实体集 没有足够的属性以形成主码的实体集称为弱实体集 有主码的实体集称为强实体集 转换为关系模式 具有简单属性的强实体集表示 比如实体集student，有三个属性：ID、name、credit 可以转换成如下关系模式： student(ID,name,credit) 具有复杂属性的强实体集的表示 比如student有一个属性address，又有子属性city，street， 那么可生成关系模式： student(ID,name,credit,city,street) 弱实体集的表示 设A为一个弱实体集，B为A所依赖的一个强实体集。 那么可以创建一个关系模式： B(a1,a2,a3,x)，其中a1，a2，a3为B的属性，x为B到A的外键约束 联系集的表示 设R为联系集，a1，a2...an为参与R的实体集构成的属性集合， b1，b2...bn为R的属性，则R的属性为： {a1,a2..an}∪{b1,b2,...bn} 如何选取主码： 对于多对多的二元联系：参与实体集的主码属性并集成为主码 对于一对一的联系集：任何一个实体的主码都可以选作为主码 对于多对一或者一对多：多的那一方的实体集可以选取作为主码 模式冗余 一般情况下，连接弱实体集与其所依赖的强实体集的联系集模式是冗余的。 模式的合并 在一对一的联系的情况下：联系集的关系模式可以跟参与联系的任何一个实体集的模式进行合并实体-联系设计问题 用实体集还是用属性 什么构成实体集，什么构成属性？这个问题要根据现实情况进行回答。 一个常见的错误是用一个实体集的主码作为另一个实体集的属性，而不是用联系 另一个错误是将相关实体集的主码属性作为联系集的属性用实体集还是用联系集 一个原则是：当描述发生在实体间的行为时采用联系集二元还是n元联系集 数据库中的联系通常都是二元的。 一些非二元的联系可以通过拆分分为二元联系，但是这样做，有时并不那么自然联系属性的布局 属性放到哪里，是实体集还是联系集？ 这也是要根据实际情况进行决定扩展的E-R特性 特化 自顶向下的，可以看做OOP当中父类转换成子类的这么样一个过程概化 同上，类似于OOP中的向上转型属性继承 高层实体集的属性可以被底层实体集继承概化上的约束 数据库设计者可以决定哪些实体能成为给定低层实体集的成员，条件可以如下： 条件定义 用户定义聚集 E-R模型的一个局限性在于它不能表达联系间的联系。 聚集是一种抽象，它把联系视为高层实体，这样就可以表达联系之间的联系了转换为关系模式 概化的表示 为高层实体集创建一个模式，为每个低层实体集创建一个模式 如果概化是不相交并且完全的，就是说不存在同时属于两个同级的低层实体集的实体聚集的表示 聚集的主码是定义该聚集的联系集的主码数据库建模的其他表示法 ER图的其他表示法 统一建模语言UML数据库设计的其他方面 数据约束和关系数据库设计 显示声明约束的优点： 自动保持数据的一致性 一些约束在数据库模式的设计中非常有用 当然也可以提高访问效率 缺点： 但是在数据更新时，执行约束会在性能上带来潜在的高代价使用需求：查询、性能 主要的两个度量方法： 吞吐量 响应时间授权需求 数据流、工作流 工作流表示一个流程中的数据和任务的组合 当用户在执行工作流中的任务时，工作流会与数据库系统进行交互，除了工作流操作的数据之外，数据库还可以存储工作流自身的数据数据库设计的其他问题 数据库设计要求设计者可以预先估计一个组织将来的需求，设计出的模式在需求发生变更时只要做最少的改动即可满足要求。 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-08 12:57:39 "},"数据库系统/数据库设计/关系数据库设计.html":{"url":"数据库系统/数据库设计/关系数据库设计.html","title":"关系数据库设计","keywords":"","body":"关系数据库设计 好的关系设计的特点 设计选择 更大的模式 比如department模式与student模式进行合并，得到两个模式的连接结果dept_stu 问题： 数据冗余 有些情况无法表示 更小的模式： 如何发现一个模式需要分解成n个更小的模式？ 函数依赖 定义这样的一条规则：如果存在模式（dept_name,budget）,则dept_name可以作为主码，那么这就叫函数依赖 记作：x → y 有损分解：分解过后无法表达一些重要的信息。 无损分解：上面取反 异常 不符合范式的关系 冗余数据 修改异常 删除异常 插入异常 原子域与第一范式 一个域是原子的，如果该域的元素被认为是不可分的单元，我们称一个关系模式R属于第一范式。 简单来说：所有关系模式数据库都符合第一范式 第二范式 每个非主属性完全函数依赖于键码 使用函数依赖进行分解 码和函数依赖 一个关系满足需求定义的现实世界约束，称为关系的合法实例 给定R的一个实例，我们说这个实例满足函数依赖x → y 的条件是：对于实例中的所有元组t1，t2 ，若t1[x] = t1[x] ，则t1[y] = t2[y] 如果R中的每个合法实例都满足函数依赖，则我们说该函数依赖在R上成立 我们以两种方式使用函数依赖： 判定关系的实例是否满足给定函数依赖集F 说明合法关系集上的约束 平凡函数依赖：如果y ⊆ x，则称x→y的函数依赖是平凡的 我们用F+表达F集合的闭包，也就是能够从给定F集合推导出来的函数依赖集合 BC范式 属于BC范式的条件是： 对于F+中所有形如a→b的函数依赖(a ⊆ R,b⊆R ),下面至少有一项成立： a → b是平凡的函数依赖（b ⊆ a） a是模式R的一个超码 分解不属于BCNF的一般规则： 设R为一个不属于BCNF的一个模式，则存在至少一个非平凡的函数依赖a→b，其中a不是R的超码，我们用两个模式取代R： （a ∪ b） （R - （b - a ）） 进行迭代直到得到一个BCNF模式集合 BCNF和保持依赖 由于设计使得函数依赖的强制实施在计算很困难，因此称这个设计不是保持依赖的 第三范式 属于第三范式的条件，下面至少一项成立： a → b是一个平凡的函数依赖 a 是R的一个超码 b - a的每个属性都包含于R的一个候选码中 函数依赖理论 函数依赖集的闭包 逻辑蕴含： A -> B,B-> h 那么 A -> H被逻辑蕴含 Amstrong 公理 自反律 增补律 传递律 合并律 分解律 伪传递律 属性集的闭包 如果 a → B，我们称属性B被a函数确定 正则覆盖 无损分解 R1,R2是R的分解，如果用R1,R2替代R没有信息损失，则该分解是无损分解 保持依赖 分解算法 BCNF分解 3NF分解 BCNF和3NF的比较 应用函数依赖进行数据库设计的目标： BCNF 无损 保持依赖 使用多值依赖的分解 多值依赖 函数依赖有时成为相等依赖 多值依赖成为元组产生依赖 设R为关系模式，让a ⊆ R 且 b ⊆ R 多值依赖 a -> -> b在R上成立的条件是： 4NF分解 更多的范式 数据库设计过程 ER模型和规范化 属性和联系的命名 为性能去规范化 时态数据建模 时态数据时具有关联时间段的数据 快照快照是指一个特定时间点上该数据的值 一些坑 没有唯一键约束 业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引 如果没有唯一索引，很容易会被插入重复数据 执行delete没带查询条件 执行删除操作时，要开启事务，同时要先查询核对影响的行数和数据准确性，再执行删除操作 ；执行删除操作后再次核实，如果情况不对立即回滚 表结构修改没有兼容老数据 比如增加了一个非null字段 时效性要求极高的场景查了备库 备库存放的数据可能不是最新的数据 悬停时间较长的事务被kill 表新增了供查询的字段，却没建索引，导致慢查询 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-08 12:49:03 "},"数据库系统/数据存储和查询/存储和文件结构.html":{"url":"数据库系统/数据存储和查询/存储和文件结构.html","title":"存储和文件结构","keywords":"","body":"物理存储介质 高速缓冲存储器 主存储器 快闪存储器 磁盘存储器 光学存储器 磁带存储器 磁盘和快闪存储器 磁盘的物理特性 磁道 扇区 读写头 磁盘臂 柱面 磁盘控制器 磁盘性能的度量 访问时间 平均寻道时间 旋转等待时间 平均旋转等待时间 数据传输率 平均故障时间 磁盘块访问的优化 缓冲 预读 调度 文件组织 碎片化 非易失性写缓冲区 日志磁盘 日志文件系统 快闪存储 RAID 通过冗余提高可靠性 通过并行提高性能 数据拆分 比特级拆分 块级拆分 RAID级别 RAID级别的选择 所需的额外存储代价 在IO方面的性能问题 磁盘故障时的性能 数据重建过程 硬件问题 软件RAID 硬件RAID 擦洗 热交换 第三级存储 光盘 磁带 文件组织 定长记录 变长记录 问题 如何描述一条记录，使得单个属性能够轻松读取 在块中如何存储变长记录，使得块中的记录可以轻松读取 文件中记录的组织 堆文件组织 顺序文件组织 散列文件组织 顺序文件组织 在插入和删除时维护记录的物理顺序会很难 重组 多表聚簇文件组织 在每一块中存储两个或者更多关系的相关记录 数据字典存储 数据字典是指对数据的数据项、数据结构、数据流、数据存储、处理逻辑等进行定义和描述，其目的是对数据流程图中的各个元素做出详细的说明，使用数据字典为简单的建模项目。简而言之，数据字典是描述数据的信息集合，是对系统中使用的所有数据元素的定义的集合 数据的数据 必须存储的信息类型 关系名 每个关系中的属性名 属性的域与长度 视图名与视图定义 完整性约束 数据库缓冲区 缓冲区管理器 缓冲区替换策略 LRU 被钉住的块 不允许写回磁盘 块强制写回 缓冲区替换策略 MRU LRU MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-15 07:49:59 "},"数据库系统/数据存储和查询/索引与散列.html":{"url":"数据库系统/数据存储和查询/索引与散列.html","title":"索引与散列","keywords":"","body":"基本概念 顺序索引:基于值得顺序排序 散列索引：基于将值平均分布到散列桶 评价维度 访问类型 访问时间 插入时间 删除时间 空间开销 搜索码：用于在文件中查找记录的属性或属性集 顺序索引 稠密索引 每个搜索码都有一个索引项 稀疏索引 只为某些搜索码建立索引 多级索引 索引的更新 插入数据更新 删除数据更新 辅助索引 多码上的索引 复合搜索码 B+树索引 B+树的结构 B+树的查询 B+树更新 插入 删除 不唯一的搜索码 两条或者多条记录在索引属性上拥有相同的值 解决方法： 创建包含原始搜索码和其他额外属性的符合搜索码 在B+树节点上使用列表来存储 B+树更新的复杂性 辅助索引和记录重定位 字符串上的索引 前缀压缩 B+树索引的批量加载 B树索引文件 多码访问 多码索引 搜索码（k1,k2k,k3...） 覆盖索引 存储附加属性 静态散列 散列函数 分布均匀 分布随机 桶溢出处理 桶不足 偏斜 散列索引 动态散列 散列函数可动态改变 数据结构 查询 更新 静态列表VS动态散列 动态散列：性能不随文件增长降低。空间开销小。并且增加了一个中间层，带来微小的性能损失。 顺序索引和散列的比较 位图索引 位的一个简单数组 位图操作的高效实现 位图与B+树 SQL中的索引定义 CREATE INDEX ON (属性列表) CREATE INDEX index_kkk ON user(username) # 在user表上创建username索引 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-16 09:18:13 "},"数据库系统/数据存储和查询/查询处理.html":{"url":"数据库系统/数据存储和查询/查询处理.html","title":"查询处理","keywords":"","body":"概述 语法分析与翻译 优化 执行 计算原语 查询执行计划 查询执行引擎 查询代价的度量 传送磁盘块数以及搜索磁盘次数 选择运算 使用文件扫描和索引的选择 线性搜索 使用索引的搜索算法 主索引，码属性等值比较 主索引，非码属性等值比较 辅助索引，等值比较 涉及比较的选择 主索引比较 辅助索引比较 复杂选择的实现 合取 析取 取反 利用一个索引的合取选择 使用组合索引的合取选择 通过标志符的交实现合取选择 通过标志符的并实现合取选择 排序 外部排序归并算法 连接运算 嵌套循环连接 块嵌套循环连接 索引嵌套循环连接 归并连接 散列连接 其他运算 去重 排序 散列 投影 集合运算 外连接 聚集 表达式计算 物化 流水线 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-18 08:57:00 "},"数据库系统/数据存储和查询/查询优化.html":{"url":"数据库系统/数据存储和查询/查询优化.html","title":"查询优化","keywords":"","body":"概述 关系表达式的转换 等价规则 连接的次序 等价表达式的枚举 表达式结果集统计大小的估计 目录信息 选择运算结果大小的估计 连接运算结果大小的估计 其他运算结果集大小的估计 不同取值个数的估计 执行计划选择 基于代价的连接顺序选择 等价规则的基于代价的优化器 启发式优化 嵌套子查询的优化 物化视图 视图维护 增量视图维护 查询优化和物化视图 物化视图和索引选择 高级话题 top-K优化 连接极小化 更新优化 多查询优化和共享室扫描 参数化查询优化 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-14 08:01:48 "},"数据库系统/ORM.html":{"url":"数据库系统/ORM.html","title":"ORM","keywords":"","body":" 对象关系映射（Object Relational Mapping，简称ORM）是通过使用描述对象和数据库之间映射的元数据，将面向对象语言程序中的对象自动持久化到关系数据库中 JDBC操作的繁琐 Hibernate 依赖 org.hibernate hibernate-core 6.0.0.Alpha2 配置 jdbc:mysql:///hibernate com.mysql.cj.jdbc.Driver root 123 update org.hibernate.dialect.MySQL57Dialect true 实体类 @Entity @Table(name = \"tb_book\") public class Book { @Id @Column(name = \"bid\") @GeneratedValue(strategy = GenerationType.TABLE) private Integer id; @Column(name = \"bname\") private String name; @Column(name = \"bauthor\") private String author; } 使用 Configuration cfg = new Configuration().configure(); SessionFactory sessionFactory = cfg.buildSessionFactory(); Session session = sessionFactory.openSession(); Transaction tx = session.beginTransaction(); Book book = new Book(); book.setName(\"cxk 篮球入门指南\"); book.setAuthor(\"cxk\"); session.save(book); tx.commit(); session.close(); sessionFactory.close(); 查询 Session session = sessionFactory.openSession(); Book book = new Book(); book.setId(2); session.get(Book.class, 2); 删除 Book book = new Book(); book.setId(2); session.delete(book); 运行原理 Mybatis 运行原理 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-02 14:42:56 "},"数据库系统/事务管理/事务.html":{"url":"数据库系统/事务管理/事务.html","title":"事务","keywords":"","body":"事务 构成单一逻辑工作单元的操作集合称为事务，可以通过commit提交一个事务，也可以使用rollback回滚 ACID 原子性(Atomicity)：不可分割的最小操作单位，要么同时成功，要么同时失败 一致性(Consistency)：事务操作前后，数据总量不变 隔离性(Isolation)：多个事务之间相互独立 持久性(Durability)：当事务提交或回滚后，数据会持久化的保存数据 只有满足一致性，事务执行结果才是正确的 事务串行执行，就能确保隔离性，此时只要满足原子性，就能满足一致性 在并发执行的情况下，要满足原子性和隔离性，才能满足一致性 满足持久性的原因是为应对系统崩溃的情况，本质上满足持久性最终的目的也是为了满足一致性 AID是因 C是果 实现原子性和持久性 原子性保证了事务的多个操作要么都生效要么都不生效，不会存在中间状态 但事实上磁盘写入总需要个过程，需要个额外的机制来保证出现下列情况后能进行恢复： 未提交事务，写入后崩溃 已提交事务，写入前崩溃 数据库通过修改数据前写入日志的情况来达到崩溃后能恢复的目的，称之为提交日志 同时为了实现事务功能 通过undo log来记录数据的修改的情况，以便随时回滚 实现隔离性 存储结构 稳定性存储器 事务原子性和持久性 补偿事务 活动的 部分提交的 失败的 终止的 提交的 事务隔离性 提高吞吐量和资源利用率 减少等待时间 并发控制 可串行化 事务隔离性和原子性 可恢复调度 无级联调度 事务隔离性级别 可串行化 强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题 可重复读 保证在同一个事务中多次读取同一数据的结果是一样的 已提交读 一个事务只能读取已经提交的事务所做的修改 未提交读 事务中的修改，即使没有提交，对其它事务也是可见的 隔离级别 脏读 不可重复读 幻读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × 无论是脏读 幻读 不可重复读，原因都是因为隔离性被破坏 实现上面各种隔离级别都是使用读锁 写锁 或者范围锁相互配合来实现的 MVCC是一种读取优化策略，它的“无锁”是特指读取时不需要加锁。MVCC的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以完全不加锁的目的 脏写 隔离性级别的实现 并发控制机制 锁 时间戳 多版本和快照隔离 并发一致性问题 并发环境下，事务的隔离性很难保证 解决并发一致性问题的方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现 丢失修改 两个事务修改同一个数据，后修改的事务覆盖之前事务的修改 脏读 一个事务修改了数据，随后回滚了，但是这个数据在回滚之前被另外一个事务读到了 不可重复读 一个事务读取数据后，这个数据被另外的事务修改了，先前的事务再读一次，发现两次读取的数据不一致 幻读 一个事务读取某个范围的数据，另外一个事务在这个范围上修改了数据，从而导致先前的事务两次读取数据不一致 不可重复读与幻读 不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。 事务的SQL语句表示 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-10 07:59:36 "},"数据库系统/事务管理/并发控制.html":{"url":"数据库系统/事务管理/并发控制.html","title":"并发控制","keywords":"","body":"并发控制 封锁 封锁粒度 锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高 封锁粒度越小，系统开销就越大 封锁类型 读写锁 共享锁：简写为S锁，可读不可写 排它锁：简写为X锁，可读可写 加了排它锁的数据，就只能允许加锁的事务进行读写 加了共享锁的数据，允许其他事务对其再加共享锁进行读，但不允许再加排它锁 意向锁 意向锁在读写锁的基础上，增加了IX（表的排它锁）与IS（表的共享锁） 当一个事务要对数据加S锁之前，就必须获得IS锁或者IX锁 当一个事务要对数据加X锁之前，必须获得IX锁 封锁协议 三级封锁协议 一级封锁协议 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁 二级封锁协议 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁 三级封锁协议 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁 两阶段封锁协议 加锁和解锁分为两个阶段进行 增长阶段：可以获得锁，不能释放锁 缩减阶段：可以释放锁，不能获得锁 MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定 封锁的实现 基于图的协议 死锁处理 死锁预防 对加锁请求进行排序 有可能导致死锁时，进行事务回滚 锁超时 死锁检测与恢复 等待图 恢复 选择牺牲者 回滚 饿死 多粒度 基于时间戳的协议 时间戳 时间戳排序协议 Thomas写规则 基于有效性检查的协议 多版本机制 多版本并发控制 MVCC（Multi-Version Concurrency Control） 利用了多版本的思想，写操作更新最新的版本快照，而读操作去读旧版本快照，没有互斥关系 undo日志 MVCC 的多版本指的是多个版本的快照，快照存储在 Undo 日志中 INSERT INTO t(id, x) VALUES(1, \"a\"); UPDATE t SET x=\"b\" WHERE id=1; UPDATE t SET x=\"c\" WHERE id=1; 上面的三条sql对应于三个事务 ReadView MVCC 维护了一个 ReadView 结构，主要包含了当前系统未提交的事务列表 多版本时间戳排序 多版本两阶封锁 快照隔离 插入操作、删除操作与谓词读 实践中的弱一致性级别 索引结构中的并发 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-08 12:35:26 "},"数据库系统/事务管理/恢复系统.html":{"url":"数据库系统/事务管理/恢复系统.html","title":"恢复系统","keywords":"","body":"故障分类 事务故障 逻辑错误 系统错误 系统崩溃 磁盘故障 存储器 稳定存储器的实现 成功完成 部分失败 完全失败 数据访问 恢复与原子性 日志记录 事务标识 数据项标识 旧值 新值 数据库修改 undo redo 并发控制和恢复 事务提交 使用日志重做和撤销事务 检查点 恢复算法 事务回滚 系统崩溃后恢复 重做阶段 撤销阶段 缓冲区管理 日志记录缓冲 数据库缓冲 操作系统在缓冲区管理中的作用 模糊检查点 非易失性存储器数据丢失的故障 归档存储 锁的提前释放和逻辑undo操作 逻辑操作 逻辑undo日志记录 有逻辑undo的事务回滚 逻辑undo中的并发问题 ARIES 远程备份系统 故障检测 控制权的移交 恢复时间 提交时间 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-20 11:37:13 "},"数据库系统/系统体系结构/数据库系统体系结构.html":{"url":"数据库系统/系统体系结构/数据库系统体系结构.html","title":"数据库系统体系结构","keywords":"","body":"集中式与客户-服务器体系结构 集中式系统 粗粒度并行 细粒度并行 CS系统 服务器系统体系结构 事务服务器系统 数据服务器系统 基于云的服务器 并行系统 吞吐量 响应时间 加速比和扩展比 互连网络 总线 网格 超立方体 并行数据库体系结构 共享内存 共享硬盘 无共享 层次 分布式系统 数据共享 自治性 可用性 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-20 11:37:13 "},"数据库系统/系统体系结构/并行数据库.html":{"url":"数据库系统/系统体系结构/并行数据库.html","title":"并行数据库","keywords":"","body":"IO 并行 划分技术 轮转法 散列划分 范围划分 偏斜处理 查询间并行 不同查询或事物彼此并行执行 查询内并行 单个查询在多个处理器和磁盘上并行执行 操作内并行 并行排序 并行连接 运算的并行计算代价 启动代价 偏斜 资源竞争 组装代价 操作间并行 流水线并行 独立并行 查询优化 并行系统设计 需注意到的可用性问题 硬件发生故障时的恢复性 数据和模式发生改变时的联机重组 多核处理器的并行性 并行性与原始速度 高速缓冲存储器和多线程 适应现代体系架构的数据库系统设计 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-21 08:59:46 "},"数据库系统/系统体系结构/分布式数据库.html":{"url":"数据库系统/系统体系结构/分布式数据库.html","title":"分布式数据库","keywords":"","body":"同构和异构数据库 分布式数据存储 复制 分片 数据复制 提供了只读事务的性能，但更新事务的开销会变大 数据分片 分库分表当中的水平、垂直 水平切片 垂直切片 透明性 分片透明性 复制透明性 位置透明性 分布式事务 局部事务 全局事务 系统结构 事务管理器 事务协调器 系统故障模式 站点故障 消息丢失 通信链路故障 网络划分 提交协议 两阶段提交 三阶段提交 事务处理的可选择性模型 发送站点协议 接收站点协议 分布式数据库中的并发控制 封锁协议 单一锁管理器方式 分布式锁管理器 数据项复制 主副本 多数协议 有偏协议 法定人数同意协议 时间戳 全局唯一标识符 = 局部唯一时间戳+站点标识符 弱一致性级别的复制 延迟传播 死锁处理 局部等待图；全局等待图 可用性 基于多数的方法 读一个、写所有可用的方法 站点重建 分布式查询处理 查询转换 连接处理 半连接策略 异构分布式数据库 数据统一视图 查询处理 多数据库中的事务管理 基于云的数据库 目录系统 目录访问协议 LDAP MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-21 08:59:46 "},"数据库系统/数据仓库与数据挖掘.html":{"url":"数据库系统/数据仓库与数据挖掘.html","title":"数据仓库与数据挖掘","keywords":"","body":"决策支持系统 数据仓库 是一个将从多个数据源中收集来的信息以统一的模式存储在单个站点上的仓储 问题： 何时和如何收集数据 使用何种模式 数据转换和清理 如何传播更新 汇总何种数据 抽取、转换、加载 数据仓库模式 事实表 雪花模式 面向列的存储 优势： 有较好的传输性能 相同类型的值存储在一起提高了压缩效率 局限： 读写单个元组需要多次IO 数据挖掘 从数据库中发现知识 支持度 置信度 分类 机器学习 决策树分类器 构造决策树分类器 贪心算法 最优划分 寻找最优划分 其他类型的分类器 神经网络分类器 贝叶斯分类器 支持向量机 回归 值的预测 分类器验证 正确性 召回率 准确率 特异性 关联规则 其他类型的关联 聚类 层次聚类 凝聚聚类 分裂聚类 其他类型的数据挖掘 文本挖掘 数据可视化 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-22 09:20:26 "},"数据库系统/信息检索.html":{"url":"数据库系统/信息检索.html","title":"信息检索","keywords":"","body":"使用术语的相关性排名 使用TF-IDF的排名方法 使用术语频率度量一份文档的相关性 基于相似性的检索 余弦相似性 使用超链接的相关性 流行度排名 PageRank 其他的流行度度量 搜索引擎作弊 同义词、多义词和本体 文档的索引 检索的有效性度量 查准率 查全率 Web的抓取和索引 信息检索：网页排名之外 查询结果多样化 信息抽取 问答系统 查询结构化数据 目录与分类 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-22 09:20:26 "},"数据库系统/对象数据库.html":{"url":"数据库系统/对象数据库.html","title":"对象数据库","keywords":"","body":" 本地支持 对象-关系映射(ORM) 复杂数据类型 book author publisher keywor SQL中的结构类型和继承 结构类型 CREATE TYPE Name AS ( firstname VARCHAR(20), lastname VARCHAR(20) ) final; 类型继承 CREATE TYPE Apple UNDER Fruit 表继承 CREATE TABLE Apple UNDER Fruit 数组和多重集合类型 对象标识和引用类型 持久化程序设计语言 对象的持久化 按类持久化 按创建持久化 按标志持久化 按可达性持久化 对象标识和指针 持久程度： 过程内部 程序内部 程序之间 持久 持久对象的存储和访问 持久化C++系统 持久化java系统 对象-关系映射 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-23 04:21:05 "},"数据库系统/高级主题/高级应用开发.html":{"url":"数据库系统/高级主题/高级应用开发.html","title":"高级应用开发","keywords":"","body":"性能调整 提高面向集合的特性 批量 嵌套子查询 批量加载和更新的调整 瓶颈位置 可调参数 第一级：硬件 第二级：数据库系统参数 第三级：模式和事务 硬件调整 增加硬件投入 缓冲区 模式调整 拆分 列存储 索引调整 物化视图 立即维护 延迟维护 物理设计的自动调整 并发事务调整 性能模拟 性能基准程序 任务集 数据库应用类型 CPC基准程序 tps 应用系统开发的其他问题 测试 移植 标准化 SQL标准 数据库连接标准 对象数据库标准 基于XML的标准 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-24 00:43:50 "},"数据库系统/高级主题/时空数据和移动性.html":{"url":"数据库系统/高级主题/时空数据和移动性.html","title":"时空数据和移动性","keywords":"","body":" 时态数据 空间数据 多媒体数据 移动数据库 数据库中的时间 SQL中的时间规范 date time timestamp 时态查询语言 时态选择 时态投影 时态连接 空间与地理数据 计算机辅助设计数据 地理数据 几何信息表示 设计数据库 地理数据 表示 光栅数据 矢量数据 空间查询 临近查询 区域查询 空间连接 空间数据的索引 k-d树 四叉树 R树 多媒体数据库 支持大对象 传输速率稳定 基于相似性检索 连续媒体数据 快 不会导致溢出 保证不同流之间同步 基于相似性的检索 图片数据 音频数据 手书数据 移动性和个人数据库 移动计算模型 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-24 04:22:55 "},"数据库系统/高级主题/高级事务处理.html":{"url":"数据库系统/高级主题/高级事务处理.html","title":"高级事务处理","keywords":"","body":"事务处理监控器 TP监控体系结构 每客户端进程模型 单服务器模型 多服务器单路由模型 多服务器多路由模型 使用TP监控器进行应用协调 事务工作流 工作流说明 工作流的故障原子性需求 工作流执行 集中式 部分分布式 完全分布式 工作流恢复 保证工作流的故障原子性 工作流管理系统 电子商务 电子目录 市场 订单结算 主存数据库 实时事务系统 硬截止时间 严格截止时间 软截止时间 长事务 持续时间长 暴露未提交数据 子任务 可恢复性 性能 不可串行化的执行 并发控制 嵌套事务和多级事务 补偿事务 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-24 09:11:56 "},"数据技术/数据技术.html":{"url":"数据技术/数据技术.html","title":"数据技术","keywords":"","body":"MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-11 03:43:47 "},"数据技术/数据挖掘.html":{"url":"数据技术/数据挖掘.html","title":"数据挖掘","keywords":"","body":"数据挖掘 推荐 基于用户的协作型过滤 为用户计算与其他用户的相似度 基于物品的协作型过滤 为物品计算与其他物品的相似度 需要提前计算好物品的相似集合 收集偏好 不管偏好是评价何物品 最终都需要一种方法将其对应到数字： 使用这一的一个item表示某一用户的偏好： 'Toby': {'Snakes on a Plane': 4.5, 'You, Me and Dupree': 1.0, 'Superman Returns': 4.0} 寻找相似的用户 欧几里得距离评价: 通过将用户转换为坐标中的点 计算点之间的距离 距离越近越相似 def sim_distance(prefs, person1, person2): # 得到shared_items的列表 si = {} for item in prefs[person1]: if item in prefs[person2]: si[item] = 1 # 如果两者没有共同之处，则返回0 if len(si) == 0: return 0 # 计算所有差值的平方和 sum_of_squares = 0 for item in si.keys(): # 这里所做的就是等同于在计算二维中x y 的差值 sum_of_squares = sum_of_squares + pow(prefs[person1][item] - prefs[person2][item], 2) return 1 / (1 + sqrt(sum_of_squares)) 皮尔逊相关度评价： 判断两组数据与某一直线拟合程度的度量 def sim_pearson(prefs, p1, p2): # 得到双方都曾评价过的物品列表 si = {} for item in prefs[p1]: if item in prefs[p2]: si[item] = 1 # 如果两者没有共同之处，则返回0 if len(si) == 0: return 0 # 得到列表元素的个数 n = len(si) # 对所有偏好求和 sum1 = sum([prefs[p1][it] for it in si]) sum2 = sum([prefs[p2][it] for it in si]) # 求平方和 sum1Sq = sum([pow(prefs[p1][it], 2) for it in si]) sum2Sq = sum([pow(prefs[p2][it], 2) for it in si]) # 求乘积之和 pSum = sum([prefs[p1][it] * prefs[p2][it] for it in si]) # 计算皮尔逊评价值 num = pSum - (sum1 * sum2 / n) den = sqrt((sum1Sq - pow(sum1, 2) / n) * (sum2Sq - pow(sum2, 2) / n)) if den == 0: return 0 r = num / den return r 为某一用户找出与其相似的用户 def topMatches(prefs, person, n=5, similarity=sim_pearson): scores = [(similarity(prefs, person, other), other) for other in prefs if other != person] scores.sort() scores.reverse() return scores[0:n] 根据相似用户推荐物品 def getRecommendations(prefs, person, similarity=sim_pearson): totals = {} simSums = {} for other in prefs: # 不和自己比较 if other == person: continue sim = similarity(prefs, person, other) # 忽略相似度小于等于0的用户 if sim 匹配物品 通过将物品与人交换 可以使用查找相似的用户的算法来查找相似的物品 def transformPrefs(prefs): result = {} for person in prefs: for item in prefs[person]: result.setdefault(item, {}) # Flip item and person result[item][person] = prefs[person][item] return result 构造物品相似集合 def calculateSimilarItems(prefs, n=10): # 建立一个key为物品 value为与其相似相近物品的的字典 result = {} # 反转物品与人 itemPrefs = transformPrefs(prefs) c = 0 for item in itemPrefs: # 针对大数据更新状态变量 c += 1 if c % 100 == 0: print(\"%d / %d\" % (c, len(itemPrefs))) # 寻找最为相近的物品 scores = topMatches(itemPrefs, item, n=n, similarity=sim_distance) result[item] = scores return result 使用提前构造好的数据集获得推荐 def getRecommendedItems(prefs, itemMatch, user): userRatings = prefs[user] scores = {} totalSim = {} # 遍历当前用户评价过的物品 for (item, rating) in userRatings.items(): # 遍历与当前物品相近的物品 for (similarity, item2) in itemMatch[item]: # 忽略已经被评价过的物品 if item2 in userRatings: continue # 分数是通过相似度*评分 scores.setdefault(item2, 0) scores[item2] += similarity * rating # Sum of all the similarities totalSim.setdefault(item2, 0) totalSim[item2] += similarity # Divide each total score by total weighting to get an average rankings = [(score / totalSim[item], item) for item, score in scores.items()] # Return the rankings from highest to lowest rankings.sort() rankings.reverse() return rankings 群组 监督学习：利用样本和期望输出来学习如何预测 无监督学习：在一组数据中寻找某种结构 分级聚类 不断将最为相似的群组两两合并 使用树状图来可视化聚类结果： 通过距离来体现各元素的相似度 计算两个数字列表的相关度： def pearson(v1, v2): # 简单求和 sum1 = sum(v1) sum2 = sum(v2) # 平方根和 sum1Sq = sum([pow(v, 2) for v in v1]) sum2Sq = sum([pow(v, 2) for v in v2]) # 乘积之和 pSum = sum([v1[i] * v2[i] for i in range(len(v1))]) # Calculate r (Pearson score) num = pSum - (sum1 * sum2 / len(v1)) den = sqrt((sum1Sq - pow(sum1, 2) / len(v1)) * (sum2Sq - pow(sum2, 2) / len(v1))) if den == 0: return 0 return 1.0 - num / den 代表一个聚类节点： class bicluster: def __init__(self, vec, left=None, right=None, distance=0.0, id=None): self.left = left self.right = right self.vec = vec self.id = id self.distance = distance 列聚类 将矩阵转置 def rotatematrix(data): newdata = [] for i in range(len(data[0])): newrow = [data[j][i] for j in range(len(data))] newdata.append(newrow) return newdata 可以得到单词的聚类结果 K-均值聚类 随机确定k个中心位置 将各个数据项分配个最近的中心点 将中心点移动到各个节点的平均位置 重复2-3 直到不再变化 def kcluster(rows, distance=pearson, k=4): # 确定每个点的最大最小值 ranges = [(min([row[i] for row in rows]), max([row[i] for row in rows])) for i in range(len(rows[0]))] # 随机创建k个中心点 clusters = [[random.random() * (ranges[i][1] - ranges[i][0]) + ranges[i][0] for i in range(len(rows[0]))] for j in range(k)] lastmatches = None for t in range(100): dis_sum = 0 print('Iteration %d' % t) bestmatches = [[] for i in range(k)] # 在每一行中寻找距离最近的中心点 for j in range(len(rows)): row = rows[j] bestmatch = 0 for i in range(k): d = distance(clusters[i], row) if d 0: for rowid in bestmatches[i]: for m in range(len(rows[rowid])): avgs[m] += rows[rowid][m] for j in range(len(avgs)): avgs[j] /= len(bestmatches[i]) clusters[i] = avgs return bestmatches, dis_sum 二维形式展示 在一个二维平面 通过不同数据项的距离来计算得到一个二维平面图 def scaledown(data, distance=pearson, rate=0.01): n = len(data) # 每一对数据项之间的距离 realdist = [[distance(data[i], data[j]) for j in range(n)] for i in range(0, n)] # 随机初始化节点再二维空间的起始位置 loc = [[random.random(), random.random()] for i in range(n)] fakedist = [[0.0 for j in range(n)] for i in range(n)] lasterror = None for m in range(0, 1000): # 寻找投影后的距离 for i in range(n): for j in range(n): fakedist[i][j] = sqrt(sum([pow(loc[i][x] - loc[j][x], 2) for x in range(len(loc[i]))])) # 移动节点 grad = [[0.0, 0.0] for i in range(n)] totalerror = 0 for k in range(n): for j in range(n): if j == k: continue # The error is percent difference between the distances errorterm = (fakedist[j][k] - realdist[j][k]) / realdist[j][k] # Each point needs to be moved away from or towards the other # point in proportion to how much error it has grad[k][0] += ((loc[k][0] - loc[j][0]) / fakedist[j][k]) * errorterm grad[k][1] += ((loc[k][1] - loc[j][1]) / fakedist[j][k]) * errorterm # Keep track of the total error totalerror += abs(errorterm) print(totalerror) # If the answer got worse by moving the points, we are done if lasterror and lasterror 搜索与排名 建立索引 分词 从html结构中获取文本节点，对其分词 def gettextonly(self, soup): v = soup.string if len(v) == 0: c = soup.contents resulttext = '' for t in c: subtext = self.gettextonly(t) resulttext += subtext + '\\n' return resulttext else: return v.strip() # 使用正则表达式进行分词 @staticmethod def separatewords(self, text): splitter = re.compile('\\\\W*') return [s.lower() for s in splitter.split(text) if s != ''] 查询 进行分词 查找分出的词的响应ID 根据这些词来查找相关url def getmatchrows(self, q): # 构造sql查询条件字符串 fieldlist = 'w0.urlid' tablelist = '' clauselist = '' wordids = [] # 分词 words = q.split(' ') tablenumber = 0 for word in words: # 获取单词的ID wordrow = self.con.execute( \"select rowid from wordlist where word='%s'\" % word).fetchone() if wordrow is not None: wordid = wordrow[0] wordids.append(wordid) if tablenumber > 0: tablelist += ',' clauselist += ' and ' clauselist += 'w%d.urlid=w%d.urlid and ' % (tablenumber - 1, tablenumber) fieldlist += ',w%d.location' % tablenumber tablelist += 'wordlocation w%d' % tablenumber clauselist += 'w%d.wordid=%d' % (tablenumber, wordid) tablenumber += 1 # 根据条件进行查询 fullquery = 'select %s from %s where %s' % (fieldlist, tablelist, clauselist) print(fullquery) cur = self.con.execute(fullquery) rows = [row for row in cur] return rows, wordids 基于内容的排名 使用一个归一化函数将结果映射到0-1之间： def normalizescores(self, scores, smallIsBetter=0): vsmall = 0.00001 # 避免除0 if smallIsBetter: minscore = min(scores.values()) return dict([(u, float(minscore) / max(vsmall, l)) for (u, l) in scores.items()]) else: maxscore = max(scores.values()) if maxscore == 0: maxscore = vsmall return dict([(u, float(c) / maxscore) for (u, c) in scores.items()]) 单词频度 根据单词在网页中出现的次数对网页进行评价 def frequencyscore(self, rows): counts = dict([(row[0], 0) for row in rows]) for row in rows: counts[row[0]] += 1 return self.normalizescores(counts) 文档位置 根据单词离文档首部的距离进行评价 def locationscore(self, rows): locations = dict([(row[0], 1000000) for row in rows]) for row in rows: loc = sum(row[1:]) if loc 单词距离 单词间距更近 得分越高 def distancescore(self, rows): # 只有一个单词 则得分一样 if len(rows[0]) 使用外部回指链接 简单计数 统计其他网页链接本网页的个数 个数越多 评分越高 def inboundlinkscore(self, rows): uniqueurls = dict([(row[0], 1) for row in rows]) inboundcount = dict( [(u, self.con.execute('select count(*) from link where toid=%d' % u).fetchone()[0]) for u in uniqueurls]) return self.normalizescores(inboundcount) PageRank 为所有的网页设置一个默认PR值 ，每个网页的PR值计算公式： PR(A) = 0.15 + 0.85 * (PR(B)/links(B) + PR(C)/links(C) + PR(D)/links(D)) 使用链接文本 根据指向网页的链接文本来评价该网页 def linktextscore(self, rows, wordids): linkscores = dict([(row[0], 0) for row in rows]) for wordid in wordids: cur = self.con.execute( 'select link.fromid,link.toid from linkwords,link where wordid=%d and linkwords.linkid=link.rowid' % wordid) for (fromid, toid) in cur: if toid in linkscores: pr = self.con.execute('select score from pagerank where urlid=%d' % fromid).fetchone()[0] linkscores[toid] += pr maxscore = max(linkscores.values()) if maxscore == 0: maxscore = 0.00001 normalizedscores = dict([(u, float(l) / maxscore) for (u, l) in linkscores.items()]) return normalizedscores MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-20 03:37:08 "},"操作系统/nav.html":{"url":"操作系统/nav.html","title":"操作系统","keywords":"","body":"操作系统 管理计算机硬件与软件资源的程序 运行在计算机上的一个软件 分为内核与外壳（我们可以把外壳理解成围绕着内核的应用程序，而内核就是能操作硬件的程序） 基本特征 并发 并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令 并发需要硬件支持 操作系统引入进程和线程，使得程序能够并发执行 共享 系统中的资源可以被多个并发进程共同使用 互斥共享 临界资源，这种资源共享需要使用同步机制来实现互斥访问 同时共享 虚拟 时分复用 多个进程能在同一个处理上运行（每个进程轮流使用处理器，快速进行切换） 空分复用 虚拟内存中的页映射，进程地址空间的内存可以不用全在物理内存中，一些可以放在外存，当需要这些内存的时候，通过页面置换算法，移到内存当中 异步 进程不一次性执行完毕，以不确定的速度前进 基本功能 进程管理 内存管理 文件管理 设备管理 系统调用 用户态(user mode) : 用户态运行的进程或可以直接读取用户程序的数据。 内核态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制 进程需要使用一些功能，通过系统调用陷入内核，由操作系统代为完成 内核 大内核 操作系统功能作为一个紧密的整体 性能很高 微内核 将一些功能独立出内核，划分成服务，降低内核的复杂性 会有一定的性能损失 中断 外中断 CPU执行指令外的事件引起，IO完成中断、时钟中断等 异常 CPU执行指令引起的，地址越界、算术溢出 陷入 在用户程序中使用系统调用 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-06 01:26:14 "},"操作系统/进程与线程.html":{"url":"操作系统/进程与线程.html","title":"进程与线程","keywords":"","body":"进程与线程 进程 进程是资源分配的基本单位 在某一个瞬间，CPU只能运行一个进程。 进程模型 计算机上所有可运行的软件，通常包括操作系统，被组织成若干顺序进程，称为进程 程序与进程的关系 进程的创建 导致进程创建的4种主要事件： 系统初始化 系统调用 用户请求创建 批处理作业初始化 守护进程：停留在后台的线程 写时复制 进程的终止 终止的条件： 正常退出（自愿） 出错退出（自愿） 严重错误（非自愿） 被其他进程杀死（非自愿） 进程的层次结构 UNIX中，进程创建一个新进程后，该进程称为其的父进程，它与它的所有后代组成一个进程组。 但在Windows中，进程之间没有层次关系，除了父进程在创建子进程时，会获得其的句柄，除此之外，没有任何联系。 进程的状态 运行态（正在占用CPU） 就绪态（可运行，但还没有运行） 阻塞态（正在等待外部事件，如IO读取） 像不像线程 调度程序：负责切换进程的执行 进程的实现 为实现进程模型，操作系统维护一张表：进程表 中断向量：中断服务程序的入口地 多道程序设计模型 CPU利用率 = 1-P^n n称为多道程序设计的道数 P为CPU空转的概率 线程 线程是独立调度的基本单位 线程的使用 使用线程的理由： 更好描述程序的行为 线程比进程更轻量 提高性能 有限状态机 每个计算机都有一个被保存的状态，存在一个会发生且使得相关状态发生改变的事件集合 经典的线程模型 每个线程都有自己的堆栈 POSIX线程 一种线程标准，定义的线程包叫做pthread 在用户空间中实现线程 用户级线程的优点： 快 可以定制自己的调度算法 局限性： 如何实现阻塞系统调用 在内核中实现线程 代价很大 混合实现 调度程序激活机制 上行调用 弹出线程 一个消息的到达导致系统创建一个处理该消息的线程 使单线程代码多线程化 全局变量的问题 进程与线程的区别 线程不拥有资源，线程只能访问隶属进程的资源 在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换 创建进程的开销比创建线程大 如创建撤销进程需要分配或回收资源，如内存空间、I/O 设备 进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容 进程间通信 有关问题： 进程之间传递信息 进程之间的活动不会出现交叉 进程之间运行的顺序 竞争条件 两个或多个进程读写某些共享数据，得到的结果取决于进程运行的精确时序 临界区 通过互斥来组织多个进程同时读写共享数据 把对共享内存进行访问的程序片段称为临界区 任何两个进程不能同时处于临界区 不对CPU的速度和数量做假设 临界区外运行的进程不能阻塞其他进程 不能使进程无限等待进入临界区 同步与互斥 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。 互斥：多个进程在同一时刻只有一个进程能进入临界区 忙等待的互斥 屏蔽中断：进程进入临界区后屏蔽所有中断，这样系统就无法切换到其他进程了 锁变量 严格轮换法： 连续测试一个变量直到某个值出现为止，称为忙等待 自旋锁：用于忙等待的锁 Peterson解法 TSL 指令 调用enter() -> 忙等待，直到获得锁 -> 调用leave() 睡眠与唤醒 优先级反转问题 生产者-消费者问题 信号量 信号量（Semaphore）是一个整型变量，可以对其进行原子操作的 down：如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0 up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作 互斥量 信号量的一个简化版本，值只能取0或者1 自旋锁是忙等待的体现 快速用户区互斥量futex pthread中的互斥量 条件变量 死锁 两个进程互相等待对方，一直阻塞下去 管程 一个管程由过程、变量、数据结构等组合成的一个集合 monitor ProducerConsumer integer i; condition c; procedure insert(); begin // ... end; procedure remove(); begin // ... end; end monitor; 在一个时刻只能有一个进程使用管程 像不像一个类（有属性，有行为） 进程可以在任何时候通过管程间接获取数据，但是不能直接获取数据 消息传递 send(目的,&msg); receive(源,&msg); 用消息传递解决生产者-消费者问题 消息传递接口 屏障 当一个进程到达屏障时，就会被阻拦，直到所有进程都到达屏障为止 避免锁：读-复制-更新（RCU） 要么读取旧版本，要么读取新版本 调度 调度程序与调度算法 简介 进程行为 IO活动与CPU计算 计算密集型 IO密集型 何时调度 运行一个新进程后 一个进程退出后 一个进程阻塞后 IO中断 非抢占式：直到一个进程阻塞或者主动释放CPU 抢占式：运行一段时间，后调度程序进行调度挑选下一个运行的进程 调度算法 调度算法的目标 批处理系统 在该系统中，调度算法目标是保证吞吐量和周转时间 先来先服务 first-come first-serverd（FCFS） 短作业优先 shortest job first（SJF） 最短剩余时间优先 shortest remaining time next（SRTN） 交互式系统 在该系统中调度算法的目标是快速地进行响应 时间片轮转 每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程 该算法效率与时间片大小有关，时间片过于小，会造成进程切换频繁，过大实时性无法得到保证 优先级调度 为每个进程分配一个优先级，按优先级进行调度 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级 多级反馈队列 它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列，在这种情况下，就能有效避免一个进程需要执行连续多个时间片而造成的切换频繁问题 保证调度 彩票调度 公平分享调度 实时系统 硬实时：必须满足一定的截止时间 软实时：可以容忍一定的超时 策略和机制 调度机制与调度策略分离 线程调度 用户级调度 内核级调度 经典进程同步问题 哲学家就餐问题 五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子 读者-写者问题 允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生 进程通信 进程同步：控制多个进程按一定顺序执行； 进程通信：进程间传输信息 为了能够达到进程同步的目的，需要让进程进行通信 管道 只支持半双工 只支持父子进程或者兄弟进程 FIFO(命名管道) 有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信 消息队列 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收 信号量 用于为多个进程提供共享对象的访问 共享存储 多个进程可以使用一个给定的存储区进行通信 可以使用文件或者内存 套接字 用于不同机器之间的进程通信 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-06 01:52:51 "},"操作系统/内存管理.html":{"url":"操作系统/内存管理.html","title":"内存管理","keywords":"","body":"内存管理 分层存储器体系 存储管理器：操作系中管理分层存储器体系的部分 无存储器抽象 PSW（程序状态字） IBM 360系统的不用交换运行多个程序 避免绝对物理地址的引用 存储器抽象：地址空间 概念 运行多个程序互相不影响，需要解决两问题： 保护 重定位 基址寄存器与界限寄存器 动态重定位 交换技术 把一个进程完整调入内存，使该进程运行一段时间，再将其写回磁盘 内存紧缩：将小空闲区合并成一大块 空闲内存管理 使用位图的存储管理 使用链表 首次适配算法 下次适配算法 最佳适配算法 最差适配算法 快速适配算法 虚拟内存 地址空间被分为多块，每块称作页 页被映射到物理内存，如果程序引用不存在的物理内存 由操作系统负责将缺失的部分装入物理内存 分页 缺页中断：当访问的页没有映射到物理内存中时，操作系统会将其他的页写到磁盘，将空出来的内存映射给当前的页，内存管理单元（MMU） 则是执行这个映射的服务 页表 页表项的结构 保护位：允许什么类型的访问（读、写、执行） 修改位：判断页面是否被写过 访问位：判断页面是否被访问过 高速缓存禁止位 加速分页过程 分页系统需要考虑的2个问题： 虚拟地址映射到物理地址必须非常快 如果虚拟地址空间很大，则页表也会很大 转换检测缓冲区（TLB）：小型硬件设备，能直接将虚拟地址映射成物理地址，而无需访问页表（二八定律） 软件TLB管理 软失效与硬失效 针对大内存的页表 多级页表 倒排页表 地址映射与散列查找 页面置换算法 主要目的：挑选出最不常使用的页面 WEB服务器文件缓存 最优页面置换算法（OPT, Optimal replacement algorithm） 无法确定哪个页面未来最少被使用 ，该算法只是一种理论算法，无法实现 最近未使用(NRU)页面置换算法 随机淘汰最近一个时钟周期没有访问、没有修改的页面 先进先出页面置换算法（FIFO, First In First Out） 选择换出的页面是最先进入的页面 第二次机会页面置换算法 淘汰掉一个进入时间最长，且最久未被使用的页面 时钟页面置换算法 使用一个指针指向最老的页面 最近最少使用(LRU)页面置换算法 在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的 工作集页面置换算法 工作集：进程当前正在使用的页面集合 淘汰掉工作集中最少使用的页面 工作集时钟页面置换算法 用软件模拟LRU 最不常使用（NFU） 会记住最近一段时间内各个时钟周期的访问情况 分页系统中的设计问题 局部分配策略与全局分配策略 缺页中断率（PFF）：用来指出何时增加或减少分配给进程的页面 负载控制 将进程从内存交换到磁盘 页面大小 选择小页面的好处：节省内存 分离的指令空间和数据空间 共享页面 如果地址空间分离实现共享页面就会非常简单 写时复制 共享库 位置无关代码：只使用相对偏移量的代码 内存映射文件 把文件当做成一个内存中的大字符数组 清除策略 分页守护进程 虚拟内存接口 分布式共享内存 有关实现的问题 与分页有关的工作 创建一个新进程时：确定程序和数据大小，创建一个页表 进程执行时：重置MMU,刷新TLB，清除之前进程的痕迹 缺页中断时：确定是哪个虚拟地址发生了中断，读入所需页面，重新执行指令 进程退出时：释放页表、页面 缺页中断处理 指令备份 重启引起缺页中断的那条指令，这不是一件容易的事 锁定内存中的页面 锁住正在做IO操作的内存中的页面保证它不会被移出内存 后备存储 linux中的swap 策略与机制分离 MMU 缺页中断处理程序 页面调度程序 分段 表碰撞：动态增长的表会导致覆盖的问题 纯分段的实现 段页式 程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能 分段和分页结合：MULTICS 段（段号，段内地址（页号，偏移地址）） 分段和分页结合：Intel x86 LDT与GDT 线性地址（目录，页面，偏移量） 分页与分段 分页 分段 透明性 对程序员透明 需要程序员显示划分每个段 地址空间维度 一维地址 二维地址 大小可否改变 页大小不可改变 段大小可以动态改变 出现原因 分页用来实现虚拟内存，以获得更大的地址空间 分段是为了独立程序和数据并且有助于共享与保护 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-02 11:00:16 "},"操作系统/文件管理.html":{"url":"操作系统/文件管理.html","title":"文件管理","keywords":"","body":"文件管理 长期存储信息的三个基本要求 能够存储大量信息 使用信息的进程终止时，信息仍旧存在 信息能够并发访问 文件 文件命名 FAT-16 NTFS 文件结构 字节序列 记录序列 树 文件类型 普通文件 目录 文件访问 顺序访问 随机访问 文件属性 文件操作 onCreate delete open close read write append seek get attrs set attrs rename 使用文件系统调用 一个简单的C语言程序： int main(){ FILE *fp; char c = -1; fp = fopen(\"./file.c\",\"r\"); while ((c = fgetc(fp)) != -1){ putchar(c); } fclose(fp); return 0; } 目录 一级目录系统 层次目录系统 路径名 绝对路径 相对路径 目录操作 create delete opendir closedir readdir rename link unlink 文件系统的实现 文件系统布局 主引导记录（MBR） 文件的实现 连续分配 链表分配 使用内存中的表进行链表分配 文件分配表 i节点 目录的实现 共享文件 链接 符号链接 日志结构文件系统（LFS） 日志文件系统 日志必须是幂等的 思考： 与数据库中的原子事务 虚拟文件系统 思考： 适配器设计模式 文件系统管理和优化 磁盘空间管理 选择块大小 速度与空间不可兼得 记录空闲块 链表与位图 磁盘配额 文件系统备份 逻辑转储与物理转储 文件系统的一致性 检查使用的块与空闲块是否一致 文件系统性能 高速缓存 内存速度 > 磁盘速度 块高速缓存 散列与快速查找 块提前读 减少磁盘臂运动 磁盘碎片整理 文件系统实例 MS-DOS文件系统 UNIX V7 文件系统 CD-ROM文件系统 ISO 9660文件系统 Rock Ridge扩展 Joliet扩展 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-31 07:57:14 "},"操作系统/输入输出.html":{"url":"操作系统/输入输出.html","title":"输入/输出","keywords":"","body":"I/O 硬件管理 I/O设备 块设备 字符设备 设备控制器 IO设备由机械部件与电子部件构成 电子部件称为设备控制器或者适配器 控制器的任务： 将串行的比特流转换为字节块， 并完成纠错工作 内存映射IO 给控制寄存器分配一个IO端口， 所有IO端口形成IO端口空间 将IO设备寄存器映射到内存上 内存映射IO优点： 无需使用特殊指令读取IO设备寄存器 不需要特殊保护机制阻止用户进程进行IO操作 可以引用内存的指令也能引用控制寄存器 缺点： 不能使用高速缓存 直接存储器存取 加入一个中间层 从CPU-设备 变成 CPU - DMA - 设备 突发模式 飞越模式： 让设备控制器将数据直接写到主存 控制器内部缓存区存在的原因 校验数据 总线可能忙 中断 中断向量 精确中断：机器停留在一个明确状态的中断 程序计数器保留在一个已知的地方 所指向的指令之前的所有指令已执行完毕 所执行的指令之后的所有指令都还未执行 所指向的指令的执行状态是已知的 不精确中断 IO软件原理 IO软件的目标 设备独立性 统一命名 错误处理 低层能处理的问题，就不要交给高层 同步与异步 缓冲 程序控制IO 让CPU做全部工作 程序控制IO伪代码: copy_from_user(buffer,p,count); for(i = 0;i 中断驱动IO 使用DMA的IO 让DMA控制数据传输，而不必打扰CPU IO软件层次 中断处理程序 在响应一个特定中断的时候，内核会执行一个函数，该函数叫中断处理程序 设备驱动程序 每个链接到计算机上的IO设备都需要某些设备特定代码进行控制，称之为设备驱动程序 可重入性 与设备无关的IO软件 与设备无关的IO软件的功能 设备驱动程序的统一接口 缓冲 错误报告 分配与释放专用设备 提供与设备无关的块大小 磁盘 结构 盘面（Platter）：一个磁盘有多个盘面 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写） 制动手臂（Actuator arm）：用于在磁道之间移动磁头 主轴（Spindle）：使整个盘面转动 磁盘硬件 磁盘 RAID 磁盘格式化 低级格式化 分区 高级格式化 磁盘臂调度算法 旋转时间：主轴转动盘面，使得磁头移动到适当的扇区上 寻道时间：制动手臂移动，使得磁头移动到适当的磁道上 数据传输时间 先来先服务算法 按照磁盘请求的顺序进行调度 公平简单，但是没有对寻道做任何优化，平均寻道时间较长 最短寻道优先 优先调度距距离磁头最近的磁道 不够公平，如果一个请求距离当前磁头比较远，会出现饥饿现象 电梯算法 总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向 错误处理 稳定存储器 稳定写 稳定读 崩溃恢复 时钟 时钟硬件 一次完成模式 方波模式 时钟软件 维护日时间 防止进程超时运行 对CPU使用情况进行记账 处理alarm系统调用 为系统各部分提供监视定时器 完成信息收集 软定时器 用户界面：键盘、鼠标和监视器 输入软件 键盘软件 原始模式 加工模式 鼠标软件 $\\Delta$x $\\Delta$y 按钮 输出软件 文本窗口 X窗口系统 图形用户界面 位图 字体 触摸屏 瘦客户机 电源管理 硬件问题 操作系统问题 显示器 硬盘 CPU 内存 无线通信 热量管理 电源管理 驱动程序接口 应用程序问题 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-02 11:08:27 "},"操作系统/死锁.html":{"url":"操作系统/死锁.html","title":"死锁","keywords":"","body":"死锁 资源 排他性使用的对象 可抢占资源 不可抢占起源 1）请求资源 2）使用资源 3）释放资源 资源获取 可能产生死锁的编码 void fa(){ down(r1); down(r2); up(r1); up(r2); } void fb(){ down(r2); down(r1); up(r1); up(r2); } 死锁简介 集合中的每一个进程都在等待只能由本集合中的其他进程才能引发的事件，那么该组进程是死锁的 资源死锁的条件 互斥：每个资源要么已经分配给了一个进程，要么就是可用的 占有和等待：已经得到了某个资源的进程可以再请求新的资源 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源 死锁建模 圆形表示进程，方形表示资源 如果产生环路，则产生死锁 处理死锁的策略 忽略问题 检测并恢复 仔细分配资源 破坏引起死锁的四个必要条件 鸵鸟策略 解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能 死锁检测和死锁恢复 每种类型一个资源的死锁检测 方框代表资源，圆圈表示进程，资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源，这样当一个图中出现了环，就代表出现了死锁 可以通过检测有向图环路的算法，进行深度优先搜索，对访问过的节点进行标记，如果发现重复的节点，则代表出现了死锁 每种类型多个资源的死锁检测 基于向量检测 从死锁中恢复 利用抢占恢复 利用回滚恢复 杀死进程恢复 死锁避免 在程序运行时避免发生死锁 资源轨迹图 安全状态和不安全状态 第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数 从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的 从安全状态出发，系统能保证所有进程都能完成 单个资源的银行家算法 多个资源的银行家算法 死锁预防 在程序运行之前避免发生死锁 破坏互斥条件 使资源可以同时被多个进程共享 破坏占有和等待条件 规定进程在开始执行前请求所需要的资源 破坏不可抢占条件 一个进程使用某个资源时，这个资源可以被其他需要的进程抢夺 破坏环路等待 给资源进行编号，规定资源的获取顺序 其他问题 两阶段加锁 通信死锁 活锁 饥饿 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-06 02:47:01 "},"操作系统/虚拟化与云.html":{"url":"操作系统/虚拟化与云.html","title":"虚拟化与云","keywords":"","body":"虚拟化的必要条件 安全性 保真性 高效性 第一类和第二类虚拟机管理程序 客户操作系统 宿主操作系统 高效虚拟化技术 在不支持虚拟化的平台上实现虚拟化 系统切换 虚拟化的开销 虚拟机管理程序是正确的微内核吗 内存虚拟化 嵌套页表的硬件扩展 回收内存 IO虚拟化 IO MMU 设备域 单根IO虚拟化 虚拟装置 多核CPU上的虚拟机 去重 授权问题 云 按需自助服务 普适的网络访问 资源池 快速可伸缩 服务可计量 云即服务 虚拟机迁移 检查点 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-06 03:55:58 "},"操作系统/多处理机系统.html":{"url":"操作系统/多处理机系统.html","title":"多处理机系统","keywords":"","body":"多处理机 多个CPU共享访问一个公用RAM 多处理机硬件 统一存储器访问（UMA） 基于总线的UMA多处理机体系结构 使用交叉开关的UMA多处理机 使用多级交换网络的UMA多处理机 NUMA多处理机 多核芯片 众核芯片 异构多核 在多核上编程 多处理机操作系统类型 每个CPU有自己的操作系统 主从多处理机 对称多处理机 多处理机同步 多处理机调度 分时 亲和调度 空间共享 群调度 把一组相关相关线程作为一个单位进行调度 一个群中的相关线程在不同的分时CPU上同时运行 群众所有成员共同开始和结束时间片 多计算机 多计算机硬件 互连技术 存储转发包交换 电路交换 网络接口 低层通信软件 节点至网络接口通信 远程直接内存访问 用户层通信软件 发送和接收 阻塞调用和非阻塞调用 远程过程调用 分布式共享存储器 复制 伪共享 实现顺序一致性 多计算机调度 负载均衡 图论确定算法 发送者发起的分布式启发算法 接受者发起的分布式启发算法 分布式系统 网络硬件 以太网 因特网 网络服务和协议 基于文档的中间件 基于文件系统的中间件 基于对象的中间件 基于协作的中间件 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-09 04:04:41 "},"操作系统/安全.html":{"url":"操作系统/安全.html","title":"安全","keywords":"","body":"环境与安全 威胁 安全性 完整性 可用性 入侵者 操作系统 可信系统 可信计算基 保护机制 保护域 最小权限原则 访问控制列表 权能字 安全系统的形式化模型 多级安全 Bell-LaPadula模型 简易安全规则 *原则 Biba模型 简单完整性规则 完整性 * 规则 隐蔽信道 隐写术 密码学原理 私钥加密技术 公钥加密技术 单向函数 数字签名 可信平台模块 认证 弱密码 UNIX密码安全性 一次性密码 挑战-响应认证 使用物理识别 使用生物识别 软件漏洞 红皇后效应 缓冲区溢出攻击 栈金丝雀保护 避免栈金丝雀 代码重用攻击 地址空间布局随机化 非控制流转向攻击 格式化字符串攻击 悬垂指针 空指针简介引用攻击 整数溢出攻击 命令注入攻击 检查时间/使用时间攻击 内部攻击 逻辑炸弹 后门陷阱 登陆欺骗 恶意软件 特洛伊木马 病毒 防御 防火墙 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-11 13:41:49 "},"操作系统/虚拟化.html":{"url":"操作系统/虚拟化.html","title":"虚拟化","keywords":"","body":" 虚拟化技术是对软件基础设施、操作系统、软件等IT资源进行有效的管理，使用户不再受物理资源的限制， 提高计算机资源的利用率 服务器虚拟化技术 Hypervisor也叫VMM（virtual machine monitor） 在虚拟程序上运行操作系统 Containers容器化技术 虚拟程序上直接运行程序，无操作系统 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-11-01 09:10:26 "},"软件工程/软件工程概论.html":{"url":"软件工程/软件工程概论.html","title":"软件工程","keywords":"","body":"软件的定义及特点 软件（中国大陆及香港用语，台湾称作软体，英文：Software）是一系列按照特定顺序组织的计算机数据和指令的集合。一般来讲软件被划分为系统软件、应用软件和介于这两者之间的中间件。软件并不只是包括可以在计算机（这里的计算机是指广义的计算机）上运行的电脑程序，与这些电脑程序相关的文档一般也被认为是软件的一部分 特点 无形的，没有物理形态，只能通过运行状况来了解功能、特性、和质量 软件渗透了大量的脑力劳动，人的逻辑思维、智能活动和技术水平是软件产品的关键 软件不会像硬件一样老化磨损，但存在缺陷维护和技术更新 软件的开发和运行必须依赖于特定的计算机系统环境，对于硬件有依赖性，为了减少依赖，开发中提出了软件的可移植性 软件具有可复用性，软件开发出来很容易被复制，从而形成多个副本 软件的种类 系统软件 支撑软件 应用软件 软件工程的起源 早期计算机程序 在1946年计算机刚诞生时，人们采用机器码编制程序，根本没有独立的软件的概念。 机器码指令只是为了驱动计算机硬件工作，就像人们调节电视机、录像机、洗衣机等家用电器的按钮一样。 1947年，冯诺依曼首先提出用流程图描述计算机的运行过程，才使人们认识到程序设计是完全不同于硬件研制的另一项工作。从此以后，软件的开发和研究才开始独立地进行。 现在人们认为 在信息产业中，微电子是基础，计算机和网络是载体，软件是核心 软件开发的三个阶段 个人程序时期 软件作坊时期 软件工程时期 软件危机 软件工程的定义 软件工程是研究和应用如何以系统性的、规范化的、可定量的过程化方法去开发和维护软件，以及如何把经过时间考验而证明正确的管理技术和当前能够得到的最好的技术方法结合起来 软件开发的本质和基本手段 软件开发的含义 实现映射的基本手段：建模 模型 软件工程框架 目标 活动 需求、设计、实现、确认、支持 原则 选择适宜的开发模型 提供高质量工程支持 重视开发过程的管理 软件工程框架的作用 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-06 03:55:58 "},"软件工程/软件过程.html":{"url":"软件工程/软件过程.html","title":"软件过程","keywords":"","body":"软件生存周期过程的概念 软件生存周期 软件生存周期过程（软件过程） 系统地给出了软件开发所需的任务，回答了软件开发需要做哪些基本映射 软件生存周期过程的分类 基本过程 支持过程 组织过程 各过程关系 软件生存周期模型 与 软件开发模型 常见的软件生存周期模型 瀑布模型 增量模型 演化模型 喷泉模型 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-07 00:31:01 "},"软件工程/软件需求.html":{"url":"软件工程/软件需求.html","title":"软件需求","keywords":"","body":"需求的作用 现代系统中软件的作用 软件在系统工程中的作用 自顶向下和自底向上的开发 需求的定义 需求的基本性质 必要性 无歧义 可测的 可跟踪 可测量 需求的分类 功能 性能 外部接口 设计约束 质量属性 需求发现 自悟 交谈 观察 小组会 提炼 需求规约 一个需求规约时一个软件所有需求陈述的正式文档，是软件的概念模型 基本性质 重要性与稳定性程度 可修改 完整 一致 格式 引言 总体描述 特定需求 作用 双方的技术合同书 项目管理控制点 产品设计的起始点 测试和使用的基础 项目需求及需求规约 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-16 04:33:12 "},"软件工程/结构化分析方法.html":{"url":"软件工程/结构化分析方法.html","title":"结构化分析方法","keywords":"","body":"软件开发方法 软件开发过程所遵循的办法和步骤 软件开发方法学 结构化方法的组成 结构化分析 结构化设计 结构化程序设计 结构化分析模型 基本术语 数据流 加工 数据存储 数据源 数据谭 模型表达工具 DFD图 数据字典 加工小说明 结构化分析过程 过程指导 建立系统的功能模型 自顶向下，逐层分解 建立数据字典 给出加工小说明 需求规格说明书 引言 概述 功能概述 约束 数据流图、数据字典、加工说明 接口 用户接口 硬件接口 软件接口 性能需求 属性 其他需求 需求验证 有关SRS内容 正确性 无二义性 完整性 可验证性 一致性 可理解性 有关SRS风格 可修改性 可被跟踪性 可跟踪性 设计无关性 注释 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-18 04:00:57 "},"软件工程/结构化设计方法.html":{"url":"软件工程/结构化设计方法.html","title":"结构化设计方法","keywords":"","body":"结构化设计 总体设计 详细设计 设计 一种软件开发活动，定义实现需求规约所需的软件结构 整体框架 体系结构设计 接口设计 数据设计 总体设计 初始设计 精化设计 初始模块结构图的设计 数据流图的分类 变换型DFD 事务型DFD 变化设计的基本步骤 复审并精化模型 确定边界 第一级分解-系统模块结构图顶层和第一层的设计 事务设计的基本步骤 初始模块结构图精化的原则 模块和模块化 模块：执行一个特殊任务的一组例程和数据结构 模块化：把系统分解成若干模块的过程 模块化的原因 降低复杂性 耦合 内容耦合 公共耦合 控制耦合 标记耦合 数据耦合 内聚 偶然内聚 逻辑内聚 时间内聚 过程内聚 通信内聚 顺序内聚 功能内聚 初始化模块结构图精化的启发式规则 常见启发式规则 接口设计 模块或软件构件间的接口 软件与其他软件硬件系统之间的接口 软件与用户的接口 人机交互界面 用户界面应具备的特性 可使用性 灵活性 可靠性 界面设计类型 外行 初学 熟练 专家 设计原则 一致性 操作步骤少 避免哑播放 Undo功能 减少记忆负担 提高学习效率 数据设计 对必须要存储的数据及其格式进行设计 文件存储 数据库设计 ORM 详细设计工具 伪代码 程序流程图 PAD图 N-S图 判定表与判定树 软件设计规约 概要设计规约 系统环境 设计描述 对每个模块的描述 文件结构和全局数据 详细设计规约 设计规约格式 软件设计评审 方法 非正式评审 正式评审 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-20 11:37:13 "},"软件工程/UML.html":{"url":"软件工程/UML.html","title":"UML","keywords":"","body":"面向对象方法 面向对象(Object Oriented,OO)是软件开发方法。 面向对象的概念和应用已超越了程序设计和软件开发，扩展到如数据库系统、交互式界面、应用结构、应用平台、分布式系统、网络管理结构、CAD技术、人工智能等领域。 面向对象是一种对现实世界理解和抽象的方法，是计算机编程技术 发展到一定阶段后的产物。 特点 封装 多态 抽象 继承 基本思想 UML 统一建模语言（英语：Unified Modeling Language，缩写 UML）是非专利的第三代建模和规约语言。UML是一种开放的方法，用于说明、可视化、构建和编写一个正在开发的、面向对象的、软件密集系统的制品的开放方法。UML展现了一系列最佳工程实践，这些最佳实践在对大规模，复杂系统进行建模方面，特别是在软件架构层次已经被验证有效。 术语与符号 类与对象 维基百科-类图 类名 属性 操作 操作的多态性 接口 协作 协作是一组类、接口和其他元素的群体，他们共同工作以提供比组成部分的总和更强的合作行为。 交互各方 交互方式 交互内容 用况 对一组动作序列的描述 主动类 体现并发行为抽象 构件 可替换的成分，遵循提供了一组接口的实现 制品 物理的、可替代的部件 节点 包 表达关系的术语 关联 泛化 实现 依赖 UML模型表达工具 静态部分建模工具 动态部分建模工具 用况图 状态图 活动图 顺序图 通信图 交互概观图 定时图 类图 类 接口 依赖 泛化 关联关系 用况图 主题 用况 参与者 依赖 泛化 关联 使用视角 设计视角 顺序图 刻画对象间的交互消息 状态图 一个状态到另一个状态的控制流 简单状态和组合状态 事件 转换 UML总结 作用 对自顶向下的建模人员来说，提供了概念建模以及软件建模 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-24 00:43:50 "},"软件工程/面向对象.html":{"url":"软件工程/面向对象.html","title":"面向对象","keywords":"","body":"面向对象 三大特性 封装 利用抽象数据类型将数据和基于数据的操作封装在一起，使其构成一个不可分割的独立实体 减少耦合 有利于维护 提供代码复用 降低重构风险 继承 继承实现了 IS-A 关系，子类可以继承父类，获得父类的非private属性与方法 父类引用指向子类对象称为 向上转型 Aniaml dog = new Dog() 多态 运行时多态 对象引用指向的具体类型到运行期间才确定 编译时多态 类图 泛化关系 继承关系 实现关系 聚合关系 整体和部分不是强依赖的，整体不存在了部分还是会存在 组合关系 组合中整体和部分是强依赖的，整体不存在了部分也不存在了 关联关系 这是一种静态关系，与运行过程的状态无关 可以用 1 对 1、多对 1、多对多这种关联关系来表示 依赖关系 依赖关系是在运行过程中起作用的 两个类是依赖关系有三种形式： 局部变量 参数 对象消息 SOLID设计原则 单一职责原则 修改一个类的原因应该只有一个 就是让一个类只负责一件事，当这个类需要做过多事情的时候，就需要分解这个类 开放封闭原则 类应该对扩展开放，对修改关闭 该原则要求在添加新功能时不需要修改代码 里氏替换原则 子类对象必须能够替换掉所有父类对象 animal.run(); // ↓ cat.run(); 如果不满足这个原则，那么各个子类的行为上就会有很大差异，增加继承体系的复杂度 接口分离原则 不应该强迫客户依赖于它们不用的方法 使用多个专门的接口比使用单一的总接口要好 依赖倒置原则 高层模块不应该依赖于低层模块，二者都应该依赖于抽象 抽象不应该依赖于细节，细节应该依赖于抽象。 变量都不应该持有指向具体类的引用 其他一些原则 迪米特法则 又叫作最少知识原则（Least Knowledge Principle，简写 LKP），就是说一个对象应当对其他对象有尽可能少的了解 合成复用原则 多使用组合，少使用继承 共同闭包原则 一起修改的类，应该组合在一起 稳定抽象原则 最稳定的包应该是最抽象的包，不稳定的包应该是具体的包 稳定依赖原则 包要依赖的包要比自己更具有稳定性 面向对象分析 OOA 概述 基本任务 模型 过程 识别类 研究用户需求，明确系统责任 研究问题域 确定系统边界 考虑问题域 审查筛选 舍弃无用对象 精简对象 与实现条件有关的对象 识别主动对象 对象分类 识别属性和操作 识别对象之间的关系 继承 当前领域的分类学知识 常识 集合关系，特征关系 属性与操作的适用范围 领域范围内的复用 关联 聚合 依赖 面向对象设计 提高软件生产率 提高质量 加强可维护性 问题域 编程语言 基础设施 复用支持 数据管理系统 界面支持系统 设计 为复用设计与编程的类增加结构 增加一般类以建立共同协议 按编程语言调整继承和多态 提高性能 为实现对象永久存储做修改 为编程方便添加低层细节 人机交互部分 设计准则 使用简便 减少人脑记忆负担 减少重复输入 容错性 及时反馈 防止灾难性错误 控制驱动部分 数据管理部分 面向对象编程 程序设计范型 面向过程程序设计范型 模块化程序设计范型 OOP语言 选择 评价标准 能否描述类和对象 能够实现一般-特殊结构 如何实现整体-部分结构 如何实现属性和操作 如何实现关联和消息通讯 用非OO编程语言实现OOD模型 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-09 06:59:47 "},"软件工程/领域驱动设计.html":{"url":"软件工程/领域驱动设计.html","title":"领域驱动设计","keywords":"","body":"领域驱动设计 模型 模型：对知识进行了选择性的简化和有意的结构化 模型与设计相互影响 模型是团队的通用语言 模型是浓缩的知识 有效建模的要素 模型与实现绑定 如果模型不能帮助开发可运行的软件 那就毫无意义 寻找一种可以绑定模型与程序设计的设计 建立了基于模型的语言 蕴含丰富的知识 提炼模型 不断对模型精简或者增加元素 讨论 语言 领域模型可以作为一种语言 文档与图 文档不应重复表示代码已经明确表达的内容 领域 分层架构 用户界面层（或表示层） 负责向用户显示信息和解释用户指令。这里指的用户可以是另一个计算机系统，不一定是使用用户界面的人 应用层 定义软件要完成的任务，并且指挥表达领域概念的对象来解决问题。这一层所负责的工作对业务来说意义重大，也是与其他系统的应用层进行交互的必要渠道 应用层要尽量简单，不包含业务规则或者知识，而只为下一层中的领域对象协调任务，分配工作，使它们互相协作。它没有反映业务情况的状态，但是却可以具有另外一种状态，为用户或程序显示某个任务的进度 领域层（或模型层） 负责表达业务概念，业务状态信息以及业务规则。尽管保存业务状态的技术细节是由基础设施层实现的，但是反映业务情况的状态是由本层控制并且使用的。**领域层是业务软件的核心** 基础设施层 为上面各层提供通用的技术能力：为应用层传递消息，为领域层提供持久化机制，为用户界面层绘制屏幕组件，等等。基础设施层还能够通过架构框架来支持4个层次间的交互模式 软件中的模型 关联 代表领域中两个实体的关联 以及技术里的关联 实体 Entity 由标志所定义的对象 这个标识是什么？是一个ID 值对象 Value Object 没有概念标识的对象 作为一个临时对象 通常用来传递消息 Service 有些操作是无法归类到某个值对象或者实体上面 需要使用Service来封装这些行为 模块 Module 对一些职责类似的对象进行边界上下文封装 建模范式 对象范式 非对象范式 混合范式 领域对象的生命周期 Aggregate Aggregate就是一组相关对象的集合，我们把它作为数据修改的单元。每个Aggregate都有一个根（root）和一个边界（boundary）。边界定义了Aggregate的内部都有什么。根则是Aggregate所包含的一个特定Entity。对Aggregate而言，外部对象只可以引用根，而边界内部的对象之间则可以互相引用 Factory 当创建一个对象或创建整个Aggregate时，如果创建工作很复杂，或者暴露了过多的内部结构，则可以使用Factory进行封装。 创建方法要是原子的 工厂应该创建抽象类型 而不是具体类 Repositry 客户需要一种有效的方式来获取对已存在的领域对象的引用 Repository是一个简单的概念框架，它可用来封装对数据库的检索技术 对类型进行抽象 充分利用与客户端解耦的优点 将事务的控制权交给客户 重构 为实现更深层次模型而进行重构 突破 提炼概念 有没有一些术语能够简洁地表达出复杂的概念 借助领域专家 书籍 不断尝试 隐式概念 注意约束 Specification 模式就可以用来约束对象状态 将过程提炼为领域对象 柔性设计 乐于使用 易于修改 模式：Intention-Revealing Interfaces 使用封装来解释代码的意图 模式：Side-Effect-Free Function 将操作粗略分为有副作用的命令以及无副作用的查询 模式：Assertion 声明前置条件与后置条件 模式：Conceptual Contour 概念轮廓 将设计元素组织成内聚的单元 模式：Standalong Class 类尽可能保持与其他类的低耦合 以此降低依赖带来的复杂度 模式：Closure Of Operation 闭合操作 入参类型与出参类型相同 声明式设计 把代码写成一种可执行的规则 也就说必须遵守某种预先定义好的规则 基于规则的编程 DSL 切入问题 分割子领域 尽可能利用已有的形式 战略设计 保持模型的完整性 看似相同的概念其实并不是同一个东西 模式：Bounded Context 限定模型的工作范围 模式：Continuous Integration 使用CI快速发现模型的错误 模式：Context Map 使用该模式描述两个边界上下文之间的关系 模式：Shared Kernel 模式：Customer/SupplierDevelopment Team 建立上下游系统关系 模式：Conformist 使用承诺维护上下游系统关系 模式：Anticorruption Layer 封装遗留/外部系统 模式：Separate Way 子系统分道扬镳 独立演化 继承总是代价高昂 而且又是获益却很小 模式：Open Host Service 定义一套Service 暴露给其他系统 模式：Published Language 使用一种通用的语言作为通信媒介 精炼 模式：Core Domain 针对核心领域模型进行优化、开发 模式：Gneric Subdomain 降低非核心领域模型的优先级 模式：Domain Vision Statement 简短描述领域模型 模式：Highlighted Core 标记核心领域模型相关元素 模式：Cohesive Mechanism 当模型的某些行为变得复杂时 将这些行为抽离到一个独立的框架里 模式：Segregated Core 增强Core的内聚性 模式：Abstract Core 对核心领域进一步抽象 降低复杂度 大型结构 通过重构来得到这些结构 模式：Evolving Order 让结构随着代码一起演变 模式：System Metaphor 一种促进系统一致性的隐喻 模式：Responsibility Layer 注意系统中的依赖 根据依赖可能会形成自然的层次结构 进而进行抽取 模式：Knowledge Level 分层提高定制灵活度 模式：Pluggable Component Framework 设计一个可插拔的灵活框架 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-27 02:47:07 "},"软件工程/面向对象范式.html":{"url":"软件工程/面向对象范式.html","title":"面向对象范式","keywords":"","body":"面向对象范式 科学思维 理想化 将未知问题转换为已知问题 工程思维 受到实际因素制约 局部最优解 分解与抽象 两种方式都是降低复杂度的手段 分层 分解与抽象组合使用对系统进行分层，缩小关注点，降低复杂性 结构化编程 按算法分解 结构化的方式，使代码更好地被理解 问题 不容易读 不容易维护 数据流图 所有的计算系统都是信息的处理与转换系统 结构图 代表模块之间的依赖关系 消除重复 抽象 测试 语句覆盖 分支覆盖 路径覆盖 特性 变更是不可避免的 做好对可以预期到的变更的设计 可修改 可操作性 世界观 数据职责（对象的本质特征）与行为职责（拥有数据后体现的行为）绑定 class Person { Date birthday; getAge(); } 类 对现实世界进行建模 抽象、隐藏细节 确定类 确定名词概念 确定所有数据与行为是否为必要 有行为有状态 -> 概念类 有状态无行为 -> 其他类 无状态有行为 -> 划分到概念类 无状态无行为 -> 抛弃 重用 不要重复造轮子？ 架构、框架/类库、模式、继承 封装 将需求的变更封装在类里 防御式编程 所有的输入，认为都有可能出错 职责 执行一项任务或掌握某种信息的义务 协作 自底向上职责聚合 自顶向下职责拆分 类关系 依赖 关联 聚合 组合 可修改性 可修改 可扩展 灵活 继承 代码重用 抽象 组合与继承 在继承中，如果父类是脆弱的，那么父类接口发生一点改变就会影响到子类的行为 使用时，保证使用继承是一种is a的关系 多态 作用：消除类型之间的耦合关系 编译器策略与运行时策略不一致 接口 一个纯抽象的类，少了抽象类的一些限制 按接口编程 定义一个契约，将变化隔离在某一部分内 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-05-09 02:45:25 "},"软件工程/敏捷软件开发.html":{"url":"软件工程/敏捷软件开发.html","title":"敏捷软件开发","keywords":"","body":"敏捷软件开发 敏捷开发以用户的需求进化为核心，采用迭代、循序渐进的方法进行软件开发。在敏捷开发中，软件项目在构建初期被切分成多个子项目，各个子项目的成果都经过测试，具备可视、可集成和可运行使用的特征。换言之，就是把一个大项目分为多个相互联系，但也可独立运行的小项目，并分别完成，在此过程中软件一直处于可使用状态。 敏捷联盟 个体交互 胜过 过程和工具 项目的关键因素是人 但是一个好过程并不能帮助项目成功 可以工作的软件 胜过 面面俱到的文档 过多的文档比过少的文档更糟 客户合作 胜过 合同谈判 成功的项目需要有序频繁的客户反馈 响应变化 胜过 遵循计划 对于下两周 做好详细的计划 为下三个月做好粗略的计划 三个月以后的事 就做极为粗糙的计划 原则 尽早交付 欢迎需求变更 交付间隔越短越好 客户与开发团队一起工作 重视人的因素 使用可以工作的软件衡量工作进度 提倡恒定的开发速度 简单就好 自组织的团队 不断反省 调整自身 极限编程 实践原则 客户作为团队成员 用户故事 短交付周期 迭代 发布 验收测试 结对编程 减少缺陷率 促进知识传播 测试驱动开发 集体所有权 持续集成 可持续的开发速度 开放的工作空间 计划游戏 简单设计 重构 隐喻 测试 单元测试 验证操作的正确性 站在调用者的角度 促使解耦 验收测试 针对每个特性编写测试脚本 敏捷设计 拙劣设计的症状 僵化性 设计难以改变 脆弱性 设计容易被破坏 牢固性 设计难以重用 粘滞性 难以做正确的事 不必要的复杂性 过分设计 不必要的复制 晦涩性 表达令人混乱 敏捷设计致力于保持系统设计在任何时间都尽可能简单 干净 富有表现力 设计模式 SOLID原则 COMMAND 模式 interface Command{ do(); undo(); } ACTIVE OBJECT 模式 while(commandListNotEmpty){ getCommandAndExecute(); } MONSTATE 模式 通过封装来使整个系统的某个对象以单一的形式展示 无需对外暴露其本身性质 NULL OBJECT 模式 使用一个空对象来代替空指针 Scrum模型 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-11 07:36:23 "},"软件工程/软件工艺.html":{"url":"软件工程/软件工艺.html","title":"软件工艺","keywords":"","body":"软件工艺 与软件工程，软件工艺提出了一种截然不同的观点，不以工程化的观点看待软件开发，而是以工匠的视角来看待软件开发 个体软件过程？ 早期的软件工程 书中提到了早期的软件都是与硬件一起开发的，所以软件的开发必须要等待硬件开发完成 并且本书赞同了软件工程适用于超大型软件系统与安全性需求高的系统 书中批判了传统软件工程忽视了优秀设计者、程序员的作用 理解软件开发 对于很多项目，传统的软件工程方法，获取并不适用 软件工艺与传统的工艺异同 都需要学习前置技术性知识 在实践中获得技术提升 随着技术发展拥有越来越多工具或者制造变得更简单 软件工艺 软件开发慢慢变成了劳动密集型产业 工艺比工程关注的点是人这个因素 软件工艺拒绝精细的分工 软件工艺意味着使用稳定的技术 会编程不等于会开发软件 大型项目适用于软件工程，中小型项目适用于软件工艺 最佳实践来源于软件工程 软件开发理应有其乐趣。否则，开发过程就是错的 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-16 07:18:41 "},"软件工程/软件测试.html":{"url":"软件工程/软件测试.html","title":"软件测试","keywords":"","body":" 静态分析 动态测试 目标 发现错误 软件测试与软件调试 过程 原则 对计算机软件进行测试前，首先需遵循软件测试原则，即不完全原则的遵守。不完全原则即为若测试不完全、测试过程中涉及免疫性原则的部分较多，可对软件测试起到一定帮助。因软件测试因此类因素具有一定程度的免疫性，测试人员能够完成的测试内容与其免疫性成正比，若想使软件测试更为流畅、测试效果更为有效，首先需遵循此类原则，将此类原则贯穿整个开发流程，不断进行测试，而并非一次性全程测试。 白盒测试 控制流程图 路径测试 语句测试 分支测试 条件组合测试 循环的测试 黑盒测试 事务流测试 等价类划分 边界值分析 步骤 单元测试 集成测试 确认测试 系统测试 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-26 09:05:17 "},"软件工程/项目管理.html":{"url":"软件工程/项目管理.html","title":"项目管理","keywords":"","body":" 指在项目活动中运用专门的知识、技能、工具和方法，使项目能够在有限资源限定条件下，实现或超过设定的需求和期望的过程 CPM 项目管理框架 项目管理内容 1、项目范围管理 2、项目时间管理 3、项目成本管理 4、项目质量管理 5、项目人力资源管理 6、项目沟通管理 7、项目风险管理 8、项目采购管理 9、项目集成管理 工具和技术 软件项目管理 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-26 09:05:17 "},"软件工程/人月神话.html":{"url":"软件工程/人月神话.html","title":"人月神话","keywords":"","body":"人月神话 编程的苦与乐 创造 非重复 交流 概念过时 人月 软件开发是一种需要人员沟通交流的非个体独立性工作 投入更多的人并不能更快地完成工作 外科手术式队伍 软件工艺式 精英领导 大众辅助 系统设计 概念完整性 唯一不变的变化就是变化本身 项目 灾祸通常来自白蚁的肆虐 而非龙卷风的侵袭 复杂性是这个行业的属性 没有银弹 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-02 04:48:17 "},"软件工程/CMM.html":{"url":"软件工程/CMM.html","title":"CMM","keywords":"","body":" 软件过程能力成熟度模型 高过程 低过程 五级标准 初始级 可重复级 已定义级 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-30 09:02:43 "},"软件工程/DevOps.html":{"url":"软件工程/DevOps.html","title":"DevOps","keywords":"","body":"DevOps DevOps（Development和Operations的组合词）是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。 代码托管 虚拟化 持续集成、交付 无缺陷编程目标 软件开发的困难 复杂 不可见 可变 一致性：兼容 软件发展的三个阶段 软件依附于硬件 软件成为独立产品 网络化服务化 个体软件过程（PSP） 与软件质量（满足用户的期望）息息相关 典型的用户期望 正常工作 性能 非功能需求（安全、可靠） 质量策略 缺陷管理 基本流程 策划 设计 编码 单元测试 总结 基本原理 软件系统的质量由组成该系统的质量最差组件决定 软件质量与软件工程师息息相关 建立持续自我改进机制 过程度量 规模 精确的规模度量在早期很难 时间 良好的时间度量有助于工程师的能力 缺陷 日程 为什么要度量 体现决策者对要实现目标的关切程度 高质量的开发是计划出来的 质量路径 测试提高质量 评审消除缺陷提高质量 PSP 评审手段消除缺陷比测试消除效率更高 有效的评审 评审检查表 分析整理历史项目的缺陷，辅助开展评审 质量控制指标 设计质量：设计的时间应该大于编码的时间 设计评审质量:设计评审的时间应该大于设计时间的50% 代码评审质量:代码评审时间应该大于编码时间的50% 代码质量:代码的编译缺陷密度应当小于10个/千行 程序质量:代码单元测试缺陷密度应当小于5个/千行 其他 环境 对阅读代码的辅助 时机 单元测试之前 个人评审与小组评审相结合 缺陷预防 敏捷软件开发 应对模糊需求、快速变化需求的最佳方法 价值观 个体和互动 高于 流程和工具 工作的软件 高于 详尽的文档 客户合作 高于 合同谈判 响应变化 高于 遵循计划 尽管右项有价值，但是左项大于右项 简单 反馈 沟通 勇气 尊重 原则 快速反馈 及早交付 简洁为本 方法 极限编程 scrum kanban kanban 渐进增量式过程改进方法学 可视化工作流 限制进行中的工作 物理看板（信息辐射强） 使用 列非固定的，随时间空间变化而变化 可以根据此看到工作状态与潜在问题 记事贴写什么？ 工作描述· 电子系统唯一标识 完成期限 负责人 工作类型 保证工作项的粒度粗细差别不大 降低前置时间（任务从开始到结束的时间）是一个追求目标 需要限制每列中的卡片 实践 技术实践： CI TDD 重构 结对编程 精益思想 消除浪费 不能增加价值的行为即为浪费 增强学习（项目内容） 尽量延迟决定 尽快发布，尽快交付 下放权力 内置完整性 全局优化 工具 任务板... 软件架构演化 单体架构 全部功能被集成在一起作为一个单一的单元 分层架构 关注点分离 每一层有特定的职责，上层只能直接访问下层 面向服务架构 关注点分离 延迟绑定（设计到运行） 消息总线与服务编排引擎 微服务架构 围绕业务能力构建的可独立开发部署的小型单元，使用远程调用进行通信 核心模式 服务注册与发现 api网关 熔断器 挑战： 对运维监控的挑战 发布更复杂，出现分布式问题 部署依赖性强 通信成本高 云原生与容器 现代应用的十二范式 云原生 可快速可靠交付软件 微服务 DevOps 持续交付 使用敏捷开发来实现加快发布速度 容器 将不同特点的应用打包成一个标准化的应用 有效分配与管理物理资源 资源隔离 容器编排与调度 分布式应用由多个容器实例组成 需要一种高效的方法来管理容器集群 容器与devops 此前交付的东西是代码 当使用容器之后，交付的就是一个镜像 XaaS 什么 即 服务 SaaS 中心化的软件的分发方式，通过网络使用软件 IaaS 虚拟化硬件资源给用户 PaaS 提供给开发者使用 IT服务标准 CMMI-SVC ITIL ISO20000 ITSS 工具链 协同开发 工作可视化。加强沟通 JIRA KanBan Rally 持续集成 jenkins 版本管理 git svn 编译工具 ant maven gradle msbuild 测试工具 junit selenium（ui测试） cucumber（自动化验收） fitnesse（管理） 监控 nagios zabbix 持续交付 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-05-08 12:36:40 "},"软件工程/ServiceComb.html":{"url":"软件工程/ServiceComb.html","title":"ServiceComb","keywords":"","body":" 致力于帮助企业、用户和开发者将企业应用轻松微服务化上云，并实现对微服务应用的高效运维管理。其提供一站式开源微服务解决方案，融合SDK框架级、0侵入ServiceMesh场景并支持多语言 设计思想 编程模型和通信模型分离，不同的编程模型可以灵活组合不同的通信模型。应用开发者在开发阶段只关注接口开发，部署阶段灵活切换通信方式；支持legacy系统的切换，legacy系统只需要修改服务发布的配置文件（或者annotation），而不需要修改代码。现阶段支持SpringMVC、JAX-RS和透明RPC三种开发方式。 内建API-first支持。通过契约规范化微服务开发，实现跨语言的通信，并支持配套的软件工具链（契约生成代码、代码生成契约等）开发，构建完整的开发生态。 定义了常用的微服务运行模型，将微服务从发现到交互过程中的各种容错手段都封装起来。该运行模型支持自定义和扩展。 注册中心 安装运行 docker pull servicecomb/service-center docker run -d -p 30100:30100 servicecomb/service-center:latest MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"软件工程/编码/编码.html":{"url":"软件工程/编码/编码.html","title":"编码","keywords":"","body":"编码 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-27 01:02:45 "},"软件工程/编码/代码重构.html":{"url":"软件工程/编码/代码重构.html","title":"代码重构","keywords":"","body":"代码重构 在不改变代码外在行为的前提下，对代码进行修改，以改进程序的内部结构 如果你要给程序添加一个特性，但发现代码因缺乏良好的结构而不易于进行更改，那就先重构那个程序，使其比较容易添加该特性，然后再添加该特性。 重构前，先检查自己是否有一套可靠的测试代码。这些测试必须有自我检验能力。 重构技术就是以微小的步伐修改程序。 如果你犯下错误，很容易便可发现它。 重构原则 为何重构 改进软件的设计 使代码更容易理解 提高编程速度 何时重构 预备性重构：添加新功能的时候 帮助理解的重构：为了理解系统或者代码所做的工作 捡垃圾式重构：偶然发现一处坏代码，重构它 修复错误的时候 代码审查的时候 何时不该重构 不会被用到的代码 重构的代价比重写的代价还高的代码 如何保证重构的正确性 测试是保证代码正确性的强有力保证 自动化 测试不通过真的会失败 频繁运行测试 注意边界条件 使用测试来重现bug 代码的坏味道 奇怪的命名 重复代码 过长的函数 过长的参数列表 全局数据 可变数据 发散式变化 一个修改会影响到许多地方 霰弹式修改 一个变化需要修改许多地方 过度依赖外部模块 类中重复的数据 基本类型偏执 总觉得基本类型效率更高，不愿使用对象 大量重复的switch/if 复杂的循环语句 冗余的元素 一个简单的函数、一个简单的操作 过度设计的通用性 过度考虑了对象/函数的用途 临时字段 过长的对象调用 没有必要的中间对象 两个模块耦合过紧 考虑将它们移动到新模块 过大的类 过度相似的类 纯数据类 数据和行为没有在一起 继承父类，但不提供父类的接口 重构列表 函数/变量 提炼函数 根据代码意图进行拆分函数，如果发现一段代码需要阅读一会才能知道是干嘛的，那就提炼它 function printOwing(invoice) { 　printBanner(); 　let outstanding = calculateOutstanding(); 　//print details 　console.log(`name: ${invoice.customer}`); 　console.log(`amount: ${outstanding}`); } ↓ function printOwing(invoice) { 　printBanner(); 　let outstanding = calculateOutstanding(); 　printDetails(outstanding); 　function printDetails(outstanding) { 　　console.log(`name: ${invoice.customer}`); 　　console.log(`amount: ${outstanding}`); 　} } 内联函数 提炼函数的反向操作 如果函数的代码跟函数名称一样拥有可读性，那么可以直接内联它 提炼变量 给一些表达式起个有意义的名称，有助于阅读、调试 return order.quantity * order.itemPrice - 　Math.max(0, order.quantity - 500) * order.itemPrice * 0.05 + 　Math.min(order.quantity * order.itemPrice * 0.1, 100) ↓ const basePrice = order . quantity * order . itemPrice; const quantityDiscount = Math. max(0, order . quantity - 500) * order. itemPrice * 0.05; const shipping = Math. min(basePrice * 0.1, 100); return basePrice - quantityDiscount + shipping; 内联变量 上述的反向重构 有些表达式本身就已经很有语义，没必要引入变量再来说明 改变函数签名 注意函数签名的上下文，不同的上下文通用性程度不一样 直接修改 迁移式 暴露新旧两个接口，将旧接口设置为废弃 封装变量 对于访问域过大的数据，使用函数进行封装，这样在重构、监控上更加容易 let defaultOwner = {firstName: \"Martin\", lastName: \"Fowler\"}; ↓ let defaultOwnerData = {firstName: \"Martin\", lastName: \"Fowler\"}; export function defaultOwner() {return defaultOwnerData;} export function setDefaultOwner(arg) {defaultOwnerData = arg;} 变量改名 好的命名是整洁代码的核心 引入参数对象 让数据项自己的关系变得清晰，并且缩短参数列表 function amountInvoiced(startDate, endDate) {...} function amountReceived(startDate, endDate) {...} function amountOverdue(startDate, endDate) {...} ↓ function amountInvoiced(aDateRange) {...} function amountReceived(aDateRange) {...} function amountOverdue(aDateRange) {...} 函数组合成类 发现行为与数据之间的联系，发现其他的计算逻辑 function base(aReading) {...} function taxableCharge(aReading) {...} function calculateBaseCharge(aReading) {...} ↓ class Reading { base() {...} taxableCharge() {...} calculateBaseCharge() {...} } 合并函数 对于多个操作相同的数据，并且逻辑可以集中的函数，可以将它们合并成同一个函数 function base(aReading) {...} function taxableCharge(aReading) {...} ↓ function enrichReading(argReading) { const aReading = _.cloneDeep(argReading); aReading.baseCharge = base(aReading); aReading.taxableCharge = taxableCharge(aReading); return aReading; } 拆分阶段 一段代码做了多件事，将它拆分为多个函数 封装 封装记录 封装能更好地应对变化 organization = {name: \"Acme Gooseberries\", country: \"GB\"}; ↓ class Organization {...} 封装集合 对集合成员变量进行封装，返回其一个副本，避免其被修改带来的诸多问题 class Person { get courses() {return this._courses;} set courses(aList) {this._courses = aList;} } ↓ class Person { get courses() {return this._courses.slice();} addCourse(aCourse) { ... } removeCourse(aCourse) { ... } } 以对象取代基本类型 一开始使用基本类型能很好地表示，但随着代码演进，这些数据可能会产生一些行为，此时最好将其封装为对象 orders.filter(o => \"high\" === o.priority || \"rush\" === o.priority); ↓ orders.filter(o => o.priority.higherThan(new Priority(\"normal\"))) 以查询取代临时变量 使用函数封装临时变量的计算，对于可读性、可复用性有提升 const basePrice = this._quantity * this._itemPrice; if (basePrice > 1000) return basePrice * 0.95; else return basePrice * 0.98; ↓ get basePrice() {this._quantity * this._itemPrice;} ... if (this.basePrice > 1000) return this.basePrice * 0.95; else return this.basePrice * 0.98; 提炼类 随着代码演进，类不断成长，会变得越加复杂，需要拆分它 class Person { 　get officeAreaCode() {return this._officeAreaCode;} 　get officeNumber() {return this._officeNumber;} } ↓ class Person { 　get officeAreaCode() {return this._telephoneNumber.areaCode;} 　get officeNumber() {return this._telephoneNumber.number;} } class TelephoneNumber { 　get areaCode() {return this._areaCode;} 　get number() {return this._number;} } 内联类 上述的反向操作，由于类职责的改变，或者两个类合并在一起会更加简单 隐藏委托关系 封装意味着模块间相互了解的程度应该尽可能小，一旦发生变化，影响也会较小 manager = aPerson.department.manager; ↓ manager = aPerson.manager; class Person { get manager() {return this.department.manager;} } 移除中间人 上述的反向操作，对于一些没必要的委托，可以直接让其跟真实对象打交道，避免中间层对象成为一个纯粹的转发对象 替换算法 不改变行为的前提下，将比较差的算法替换成比较好的算法 function foundPerson(people) { 　for(let i = 0; i ↓ function foundPerson(people) { 　const candidates = [\"Don\", \"John\", \"Kent\"]; 　return people.find(p => candidates.includes(p)) || ''; } 搬移特性 搬移函数 对于某函数，如果它频繁使用了其他上下文的元素，那么就考虑将它搬移到那个上下文里 class Account { 　get overdraftCharge() {...} } ↓ class AccountType { get overdraftCharge() {...} } 搬移字段 对于早期设计不良的数据结构，使用此方法改造它 class Customer { get plan() {return this._plan;} get discountRate() {return this._discountRate;} } ↓ class Customer { get plan() {return this._plan;} get discountRate() {return this.plan.discountRate;} } 搬移语句到函数 使用这个方法将分散的逻辑聚合到函数里面，方便理解修改 result.push(`title: ${person.photo.title}`); result.concat(photoData(person.photo)); function photoData(aPhoto) { 　return [ 　　`location: ${aPhoto.location}`, 　　`date: ${aPhoto.date.toDateString()}`, ]; } ↓ result.concat(photoData(person.photo)); function photoData(aPhoto) { 　return [ 　　`title: ${aPhoto.title}`, 　　`location: ${aPhoto.location}`, 　　`date: ${aPhoto.date.toDateString()}`, 　]; } 搬移语句到调用者 上述的反向操作 对于代码演进，函数某些代码职责发生变化，将它们移除出去 以函数调用取代内联代码 一些函数的函数名就拥有足够的表达能力 let appliesToMass = false; for(const s of states) { if (s === \"MA\") appliesToMass = true; } ↓ appliesToMass = states.includes(\"MA\"); 移动语句 让存在关联的东西一起出现，可以使代码更容易理解 const pricingPlan = retrievePricingPlan(); const order = retreiveOrder(); let charge; const chargePerUnit = pricingPlan.unit; ↓ const pricingPlan = retrievePricingPlan(); const chargePerUnit = pricingPlan.unit; const order = retreiveOrder(); let charge; 拆分循环 对一个循环做了多件事的代码，拆分它，使各段代码职责更加明确 虽然这样可能会对性能造成一些损失 let averageAge = 0; let totalSalary = 0; for (const p of people) { 　averageAge += p.age; 　totalSalary += p.salary; } averageAge = averageAge / people.length; ↓ let totalSalary = 0; for (const p of people) { 　totalSalary += p.salary; } let averageAge = 0; for (const p of people) { 　averageAge += p.age; } averageAge = averageAge / people.length; 以管代取代循环 一些逻辑如果采用管道编写，可读性会更强 const names = []; for (const i of input) { if (i.job === \"programmer\") names.push(i.name); } ↓ const names = input .filter(i => i.job === \"programmer\") .map(i => i.name); 移除死代码 移除那些永远不会允许的代码 重新组织数据 拆分变量 如果一个变量被用于多种用途，很明显违反了单一职责原则，这样的代码会造成理解上的困难 let temp = 2 * (height + width); console.log(temp); temp = height * width; console.log(temp); ↓ const perimeter = 2 * (height + width); console.log(perimeter); const area = height * width; console.log(area); 字段改名 对于命名不够良好的字段进行改名 以查询取代派生变量 使用查询封装变量是消除可变数据的第一步 get discountedTotal() {return this._discountedTotal;} set discount(aNumber) { 　const old = this._discount; 　this._discount = aNumber; 　this._discountedTotal += old - aNumber; } ↓ get discountedTotal() {return this._baseTotal - this._discount;} set discount(aNumber) {this._discount = aNumber;} 将引用对象改为值对象 如果非一定需要引用对象，使用值对象不可变的特性能避免很多问题 将值对象改为引用对象 如果一个对象需要在多个地方做更新，值对象就不适合了，需要改为引用 简化条件逻辑 分解条件表达式 使用函数封装条件逻辑，提升代码的可理解性 if (!aDate.isBefore(plan.summerStart) && !aDate.isAfter(plan.summerEnd)) 　charge = quantity * plan.summerRate; else 　charge = quantity * plan.regularRate + plan.regularServiceCharge; ↓ if (summer()) 　charge = summerCharge(); else 　charge = regularCharge(); 合并条件表达式 一些条件的返回值都相等，就将它们封装到同一个函数逻辑里面 if (anEmployee.seniority 12) return 0; if (anEmployee.isPartTime) return 0; ↓ if (isNotEligibleForDisability()) return 0; function isNotEligibleForDisability() { 　return ((anEmployee.seniority 12) 　　　　　|| (anEmployee.isPartTime)); } 以卫语句取代嵌套条件表达式 有时候单一出口原则，似乎不是那么重要 function getPayAmount() { 　let result; 　if (isDead) 　　result = deadAmount(); 　else { 　　if (isSeparated) 　　　result = separatedAmount(); 　　else { 　　　if (isRetired) 　　　　result = retiredAmount(); 　　　else 　　　　result = normalPayAmount(); 　　} 　} 　return result; } ↓ function getPayAmount() { 　if (isDead) return deadAmount(); 　if (isSeparated) return separatedAmount(); 　if (isRetired) return retiredAmount(); 　return normalPayAmount(); } 以多态取代条件表达式 如果发现一些行为适合用多态取代，试试这样重构它 switch (bird.type) { 　case 'EuropeanSwallow': 　　return \"average\"; 　case 'AfricanSwallow': 　　return (bird.numberOfCoconuts > 2) ? \"tired\" : \"average\"; 　case 'NorwegianBlueParrot': 　　return (bird.voltage > 100) ? \"scorched\" : \"beautiful\"; 　default: 　　return \"unknown\"; ↓ class EuropeanSwallow { 　get plumage() { 　　return \"average\"; 　} class AfricanSwallow { 　get plumage() { 　　 return (this.numberOfCoconuts > 2) ? \"tired\" : \"average\"; 　} class NorwegianBlueParrot { 　get plumage() { 　　 return (this.voltage > 100) ? \"scorched\" : \"beautiful\"; } 引入特例 所谓特例，就是满足这个类的行为，但却表达了特例的含义 if (aCustomer === \"unknown\") customerName = \"occupant\"; ↓ class UnknownCustomer { get name() {return \"occupant\";} 引入断言 断言提供了一种对系统当前状态的假设，对调试以及阅读很有帮助 if (this.discountRate) base = base - (this.discountRate * base); ↓ assert(this.discountRate>= 0); if (this.discountRate) base = base - (this.discountRate * base); 重构API 查询函数和修改函数分离 对于无副作用的函数，有助于测试 function getTotalOutstandingAndSendBill() { const result = customer.invoices.reduce((total, each) => each.amount + total, 0); sendBill(); return result; } ↓ function totalOutstanding() { return customer.invoices.reduce((total, each) => each.amount + total, 0); } function sendBill() { emailGateway.send(formatBill(customer)); } 函数参数化 本质还是消除重复，将函数名字中的参数提取到参数列表中 function tenPercentRaise(aPerson) { aPerson.salary = aPerson.salary.multiply(1.1); } function fivePercentRaise(aPerson) { aPerson.salary = aPerson.salary.multiply(1.05); } ↓ function raise(aPerson, factor) { aPerson.salary = aPerson.salary.multiply(1 + factor); } 移除标记参数 标记参数的存在会增加理解接口调用的难度 function setDimension(name, value) { 　if (name === \"height\") { 　　this._height = value; 　　return; 　} 　if (name === \"width\") { 　　this._width = value; 　　return; 　} } ↓ function setHeight(value) {this._height = value;} function setWidth (value) {this._width = value;} 保持对象完整 传递整个对象能更好地应对未来的变化 const low = aRoom.daysTempRange.low; const high = aRoom.daysTempRange.high; if (aPlan.withinRange(low, high)) ↓ if (aPlan.withinRange(aRoom.daysTempRange)) 以查询取代参数 参数列表尽量避免重复，参数列表越短越容易理解 availableVacation(anEmployee, anEmployee.grade); function availableVacation(anEmployee, grade) {} ↓ availableVacation(anEmployee) function availableVacation(anEmployee) {} 以参数取代查询 上述操作的反向重构，如果不想函数依赖某个元素，那就使用这个方式 移除设值函数 取消设值函数，代表着数据不应该被修改的意图 class Person { get name() {...} set name(aString) {...} } ↓ class Person { get name() {...} } 以工厂函数取代构造函数 构造函数使用起来较不灵活，尝试把创建对象的职责交给工厂 leadEngineer = new Employee(document.leadEngineer, 'E'); ↓ leadEngineer = createEngineer(document.leadEngineer); 以命名取代函数 命令对象大都服务于单一的函数，命令相交于过程性代码，拥有了大部分面向对象的能力 function score(candidate, medicalExam, scoringGuide) { let result = 0; let healthLevel = 0; // long body code } ↓ class Scorer { constructor(candidate, medicalExam, scoringGuide) { this._candidate = candidate; this._medicalExam = medicalExam; this._scoringGuide = scoringGuide; } execute() { this._result = 0; this._healthLevel = 0; // long body code } } 以函数取代命令 上述的反向重构，在不是很复杂的情况下，直接使用函数完成任务即可 处理继承关系 函数上移 本质上还是为了避免重复，重复代码是滋生bug的温床 class Employee {...} class Salesman extends Employee { 　get name() {...} } class Engineer extends Employee { 　get name() {...} } ↓ class Employee { 　get name() {...} } class Salesman extends Employee {...} class Engineer extends Employee {...} 字段上移 同上，函数换成字段 构造函数本体上移 将子类里的共同行为提取到父类 class Party {...} class Employee extends Party { 　constructor(name, id, monthlyCost) { 　　super(); 　　this._id = id; 　　this._name = name; 　　this._monthlyCost = monthlyCost; 　} } ↓ class Party { 　constructor(name){ 　　this._name = name; 　} } class Employee extends Party { 　constructor(name, id, monthlyCost) { 　　super(name); 　　this._id = id; 　　this._monthlyCost = monthlyCost; 　} } 函数下移 函数上移的反向重构，如果超类的某个函数只与部分子类有关，那就需要将函数下移 字段下移 字段上移的反向重构，动机同上 以子类取代类型码 使用多态来替代逻辑判断 function createEmployee(name, type) { return new Employee(name, type); } ↓ function createEmployee(name, type) { switch (type) { case \"engineer\": return new Engineer(name); case \"salesman\": return new Salesman(name); case \"manager\": return new Manager (name); } 移除子类 随着代码演进，子类压根就不需要了 class Person { 　get genderCode() {return \"X\";} } class Male extends Person { 　get genderCode() {return \"M\";} } class Female extends Person { 　get genderCode() {return \"F\";} } ↓ class Person { get genderCode() {return this._genderCode;} } 提炼超类 如果两个类再做相似的事，利用继承机制将它们的相似之处进行提炼 class Department { 　get totalAnnualCost() {...} 　get name() {...} 　get headCount() {...} } class Employee { 　get annualCost() {...} 　get name() {...} 　get id() {...} } ↓ class Party { 　get name() {...} 　get annualCost() {...} } class Department extends Party { 　get annualCost() {...} 　get headCount() {...} } class Employee extends Party { 　get annualCost() {...} 　get id() {...} } 折叠继承体系 随着继承体系演化，一个类与其超类已经没有多大区别 class Employee {...} class Salesman extends Employee {...} ↓ class Employee {...} 以委托取代子类 继承会给子类带来极大的耦合，父类的任何修改都会影响到子类，使用委托就是一种组合关系，在任何情况下，组合应该优先于继承 class Order { 　get daysToShip() { 　　return this._warehouse.daysToShip; 　} } class PriorityOrder extends Order { 　get daysToShip() { 　　return this._priorityPlan.daysToShip; 　} } ↓ class Order { 　get daysToShip() { 　　return (this._priorityDelegate) 　　　? this._priorityDelegate.daysToShip 　　　: this._warehouse.daysToShip; 　} } class PriorityOrderDelegate { 　get daysToShip() { 　　return this._priorityPlan.daysToShip 　} } 以委托取代超类 如果父类的一些接口不适合让子类暴露，那么这个类应该就通过组合的方式复用 class List {...} class Stack extends List {...} ↓ class Stack { constructor() { this._storage = new List(); } } class List {...} 速查表 坏味道（英文） 坏味道（中文） 页码 常用重构 Alternative Classes with Different Interfaces 异曲同工的类 83 改变函数声明（124），搬移函数（198），提炼超类（375） Comments 注释 84 提炼函数（106），改变函数声明（124），引入断言（302） Data Class 纯数据类 83 封装记录（162），移除设值函数（331），搬移函数（198），提炼函数（106），拆分阶段（154） Data Clumps 数据泥团 78 提炼类（182），引入参数对象（140），保持对象完整（319） Divergent Change 发散式变化 76 拆分阶段（154），搬移函数（198），提炼函数（106），提炼类（182） Duplicated Code 重复代码 72 提炼函数（106），移动语句（223），函数上移（350） Feature Envy 依恋情结 77 搬移函数（198），提炼函数（106） Global Data 全局数据 74 封装变量（132） Insider Trading 内幕交易 82 搬移函数（198），搬移字段（207），隐藏委托关系（189），以委托取代子类（381），以委托取代超类（399） Large Class 过大的类 82 提炼类（182），提炼超类（375），以子类取代类型码（362） Lazy Element 冗赘的元素 80 内联函数（115），内联类（186），折叠继承体系（380） Long Function 过长函数 73 提炼函数（106），以查询取代临时变量（178），引入参数对象（140），保持对象完整（319），以命令取代函数（337），分解条件表达式（260），以多态取代条件表达式（272），拆分循环（227） Long Parameter List 过长参数列 74 以查询取代参数（324），保持对象完整（319），引入参数对象（140），移除标记参数（314），函数组合成类（144） Loops 循环语句 79 以管道取代循环（231） Message Chains 过长的消息链 81 隐藏委托关系（189），提炼函数（106），搬移函数（198） Middle Man 中间人 81 移除中间人（192），内联函数（115），以委托取代超类（399），以委托取代子类（381） Mutable Data 可变数据 75 封装变量（132），拆分变量（240），移动语句（223），提炼函数（106），将查询函数和修改函数分离（306），移除设值函数（331），以查询取代派生变量（248），函数组合成类（144），函数组合成变换（149），将引用对象改为值对象（252） Mysterious Name 神秘命名 72 改变函数声明（124），变量改名（137），字段改名（244） Primitive Obsession 基本类型偏执 78 以对象取代基本类型（174），以子类取代类型码（362），以多态取代条件表达式（272），提炼类（182），引入参数对象（140） Refused Bequest 被拒绝的遗赠 83 函数下移（359），字段下移（361），以委托取代子类（381），以委托取代超类（399） Repeated Switches 重复的switch 79 以多态取代条件表达式（272） Shotgun Surgery 霰弹式修改 76 搬移函数（198），搬移字段（207），函数组合成类（144），函数组合成变换（149），拆分阶段（154），内联函数（115），内联类（186） Speculative Generality 夸夸其谈通用性 80 折叠继承体系（380），内联函数（115），内联类（186），改变函数声明（124），移除死代码（237） Temporary Field 临时字段 80 提炼类（182），搬移函数（198），引入特例（289） MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-05 01:27:17 "},"软件工程/编码/代码审查.html":{"url":"软件工程/编码/代码审查.html","title":"代码审查","keywords":"","body":"代码审查 代码审查也叫代码复查，即通过阅读代码的方式来检查代码是否符合要求 为何要代码审查 代码审查是提高代码质量，提前发现 BUG ，统一团队代码规范的一个重要途径 谁来审查 审查什么 设计规范 可读性与可维护性 是否有错误（需求与BUG） 测试代码是否良好 性能 安全性 审查工具 git Upsource 审查形式 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-27 01:02:45 "},"软件工程/编码/整洁代码.html":{"url":"软件工程/编码/整洁代码.html","title":"整洁代码","keywords":"","body":"整洁代码 代码是需求的精确性表达 代码不会消失 读起来令人愉悦 只做好一件事 明确地展现出要解决问题的张力 整洁代码以测试作为基础 不要重复代码 深合己意 代码更多的时候是用来读 命名 名副其实：变量 函数 类的名称要充分体现它们的作用 避免误导： 避免使用与本意相悖的词 Accounts accountList; // bad List accountList; // good 谨慎使用不同之处特别小的名称 var userPermissionControllService; var userPermissionControllerService; 以及小写字母l与大写字母O与数字 1 0 相似的情况 int l = 0; int o = 1; if (l == 0) return o = l; 有意义的区分： 避免使用数字系列命名 void copy(StringBuffer s1, StringBuffer s2); // bad void concat(StringBuffer source, StringBuffer target); // good 避免使用意义相同的名称 class Product{} class ProductInfo{} // 加个Info并没有说明什么 class ProductDetail{} 使用读得出来的名称: 方便讨论 使用可搜索的名称： 为常量命名 方便维护 double circleArea = 3.14 * Math.pow(radius, 2); // bad double CIRCLE_PI = 3.1415926; // good 名称长短与其作用域大小相对应 private static final double CIRCLE_PI = 3.14; void calcArea() { final double PI = 3.14 ... } 避免使用编码：这些技巧在IDE智能的时代有它的用处 避免匈牙利标记法在变量名称携带类型 int iPort = 8080; // 该变量为int类型 bad 避免前缀标记成员变量 private List m_listeners; // bad 避免避免接口与实现携带I前缀或者Imp后缀 interface IUserService{} // bad class UserServiceImp implements UserService {} // bad class DefaultUserService implements UserService {} // good 避免思维映射：传统管用i j 表示循环计数器 其他情况下要避免使用单字母 for (int i=0;i 类名与对象名应该是名词或者名词短语 class Customer{} Processor processor; 方法名应该是动词或者动词短语 void getServerInfo(); 命名时避免抖机灵 threadPoll.kill(); // bad threadPoll.shutdown(); // good 使用概念一致的命名： SELECT DELETE UPDATE INSERT 避免将同一术语用于不同概念 // bad void addUser(); BigDecimal addPrice(BigDecimal target); 尽量使用技术性名称而非业务领域名称 是在没有技术名词 与问题领域更近的代码 可以采用业务领域的名称 Queue jobQueue; // 技术名词 DinnerOrder order; // 业务名词 如果无法通过类或者方法来给名称提供上下文 那么只能给名称添加前缀来添加上下文了 class Address { String username; String phone; String country; String postCode; } String addressCode; // 在一个没有上下文的环境中 短名称够清楚就行了 不要添加不必要的上下文 class ShopSystemUserService {} // bad 函数 短小： 块内调用的子函数具有说明性 String renderJsp(){ var classCode = compileJsp(); return executeJspService(classCode); } 不该有复杂的嵌套结构 void badFunction() { // bad if (..) { while(){ ... for(..){..} } } } 只做一件事：函数内部的实现充分体现函数名称 确保函数中的语句在同一抽象层级上面 String renderJsp(){ var classCode = compileJsp(); return executeJspService(classCode); } 使用多态取代switch语句 // bad Money calcPay(Employee e){ switch(e.type) { case MANAGER: return e.getPay() - 20%; case COMMON: return e.getPay() - 10%; ... } } // good abstract class Employee{ abstract Money getPay(); } class CommonEmployee{ Money getPay(){...} } class ManagerEmployee{ Money getPay(){...} } 使用描述性的名称能理性设计思路 帮助改进之 var result; var searchResult; var movieSearchResult; // best 函数参数： 参数越多函数越难理解 public void convertAndSend(Object object){..} public void correlationConvertAndSend(Object object, CorrelationData correlationData){..} public void convertAndSend(String routingKey, final Object object, CorrelationData correlationData){...} // bad exchange.send(String rotingKey,Object msg); // better 使用标志参数(boolean)就代表函数不止做一件事 应该拆分成两个函数 void submitTask(Task t, boolean flag){ // 尤其flag命名并不能说明做什么 改成isSync 可能好一点 if (flag) { sync }else { async } } // good void submitTaskAsync(){...} void submitTaskSync(){...} 函数和参数应当形成一种动词/名词对形式 write(PrintWriter pw, String msg); // bad printWriter.write(msg); // good 副作用：避免使用输出参数(out) 需要修改状态 就将该状态作为对象的属性 void removeNegative(List list); // bad list.removeIf(...); // good 分割指令与询问：函数要么做什么 要么回答什么 不能两者得兼 boolean set(String k, String v){ // bad 这个函数承担了两个职责 if (exists){ return true; } ... return false; } // good boolean exists(String k); void set(String k,String v); 异常代替错误码： 错误处理代码就能从主路径代码分离出来 // bad if (!err){ if (!err){ ... } } // good try { } catch (Error1){ } catch (Error2){ } 主体以及错误处理代码可以抽离成函数 try { generateSearchResult(); } catch(){ logError(); sendErrorMsg(); } 错误码枚举一旦发生修改 依赖其的模块都要重新编译 使用继承异常的方式可以进行平滑扩展 别重复自己：重复可能是软件中一切邪恶的根源 结构化编程：单一出入口原则在大函数中才有明显的好处 注释 注释容易与代码不一致 欺骗读者 注释无法美化代码 糟糕的代码还是糟糕的代码 尽可能使用代码阐述你的意图 而非注释 好的注释 法律信息 提供信息 interface SessionFactory { // 新建一个数据库连接并返回 Session openSession(); } 对意图的解释 // 寻找0到n的素数 根据数学证明 只要到n的平方根就行了 for(int i=0;i 阐释一些难以理解的参数或者返回值 // 发送对象为空，代表是一条广播消息 if (StringUtils.isEmpty(payload.getTo())){ ... } else { broadcast } 警示会出现某种后果 // 该方法使用一个listener的确认 使用synchronized关键字保证只有一个线程能进入 public synchronized ConfirmResult sendTextMessage(String target, String text) {...} TODO注释 // 向消息队列写入消息：订单 订单详情 TODO 强调方法貌似不合理之处的重要性 void onMessage(ByteBuf buf){ ... buf.release(); // 需要减少缓冲区的引用计数 } 公共 API 中的 Javadoc 坏注释 无法给读者提供有效的信息 // 提交任务 boolean success = submitTask(); 多余的注释/废话注释 编写代码时 着重于代码的表现力 而非加之以注释 // bad 等待timeout个时间 然后关闭 void close(int timeout){ wait(timeout); close(); } 误导性注释 代码与注释所说的不是一回事 循规蹈矩注释：每个方法变量都要javadoc 日志式注释记录每一次修改 在版本控制系统出现后意义不大 标记栏注释 // 注意!!! //////////// 特别重要才使用 使用多的话 就会被淹没在大量斜杠中 括号后面的注释 对于大函数或许才有意义 try{ if (){ while(){ }//while } // if }catch{ } // catch 作者与署名 同样 VCS可以工作的更好 注释掉的代码 包含着HTML标签的注释 携带非本地信息 // 提交任务 每隔5分钟运行一次 这里的5分钟跟这个函数毫无关系 void submitTask(); 信息过多 将一些RFC提案整个添加到注释里 格式 原始代码其代码风格和可读性仍会影响到其可维护性和可扩展性 垂直格式 短文件比常文静更易于理解 // 紧密在一起的代码代表概念相关 DeliveryInfoDO deliveryInfoDO = new DeliveryInfoDO(); deliveryInfoDO.setBuilding(deliveryDTO.getBuilding()); deliveryInfoDO.setDetail(deliveryDTO.getDetail()); // 使用空白行隔开 每个空白行都是一个线索 deliveryRepository.save(deliveryInfoDO); if (deliveryDTO.getDefaultDelivery() != null && deliveryDTgetDefaultDelivery()) { consumerDeliveryRepository.resetDefaultDelivery(consumer.getUserId()); } 垂直距离： 关系密切的概念应相互靠近 本地变量声明尽可能靠近其使用位置 实体变量声明在类的顶部(Java) 有联系的函数放在一起 调用者尽可能在被调用者上面 横向格式 尽力保持代码行短小 使用空格分割相关性较弱的元素： 分割赋值操作符 int[] data = new int[10]; 分割函数参数 deliveryService.updateDelivery(token, deliveryId, deliveryDTO); 使用缩进表现源文件的继承结构 缩进可以快速展现出当前的范围 对象和数据结构 过程式代码容易在不改动数据结构的情况下增加函数 面向对象则容易在不改动函数的情况下增加新类 迪米特法则：模块不应了解它所操作对象的内部情形 // bad String url = host.getContext().getServlet().getName(); 避免在DTO中塞入逻辑 保持简单setget即可 错误处理 使用异常而非返回码 先写try-catch语句 try-catch定义了一个范围 使用TDD开发剩下的逻辑 使用不可控异常 可控异常违反了开闭原则 底层的修改会直接贯穿到高层 构造异常时 提供足够的环境说明 以便快速排错 根据调用者需要定义异常 也就说打包第三方 API try { } catch(ThirdPartException e){ throw new BusinessException(e); } 使用特例模式来避免应付异常 // bad try { getEmployee().run(); } catch(NullPointerException e){ ... } void getEmployee(){ maybe return null; } // good void getEmployee(){ normal return new Employee(); sometimes return new EmptyEmployee(); } 避免传递null 边界 整洁的边界应该避免我们的代码过多了解第三方代码中的信息 第三方包 封装第三方API来避免在系统中传递使用第三方接口 学习性测试：通过编写测试来学习第三方API 不仅可以学习API使用 同时测试也是更新第三方包时的保障 使用尚不存在的代码 通过适配器适配尚未实现的接口 来进行已知与未知的隔离 // 未知 interface ThirdPartInterface{...} // 未知与已知的交界处 interface ThirdPartAdapter extends ThirdPartInterface{...} 单元测试 脏测试等同于甚至坏于没测试 测试必须随着生产代码演进而修改 单元测试使代码可扩展 可维护 可复用 作用： 提升软件质量 促进代码优化 提升后期效率 增加重构自信 单元测试编写原则： 边界值测试 边界是最容易出错的地方 正确的输入 并得到预期的结果 错误的输入 得到预期的错误结果 整洁的测试代码 可读性 构造-操作-检验 通过不断重构测试就会慢慢得到一个文档的测试API 随着重构代码也会更有表现力 assertUserExistsInDatabase(\"cxk\"); // 一个测试API 对于测试环境 CPU内存等资源没有那么紧张 所以测试也并非一定要追求效率 每个测试应拥有尽可能少的断言 个人认为 可以对断言进行抽象 如上述的测试API 同时 测试应只测试一个概念 将多件事混杂在一起只会导致概念的混乱 @Test void testUserService(){...} // bad 过于混杂 @Test void testUserInsertFailed(){...} // better 整洁测试的准则：FIRST fast 测试运行要足够快 independent 测试之间要相互独立 repeatable 测试可在任何环境中重复通过 self-validating 通过一个布尔值表示测试是否通过（自动化） timely 测试要及时编写 指的是TDD 测试在生产代码之前编写 单元测试覆盖率 粗粒度覆盖： 方法覆盖与类覆盖 细粒度覆盖： 行覆盖 执行的语句总数 / 全部语句总数 分支覆盖 确保判定条件的真假都会被执行 if (condition) {...} // condition 为真为假的时候都要测试 条件判定覆盖 让判定条件中的语句真假都会被执行 if (condition1 && condition2) {...} // condtion1 和 condtion2 为真为假的组合 也就是要4种组合 条件组合覆盖 所有参数的可能取值 路径覆盖 测试所有可能的路径 类 组织： public static int PORT = 8080; private static String MAGIC_NUMBER = 0XCAFE_BABE; private String instanceName; protected String subName; public void run(){...} private void innerRun(){...} 尽可能进行封装 除非玩不得以 否则不要暴露 类应该短小： 判断类短小的标准使用职责数来衡量 而非代码行数 系统应该由许多短小的类而非少量巨大的类组成 类应只由少量实体变量组成 这些变量如果同时被越多的函数操作 就代表这个类内聚性越高 通过拆分函数以及函数相关的实体变量到其他类来将一个大类拆分为几个小类 方便修改的组织： 符合OCP 使用接口隔离修改 当采取诸如DIP等原则时 系统各个组件的耦合就已经非常低了 此时也方便测试 系统 分离系统的构造与使用 使用main组件： 使用工厂控制对象的创建 使用依赖注入容器来管理对象 测试驱动系统架构 代码层面与架构关注面分离开 避免侵入性代码 没有必要先做大设计 延迟决策 使用DSL 填平了领域与实现之间代码的壕沟 迭进 简单设计原则： 运行所有测试 会促使类短小且单一 符合SRP 同时测试越多 代码之间耦合越低 符合DIP 重构 测试消除了对修改代码的恐惧 不可重复 代码具有良好的表达力 使用好名称 标准命名法 良好的单元测试也能表达出某个类的作用 尽可能减少类和方法 似乎违反SRP 但是这条规则与SRP达到一个平衡 并发编程 并发解耦了目的与时机 一些问题： 并发一般只有在IO密集型的程序或者有多个处理器上的机器才有效率提升 并发系统的设计与单线程设计极不相同 正确的并发是很复杂的 防御原则 谨记数据封装 限制数据作用域 严格限制多个线程访问的共享数据 使用数据复本 有些情况下的并发可以只读 这个时候可以使用复制的方式避免共享 线程应尽可能独立 不与其他线程共享数据 执行模型 大部分并发问题都是下列模型的变种： 生产者-消费者 限定资源模型 有着固定数量的资源 读者-写者 读写问题 哲学家就餐问题 资源竞争问题 建议 不要在客户端调用一个对象的多个同步方法： 这可能造成多个线程下的数据不一致问题 解决： 客户端代码锁定 synchronized(lock){ obj.f1(); obj.f1(); } 服务端锁定 // AtomicInteger public int incrementAndGet(){} 适配服务端 使用适配器模式 保持同步区域微小 尽早考虑关闭问题 　测试 将偶然的失败看做线程问题 先确保单线程代码可工作 配置多线程代码在不同的配置环境下执行 在代码里插入试错代码：sleep yeild 手工 aop 速查 注释 注释应只包含有关代码的技术信息　像修改时间　作者等没必要放入注释 对于过时　不正确的注释　这些注释很快就会消失　少写 少写废话注释　代码已经能表达的　没必要加注释 注释需要花时间写到最好 代码不要注释　直接删除 环境 系统构建与运行单元测试应只需一个指令 函数 参数越少越好 输出参数违反直觉　避免使用 标识参数应该被消灭 丢弃永不调用的方法 一般性问题 理想的源文件只包含一种编程语言 函数或者类的实现应该是其他程序员所期待的 对于测试需要追索每种边界条件 忽视安全警告相当危险 重复 最明显的是重复代码 较隐蔽的是相同的条件判断 if switch链条 最隐蔽的是算法相似　但代码不同 建立合适的抽象层级 抽象类来容纳较高层的概念　实现类容纳较低层 通常来说　父类对之类一无所知 隐藏数据　通过隐藏来达到限制信息　从而控制耦合度 删除不执行的死代码 垂直分隔 本地变量应该定义在其首次使用的上面　私有函数应该定义在其首次使用的下面 概念前后不一致 毫无关系的东西不该耦合 类的方法应该只对它自己的变量及函数感兴趣　少去依赖外部类的变量函数 代码要充分展现作者意图 对于需要考虑动态行为的静态方法　可能有问题 使用临时变量存储计算过程　提供可读性 函数名称应表达其行为 要理解自己编写的算法 模块的依赖应该是物理依赖 使用多态取代if switch 遵循团队代码规范 用命名常量代替魔数 避免代码含糊不清 良好的结构优于良好的命名 对条件表达式进行命名 一个函数只做一件事 暴露函数调用的前后顺序 封装边界条件 函数应该只有一种抽象层级 配置数据放在高层 避免传递浏览　也就是最小知道原则 Java 使用导入通配符避免过长的导入列表 不要通过继承的方式使用常量 名称 使用描述性的名称 名称应与抽象层级相符 使用标准命名法 名称无歧义 为较大的范围选用较长的名称 避免编码　前缀后缀 名称要说明副作用 测试 使用覆盖率测试覆盖大部分测试 注意边界条件 缺陷可能扎堆发生 测试要快 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-26 02:40:14 "},"软件工程/编码/编码规范.html":{"url":"软件工程/编码/编码规范.html","title":"编码规范","keywords":"","body":"编码规范 命名 当很难找到一个合适的名称的时候，表明可能是对问题域理解的还不够透彻 有意义的命名 命名一致性 自说明性 规范 代码规范 格式 空行 命名 日志 注意日志级别 异常 统一异常处理 错误码 埋点规范 架构规范 破窗效应 函数 通过函数封装判断 避免过长的函数参数列表 避免过长的函数 单一职责原则 精简辅助代码 判空 鉴权 ... 组合函数 公有函数的语义是其实现的概要 函数式编程 设计原则 SOLID DRY dont repat youself YAGNI you ain't gonna need it Rule of Three 第一次使用时，编写它 第二次使用时，复制它 第三次使用时，就需要进行封装了 KISS keep it simple and stupid POLA 最小惊奇原则 设计模式 一种工具或手段，提供了公认的话语概念 模型 UML 领域模型 DDD 数据驱动：对数据库建模->编写业务逻辑 相对于传统的贫血过程式编程 DDD充分利用了面向对象的优点，实体拥有行为，语义化更高 一些概念： 领域实体 聚合根 领域服务 领域事件 边界上下文 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-27 01:02:45 "},"软件工程/设计模式.html":{"url":"软件工程/设计模式.html","title":"设计模式","keywords":"","body":"设计模式 开闭原则 对扩展开放，对修改关闭 里氏代换原则 任何基类可以出现的地方，子类一定可以出现 依赖倒转原则 针对接口编程，依赖于抽象而不依赖于具体 迪米特法则 一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立 合成复用原则 原则是尽量使用合成/聚合的方式，而不是使用继承 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"软件工程/设计模式/创建型模式.html":{"url":"软件工程/设计模式/创建型模式.html","title":"创建型模式","keywords":"","body":"创建型模式 封装了系统使用哪些类 隐藏了这些类类的实例是如何创建和放在一起的 建造者 将复杂对象的构建与表示相分离，同样的构建过程可以创建不同的表示 可以改变一个产品内部表示 构造代码与表示代码分离 对构造进行更细粒度的控制 interface Builder{ Builder process1(); Builder process2(); Builder process3(); Product build(); } class ConcreteBuilder implements Builder{ // 方法实现... } class ProductDirector{ public Product constructProduct(Builder builder){ builder.process1(); builder.process2(); builder.process3(); return builder.build(); } } // 使用 ProductDirector director = new ProductDirector(); Product product = director.constructProduct(new ConcreteBuilder()); 工厂模式 简单工厂 客户无需知道具体产品的名称，只需要知道产品类所对应的参数即可 class Factory{ public Product get(int condition){ switch(condition){ case 1: return new Product1(); case 2: return new Product2(); } return null; } } 但是工厂的职责过重，而且当类型过多时不利于系统的扩展维护 工厂方法 定义一个接口，让子类创建该接口的实例，也就是将实例化延迟到工厂的子类 工厂方法模式适合于构造同属于同一个类别的不同产品，所有的产品属于同一个系列中 abstract class Factory{ abstract Product get(); } class Product1Factory extends Factory{ Product get(){...} } class Product2Factory extends Factory{ Product get(){...} } // 使用 Factory factory = new Product1Factory(); Product product = factory.get(); 抽象工厂 提供一个创建一系列相关或相互依赖对象的接口，而无需指定具体类 分离了具体的类 使得产品改变变得容易 利于维护产品的一致性 扩展产品种类困难 abstract class Factory{ abstract Product get(int condition); } class ProductAFactory extends Factory{ ProductA get(int condition){...} } class ProductBFactory extends Factory{ ProductB get(int condition){...} } class ProductA implements Product{} class ProductB implements Product{} // 使用 Factory factory = new ProductAFactory(); Product product = factory.get(condition); 原型 通过一个原型对象创建新的对象 可以在运行时刻动态改变产品种类 改变值或结构就能获得新对象 动态配置 class Product { Part1 part1; @Override protected Object clone() throws CloneNotSupportedException { Product product = (Product) super.clone(); product.part1 = (Part1)part1.clone(); return product; } } 单例 一个类仅有一个实例，并拥有一个全局访问点 饿汉式 类初始化时,会立即加载该对象，线程天生安全,调用效率高 public class Singleton { private static final Singleton SINGLETON = new Singleton(); private Singleton() { } public static Singleton getInstance(){ return SINGLETON; } } 懒汉式 类初始化时,不会初始化该对象,真正需要使用的时候才会创建该对象,具备懒加载功能 public class Singleton { private static Singleton SINGLETON ; private Singleton() { } // 线程不安全 public static Singleton getInstance(){ if (SINGLETON == null){ SINGLETON = new Singleton(); } return SINGLETON; } } 静态内部类方式 结合了懒汉式和饿汉式各自的优点，真正需要对象的时候才会加载，加载类是线程安全的 public class Singleton { private Singleton() { } private static class SingletonClass{ public static final Singleton SINGLETON = new Singleton(); } public static Singleton getInstance(){ return SingletonClass.SINGLETON; } } 枚举单例 使用枚举实现单例模式 优点:实现简单、调用效率高，枚举本身就是单例，由jvm从根本上提供保障!避免通过反射和反序列化的漏洞， 缺点没有延迟加载 public class Singleton { private Singleton() { } private enum SingletonEnum{ INSTANCE; private Singleton singleton; SingletonEnum() { singleton = new Singleton(); } public Singleton getSingleton() { return singleton; } } public static Singleton getInstance(){ return SingletonEnum.INSTANCE.getSingleton(); } } 双重检测加锁 因为JVM本质重排序的原因，可能会初始化多次，不推荐使用 public class Singleton { private static Singleton SINGLETON; private Singleton() { } public static Singleton getInstance(){ if (SINGLETON == null){ synchronized (Singleton.class){ if (SINGLETON == null){ SINGLETON = new Singleton(); } } } return SINGLETON; } } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-06 04:48:58 "},"软件工程/设计模式/结构型模式.html":{"url":"软件工程/设计模式/结构型模式.html","title":"结构型模式","keywords":"","body":"结构型模式 如何组合类和对象以获得更大的结构 适配器 将一个接口转换成另一个接口 双向适配器 interface Target{ void ops(); } class Adaptee{ public void run() { } } class Adapter implements Target{ private Adaptee adaptee; public Adapter(Adaptee adaptee) { this.adaptee = adaptee; } @Override public void ops() { // do something adaptee.run(); } } // 使用 Target target = new Adapter(new Adaptee()); target.ops(); 分类： 类适配器 对象适配 接口适配方式 桥接 将抽象部分与实现部分分离,使它们都可以独立地变化 abstract class Window { //... abstract setMenu(Menu menu) } interface Menu{} class LinuxWindow extends Window{...} class MacWindow extends Window{...} class PlainMenu implements Menu{...} class RichMenu implements Menu{...} 组合 将对象组合成树形结构的部分-整体层次结构 class Person{ String name; Phone phone; //... } 装饰器 给一个对象添加额外的职责 装饰器与被装饰的对象都拥有同一个接口，所以说，装饰器对客户来说是透明的 abstract class InputStream{...} class FileInputStream extends InpurStream{...} 外观 为系统中的一组接口提供一致的界面 class Facade{ private SubSystem1 subSystem1; private SubSystem2 subSystem2; void ops(){ subSystem1.ops1(); subSystem2.ops2(); } } // 使用 Facade facade = new Facade(); facade.ops(); 享元 共享系统中大量的细粒度对象 提高性能 class MessageFactory{ Message getHeartBeatMeessage(); } interface Message{...} class HeartBeatMessage implements Message{...} 代理 为其他对象提供一个代理访问控制 又称为委托模式 静态代理 结构简单，代码繁琐 interface Subject{ void run(); } class Proxy implements Subject{ private Subject realObject = new RealSubject(); void run(){ //before realObject.run(); //after } } // 使用 Subject subject = new Proxy(); subject.run(); 动态代理 JDK动态代理 SubjectImpl impl = new SubjectImpl(); Subject proxy = (Subject) Proxy.newProxyInstance(impl.getClass().getClassLoader(), impl.getClass().getInterfaces(), (proxy1, method, args1) -> { System.out.println(\"pre invoke\"); return method.invoke(impl, args1); }); proxy.request(); 如果多个接口重名，则调用接口方法以第一个接口为主 cglib动态代理 Enhancer enhancer = new Enhancer(); Object target = new Object(); enhancer.setSuperclass(Object.class); enhancer.setCallback((MethodInterceptor) (obj, method, args1, proxy) -> { System.out.println(method+\" invoke\"); return method.invoke(target, args1); }); Object o = enhancer.create(); System.out.println(o.hashCode()); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-06 05:23:17 "},"软件工程/设计模式/行为模式.html":{"url":"软件工程/设计模式/行为模式.html","title":"行为模式","keywords":"","body":"行为模式 主要涉及到算法和对象之间的职责分配 责任链 使多个对象都有机会处理请求，避免发送者与接受者之间的耦合 拥有动态添加职责的灵活性 不保证被接受 public interface Filter { void doFilter(ServletRequest var1, ServletResponse var2, FilterChain var3) throws IOException, ServletException; } public class LoggingFilter implements Filter { @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { //... } } 命令 将请求封装为对象 解释器 定义一个文法，定义一个解释器，解释器解释执行做一些操作 迭代器 提供一种顺序访问对象中的各个元素，并不暴露内部表示 外部迭代与内部迭代的区别在于是由客户控制还是迭代器控制迭代 interface Iterator{ hasNext(); next(); } class ArrayListItr implements Iterator{...} 中介者 用一个中介对象封装一系列对象之间的交互 与外观模式不同之处在于中介模式的交互是双向的，而外观模式只是从外观对象到子系统之间的单向协议 备忘录 不破坏封装性的情况下，保存一个对象的内部状态 观察者 定义对象间一对多的依赖关系，依赖它的对象都会得到通知并自动更新 具体目标与具体观察者之间是抽象耦合 广播通信 推模型与拉模型 abstract class Subject{ add(Observer ob); del(Observer ob); notify(); } interface Observer{ update(); } class ConcreteSubject{ notify(){ obServerlist.forEachNotify(); } } class ConcreteObserver implements Observer{ ... } 状态 允许一个对象在其内部状态改变时改变它的行为 对象就是一个状态机，当从一个状态转移到另外一个状态，其行为就会发生改变 class LoginContext{ private UserState state; login(){ state.login() } } interface UserState{ login(); } class UserNormalState{ login(){ if (loginFailCount == 5){ context.state = new UserBannedState(); } print \"login success\"; } } class UserBannedState{ login(){ print \"you are banned\"; } } 策略模式 封装一系列算法，以使它们可以互相替换 策略模式与状态模式之间的区别在于状态模式的各个状态之间是有联系的 interface Strategy{ void algorithm(); } class Context { private Strategy strategy; public Context(Strategy strategy) { this.strategy = strategy; } void execute(){ strategy.algorithm(); } } class StrategyA implements Strategy{ // 具体实现 } // 使用 Context context = new Context(new StrategyA()); context.execute(); 模板方法 在父类当中定以算法骨架，将一些步骤延迟到子类当中实现 实现一些操作时，整体步骤很固定，但是呢。就是其中一小部分容易变，这时候可以使用模板方法模式，将容易变的部分抽象出来，供子类实现 钩子操作 abstract class BaseAlgorithm{ void process(){ process1(); process2(); } abstract void process1(); abstract void process2(); } class ConcreteAlgorithm extends BaseAlgorithm{ // 实现方法 } // 使用 BaseAlgorithm algorithm = new ConcreteAlgorithm(); algorithm.process(); 访问者 表示一个作用于对象结构中的各元素的操作 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-06 05:53:53 "},"软件工程/设计模式/MVC.html":{"url":"软件工程/设计模式/MVC.html","title":"MVC","keywords":"","body":"MVC model:模型代表一个存取数据的对象或 JAVA POJO。它也可以带有逻辑，在数据变化时更新控制器 view:视图代表模型包含的数据的可视化 controller:控制器作用于模型和视图上。它控制数据流向模型对象，并在数据变化时更新视图。它使视图与模型分离开 Model1模型 Model2模型 当有用户的行为触发操作时，会有控制器更新模型，并通知视图进行更新，在这时视图向模型请求新的数据 优势 清晰的职责划分 组件独立，代码重用 后期维护方便 适合任何项目 弊端 展示数据慢（针对jsp） 对开发者架构设计能力要求高 异步交互不方便 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-06 06:03:42 "},"软件工程/服务计算.html":{"url":"软件工程/服务计算.html","title":"服务计算","keywords":"","body":"服务计算 服务 服务时为客户所执行的非持久的，无形的体验 服务模型与制造模型 单纯的制造持续减少，服务产业持续增长 服务系统 用以实现业务服务的IT软件系统 IT使能服务：业务服务由服务系统提供 问题 复杂 灵活 专业化与外包 计算环境演化 IT专家与领域专家的沟通 价值与创新 服务系统家族 面向泛型 使用软件工程相关方法工具进行开发 复用 命令式（过程式）泛型 面向对象泛型 使用设计模式应对可以预料到的变化 基于构件的泛型 构件:模块化的、可部署、可替换的软件系统组成部分，它封装了内部的具体实现并对外提供统一接口。 好处： 接口稳定，内部实现发生变化不会导致变化扩散 面向服务的泛型 服务：自治、开放、自描述、与实现无关的网络构件 服务组合 面向服务的应用逻辑,遵循面向服务的设计原则,采用服务和服务组合加以实现。 由于面向服务倾向于将服务打造为无关的企业资源, -一个服务可能被多个消费者程序所调用,它们能在不同的服务组合中组合同一个服务。 服务库存 服务库存，是在组织或组织的合理部分边界内一组独立标准化并治理的完备服务。 分层 应用服务层 业务服务层 编排服务层（非必须） 演化 龙卷风模型 各个服务按需独立开发 依赖先前的服务进行开发 使用开发完成的服务进行组合，达到快速开发 服务生态系统 当服务库存按照面向服务的方式进行良好规划和设计、经过长时间演化、已经基本完备;该组织的服务系统均已合理地转向面向服务的实现,那么该组织内的服务生态系统就被构建起来。 垂直服务：可以被消费者直接调用，满足消费者需求 水平服务：需要组合多个服务才能提供服务 生命周期 分析 设计 开发 测试 部署 管理 服务层次 交付策略（开发方式） 自顶向下：分析优先 自底向上：按需交付，封装并集成遗留系统 敏捷策略 面向服务的计算 快速、低成本。在异构环境中分布式应用的灵活组合 面向对象 vs 面向服务 面向服务的架构SOA 面向服务的企业 使用服务对应用封装 SOA三角操作模型 分层 操作型系统层：只为一个目的服务一类特定用户 服务组件层：提供用以实现服务层中所定义服务的代码容器 服务层：服务层将SOA三角操作模型，扩展为综合的逻辑层次,以支持服务注册、服务分解、服务发现、服务绑定、接口聚合和生命周期管理。 业务过程层：以组合和分解的方式处理业务逻辑 编排 编导 消费者层：通过业务服务快速构建用户接口来满足消费者需求 web service xml：定义数据，信息交换 xml schema：定义数据结构 soap：平台无关消息传送 wsdl：平台技术无关服务描述 ws-bpel/ws-cdl:脚本 uddi，wsil：服务发布与查找 抽象模型 SOAP 提供了单向、不带状态的消息交互范式 一个定义了消息传输的数据抽象接口 WSDL 提供了一种基于XML的标准接口定义语言/服务能力定义语言,用以在服务的提供者/调用者/服务注册之间,交换必要的有关Web Service的信息 面向服务的分析 需要构建哪些服务，每个服务需要封装哪些逻辑 定义流程自动化需求 识别现有自动化系统 业务服务 以任务为核心 以实体为核心 服务建模 面向服务设计 从服务候选中派生出具体的服务设计，装配到实际业务流程 以实体为核心 应用服务 以任务为核心 服务开发 特定平台及语言： 开发定制服务 包装遗留系统 构建应用系统 服务设计 标准化服务合约 技术性 非技术性 版本问题：服务合约的演化 技术依赖 标准化服务策略 服务耦合 逻辑-合约耦合 先设计合约，再设计底层方案逻辑 合约-逻辑耦合 根据实际设计生产合约，是一种反模式 合约-技术耦合 合约-实现耦合 合约-功能耦合 服务没有可复用性 消费者-合约耦合 接口粒度 服务抽象 为了获得信息隐藏的正确平衡点 抽象度量：合约内容 详细合约 简明合约 优化合约 服务可复用性 计划的可复用 针对的可复用 完全可复用 无关服务与周围环境之间保持中立或者无关 服务越是无关，复用潜能越大 服务可复用性原则倾向于降低服务粒度 服务自治 当前服务不依赖于其他因素 运行时自治 设计时自治 服务拥有者对服务修改的自由度 风险： 错误判断了服务的范围，导致修改困难 对遗留系统的封装，修改困难 过度设计 服务无状态性 使用状态库保存状态 使用消息保存状态 代价： 性能代价 设计代价 服务可发现性 服务可组合性 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-02 03:10:29 "},"软件工程/架构/架构.html":{"url":"软件工程/架构/架构.html","title":"架构","keywords":"","body":"架构 架构的分类： 基础架构 以云平台 操作系统等基础设施为主 中间件与大数据架构 业务系统架构 通用软件系统 办公软件 浏览器等一类 离线业务系统 大数据分析 数据挖掘系统 在线业务系统 在线为特定业务服务的系统 这些不同分类的架构界限不是很清晰 随着时间演进 各个类型之间的系统边界会互相渗透 架构的演进 站在后端开发人员的角度上软件架构风格从大型机（Mainframe），到原始分布式（Distributed），到大型单体（Monolithic），到面向服务（Service-Oriented），到微服务（Microservices），到服务网格（Service Mesh），到无服务（Serverless） 谈起微服务，会想到技术异构，便于部署，高性能等等，但这些似乎都只是锦上添花，架构的核心在于解决软件的存活问题，如果一个软件压根就不能提供服务，这些锦上添花的功能也毫无作用 架构的目标 用最小的人力成本来满足构建和维护该系统的需求 乱麻系统 过度的自信导致软件维护成本持续上升 两个维度 行为价值 让系统正常运行 架构价值 让系统更容易修改 四种架构模式 按层封装 也就说传统的水平分层架构，在项目初期很合适 package controller{ Controller; } package service { Service; ServiceImpl; } package dao { Dao; } 按功能封装 即垂直切分 package Order { OrderController; OrderService; OrderDao; } 端口与适配器 package controller{...} package domain { Service; ServiceImpl; Domain; } package dao{...} 按组件封装 优点服务架构的味道 package controller {...} package order { Service; Dao; } COLA 分层 扩展设计 在系统设计时，针对业务或者场景预留一些扩展点 具体技术下的架构 单体架构：Spring Boot 使用传统的分层，打成一个jar包 运行它 微服务：Spring Cloud 高可用 高性能等需求使我们不得不对系统进行拆分，在前面的单体架构下，分成多个工程 业务代码与服务基础设施代码耦合在一起 构成了传统的微服务，也是目前最流行的架构 微服务：K8S 在传统的微服务下，基础设施代码与业务代码耦合在一起，这个阶段下使用了K8S的容器基础设施来完成大部分服务治理功能，应用程序可以更专注我们的业务 服务网格：Istio K8S将服务治理沉淀到基础设施只是第一步，接下来服务网格将这事做的更加彻底，更加可管理 可观测 另外一条支线：无服务 上传代码，某些事件会触发你的代码运行它，彻底不用管理基础设施，一切交给云 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-27 07:57:51 "},"软件工程/架构/编程范式.html":{"url":"软件工程/架构/编程范式.html","title":"编程范式","keywords":"","body":"编程范式 结构化编程 结构化编程是对程序的控制权的直接转移进行了限制和规范 可推导性 错误地使用goto是有害的 可将模块递归降解为可推导的单元 测试只能证明程序存在错误，而不能证明其正确 面向对象编程 面向对象编程是对程序的控制权的间接转移进行了限制和规范 封装 继承 多态 多态中接口与实现的强大作用 依赖反转 当进行依赖反转之后，软件模块则可以进行独立开发，独立部署 函数式编程 函数式编程是对赋值操作进行限制和规范 函数式编程中的变量是不可变的 可变性的隔离 服务被切分为可变和不可变两种组件 事件溯源 不保存具体状态，而是保存操作日志，根据日志计算某一具体时刻的状态 总结 软件，是由顺序结构，分支结构，循环结构和间接转移几种行为组成，无可增加，也缺一不可 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-27 06:33:44 "},"软件工程/架构/设计原则.html":{"url":"软件工程/架构/设计原则.html","title":"设计原则","keywords":"","body":"设计原则 软件构建目标 改动 理解 复用 SRP:单一职责原则 任何一个软件模块都应只对某一类行为负责 主要讨论的是函数与类的关系 OCP:开闭原则 设计良好的软件应该容易扩展，而禁止修改 将旧代码的修改量降低至最小 依赖方向的控制 通过接口来反转组件之间的依赖关系，使得高阶组件不会因低阶组件被修改而受到影响 信息隐藏 通过中间层使高层组件不过度依赖低层组件的内部细节 LSP:里氏替换原则 一个软件实体如果使用的是一个基类的话，那么一定适用于其子类，而且它根本不能察觉出基类对象和子类对象的区别 是一个指导接口与其实现方式的设计原则 ISP:接口隔离原则 对模块来说，跟它无关的接口一旦发生变更，应该不能影响到该模块 软件设计如果依赖了它并不需要的东西，会带来麻烦 DIP:依赖反转原则 想要设计一个灵活的系统，则就应多引用抽象类型，而非具体实现 主要关注的是系统中那些经常变动的 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-28 07:07:35 "},"软件工程/架构/系统设计/系统设计.html":{"url":"软件工程/架构/系统设计/系统设计.html","title":"系统设计","keywords":"","body":"系统设计 性能 性能指标 响应时间 某个请求从发出到接收到响应消耗的时间 吞吐量 系统在单位时间内可以处理的请求数量，通常使用每秒的请求数来衡量 并发用户数 系统能同时处理的并发用户请求数量 性能优化 集群 将多台服务器组成集群，使用负载均衡将请求转发到集群中 缓存 缓存对于性能的提升体现在响应时间上 异步 将消息发送到消息队列之后立即返回，之后这个操作会被异步处理 伸缩性 不断向集群中添加服务器来缓解不断上升的用户并发访问压力和不断增长的数据存储需求 如果系统存在性能问题，那么单个用户的请求总是很慢的。 如果系统存在伸缩性问题，那么单个用户的请求可能会很快，但是在并发数很高的情况下系统会很慢 只要集群中的服务器是无状态的，那么往集群中添加服务器后进行负载均衡是很容易的 扩展性 添加新功能时对现有系统的其它应用无影响 使用消息队列对上下游应用解耦 使用分布式服务将业务与服务分离，服务都是一些可复用的服务，添加新功能时，只要调用已有的服务即可 安全性 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-28 11:11:11 "},"软件工程/架构/系统设计/分布式.html":{"url":"软件工程/架构/系统设计/分布式.html","title":"分布式","keywords":"","body":"分布式 为什么要分布式 模块耦合过高很可能造成牵一发动全身 代码发布成本很高 提高开发效率 分布式系统解决了什么问题 单机性能瓶颈导致的成本问题 小型机器不够用 大型机器又很贵 用户量以及数据量增大不得不使用分布式 业务高可用的要求 分布式锁 在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁 阻塞锁使用一个互斥量来实现： 0代表其他进程在使用锁 1代表未锁定 可以用一个整数表示，或者也可以用某个数据是否存在来表示 数据库唯一索引 获得锁时向表中插入一条记录，释放锁时删除这条记录 锁没有失效时间，容易死锁 是非阻塞的，获取锁失败就报错 不可重入 redis setnx 1.获取锁的时候，对某个key执行setnx，加锁（如果设置成功（获得锁）返回1，否则返回0），并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的value值为一个随机生成的UUID，通过此在释放锁的时候进行判断。 2.获取锁的时候还设置一个获取的超时时间(防止死锁)，若超过这个时间则放弃获取锁。 3.释放锁的时候，通过UUID判断是不是该锁，若是该锁，则执行delete进行锁释放 实现 public class RedisLock { private StringRedisTemplate template; private static final String LOCK_KEY = \"LOCK\"; private String identifyValue; public RedisLock(StringRedisTemplate template) {this.template = template;} /** * @param acquireTimeout 获取锁之前的超时时间 * @param expireTime 锁的过期时间 * @return */ public boolean lock(long acquireTimeout, long expireTime) { // 获取锁的时间 long inTime = System.currentTimeMillis(); identifyValue = UUID.randomUUID().toString(); for (; ; ) { // 判断获取锁是否超时 if (System.currentTimeMillis() - inTime >= acquireTimeout) { return false; } // 通过setnx的方式来获取锁 if (template.opsForValue().setIfAbsent(LOCK_KEY, identifyValue, expireTime, TimeUnit.MILLISECONDS)) { // 获取锁成功 return true; } // 获取锁失败，继续自旋 } } public void release() { if (identifyValue == null){ throw new IllegalStateException(\"没有获取锁\"); } // 删除的时候验证value，必须确保释放的锁是自己创建的 if (!identifyValue.equals(template.opsForValue().get(LOCK_KEY))){ throw new IllegalStateException(\"锁的value不一致\"); } template.delete(LOCK_KEY); } } 与zookeeper比较 相对比来说Redis比Zookeeper性能要好，从可靠性角度分析，Zookeeper可靠性比Redis更好。因为Redis有效期不是很好控制，可能会产生有效期延迟 redis redlock 使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用 计算获取锁消耗的时间，只有消耗的时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，才认为获取锁成功 如果获取锁失败，就到每个实例上释放锁 zookeeper临时节点 多个进程同时在zookeeper.上创建同一个相同的节点(/lock) , 因为zookeeper节点是唯一的，如果是唯一的话，那么同时如果有多个客户端创建相同的节点/lock的话，最终只有看谁能够快速的抢资源，谁就能创建/lock节点,创建节点不成功的进程，会注册一个监听事件，等节点被删除的时候，重新竞争这个锁 这个时候节点类型应该使用临时类型。 当一个进程释放锁后（关闭zk连接或者会话超时），临时节点会被删除，等待锁的其他进程会收到节点被删除的通知，这些等待的进程会重新参与到竞争 需要注意的是，要根据业务设置锁等待时间，避免死锁 实现 上锁 public void lock() { // 尝试获取锁，如果成功，就真的成功了 if (tryLock()) { System.out.println(Thread.currentThread().getName() + \"获取锁成功\"); // 否则等待锁 } else { waitLock(); // 当等待被唤醒后重新去竞争锁 lock(); } } private boolean tryLock() { try { // 通过zk创建临时节点的成功与否来表示是否获得锁 zkClient.createEphemeral(\"/lock\"); return true; } catch (Exception e) { return false; } } private void waitLock() { // 监听节点被删除的事件 zkClient.subscribeDataChanges(\"/lock\", new IZkDataListener() { @Override public void handleDataDeleted(String s) throws Exception { // 如果节点被删除，唤醒latch if (latch != null) { latch.countDown(); } } }); // 如果zk有lock这个锁 if (zkClient.exists(\"/lock\")) { // 在这里进行等待，直至被上面的事件监听唤醒 latch = new CountDownLatch(1); try { latch.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } } // 等待完成删除所有监听事件，避免监听器堆积影响性能 zkClient.unsubscribeAll(); } 释放锁 public void release() { if (zkClient != null) { // 关闭zk客户端，临时节点也随之被删除，相当于释放锁，让其他人去竞争 zkClient.close(); System.out.println(Thread.currentThread().getName()+\"释放锁完成\"); } } zookeeper临时顺序节点 有一把锁，被多个人给竞争，此时多个人会排队，第一个拿到锁的人会执行，然后释放锁；后面的每个人都会去监听排在自己前面的那个人创建的 node 上，一旦某个人释放了锁，排在自己后面的人就会被 zookeeper 给通知，一旦被通知了之后，就 ok 了，自己就获取到了锁 zk锁 vs redis锁 redis 分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能 zk 分布式锁，获取不到锁，注册个监听器即可，等待zk的通知 redis如果客户端没有及时释放锁，会发生死锁 分布式Session 集群产生的问题 服务器集群后，因为session是存放在服务器上，客户端会使用同一个Sessionid在多个不同的服务器上获取对应的Session，从而会导致Session不一致问题 解决方案 cookie代替session nginx将同一个ip的请求都转发到同一台服务器 使用数据库存储session 使用web容器的session同步 使用redis存储session 使用token或者jwt存储用户信息，需要时再去数据库或者cache查 SpringSession 使用redis存储session 依赖 org.springframework.boot spring-boot-starter-data-redis org.springframework.session spring-session-data-redis 配置 @EnableRedisHttpSession 这时候，Session的存取都是通过redis来了 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-20 08:56:12 "},"软件工程/架构/系统设计/分布式理论.html":{"url":"软件工程/架构/系统设计/分布式理论.html","title":"分布式理论","keywords":"","body":"分布式理论 分布式系统：部署在不同结点上的系统通过网络交互来完成协同工作的系统 CAP理论 一致性(Consistency)：服务A、B、C三个结点都存储了用户数据， 三个结点的数据需要保持同一时刻数据一致性。 对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性 可用性(Availability)：服务A、B、C三个结点，其中一个结点宕机不影响整个集群对外提供服务，如果只有服务A结 点，当服务A宕机整个系统将无法提供服务，增加服务B、C是为了保证系统的可用性。 对于用户的每一个操作请求总是能够在有限的时间内返回结果 分区容忍性(Partition Tolerance)：分区容忍性就是允许系统通过网络协同工作，分区容忍性要解决由于网络分区导致数据的不完整及无法访问等问题。 最多只能同时满足其中两项 如果放弃分区容错性（CA without P），意味着我们将假设节点之间通讯永远是可靠的。永远可靠的通讯在分布式系统中必定不成立的 如果放弃可用性（CP without A），意味着我们将假设一旦网络发生分区，节点之间的信息同步时间可以无限制地延长 如果放弃一致性（AP without C），意味着我们将假设一旦发生分区，节点之间所提供的数据可能不一致 分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的，所以CAP理论实际上是要在可用性和一致性之间做权衡 保证一致性（CP），不能访问未同步完成的节点，也就失去了部分可用性 脑裂 n/2+1 过半！ 使用奇数台！ 保证可用性（AP），允许读取所有节点的数据，但是数据可能不一致 BASE理论 BA：（Basically Available ），基本可用 分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性 S：（ Soft State），软状态，状态可以在一段时间内不同步 允许系统不同节点的数据副本之间进行同步的过程存在时延 E：（Eventually Consistent ），最终一致，在一定的时间窗口内， 最终数据达成一致即可 Paxos 对多个节点产生的值，该算法能保证只选出唯一一个值 节点类型 提议者（Proposer）：提议一个值 接受者（Acceptor）：对每个提议进行投票 告知者（Learner）：被告知投票的结果，不参与投票过程 Paxos描述了这样一个场景，有一个叫做Paxos的小岛(Island)上面住了一批居民，岛上面所有的事情由一些特殊的人决定，他们叫做议员(Senator)。议员的总数(Senator Count)是确定的，不能更改。岛上每次环境事务的变更都需要通过一个提议(Proposal)，每个提议都有一个编号(PID)，这个编号是一直增长的，不能倒退。每个提议都需要超过半数((Senator Count)/2 +1)的议员同意才能生效。每个议员只会同意大于当前编号的提议，包括已生效的和未生效的。如果议员收到小于等于当前编号的提议，他会拒绝，并告知对方：你的提议已经有人提过了。这里的当前编号是每个议员在自己记事本上面记录的编号，他不断更新这个编号。整个议会不能保证所有议员记事本上的编号总是相同的。现在议会有一个目标：保证所有的议员对于提议都能达成一致的看法 一些paxos原型描述:https://www.douban.com/note/208430424/ Raft 分布式一致性协议，主要是用来竞选主节点 有三种节点：Follower、Candidate 和 Leader。Leader 会周期性的发送心跳包给 Follower。每个 Follower 都设置了一个随机的竞选超时时间，一般为 150ms~300ms，如果在这个时间内没有收到 Leader 的心跳包，就会变成 Candidate，进入竞选阶段 竞选阶段Candidate会向其他节点发送投票请求，Follower同意投票则向该Candidate回复同意投票 当 Candidate获得超过半数票时，就成为Leader节点 如果有多个Candidate获得相同的票数，则重新开始投票 每个节点设置的随机竞选超时时间不同，因此下一次再次出现多个 Candidate 并获得同样票数的概率很低 数据同步 自客户端的修改都会被传入 Leader。此时该修改还未被提交，只是写入日志中 Leader 会把修改复制到所有 Follower Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交 此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-11 06:55:36 "},"软件工程/架构/系统设计/分布式系统.html":{"url":"软件工程/架构/系统设计/分布式系统.html","title":"分布式系统","keywords":"","body":"分布式系统 存储系统 GFS HDFS 计算系统 批处理：MapReduce 流处理：Storm 节点关系 主从式 对等式 前端技术 MVC框架 反向代理 nginx vanish 负载均衡 dns 硬件：F5 软件：LVS 分布式中间件 分布式同步服务中间件 分布式一致性协议：paxos raft ark npc chubby zookeeper 关系型数据库访问中间件 客户端转发 服务端转发 mysql 代理 cobar mycat sharding jdbc 分布式服务调用中间件 dubbo dubbox protocol buffers 一个语言平台无关的序列化反序列化库 grpc thrift motan 分布式消息服务中间件 kafka 分布式跟踪服务中间件 dapper zipkin pinpoint 鹰眼 分布式存储服务 分布式文件系统 GFS HDFS 大文件 TFS 海量小文件 NoSQL数据库 牺牲C 选择AP 基于键值对 LevelDB Tair Dynamo Memcached Redis Berkeley DB 基于列 Bigtable HBase Cassandra 基于文档 MongoDB CouchDB RethinkDB 基于图 Neo4j 时间序列 influxDB NewSQL 关系型数据库与NoSQL的融合 Megastore Spanner F1 OceanBase 构建思想 云化 虚拟化技术 分布式 一切都可能失败与冗余思想 多节点 主从架构 分片 水平扩展 数据：分片 服务： 集群 负载均衡 数据中心：异地主从 异地多活 尽可能简单 组件数量 服务依赖 架构 设计 异步化削峰填谷解耦 最终一致性 微服务思想 服务跟踪 资源池化 思考 大型互联网公司架构共性 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-03 03:56:00 "},"软件工程/架构/系统设计/分布式事务.html":{"url":"软件工程/架构/系统设计/分布式事务.html","title":"分布式事务","keywords":"","body":"分布式事务 在分布式系统中一次操作由多个系统协同完成，这种一次事务操作涉及多个系统通过网络协同完成的过程称为分布式事务。 柔性事务与刚性事务 柔性事务满足BASE理论（基本可用，最终一致） 刚性事务满足ACID理论 解决方案 两阶段提交(2PC) 准备阶段：协调者向参与者发起指令，参与者评估自己的状态，如果参与者评估指令可以完成，则会写redo或者undo日志，然后锁定资源，执行操作，但并不提交 提交阶段:如果每个参与者明确返回准备成功，则协调者向参与者发送提交指令，参与者释放锁定的资源，如何任何一个参与者明确返回准备失败，则协调者会发送中止指令，参与者取消已经变更的事务，释放锁定的资源。 优点：实现强一致性 缺点：整个事务的执行需要由协调者在多个节点之间去协调 单点问题：协调者如果发生故障会造成很大影响 性能问题：所有事务参与者在等待其它参与者响应的时候都处于同步阻塞等待状态，无法进行其它操作 一致性风险：当在提交阶段网络发生异常，只有部分参与者commit了消息，造成数据不一致 任意一个节点失败就会导致整个事务失败 三阶段提交(3PC) 为了缓解2PC的缺点 3PC增加了一个询问阶段 询问阶段：协调者询问参与者是否可以完成指令，协调者只需要回答是还是不是，而不需要做真正的操作，这个阶段超时将导致事务中止 准备阶段 提交阶段 三段式提交对单点问题和回滚时的性能问题有所改善，但是它对一致性风险问题并未有任何改进 共享事务 通过多个服务共用一个数据源的方式来实现，不过这种方式很鸡肋，因为往往数据库才是整个系统的瓶颈 事务补偿(TCC) 优点：最终保证数据的一致性，在业务层实现事务控制，灵活性好。 缺点：开发成本高，每个事务操作每个参与者都需要实现try/confirm/cancel三个接口。 使用消息队列实现最终一致性 在这种方案下，只有事务的一部分成功，事务的其他部分如果失败后就不断重试，直至操作成功或者人工介入 最大努力通知方案 类似于第三方支付的支付回调 一直进行重试 直到成功为止 本地消息表 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中 之后将本地消息表中的消息转发到消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发 分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作 补偿的方式 生产者一定要将数据投递到MQ服务器中（消息确认机制） MQ消费者消息能够正确消费消息，采用手动ACK模式（当消费者消费消息失败，则不确认消息，消息进行重试） 当生产者出错回滚，发送到补偿队列的消息会检测生产者的数据是否提交成功，如果没有，则补偿队列的消费者会重新执行一遍生产者没有提交的事务 SAGA 通过将事务拆分为一系列正向原子操作T1 T2 ... TN 与一系列的补偿原子操作：C1 C2 ... CN 这些操作都必须保证是幂等的，当事务发生失败，可以采取两种策略： 正向恢复 不断重试T 直至成功 反向恢复 反向执行补偿操作 将数据恢复至原始状态 LCN 原理 使用 启动tx-manager 客户端 依赖 com.codingapi.txlcn txlcn-tc 5.0.2.RELEASE com.codingapi.txlcn txlcn-txmsg-netty 5.0.2.RELEASE 配置 @EnableDistributedTransaction 使用 发起者 @LcnTransaction @Transactional(rollbackFor = Exception.class) public void consume(){ jdbcTemplate.update(\"INSERT INTO tb_order VALUES(1,1,'test')\"); String result = producerRemote.home(); } 参与者 @LcnTransaction @Transactional(rollbackFor = Exception.class) public String home() { jdbcTemplate.update(\"UPDATE stock SET stock = stock -1 WHERE product_id = 1\"); return name+port; } 集群 启动多台tx-manager 发起者与参与者配置地址 tx-lcn.client.manager-address=127.0.0.1:8070,127.0.0.1:8071 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-11 07:15:26 "},"软件工程/架构/系统设计/高并发.html":{"url":"软件工程/架构/系统设计/高并发.html","title":"高并发","keywords":"","body":"高并发 高并发读 高并发写 高并发读写 单个数据库每秒两三千并发就基本扛不住了 系统拆分 将单体系统拆分成多个系统或者多个服务，每个子系统使用自己的数据库，提高并发度 大部分的系统都是需要经过多轮拆分的，第一轮拆分将系统粒度划的小一点，可能随着业务的发展，单个系统会变得更复杂，所以需要进一步的拆分 高并发读 策略：加缓存 大部分高并发的场景，都是写多读少，使用缓存，可以有效抗住高并发 对于缓存需要考虑 雪崩 击穿 穿透 等缓存问题 本地缓存或以Redis为代表的集中式缓存 数据库主从复制分担主库压力 CDN 静态加速 策略：并发读 异步RPC 要求各个调用之间是独立的 既然数据库每秒能撑住的请求是有限的，那么就可以使用MQ，大量的请求灌入MQ，利用MQ的削峰，让下游系统慢慢消费 冗余请求 通过每次调用多个服务器 哪个返回的快就使用的哪个 分库分表 让每个表的数据少一点，提高SQL的执行速度 策略：重写轻读 某些事件产生的数据提前聚合好 等需要的时候直接读取即可 而非在需要的时候实时计算 总结：读写分离 数据库读写分离 大部分对数据库的请求都是读多写少，所以读写分离，分配多一些机器给读请求，能有效提高性能 高并发写 策略：数据分片 数据库分库分表 JDK的ConcurrentHashMap 通过分段(之前的版本) 来降低竞争 Kafka的分区 不同的分区可以并发地读写 ES分布式索引 策略：任务分片 指令流水线 mapreduce 策略：异步化 系统层面：异步网络模型 JDK层面 NIO等 接口层面 线程池 异步调用 Future等 业务层面 RPC方式 策略：批量 批量写入数据 将小操作合并成一整个大操作 负载均衡 链路负载均衡 通过DNS解析来完成 实时性不强 一旦后端服务器down 这种负载方式无法及时发现 操作系统负载均衡 利用系统级别的中断以及多队列网卡等来充分利用资源 达到负载均衡的功能 集群负载均衡 硬件负载均衡 F5 软件负载均衡 LVS HAProxy 请求会经过多态服务器 会增加网络时延 LVS D-NAT模式 DR模式 将RS的VIP配置在内核中 TUN模式 调度算法: 静态 轮询 加权轮询 ... 动态 最少连接 加权最少连接 ... 流程： node01: ifconfig eth0:8 192.168.150.100/24 node02~node03: 1)修改内核： echo 1 > /proc/sys/net/ipv4/conf/eth0/arp_ignore echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore echo 2 > /proc/sys/net/ipv4/conf/eth0/arp_announce echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce 2）设置隐藏的vip： ifconfig lo:3 192.168.150.100 netmask 255.255.255.255 RS中的服务： node02~node03: yum install httpd -y service httpd start vi /var/www/html/index.html from 192.168.150.1x LVS服务配置 node01: yum install ipvsadm ipvsadm -A -t 192.168.150.100:80 -s rr ipvsadm -a -t 192.168.150.100:80 -r 192.168.150.12 -g -w 1 ipvsadm -a -t 192.168.150.100:80 -r 192.168.150.13 -g -w 1 ipvsadm -ln 验证： 浏览器访问 192.168.150.100 看到负载 疯狂F5 node01： netstat -natp 结论看不到socket连接 node02~node03: netstat -natp 结论看到很多的socket连接 node01: ipvsadm -lnc 查看偷窥记录本 TCP 00:57 FIN_WAIT 192.168.150.1:51587 192.168.150.100:80 192.168.150.12:80 FIN_WAIT： 连接过，偷窥了所有的包 SYN_RECV： 基本上lvs都记录了，证明lvs没事，一定是后边网络层出问题 问题： LVS可能会发生单点故障 主备 RS挂的话，部分请求会失败 keepalived 作为一个通用工具，解决高可用问题 配置 vrrp_instance VI_1 { state MASTER // 备服务器BACKUP interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 172.17.0.100/16 dev eth0 label eth0:3 } } virtual_server 172.17.0.100 80 { delay_loop 6 lb_algo rr lb_kind DR nat_mask 255.255.255.0 persistence_timeout 0 protocol TCP real_server 172.17.0.4 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 172.17.0.6 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-28 10:42:45 "},"软件工程/架构/系统设计/可用性.html":{"url":"软件工程/架构/系统设计/可用性.html","title":"可用性","keywords":"","body":"可用性 冗余 保证高可用的主要手段是使用冗余 对于应用服务器来说，保证是无状态的，就可以实现冗余 而对于存储服务器，需要通过主从复制来实现冗余 限流 当系统资源不够，不足以应对大量请求，即系统资源与访问量出现矛盾的时候，我们为了保证有限的资源能够正常服务，因此对系统按照预设的规则进行流量限制或功能限制的一种方法 限流原因 流量大 保护服务 限流形式： 技术层面限流 限制并发 限制速率等 业务层面限流 类似于秒杀下场景的商品总量 抢完就完 计数器算法 系统维护一个计数器，来一个请求就加1，请求处理完成就减1，当计数器大于指定的阈值，就拒绝新的请求。 基于这个简单的方法，可以再延伸出一些高级功能，比如阈值可以不是固定值，是动态调整的。另外，还可以有多组计数器分别管理不同的服务，以保证互不影响等。 线程池大小，数据库连接池大小、nginx连接数等都属于计数器算法。 全局或某段时间范围达到阈值则限流 滑动窗口计数 滑动窗口原理是在每次有访问进来时，先判断前 N 个单位时间内的总访问量是否超过了设置的阈值，并对当前时间片上的请求数 +1 队列 就是基于FIFO队列，所有请求都进入队列，后端程序从队列中取出待处理的请求依次处理。 基于队列的方法，也可以延伸出更多的玩法来，比如可以设置多个队列以配置不同的优先级 漏桶算法 漏桶(Leaky Bucket)算法思路很简单,水(请求)先进入到漏桶里,漏桶以一定的速度出水(接口有响应速率),当水流入速度过大会直接溢出(访问频率超过接口响应速率),然后就拒绝请求,可以看出漏桶算法能强行限制数据的传输速率 令牌桶算法 设置一个令牌桶，另外有一个脚本以持续恒定的速度往令牌桶里面放令牌，后端处理程序每处理一个请求就必须从桶里拿出一个令牌，如果令牌拿完了，那就不能处理请求了。我们可以控制脚本放令牌的速度来达到控制后端处理的速度，以实现动态流控 使用guava实现 @RestController public class Controller { /** * 一个每秒创建一个token的桶 */ RateLimiter limiter = RateLimiter.create(1); @RequestMapping(\"index\") public String index(){ // 500ms内无法获取令牌，返回错误，否则成功 if (limiter.tryAcquire(500, TimeUnit.MILLISECONDS)){ return \"success\"; }else { return \"error\"; } } } 令牌桶与漏桶 主要区别在于“漏桶算法”能够强行限制数据的传输速率，而“令牌桶算法”在能够限制数据的平均传输速率外，还允许某种程度的突发传输。在“令牌桶算法”中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，因此它适合于具有突发特性的流量。 隔离 指将系统或资源分隔开 在发生故障时尽可能缩小影响范围 线程隔离 主要是在多线程环境下，对线程池进行治理，把核心业务和非核心业务分割开。 使用线程池来进行隔离，不同线程池中的线程是互相隔离的 Tomcat 中的线程隔离： 线程隔离，只能保证在分配线程这个资源上进行隔离，并不能保证整体稳定性 进程隔离 java cpu、内存这些资源可以通过不同的虚拟机进程来做隔离。 集群式 分布式 集群隔离 一些模块容易在并发量高的时候因为这种功能把整个模块占有的资源全部耗尽 解决方案 独立拆分模块 微服务化 机房隔离异地多活 把服务建立整体副本（计算服务、数据存储），在多机房内做异地多活或冷备份、是微服务数据异构的放大版 当在机房层面出现问题的时候，可以通过智能dns、httpdns、负载均衡等技术快速切换 数据（读写）分离 通过主从模式，将mysql、redis等数据存储服务集群化，读写分离，那么在写入数据不可用的时候，也可以通过重试机制临时通过其他节点读取到数据。 多节点在做子网划分的时候，除了异地多活，还可以做数据中心，所有数据在本地机房crud 异步同步到数据中心，数据中心再去分发数据给其他机房 动静分离 cdn 爬虫隔离 有的系统有时候就会因为爬虫流量过高而导致资源耗尽，服务不可用 熔断 限流是服务方对自己的保护 熔断是调用方对自己的保护 某个接口请求失败率达到一定阈值 就直接熔断这个接口(调用方不再调用它) 或者响应时间达到阈值 也可以熔断 降级 为了保证整体系统可用性，可以牺牲一部分功能依旧提供有损服务 降级处理 兜底数据 默认值: 设置安全的默认值，不会引起数据问题，比如库存为0 静态值:请求的页面或api无法返回数据，提供一套静态数据展示，比如加载失败提示重试，或默认菜单 缓存: 缓存无法更新便使用旧的缓存 降级原则 距离用户越近 造成损失越小 避免滚雪球效应 降级不是一种具体的技术手段 更多的与业务相关 需要根据业务来决定如何降级 降级类型 限流降级 当流量洪峰到达的时候，对于丢弃的用户可以提供友好的提示 超时降级 对调用的数据设置超时时间，当调用失败，对服务降级 重试/自动处理 当达到重试次数后，增加访问标记，服务降级，异步探测服务是否恢复(熔断器半开) 注意幂等性 数据组装降级 多库/多维度组装JSON/XML时，如果有一些不重要的数据无法获取或数据出错，可以忽略继续 爬虫降级 分析机器人行为 引到到静态页或缓存页 读降级 多级缓存架构下，后端缓存或db不可用，可以使用前端缓存或兜底数据 写降级 高并发场景下，写入操作无法及时到达或抗压，可以异步消费数据/cache更新/log等方式 前端降级 js 埋点 接入层降级 nginx 应用层降级 hystrix sentinel 片段降级 忽略js文件加载 静态化降级 缓存静态化html 作为兜底数据 灰度发布与回滚 新功能灰度上线 蓝绿部署 金丝雀发布 旧系统灰度重构 新旧系统共存 通过在入口处进行流量分发 回滚 通过开关停止将流量分发到新系统 监控与报警 监控体系： 资源监控 内存 CPU等 系统监控 接口请求信息 响应时间等等 业务监控 订单交易数 支付成功率等等 报警： 日志 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-28 11:11:11 "},"软件工程/架构/系统设计/集群.html":{"url":"软件工程/架构/系统设计/集群.html","title":"集群","keywords":"","body":"集群 负载均衡 高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用 伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点 算法 轮询（Round Robin） 每个请求轮流发送到每个服务器上 该算法笔记适合每个服务器性能差不多的场景 加权轮询（Weighted Round Robbin） 在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值 权值更高的服务器接收更多的请求 最少连接（Least Connections） 将请求发送给当前最少连接数的服务器上 加权最少连接（Weighted Least Connection） 根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数 随机算法（Random） 把请求随机发送到服务器上 源地址哈希法 (IP Hash) 通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号 这样就可以保证同一ip的客户的请求都会转发到同一台服务器，这个算法可以解决分布式session问题 转发实现 HTTP重定向 负载均衡服务器使用某种负载均衡算法计算得到服务器的 IP 地址之后，将该地址写入 HTTP 重定向报文中，状态码为 302。客户端收到重定向报文之后，需要重新向服务器发起请求 这样客户端需要两次请求，性能会收到一定影响 DNS域名解析 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址 优点是可以返回离用户地理位置更近的服务器 缺点是DNS具有多级结构，DNS解析结果可能被各级缓存，修改DNS记录后，需要比较长的时间才能生效 大型网站基本使用了 DNS 做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡 反向代理服务器 位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器 反向代理服务器可能会成为性能瓶颈 网络层 nginx之类的代理服务器是工作在应用层上的，网络层上的反向代理可以直接修改数据包目的IP地址，进行转发，但在服务器的响应还是需要经过负载均衡器 链路层 在链路层根据负载均衡算法计算源服务器的 MAC 地址，并修改请求数据包的目的 MAC 地址，并进行转发 通过配置源服务器的虚拟 IP 地址和负载均衡服务器的 IP 地址一致，源服务器的响应可以直接发送给客户端，不用经过负载均衡器 session管理 Sticky Session 配置负载均衡器，使得一个用户的所有请求都路由到同一个服务器，这样就可以把用户的 Session 存放在该服务器中 当该节点宕机后，该节点的所有会话数据都将丢失 Session Replication 在服务器之间进行 Session 同步操作，每个服务器都有所有用户的 Session 信息 内存占用过多，且同步过程会影响性能 Session Server 使用一个单独的服务器存储 Session 数据，如可以使用mysql或者redis来实现 这可以使应用服务器保持无状态，但缺点是需要对session存取代码进行改造 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-17 07:04:19 "},"软件工程/架构/系统设计/缓存.html":{"url":"软件工程/架构/系统设计/缓存.html","title":"缓存","keywords":"","body":"缓存 为什么使用 收益： 加速读写：缓存通常都是全内存的 降低后端负载：帮助后端减少访问量和复杂计算（以复杂SQL为主） 成本： 数据不一致性：缓存层和存储层的数据存在着一定时间窗口的不一致 代码维护成本：加入缓存后，需要同时处理缓存层和存储层的逻辑 运维成本：如Redis集群的加入 运维会更有难度 特征 命中率 某个请求能够通过访问缓存而得到响应时，称为缓存命中 缓存命中率越高，缓存的利用率也就越高 最大空间 缓存的利用空间是有限的 当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据 更新策略 当缓存使用量超过了预设的最大值时候 FIFO LRU LFU 等算法用来剔除部分数据 数据一致性最差（因为数据的过期完全取决于缓存） 但基本没有维护成本 超时剔除通过给缓存数据设置过期时间，让其在过期时间后自动删除 段时间窗口内（取决于过期时间长短）存在一致性问题 维护成本不高 只需要设置一个过期时间 应用方对于数据的一致性要求高，需要在真实数据更新后，立即主动更新缓存数据 一致性很高 但是维护成本也是最高的 缓存粒度 究竟是缓存全部属性还是只缓存部分重要属性呢 从三个维度判断： 通用性：缓存全部数据比部分数据更加通用 但是数据具有热点 一般只有几个属性用的比较多 空间带宽。缓存全部数据要比部分数据占用更多的空间及带宽 代码维护：部分数据一旦要加新字段需要修改业务代码 位置 浏览器缓存 ISP缓存 ISP是网络访问的第一跳，这个地方有缓存能大大加快用户的访问速度 反向代理缓存 本地缓存 这里指的是将缓存存放在服务器进程内 分布式缓存 使用专门的服务器集群来存放缓存 数据库缓存 一般数据库都有自己的缓存机制 CPU缓存 cdn 缓存问题 缓存雪崩 在高并发的情况下吗，由于于数据没有被缓存中或者缓存都采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部发到DB，DB瞬时压力过重雪崩 解决方案 锁 比如对某个key只允许一个线程数据库查询数据和写缓存，其他线程等待 但是这样就只能限制同一时间只能有一个线程访问数据库，吞吐量还是不行 消息中间件 缓存中间件没有命中的情况下，生产者将数据库查询请求通过消息中间件发送给消费者，消费者查询数据库后再返回给生产者，生产者再返回给客户端，MQ具有削峰的功能，能缓解数据库过高的请求压力 使用多级缓存以及分布式缓存 分析用户的行为，尽量让缓存失效的时间均匀分布 概括： 保证缓存层服务的高可用 对后端服务进行限流降级 一旦后端服务不可用 直接降级返回一个友好结果 热点key 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题： 如果这个key的计算不能在短时间完成，那么在这个 key 在效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞 解决方案 锁 在重建缓存时 只允许一个线程重建 其他线程必须等待 不设置过期时间，而将过期时间设置在数据中，如果检测到数据过期了，再清除掉 或者当发现超过逻辑过期时间后，会使用单独的线程去构建缓存 缓存穿透 指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空。这样就会导致每次查询不存在的数据都会绕过缓存去查询数据库 解决 把空结果，也给缓存起来，这样下次同样的请求就可以直接返回空了，即可以避免当查询的值为空时引起的缓存穿透 这种方案对空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间 同时也会有一定的数据不一致性 也可以使用布隆过滤器直接对这类请求进行过滤 这种方法适用于数据命中不高、数据相对固定、实时性低（通常是数据集较大）的应用场景 缓存一致性 要求数据更新的同时缓存数据也能够实时更新 解决 当数据更新的同时立即去更新缓存 读请求和写请求串行化，串到一个内存队列里去 读缓存之前判断缓存是否是最新，否则先进行更新缓存 更新数据时，先更新数据库，再删除缓存 为什么要删除缓存，而非更新缓存，如果缓存采用更新的方式，可能这个缓存压根就不会被用到，应该是用到缓存才去写入缓存 保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据 缓存无底洞 随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作 解决 优化细粒度的远程调用 减少网络通信次数 使用长连接或者连接池 客户端缓存 浏览器缓存 ETag ETag: \"5d8c4a06-a0fc\" ETag 用来校验用户请求的资源是否有变化 Cache-Control、 Last-Modified 、Expires Last-Modified : 表示文档最后修改时间，浏览器在访问重复资源的时候会发送IF-Modified-Since 携带此时间去服务器验证，如果时间匹配则返回304，浏览器加载本地资源 Expires： 文档过期时间，在浏览器内可以通过这个时间来判断是否发送请求 Cache-Control ：http1.1的规范，使用max-age表示文件可以在浏览器中缓存的时间以秒为单位 Cache-Control和ETag的区别 Cache-Control直接是通过不请求来实现，而ETag是会发请求的，只不过服务器根据请求的东西的内容有无变化来判断是否返回请求的资源 Age 是CDN添加的属性表示在CDN中缓存了多少秒 via 用来标识CDN缓存经历了哪些服务器，缓存是否命中，使用的协议 浏览器缓存原则 首页可以看做是框架 应该禁用缓存，以保证加载的资源都是最新的 还有一些场景下我们希望禁用浏览器缓存。比如轮训api上报数据数据 浏览器缓存很难彻底禁用，大家的做法是加版本号，随机数等方法。 只缓存200响应头的数据，像3XX这类跳转的页面不需要缓存。 对于js，css这类可以缓存很久的数据，可以通过加版本号的方式更新内容 不需要强一致性的数据，可以缓存几秒 异步加载的接口数据，可以使用ETag来校验。 在服务器添加Server头，有利于排查错误 应用缓存 分为手机APP和Client以及是否遵循http协议 在没有联网的状态下可以展示数据 流量消耗过多 漂亮的加载过程 提前下发 避免秒杀时同时下发数据造成流量短时间暴增 兜底数据 在服务器崩溃和网络不可用的时候展示 临时缓存 退出即清理 固定缓存 展示框架这种，可能很长时间不会更新，可以随客户端下发 父子连接 页面跳转时有一部分内容不需要重新加载，可用从父菜单带过来 预加载 某些逻辑可用判定用户接下来的操作，那么可用异步加载那些资源 异步加载 先展示框架，然后异步加载内容，避免主线程阻塞 数据分布 哈希分布 哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上 传统的哈希分布算法存在一个问题：当节点数量变化时，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移 顺序分布 将数据划分为多个连续的部分，每个节点固定存放一定范围内的数据，按数据的 ID 或者时间分布到不同节点上 可以保持数据的顺序，并且可以控制服务器的数据量 一致性哈希 Distributed Hash Table（DHT） 是一种哈希分布方式，其目的是为了克服传统哈希分布在服务器节点数量变化时大量数据迁移的问题 将哈希空间看做一个环，服务器节点分布在这些环上，当一个数据计算出哈希值后，找出这个哈希值后面最近的一台服务器，将数据存放到这台服务器上 当服务器节点发生变更，受到影响的，只是变更节点的后一台服务器，只需对这台服务器的数据进行重新再计算哈希即可 虚拟节点 一致性哈希存在数据分布不均匀的问题，节点存储的数据量有可能会存在很大的不同 那么就可以通过增加虚拟节点的方式，把这些节点映射到真正的服务器节点，使得数据分布更加均匀 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-12 06:39:20 "},"软件工程/架构/系统设计/静态化.html":{"url":"软件工程/架构/系统设计/静态化.html","title":"静态化","keywords":"","body":"静态化 全量静态化 对于小型网站，页面不多，可以采用这个方式 按需静态化 当数据发生变更，往MQ推送一条消息，消费者消费后推送最新数据到缓存 过一段时间，nginx感知到缓存变化，再生成新页面 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-22 02:17:10 "},"软件工程/架构/系统设计/网关.html":{"url":"软件工程/架构/系统设计/网关.html","title":"网关","keywords":"","body":"网关 流量网关 全局性流控 日志统计 防止 SQL 注入 防止 Web 攻击 屏蔽工具扫描 黑白名单控制 业务网关 请求接入：作为所有 API 接口服务请求的接入点，管理所有的接入请求； 业务聚合：作为所有后端业务服务的聚合点，所有的业务服务都可以在这里被调用； 中介策略：实现安全、验证、路由、过滤、流控，缓存等策略，进行一些必要的中介处理； 统一管理：提供配置管理工具，对所有 API 服务的调用生命周期和相应的中介策略进行统一管理。 一些网关 网关 限流 鉴权 监控 易用性 可维护性 成熟度 Spring Cloud Gateway 可以通过IP，用户，集群限流，提供了相应的接口进行扩展 普通鉴权、auth2.0 Gateway Metrics Filter 简单易用 spring系列可扩展强，易配置 可维护性好 spring社区成熟，但gateway资源较少 Zuul2 可以通过配置文件配置集群限流和单服务器限流亦可通过filter实现限流扩展 filter中实现 filter中实现 参考资料较少 可维护性较差 开源不久，资料少 OpenResty 需要lua开发 需要lua开发 需要开发 简单易用，但是需要进行的lua开发很多 可维护性较差，将来需要维护大量lua脚本 很成熟资料很多 Kong 根据秒，分，时，天，月，年，根据用户进行限流。可在原码的基础上进行开发 普通鉴权，Key Auth鉴权，HMAC，auth2.0 可上报datadog，记录请求数量，请求数据量，应答数据量，接收于发送的时间间隔，状态码数量，kong内运行时间 简单易用，api转发通过管理员接口配置，开发需要lua脚本 \"可维护性较差，将来需要维护大量lua库 相对成熟，用户问题汇总，社区，插件开源 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-21 01:30:25 "},"软件工程/架构/系统设计/开放平台设计.html":{"url":"软件工程/架构/系统设计/开放平台设计.html","title":"开放平台设计","keywords":"","body":"开放平台设计 在互联网时代，把网站的服务封装成一系列计算机易识别的数据接口开放出去，供第三方开发者使用，这种行为就叫做Open API，提供开放API的平台本身就被称为开放平台 使用加签名方式，防止篡改数据 使用HTTPS加密传输 搭建OAuth2.0认证授权 使用令牌方式 搭建网关实现黑名单和白名单 令牌 通过app id与 app secret 获取一个临时token，此token具有操作的权限 OAuth2.0 OAuth： OAuth（开放授权）是一个开放标准，允许用户授权第三方网站访问他们存储在另外的服务提供者上的信息，而不需要将用户名和密码提供给第三方网站或分享他们数据的所有内容 概念 appId 商户号 appKey 商户密钥 授权码Code 获取accessToken access Token 调用接口权限访问令牌 回调地址 授权成功，重定向地址 openid 开放平台生产唯一的用户id 认证授权过程 网站主动跳转到服务商并携带id和key，显示授权界面 用户同意授权，服务商重定向向网站传递code 网站通过code获取access_token 刷新access_token（如果需要） 网站使用access_token + open_id 向服务商拉取用户信息 联合登录 获取 open id 根据open id查询用户 如果存在 生成令牌 否则关联账号 参数传递安全 后端服务器传递参数，返回token给前端，前端通过token请求另外一台服务器 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-18 07:59:49 "},"软件工程/架构/系统设计/SSO.html":{"url":"软件工程/架构/系统设计/SSO.html","title":"SSO","keywords":"","body":"SSO 单点登录 大型互联网公司中，公司旗下可能会有多个子系统，每个登陆实现统一管理多个账户信息统一管理 SSO单点登陆认证授权系统 架构 浏览器访问client，client发现没有登录，跳转到server 浏览器在server上进行登录认证后跳转回client server回调client的时候，携带了一个session id，客户端可以使用这个session id向server查询来验证请求有效性，验证通过client会向浏览器写入cookie，登录成功 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-31 02:08:31 "},"软件工程/架构/系统设计/支付系统设计.html":{"url":"软件工程/架构/系统设计/支付系统设计.html","title":"支付系统设计","keywords":"","body":"支付系统设计 表设计 整体流程 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-04-06 05:09:54 "},"软件工程/架构/组件构建原则.html":{"url":"软件工程/架构/组件构建原则.html","title":"组件构建原则","keywords":"","body":"组件构建原则 组件 组件是软件的部署单元，是可以独立完成部署的最小实体 独立部署 独立开发 组件聚合 REP:复用/发布等同原则 组件中的模块和类之间应该有一个共同的主题或者大方向 CCP:共同闭包原则 应将那些会为了一个目的而同时修改的模块与类放到一个组件中 CRP:共同复用原则 将经常共同复用的模块与类放在同一组件中 不依赖不需要用到的东西 组件耦合 ADP:无依赖环原则 组件不应该出现循环依赖 每周构建 将一周的前几天用来开发新代码，最后一天进行冲突解决 消除循环依赖 通过划分独立组件进行独立开发及发布 解决循环依赖 依赖反转 将相互依赖的模块提取到一个新模块 抖动：随着项目的开发，组件结构会不断扩张变化 自上而下的设计 组件结构图更像是构建性与维护性方面的地图，组件结构图一个重要的目标是如何隔离频繁的组件变更 组件的依赖关系是随着项目的逻辑设计而演进的，无法一开始就设计出完美的组件结构图 SDP:稳定依赖原则 稳定性 与依赖于该模块的模块数量成正比 越上层的组件越不稳定 抽象组件 比如只存放接口的包 抽象组件通常非常稳定 SAP:稳定抽象原则 一个组件的抽象化程度应与其稳定性程度保持一致 抽象化衡量程度 抽象程度 = 抽象类和接口的数量 / 组件中类的数量 痛苦区：非常稳定且非常具体 如数据库表结构与工具类 无用区 无限抽象，无人使用 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-29 08:22:17 "},"软件工程/架构/软件架构.html":{"url":"软件工程/架构/软件架构.html","title":"软件架构","keywords":"","body":"软件架构 软件架构是什么 最适合当软件架构师的，是一线能力最强的程序员 软件架构的最高优先级是保持系统正常工作，软件架构的策略就是京可能长时间保留尽可能多的可选项 开发 一个软件系统的开发，应该就是要方便其开发团队 流行的不一定好，适合的才是最好的 一个系统的架构，反映了开发该系统的团队组织结构 部署 良好的软件结构可以让系统构建完成就能部署，同时实现一键式的轻松部署是设计软件架构的一个目标 运行 设计良好的架构能明确地反映出系统运行时的需求 架构是系统运行时的一个表示 维护 维护的主要成本 探秘：解决问题的最佳方式 风险：解决问题衍生出的新问题 保持可选项 用例：对系统如何响应外接请求的描述 软件系统可降解为 策略：业务逻辑 细节：具体实现技术，数据库、web等 在大部分时间，无法预知系统的所有用例，越晚决定实现细节，就能掌握更多信息，更有利于决策 设备无关性 高层策略与低层实现细节分离 解耦 系统可以被按层解耦，将不同层隔离开来，避免变化扩散到其他层 当对用例进行分组时，增加新用例就会对旧的用例影响降低 解耦模式 源码解耦：控制源代码模块的依赖关系 部署层次解耦：控制可部署模块的依赖关系 服务解耦：依赖关系降低到服务层次 软件架构是生长的，从单体到相互独立可部署单元，再到服务化 设计良好的架构应该允许软件系统从单体到服务，也可以从服务退化到单体 重复 重复需要分清表面重复还是实际重复，随着软件的演进，两段重复的代码可能会变得不同 独立性 开发独立性：当对系统进行解耦时，不同的模块就可以由多个团队来分工开发 部署独立性：同样，解耦之后部署就可以互不影响 边界划分 软件架构设计就是一门划分边界的艺术 为了划分划分边界线，软件系统被分割成组件，这些组件的一部分是核心的业务相关组件，另一部分是非核心的但是是提供必要功能的组件，让这些非核心组件去依赖系统的核心组件 通过划清边界，可以推迟一些细节性的决策 何时何地划分 画在不相关的事情中间 IO是无关紧要的，软件系统的核心，是业务逻辑 插件式架构 软件开发技术发展的历史就是如何想方设法增加插件，这些插件要么可以去掉，要么要多种实现 边界剖析 跨边界调用 边界线一侧的函数调用另外一侧的函数 自律式的组件划分 边界形式 部署层次的组件 线程 进程 服务 策略与层次 本质上，软件系统是一组策略语句的集合 软件架构的重点之一，是将策略彼此分离 层次 直接管理IO的策略，层次是最低的 高层策略一般变更没有低层策略频繁 当源码依赖方向统一调整到指为高层策略，可以大幅度降低系统变更带来的影响 业务逻辑 业务逻辑就是系统中真正用于赚钱或者省钱的过程，这些过程被称为关键业务逻辑，关键业务逻辑通常会处理一些数据，这些数据叫做关键业务数据，关键业务逻辑与关键业务数据通常是紧密相连的，所以将他们两个放在一起，这种对象称之为业务实体 用例 输入 步骤 输出 请求和响应模型 对用例的输入输出对象，应该保持独立 整洁架构 许多架构都是按照不同关注点对软件进行切割 特点 独立于框架 独立于UI 独立于数据库 独立于外部机构 可测试 依赖关系规则 内层圆不应该依赖外层圆 外层圆的变更不应影响到内层圆 谦卑对象 谦卑对象模式是让单元测试的编写者区分容易测试的行为与难以测试的行为 一个优秀的架构，应该拥有强大的可测试性 展示器与视图 不完全边界 单向边界 设计架构时，往往需要使用反向接口来维护边界两侧组件的隔离性 边界与层次 作为架构师，需要考虑： 什么地方需要设计架构边界设计 设计这些边界会带来多大的成本 同时，设计边界需要深思熟虑，过度的工程设计往往比工程设计不足还要糟糕 Main组件 系统中，至少需要一个组件来负责创建、协调、监督其他组件，这个组件称为Main组件 Main组件是系统中细节信息最多的组件，即Main组件是一个底层模块，处于架构圈的外层 服务化 服务这种形式说到底只是一种跨进程或跨平台的调用方式而已，并不等于一种架构 带来的好处 强解耦？ 未必，任何共享数据的行为都会导致强耦合。就像在数据结构的一个字段发生变更，那许多东西都要发生改变 独立开发部署？ 大型系统一样可以采用单体模式 测试 测试组件，可以视为最外圈的最外圈程序 可测试设计 脆弱的测试问题 不良的测试设计，会导致一个对通用组件的修改产生许多测试错误 解决方法就是测试不要依赖于多变的东西 整洁的嵌入式架构 固件程序也可以指针对具体平台的编码 程序适用测试 仅仅停留在让代码能跑起来的阶段 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-04 07:28:26 "},"软件工程/架构/实现细节.html":{"url":"软件工程/架构/实现细节.html","title":"实现细节","keywords":"","body":"实现细节 数据库 为系统中的数据设计结构 web web只是一种io设备 应用程序框架 引入框架带来的风险 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-05 07:00:23 "},"软件工程/架构/网站架构演进.html":{"url":"软件工程/架构/网站架构演进.html","title":"网站架构演进","keywords":"","body":"网站架构演进 传统架构 -> 分布式架构 -> SOA（Service-Oriented Architecture）架构 -> 微服务架构 传统架构 传统的架构，分为三层架构 web控制层、业务逻辑层、数据库访问层。 也就是单点应用，一旦有一个模块导致服务不可用，可能会影响整个项目 分布式架构 分布式架构基于传统架构演变过来，将传统的单体项目以项目模块进行拆分，降低耦合度，项目独立开发部署，并能直接对外提供服务，项目间通信通过RPC SOA架构 把系统按照实际业务，拆分成刚刚好大小的、合适的、独立部署的模块，每个模块之间相互独立 模块通过RPC通信配合来完成工作 特点 底层基于SOAP或ESB soap就是Http或者是Https通道传输XML数据实现的协议 缺点 依赖于中心化服务发现机制 SOAP协议使用的xml传输有缺陷 缺少服务治理与管理设施 微服务架构 微服务架是从SOA架构演变过来，比SOA架构粒度会更加精细 架构特征 协议技术无关 服务独立性非常高 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-04 08:39:33 "},"软件工程/架构/服务架构演进.html":{"url":"软件工程/架构/服务架构演进.html","title":"服务架构演进","keywords":"","body":"服务架构演进 Unix的分布式设计哲学 保持接口与实现的简单性，比系统的任何其他属性，包括准确性、一致性和完整性，都来得更加重要。 原始分布式时代 上世纪7 80年代 当时计算机硬件局促的运算处理能力，已直接妨碍到了在单台计算机上信息系统软件能够达到的最大规模。为突破硬件算力的限制，各个高校、研究机构、软硬件厂商开始分头探索，寻找使用多台计算机共同协作来支撑同一套软件系统运行的可行方案 这个时代提出了RPC的雏形以及日后分布式文系统的最早实现AFS “调用远程方法”与“调用本地方法”尽管只是两字之差，但若要同时兼顾到简单、透明、性能、正确、鲁棒、一致的话，两者的复杂度就完全不可同日而语 某个功能能够进行分布式，并不意味着它就应该进行分布式，强行追求透明的分布式操作，只会自寻苦果 这个时间段过后的一端时间 摩尔定律的黄金时代 计算机的算力不断提升 在日后的一端时间 单体软件架构还是主流 单体系统时代 在微服务盛行的这段日子 单体系统好像总是以反派身份登场 但对于小型系统 不论是开发 测试 部署，单体系统都有着不可比拟的优越性 乍一看单体架构的缺点似乎会是不可拆分 难以扩展 无法继续支撑越来越大的软件规模 但几乎所有的单体系统都会进行分层拆分： 单体系统的缺陷在于拆分之后的隔离与自治能力上的欠缺，所有的代码都会运行在同一进程空间之内 一旦发生问题 问题就会扩散到整个系统，并且如果想要发布新版本 维护也是一个难题 为了允许程序出错，为了获得隔离、自治的能力，为了可以技术异构等目标，是继为了性能与算力之后，让程序再次选择分布式的理由 SOA时代 烟囱式架构：指的是一种完全不与其他相关信息系统进行互操作或者说协调工作的设计模式 微内核架构：也被称为插件式架构，将公共服务、数据、资源集中到一块，成为一个被所有业务系统共同依赖的核心，具体的业务系统以插件模块（Plug-in Modules）的形式存在 事件驱动架构：通过一个事件管道，各个自系统通过发送/接收事件的方式进行交互 SOA的终极目标是希望总结出一套自上而下的软件研发方法论，所以SOA本身有着许多规范，但正是由于过于严格的规范定义带来过度的复杂性 微服务时代 轻量级 围绕业务 异构 自动化 在微服务的早期 它还是被作为SOA的一种补充手段 微服务追求的是更加自由的架构风格，摒弃了几乎所有SOA里可以抛弃的约束和规定 后微服务时代 从软件层面独力应对微服务架构问题，发展到软、硬一体，合力应对架构问题的时代 这里的硬件指的更多是诸如容器 虚拟化技术等为主的基础设施 为了解决在硬件上的服务治理粒度过粗的问题，这个时代完成了第二次进化，也就是服务网格的引入，到目前为止，服务网格还算是个新概念，仍然还在发展 另外一条路-无服务时代 如果说微服务架构是分布式系统这条路的极致，那无服务架构，也许就是“不分布式”的云端系统这条路的起点 后端设施：指数据库、消息队列、日志、存储，等等这一类用于支撑业务逻辑运行，称其为后端即服务 函数：指的业务逻辑代码 无服务的无状态特征天生就不适合做某些事，或许在某些场景下，它会做的更好，但长期来看，还是为以服务架构为主 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-08 06:38:58 "},"软件工程/架构/前后端分离.html":{"url":"软件工程/架构/前后端分离.html","title":"前后端分离","keywords":"","body":"前后端分离 传统开发 需求-UI-前端-后端-集成-测试-交付 分离 需求-UI-前后端约定接口并行开发-集成-测试-交付 注意事项 前后端项目必须独立开发 独立部署 独立存放 通过接口进行合作 Mock.js mock js 数据 入门案例 let Mock = require('mockjs') let data = Mock.mock( { 'list|5':[{id:1,name:'kd'}] } ); 语法规则 文档 Easy-Mock 一个协同在线数据模拟服务 Easy-Mock MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-07 00:48:42 "},"软件工程/架构/前端工程化.html":{"url":"软件工程/架构/前端工程化.html","title":"前端工程化","keywords":"","body":"前端工程化 前端集成解决方案 build tool：自动化 规范 编码规范 文件命名 编码规范:eslint 开发流程 敏捷开发 代码审查 接口规范 单元测试 版本控制工具 分支管理 commit规范 构建工具 grunt webpack gulp 模块化/组件化 JS模块化：AMD CMD CSS模块：less sass 架构 刀耕火种 -> SPA 架构组织 目录组织 页面组织 消除重复代码 其他 设计模式 性能 兼容 产品设计与迭代 工程师拥有一定的技术背景 可以拥有更全的视角审视产品 发布 一个完整的发布流程应该是什么？ 自动化 手工 数据统计与分析 使用第三方 边界划分/模块划分 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-07 00:48:42 "},"软件工程/架构模式/架构模式.html":{"url":"软件工程/架构模式/架构模式.html","title":"架构模式","keywords":"","body":"架构模式 企业应用架构模式 架构 架构师最高层次的系统分解，且是组成系统的不易改变的组件 企业应用 一般来说，企业应用指的是大型系统 特点 持久化数据 大量数据 高并发 大量数据展示操作页面 多个系统集成 业务逻辑复杂 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"软件工程/架构模式/概览.html":{"url":"软件工程/架构模式/概览.html","title":"概览","keywords":"","body":"表述 分层 上层使用下层定义的各种服务，下层对上层隐藏下下层的细节 层次并不能封装所有东西，有时会带来级联修改，过多的层次也会影响性能 三个基本层次 表现层 领域层 数据源层 组织领域逻辑 编写业务逻辑 事务脚本 优点 易于理解 能与简单数据源层很好合作 事务边界容易划分 缺点 业务复杂导致代码冗余复杂 领域模型 使用面向对象的方法 开销来源于使用复杂以及数据源的复杂，还要面对将领域模型映射到数据库的问题 表模块 围绕表组织领域逻辑 服务层 将领域层再拆为两层，服务层提供简单的API接口 映射到关系数据库 架构模式 活动记录 类似于JAVA Bean 数据映射器 ORM 行为 如何保证对领域对象的修改能及时存储到数据库 标志映射 保证相同的对象只被加载一次 延迟加载 读取数据 结构映射模式 关系的映射 外键映射一对多 关联表映射多对多 继承 单表继承 多个层次共享同一张表 具体表继承 一个层次一张表 类表继承 一个类一张表 建立映射 将数据库设计看做一种持久化对象数据的方法 双向映射 将对象-数据库以及数据库-对象两种映射分开设计 元数据 通过元数据的描述自动生成代码 数据库连接 使用连接池管理连接 将连接与事务绑定在一起 web表现层 模板视图 jsp php 转换视图 json 两阶视图 生成一个逻辑视图，再将逻辑视图对应到html 并发 本质问题 更新丢失 不一致读 执行语境 一个请求对应一个会话，可以使进程，也可以是线程，但创建进程耗费资源，使用线程又会导致线程安全问题 数据库中的语境是事务 方案 隔离：划分数据，一片数据只能被一个工作单元访问 不变：不变的数据是线程安全的 乐观锁与悲观锁 使用读写控制 死锁 事务 事务是一个又边界的工作序列，开始和结束都有明确定义 事务的特性 事务资源 横跨多个请求的被称为长事务 锁升级：一个事务锁住了许多行，则直接升级到对整个表的锁 减少事务隔离提高灵活性 可串行化：当并发执行的结果与以某种顺序一致时 系统事务与业务事务 离线并发控制 只有在数据提交失败的时候才能发现 应用服务器并发 使用每会话一个进程的方式来避免处理线程的麻烦 会话状态 无状态服务器 存储方法 客户端存储 cookie 注意会话数据大小以及数据安全性完整性 服务器存储 session 数据库存储 将会话信息存储在数据库中 会话迁移 会话可以在服务器集群之间转移 分布 远程接口与本地接口 进程内的过程调用非常快 何时必须使用分布对象 客户机与服务器之间 服务器与数据库之间 web系统之间 使用软件包 分布边界 注意远程调用的边界 分布接口 基于XML与HTTP 如果系统基于相同的平台构建，最好使用系统自己的远程调用机制 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-15 06:59:00 "},"软件工程/架构模式/领域逻辑模式.html":{"url":"软件工程/架构模式/领域逻辑模式.html","title":"领域逻辑模式","keywords":"","body":"领域逻辑模式 事务脚本 使用过程来阻止业务逻辑，每个过程处理来自表现层的单个请求 事务脚本的组织 将同一主题的事务脚本放到同一个类当中 一个脚本对应一个类 许多问题本身是简单的，一个简单的解决方案可以加快开发速度 领域模型 合并了行为和数据 组织 实体bean ORM 当使用领域模型时，使用数据映射器有助于保持领域模型与数据库的独立性 领域模型的要点在于隐藏数据库的存在，使其对于上层不可见 表模块 处理数据库中表或视图中所有行的业务逻辑的一个封装 组织 表模块以一个类对应数据库中的一个表来组织领域逻辑，仅使用一个单一实例 表模块很大程度依赖于以表方式组织的数据 服务层 通过服务层提供一组可用的操作集合给外部使用 服务层定义了应用程序的边界和从接口客户层角度所看到的的系统、 业务逻辑的种类 领域逻辑 应用逻辑 实现 领域外观 做的事不多，属于瘦客户端 操作脚本 拥有较多的业务逻辑，对领域层进行操作 服务识别与操作 服务层操作的起点是用例模型以及用户界面 如果系统只有一种用户，那可能不需要使用服务层 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-15 06:59:00 "},"软件工程/架构模式/数据源架构模式.html":{"url":"软件工程/架构模式/数据源架构模式.html","title":"数据源架构模式","keywords":"","body":"数据源架构模式 表数据入口 一个实例代表处理一张表中所有的行 通常是无状态的 interface Person { RecordSet find(int id); RecordSet findWithXXX(...); void update(...); } 表数据入口可能是最简单的数据库接口模式 行数据入口 一个实例代表一条记录 class Person { name,age; insert(); update(); } interface PersonFinder { Person find(...); } 活动记录 一个包装表或视图中某一行的对象，封装了对数据库的操作访问 class Person { name,age; insert(); delete(); bool isAudlt(); } 活动记录的本质是一个领域模型 活动记录的数据结构应该与数据库完全吻合 活动记录与行数据入口的区别在于行数据入口只有数据访问，二活动记录封装了一些逻辑 使用 活动记录适用于不太复杂的逻辑 活动记录使对象与数据库的耦合过紧 数据映射器 在对象和数据库之间的一个中间层 数据映射器自身不被领域层所察觉 interface PersonMapper { Person select(...); update(Person); } 当需要分离对象与数据库时，使用数据映射器 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-16 08:39:22 "},"软件工程/架构模式/对象关系行为模式.html":{"url":"软件工程/架构模式/对象关系行为模式.html","title":"对象关系行为模式","keywords":"","body":"对象-关系行为模式 工作单元 维护受影响的对象列表，并协调对象的修改以及解决并发问题 interface WorkUnit { new(Object),Dirty(Object),Clean(Object) } 工作单元会将被修改的对象变化记录下来，存储到数据库 工作单元解决的基本问题是记录各种操作过的对象 调用者注册：修改之后调用者手动提交来保存对象 对象注册：将注册方法置于对象中 工作单元控制器：查询时返回一个拷贝对象，提交时比较拷贝对象与原有的对象，进行有选择的更新 工作单元可以保证更新顺序，并且按照相同的数据更新表可以很少地减少死锁 标识映射 通过给每个对象指定一个标识，避免重复加载，当需要对象时，通过映射来找到对象 无论需要一个什么对象，先检查标识映射，看需要的对象是否在其中 键的选择：数据库主键 显式的标识映射可以利用编译时检查的优点 标识映射与会话相绑定 使用 管理对象 做缓存 延迟加载 一个不包含所需要的所有数据但知道如何获取这些数据的对象 延迟初始化：每次获取都判断是否为空，如果空就去获取数据 虚代理：一个获取数据的代理对象，类可以把它当做真实的对象 值保持器：包装某个对象的对象，但是缺点是不如虚代理，类必须知道这个保持器的存在 重影：首次加载只加载ID，当需要某个域时，则会加载入全部的域 使用的最佳时机：需要额外的调用，并且当主对象被使用时，额外加载的数据没被使用的时候 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-17 08:14:05 "},"软件工程/架构模式/对象关系结构模式.html":{"url":"软件工程/架构模式/对象关系结构模式.html","title":"对象关系结构模式","keywords":"","body":"对象-关系结构模式 标识域 在对象中保存的一个数据库标识域 键的选择 有意义键与无意义键 危险在于有意义键由人指定，可能会发生错误 简单键与组合键 组合键的好处在于当处于多个表相关的上下文时，更容易使用 表唯一键与数据库唯一键 键的表示 对于组合键，最好的方式是建立一个键类，来存放基本类型键值 键的生存 自动生成域：不断递增 数据库计数器：没有统一的标准，并非所有数据库都支持 GUID：保证了同一时空的所有机器生成的GUID都是不唯一的，但是生成的串比较大 键表，通过在数据库保存下一个有效值来生成键 外键映射 把对象的之间的关联映射到表之间的外键关联 关联表映射 将多对多的对象关联映射为数据库中的关联表 依赖映射 一个类为依赖它的类执行数据库映射 嵌入值 把对象映射成另一个对象表的一部分 序列化LOB 将小对象之间的关系保存到大对象中，并将大对象保存序列化到数据库 单表继承 将类的整个继承层次表示为一张表 加载数据的时候需要决定用哪个类来实例化这些数据 类名 代码域 类表继承 一个类一张表 将数据映射成对象需要比较复杂的方案 具体表继承 一个层次一张表 继承映射器 一种可以处理继承层次的数据库映射器 子类调用父类映射器加载数据后，再加载子类的特有数据 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-18 07:08:49 "},"软件工程/架构模式/对象关系元数据映射模式.html":{"url":"软件工程/架构模式/对象关系元数据映射模式.html","title":"对象关系元数据映射模式","keywords":"","body":"对象-关系元数据映射模式 元数据映射 把关系对象映射的信息保存到元数据中(meta data) 代码生成：输入元数据，输出实现类的源代码 反射程序：读入元数据动态生成 查询对象 一个描述一次数据库查询的对象 解释器模式 spring data jpa中的对象查询以及JPQL 资源库(Repository) 协调领域层与数据源层，使用类似集合的接口访问领域对象 资源库提供了一个更符合面向对象观点的持久层实现 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-19 06:05:16 "},"软件工程/架构模式/web表现模式.html":{"url":"软件工程/架构模式/web表现模式.html","title":"web表现模式","keywords":"","body":"web表现模式 MVC 把用户界面的交互拆分到三个角色里 模型：表示领域信息的对象 视图：模型的显式 控制器：协调模型与视图 表现与模型关注点不同，表现侧重于可视化界面，而模型侧重于业务逻辑 同样的模型可以有不同的表现 不可见对象更容易测试 当系统有了一些不可见的逻辑时，就需要注意实现分离 页面控制器 为特定页面或动作处理请求的对象 一个控制器绑定在一个请求上 基本责任： 解码数据 处理数据 调用视图 servlet与jsp 前端控制器 处理所有请求的控制器，执行一些通用的行为，并且行为可以在运行时动态修改 每次请求都会产生新对象，可以避免线程安全问题 模板视图 通过在HTML标记一些数据，来让处理器渲染 模板引擎 辅助对象 条件显示 迭代显示 缺点 很容易被插入复杂的逻辑 难以测试 转换视图 转换视图把领域数据作为输入，HTML作为输出 与模板视图的区别是转换视图侧重于数据的输入，而模板视图更侧重于输出 两步视图 类似于编译，把业务数据转换为一种中间表示，再从中间表示渲染视图 两步视图的价值来源于分离了第一阶段与第二阶段，使改变更加容易 应用控制器 一个处理程序流的集中控制点 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-20 07:38:34 "},"软件工程/架构模式/分布模式.html":{"url":"软件工程/架构模式/分布模式.html","title":"分布模式","keywords":"","body":"分布模式 远程外观 对细粒度接口对象进行封装，提供粗粒度接口，提高网络传输效率 进程内调用的开销笔进程外的小 远程外观的设计都是基于特定客户的需要 数据传输对象（DTO） 传输数据的对象 一般都只用在跨进程的调用当中 DTO中的域应该都是非常原始和简单的 如何序列化 自动化 传输双方保持一致 组装器 组装器对象负责将领域对象转为DTO MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-21 10:48:16 "},"软件工程/架构模式/离线并发模式.html":{"url":"软件工程/架构模式/离线并发模式.html","title":"离线并发模式","keywords":"","body":"离线并发模式 乐观离线锁 使用冲突检测与事务回滚来防止事务冲突 验证一个提交的修改不会与其他修改发生冲突 通过版本号来实现 悲观离线锁 每次只允许一个会话访问数据 尽可能早检测出冲突 独占写锁 当编辑数据时，需要对数据加锁 独占读锁 当读取数据时，需要加锁 读写锁 读锁与写锁是互斥的 可以进行并发地读 锁管理对象 实现尽可能简单，使用散列表映射锁及锁的持有者 粗粒度锁 用锁锁住一组相关的对象 隐含锁 将加锁的任务交给父类或者框架 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-22 07:41:30 "},"软件工程/架构模式/会话模式.html":{"url":"软件工程/架构模式/会话模式.html","title":"会话模式","keywords":"","body":"会话模式 客户会话状态 将会话状态保存在客户端 无状态 集群 客户会话状态经常只是用来保存标识号 服务器会话状态 将会话状态保存到服务端 会话状态的持久化 数据库会话状态 将会话状态保存到数据库中 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-22 07:48:07 "},"软件工程/架构模式/基本模式.html":{"url":"软件工程/架构模式/基本模式.html","title":"基本模式","keywords":"","body":"基本模式 入口 入口对象是对外部系统或资源访问的封装 封装外部资源，创建一个简单的API 入口模式可以使简单的接口转发，与外观模式不同的是，外观接口通常由服务端提供，具有通用性 映射器 在两个独立的对象之间的中间层 主要是在两个子系统之间建立通信，并且不被子系统所感知 要达到这样的目的，需要监听子系统的通信请求 层超类型 某一类型充当一层中所有类型的超类型 当一层中的所有对象都具有共同的一些特性时，这些特性就可以被抽取成超类代码 分离接口 在与接口定义分离的地方实现该接口 注册表 一个全局可见的对象，其他对象可以通过此对象获得 可以使用单例模式 但当增加一种新类型时，注册表必须被修改 但也可以使用隐式注册表，只是会失去编译时检查的优点 值对象 小而简单的对象，判等时不依据标识ID 货币 表示一个货币值的对象 特殊情况 提供特殊行为的子类 主要是为了避免针对特殊情况进行编程而引入的 插件 通过配置来连接类 服务桩 在测试时mock外部服务 记录集 表格数据在内存的表现形式 离线记录集 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-23 08:29:37 "},"软件工程/微服务/微服务.html":{"url":"软件工程/微服务/微服务.html","title":"微服务","keywords":"","body":"微服务 集中式架构 -> 垂直拆分 -> 分布式服务 -> 服务治理（SOA） -> 微服务 概念 足够小，内聚性高 自治，一个服务就是一个独立的实体 原则 围绕业务建模而非技术建模 自动化文化 隐藏实现细节 去中心化 独立部署 隔离失败 当进行远程调用时，要有机制当调用失败时能将错误隔离在一定的范围内 可观察 一个服务应提供一定的接口来反映其运行情况 什么时候不适合微服务 对要构建的系统越不熟悉，对系统的各个组件划分也就越困难 所以还是先构建单体系统，再逐步对其拆分 好处 技术异构性 弹性，一个服务不可用不会导致级联故障 可扩展，一个服务可以运行多个实例 简化部署 符合组织结构 可组合性 容易替换 面向服务的架构(SOA) SOA是一种设计方法，其中包含多个服务，而服务之间通过配合最终会提供一系列功能。一个服务通常以独立的形式存在于操作系统进程中。服务之间通过网络调用，而非采用进程内调用的方式进行通信。 微服务架构可以看做是实现SOA的一种特定方法 其他的分解技术 共享库 模块 架构师的视角 软件不同于建筑，相对来说，软件的不可预测因素更多，我们应该设计出一个合理的框架，在这个框架可以慢慢演化出正确的系统，也就是生长的架构。 避免对所有事情做出过于详尽的设计，将注意力专注在大方向上 同时，架构设计就是在做取舍，要有原则及实践来指导设计 分区 相对来说，应该多担心区域之间发生的交互，而非区域内的事情 良好的服务应该具有的属性 监控 每个服务都应该有标准的方式报告其健康状态 接口 架构的安全性 应该有良好的隔离性 代码治理 提供范例来指导开发人员如何编写代码 提供服务代码模板来简化开发人员的工作 技术债务 短期的利益，长期来看是要付出代价的，应该要维护好这个债务列表 例外管理 一次例外是例外，多次例外就是规则了 系统设计 康威定律 即系统设计本质上反映了企业的组织机构。系统各个模块间的接口也反映了企业各个部门之间的信息流动和合作方式 服务所有权 拥有服务的团队可以对服务做出修改，只要不影响服务的消费者 为什么要共享服务 多个团队共同维护一个服务 难以拆分 团队的组建是基于技术的，而不是业务 人员流动更自由 内部开源 不再采取团队结构，而是让一小部分人称为核心提交者，其他人可以提交PR 孤儿服务 孤儿服务指的是一段时间没有更改的服务 如果团队的组织是按照限界上下文的话，那一个团队可能拥有多个服务，这个孤儿服务在这个团队手上，当发生需求变更时，修改是很容易的。同时，采取了微服务的架构，很多服务都可以进行快速重写 反向的康威定律 系统设计会影响组织结构吗？ 挑战 如何划分服务 分布式架构带来新的问题 运维挑战 生命周期 设计 单体应用是否先行 划分服务范围 服务通信方式 可恢复性 部署 部署操作标准化 持续交付流水线 监控 四层架构 平台层 服务层 实现业务功能或者技术功能的微服务 聚合服务与多元服务 关键路径：业务线上重要的服务点 通信 同步 异步 服务边界 用来屏蔽内部实现细节，提供一个外部统一访问点 API网关 Backend for frontend 为特定群体服务的网关 客户端 传统单体客户端 微前端 查询 远程调用接口的代价很大，需要对一些查询接口提供批量查询接口 高可靠微服务 负载均衡与服务监控 限流 服务网格 引入一个代理来代替服务间的直接通信 故障类型 硬件 网络通信 外部依赖服务 内部代码 后备方案 降级 缓存 调用其他服务完成 超时 断路器 为了保护服务 异步通信 可复用的微服务框架 服务发现 信息收集（可观测性） 负载均衡与限流 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-19 06:32:42 "},"软件工程/微服务/服务建模.html":{"url":"软件工程/微服务/服务建模.html","title":"服务建模","keywords":"","body":"服务建模 设计方法 根据业务能力划分 根据用例划分 根据技术能力划分 好服务的标准 松耦合 尽可能少地知道外部服务的信息 高内聚 相关的行为聚集咋一起 bounded context 这里的product就是共享模型 模块与边界 模块的边界是绝佳的微服务候选者，但是新系统最好是先使用单体系统，过于早的边界划分，如果错了，代价会很大 业务功能 进行建模时，如果只考虑模型而不考虑具体业务功能，则就导致大量贫血的基于CRUD操作的服务 但是需要大量的业务知识 根据业务能力进行拆分的话，适合在初期，到了后期，随着系统体量增长，需要进一步拆分 逐步划分 一开始划分的是一些粗粒度的边界，接下来再对这些粗粒度边界继续划分成较细粒度的边界 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-18 08:38:09 "},"软件工程/微服务/集成.html":{"url":"软件工程/微服务/集成.html","title":"集成","keywords":"","body":"集成 理想的集成技术 避免破坏性修改 一个服务的修改会导致服务的消费方也发生变化 保证API的技术无关性 也就说，API不管使用什么技术，应该都能实现，保证通信方式的技术无关性是非常重要的，这样各个服务才有可能使用不同的技术实现 使服务易于消费方使用 隐藏内部实现细节 如果消费方与服务的实现细节绑定在一起，会增加两者间的耦合 同步还是异步 同步通信，发起一个远程调用后，会阻塞自己并等待整个操作的完成 异步通信，则不需要等待操作结束就可以访问 使用哪种方式，要取决于哪种风格的通信解决的问题 跨服务业务流程 有两种方式：编排与协同 编排是有一个控制中心，指导其他服务应该做些什么，具体怎么做，则交给具体服务 事件发生： 控制中心调用服务A 控制中心调用服务B 使用这种方式的缺点是会让控制中心承担太多的职责，并会导致少量的“上帝服务（上帝视角）” 若使用协同，则是可以客户触发一个事件，监听到这个事件的具体服务去做一些事情 事件发生： 服务A接收到事件，做一些事 服务B接收到事件，做一些事 这个方式的优点是能显著地消除耦合，但是缺点是无法看到清晰的业务流程，所以这种方式需要一定的监控手段来保证业务的正确性 同步的编排方式 远程过程调用（RPC） 在分布式计算，远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一个地址空间（通常为一个开放网络的一台计算机）的子程序，而程序员就像调用本地程序一样，无需额外地为这个交互作用编程（无需关注细节） 一些问题 技术耦合 如果使用JAVA RMI，就会将服务端与客户端都绑定在JVM上 远程调用的开销 网络是不可靠的 脆弱 一端的修改很容易影响到另外一端 REST REST是RPC的一种替代方案 REST与HTTP REST本身没有定义应该使用哪种协议实现，但是使用HTTP协议，会简单的很多 超媒体控制 让客户端自行遍历与发现API，可以很好地隐藏低层细节，使得客户端与服务端之间实现了松耦合 载体形式 JSON XML 过多的约定 数据持久化继承并非是一件需要过早操心的事，最好是先设计外部接口，这样可以确保服务的接口是由消费者的需求驱动出来的 缺点 基于HTTP的REST有一些缺点： 时延不低 数据包不够精简 需要手动编写客户端代码 有些框架HTTP动词支持不好 异步的协作方式 需要一些中间件来实现异步协作，尽量让中间件保持简单 技术选择 MQ 基于HTTP的发布订阅模式 异步架构复杂性 采用异步架构，要考虑的事情就更多了 服务即状态机 服务拥有在限界上下文中的所有逻辑，这样可以在唯一一个地方处理逻辑 响应式扩展 把多个调用的结果组装起来，并在此上做操作（类似于stream） 微服务中代码复用的危险 不同的服务复用同一块代码，一个服务修改的代码很可能影响另一个服务 按引用访问 在进行事件通知时，传递的数据应该是指向资源的一个引用，这样当其他服务处理这个事件时，就可以根据这个引用得到最新的数据，而避免数据不一致的情况 版本管理 尽可能推迟修改 宽进严出原则：对自己发送的东西要严格，对接收的东西可以宽容一点 及早发现破坏性修改 使用语义化的版本管理 通过版本号来告知消费方功能增加或是否向后兼容 多版本接口共存 多版本服务共存 用户界面 数字化 未来的需求很难预测，提供细粒度的API 不同场景的约束 API的组合 使用网关来缓解客户端与服务之间的过多交互 服务直接提供UI片段 为前端服务的后端 再在服务之上封装一个API提供粗粒度的接口，这些接口通过调用下层的服务来提供服务 但是这层API很容易发展为一个怪兽，并且可能会有业务逻辑混入其中 集成第三方软件 一些风险： 缺乏控制 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-10 07:48:13 "},"软件工程/微服务/分解单块系统.html":{"url":"软件工程/微服务/分解单块系统.html","title":"分解单块系统","keywords":"","body":"分解单块系统 下手处 根据改变速度，团队结构，安全需求以及实现技术等对其进行分离 停止挖掘 当开发新功能时不应该为旧单体应用添加新代码，最佳方法应该是将新功能开发成独立微服务 前后端分离 将单体应用进行前后端分离，有两个好处： 使得可以接入微服务 界面与业务逻辑可以独立部署 抽出服务 对抽取成服务的模块进行优先级排序 经常变化的 资源消耗大户 粗粒度边界 抽取模块 定义粗粒度接口 将调用变为远程调用 拆分服务 扩展 迁移 收缩 删除原先服务的无用代码 依赖处理 数据库 分析数据库表的依赖关系，把不同的表或者不同的数据分到不同的限界上下文里 外键 放弃，改用api调用来实现数据查询 共享数据 静态数据 如果要求不苛刻，可以使用配置文件，否则使用一个专门的服务器来管理静态数据 动态数据 独立出一个服务，专门来处理 共享表 需要重新审视设计，进行分表操作 数据库重构 先分离数据库再分离服务，虽然这样会破坏事务完整性，但是可以保证随时可以回退 事务 分离数据库之后，如何保证事务的安全性？ 如果一个事务中的部分操作成功，部分操作失败，该如何？ 再试一次 也就是最终一致性，如果失败了，将其放入队列，稍后重试 终止操作 发起一个补偿事务，来撤销成功的操作 但是如果补偿事务再失败的话，可以引入重试或者人工操作 分布式事务 也就是两阶段提交，每个事务参与者需要向事务管理器投票，如果所有参与者都同意，则事务管理器告诉所有参与者提交，否则只要有一个不同意，则所有事务参与者都有放弃此次事务 引入这些都会增加系统的复杂性，最好的方式是避免这种跨服务的事务 报表问题 如果分离了数据库，那么如何解决需要所有数据的后台报表应用？ 服务调用 SQL接口 提供一个批量API 指导系统将数据写入到一个共享位置来解决传输问题 数据导出 由服务主动推送数据到报表服务器 事件数据导出 当服务发生事件时，服务主动推送这些事件到一个中间件上 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-18 08:38:09 "},"软件工程/微服务/部署.html":{"url":"软件工程/微服务/部署.html","title":"部署","keywords":"","body":"部署 微服务生产环境 持续集成 持续集成的一个主要作用是保证新提交的代码与已有代码进行集成 真正的持续集成 代码应该频繁地被集成 应该有测试来验证正确性 构建失败后的第一任务时修复失败 微服务与持续集成 有三种方式来分别管理微服务代码库与CI服务器 所有微服务存于一个代码库，一个CI服务器 这种方式在项目初期可以行得通，但是会造成每次提交代码都会对所有服务进行集成，而且可能一个服务集成失败也会影响到原来正常的服务 所有微服务共享一个代码库，但是每个服务拥有一个独立的CI构建过程 这样的情况下，跨服务修改会变得困难 所有微服务拥有自己的代码库，以及自己的CI构建过程 构建流水线与持续集成 把一个复杂的构建流程分成许多个阶段，称之为构建流水线，不仅能更早地发现错误，而且可以很好地反映软件的质量 持续交付(CD)基于以上概念 平台特定构建物 不同的技术栈最后的构建物使用、安装不尽相同，所以很需要一种通用的技术来对这些构建物进行处理 操作系统构建物 一种屏蔽这种技术栈差异的方式是使用操作系统构建物，也就说操作系统能直接执行的文件 镜像 通过虚拟化平台，创建一个包含软件所需环境的镜像，这样就可以快速进行部署，并且屏蔽底层细节 甚至可以直接将镜像作为构建物，最后只需启动镜像即可 有时候，如果机器修改了一些配置，就会造成实际配置与源代码管理中的配置不一致，这称为配置飘逸，所以需要有一种技术，能够禁止对部署镜像服务器的所有修改，也就是不可变服务器 服务配置 对服务的配置，可以使用一个专用系统来处理，称之为配置中心 服务与主机 单主机多服务 由于虚拟化基础设施本身也会占用一定的资源，所以这种方式本身虽然能提高资源的利用率，但会造成一些问题： 监控变得更加困难 放弃了微服务能独立部署不同服务的好处 不利于团队的自治性 增加了扩展的复杂性 应用程序容器 诸如tomcat等的容器可以让多个服务运行在同一个进程里，但这种方式不仅会限制技术栈的选择，而且还会使监控、分析等变得更加困难 一台主机一个服务 代表技术是虚拟机与容器 这种方式虽然浪费了一些资源，但是可以减少潜在的单点故障以及拥有更多的技术栈选择 调度模型 平台即服务(paas) 属于serverless，近些年越来越受青睐 将底层机器的管理全部交给云，只需要提供一个软件，就能帮你运行 部署方式 蓝绿部署 有时候，某些问题只有在特定环境下才能出现，蓝绿部署就是部署新版本服务后，不停止老版本服务，先对新服务运行一些测试，如果没问题就把流量从老服务转发到新服务，一旦出现问题，快速切换回老服务。 但需要你能切换生产流量到不同的主机以及拥有足够的主机来部署两个服务 金丝雀发布 金丝雀发布则是将部分生产流量从老服务切换到新服务，来验证系统是否按预期执行，金丝雀发布与蓝绿部署的区别在于，金丝雀发布老旧版本共存时间较长，而蓝绿部署一旦确定新系统没问题，就会关停老系统 自动化 微服务的引入，主机数量肯定会上升，如果手动管理这些机器，恐怕没那么容易，引入自动化能很好地提升工作效率 虚拟化 传统的虚拟化 传统的虚拟化技术，运行在操作系统之上的一个虚拟机软件，这个虚拟机软件再虚拟出硬件给操作系统运行 轻量级虚拟化 Hypervisor vagrant linux容器 docker 容器化部署 容器化集群部署 通过软件工具管理共享主机资源池，屏蔽主机层 部署接口 使用一个统一的部署接口来部署服务 构建这样的一个系统工作量很大，但是到后期，这些都是值得的 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-20 01:19:51 "},"软件工程/微服务/测试.html":{"url":"软件工程/微服务/测试.html","title":"测试","keywords":"","body":"测试 对于微服务来说，服务的拥有者应该负责测试代码的编写。 测试运行的缓慢会影响修复错误的效率，从而影响开发 类型 面向技术的测试：如单元测试，非功能性测试（安全、性能） 面向业务的测试：验收测试，探索性测试 范围 测试金字塔 单元测试 但测试通常是只测试一个函数和方法调用，并且应该跟外部环境无关 同时，单元测试对代码重构非常重要 服务测试 只对单个服务进行测试可以提高测试的隔离性，针对服务所需要的外部合作者，一般都是mock或者打桩 用户界面测试 这种测试覆盖了整个系统 各种测试的比例 根据经验，下面一层的测试通常要比上面一层的测试多一个数量级，因为越往上的测试，反馈周期越长，出了错误就没有那么快可以解决 实现服务测试 打桩：为被测服务的一些请求创建一些预设的响应 mock：mock会验证请求是否被正确调用 引入mock可能会更加复杂，所以可以创建一个智能的打桩服务 用户界面测试 集成的服务数量越多，测试就会越脆弱，不确定性也就越强 消费者驱动测试：针对消费者的需求产生测试 部署后再测试 平均修复时间胜于平均故障时间 跨功能测试 性能测试 性能测试需要有目标 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-20 01:19:51 "},"软件工程/微服务/监控.html":{"url":"软件工程/微服务/监控.html","title":"监控","keywords":"","body":"监控 目的 长期趋势分析 对照分析 告警 故障分析与定位 度量指标 时延 错误量 通信量 资源使用率 链路追踪 监控服务间的行为 链路追踪的组成： 日志中有用的信息 时间 标识 系统标识 用户标识 事件标识... 来源 日志级别 分类 Prometheus 架构 单服务单主机 主要监控主机的CPU、内存等数据以及服务所产生的日志 单服务多主机 如果所有主机都发生问题，那么可能是服务的问题 否则如果只是某一主机出现异常，问题定位就比较简单 同时，单一服务部署到多台主机，一般需要负载均衡器来分发请求，所以也要对负载均衡器进行监控 多服务多主机 此时问题定位就没那么容易了，必须收集到足够多的数据 日志 应该有一个专门的日志系统来聚合服务的日志 服务指标 需要有一个专门的系统来对收集来的信息进行聚合，分类展示 综合监控 通常可以对系统一些资源指标进行监控，判断实际值是否超出设定的阈值，但这些数据并不能直接说明服务是否能正常工作 语义监控 通过端到端的测试来监控服务的工作正常与否 关联标识 微服务架构系统提供的功能通常是由一系列的服务调用配合来完成，但是如果上游服务出现了一个错误，将错误扩展到下游，如何定位这个错误？ 解决这个问题的方法，是给一个个调用链分配一个标识，这样就可以根据这个标识找到这个调用链上的所有调用 标准化 无论是日志的格式，还是工具，都需要标准化 考虑受众 需要对日志的使用者，他们需要知道什么，想要什么以及如何消费数据等考虑清楚 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-21 01:13:25 "},"软件工程/微服务/安全.html":{"url":"软件工程/微服务/安全.html","title":"安全","keywords":"","body":"安全 验证与授权 验证：用来确定你是谁 授权：确定你能做什么 单点登录SSO 单点登录是指当主题视图访问某一资源时，会被重定向到一个身份提供者，这个提供者负责鉴别主体，鉴别完成之后将通知服务提供者采取相应操作 单点登录网关 使用一个统一的网关来鉴别主体，有效地减少重复编码。 但是需要解决的一个问题是，随着服务间的调用，如何在服务间传递这个身份信息？ 使用HTTP头携带是个不错的办法 深度防御 把所有鸡蛋放在一个篮子里是不安全的，深度防御的理念是对系统中的每一层做防御，以避免单点故障带来的严重后果 细粒度的授权 当授权角色细分达到一定的粒度时，对系统的管理维护来说是很复杂的。 整体来说，权限的粒度划分应该要以组织的结构为依据 服务间的验证与授权 边界内信任 就如局域网内的通信，在边界内的服务通信，通常都被默认为安全的 HTTP(S)身份认证 使用HTTP是不安全的，但是如果使用HTTPS则需要考虑证书的管理问题以及HTTPS无法被缓存等 证书 哈希 API密钥 通过服务端管理密钥来识别服务调用者以及对调用者进行管理 静态数据的安全 选择一个众所周知的加密算法，而非自己实现 加密算法应取决于密钥的复杂性，而非算法的保密性 选择应该加密的数据 按需解密 密钥管理 深度防御 防火墙 不同的范围使用不同的防火墙 日志 日志虽然无法预防，但是可以事后检测发生了什么 IDS IDS通常是在可信范围内尽力查找可疑目标 网络隔离 微服务可以利用分布部署的优点来进行网络隔离 操作系统 操作系统的漏洞仍然不可小视 保持节俭 真的需要存储那么多数据吗？ 为了安全，或者为了用户的隐私，只需要存取必须的数据即可 内建安全 可以将一些自动化的安全工具集成的CI中 外部验证 外包出去给第三方进行渗透测试 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-15 07:07:27 "},"软件工程/微服务/规模化.html":{"url":"软件工程/微服务/规模化.html","title":"规模化","keywords":"","body":"规模化微服务 故障 与其为防止故障做上一百个准备，不如定制一个快速从故障中恢复过来的流程 测量 响应时间 对于响应时间的测量，有时候网络是有异常情况的，所以使用百分比来测量连接的响应时间 可用性 对于24/7小时服务，可接受停机报告只有在历史报告的角度才有用 数据持久性 数据应该保持多久，能容忍多少丢失？ 功能降级 微服务系统是的功能是由多个服务合作提供的，所以某些不重要的服务即使不可用，也不该让整个系统不可用 架构性安全 也就说必须实现接口隔离，如果一个服务的请求都是共享同一个连接池，那很有可能某一接口会导致阻塞的请求越来越多，从而导致不可用 一些情况 超时 超时设置的太短或者太长都不好，尝试着设置一个默认的超时时间，记录日志，看超时的时候发生了什么 熔断器 如果发生一定量的失败请求后，断路器会打开，在断路器打开后任何调用都会快速失败，此后，客户端会发一些请求给生产者看服务是否恢复，如果恢复，就关闭断路器 接口隔离 可以把熔断器当做接口隔离服务不可用时的一种隔离手段 服务隔离 幂等性 所以幂等就是调用一次与调用多次的结果都是一样的，这种情况，在基于事件的协作下可能很好用 扩展 用更强的主机 垂直扩展 负载拆分 对单主机多服务进行服务拆分 将服务拆分为更小的服务 分散风险 尽量将服务分散在不同的主机、不同的数据中心 负载均衡 基于worker的系统 基于消息队列来实现 重新设计 设计一个系统时，我们往往不知道真正想要构建的是什么，如果在刚开始构建时引入了太多对未来的预测，这会耗费本可以花在更重要的事上的精力 数据库 读取扩展 对于数据来说，大部分数据读取的次数远远比写的次数要多得多 对于许多关系型数据库，可以设置在单个节点进行写操作，写入的这些数据将在某一时刻被同步到所有数据库节点，而读取操作可以被分发到各个节点上，但这可能会读取到不一致数据，虽然最终结果是一致的，这杯称为最终一致性 写扩展 可以对要被写的数据进行分片，存到不同的数据库上，但会引入对数据库查询的复杂性 使用共享的数据库基础设施 这会很节省主机资源，但是也会影响一个重要的单点故障 CQRS 类似于日志数据库，通过存取一系列的操作日志，来计算出某一具体时刻的数据 缓存 客户端缓存 缓存控制在客户端，所以如果想控制缓存是很困难 HTTP缓存 代理服务器缓存 好处是对客户端透明的，但会引入额外的网络跳数 服务器缓存 对客户端完全透明，而且想要控制缓存也必将容易 后写式缓存，有些情况会对同一数据执行许多次写操作，此时就可以先将数据缓存在内存中，待到特定时刻再写到数据源中 缓存过期的数据，当服务不可用时，可以返回这些过期的版本 当缓存大量击穿时，不应该采取同步的方法，而应该对客户快速失败，后台异步调用服务增加缓存 缓存应该保持简单 自动伸缩 可以一些规则，让运维系统自动增减服务实例 CAP定理 一致性：访问多个节点都得到同意的数据 可用性：每个请求都能获得响应 分区容忍性：某些节点无法联系之后，整个集群还能继续提供服务 这三个条件无法同时满足，当一个上去了，另外两个就要下来了 服务发现 DNS 动态的服务注册 zookeeper consul eureka 文档 swagger hal MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-16 07:30:33 "},"软件工程/微服务/分布式日志.html":{"url":"软件工程/微服务/分布式日志.html","title":"分布式日志","keywords":"","body":"分布式日志 传统日志收集 传统项目中，如果在生产环境中，有多台不同的服务器集群，如果生产环境需要通过日志定位项目的Bug的话，需要在每台节点上使用传统的命令方式查询，这样效率非常底下 ELK elasticsearch logstash kibana 1、每台服务器集群节点安装Logstash日志收集系统插件 2、每台服务器节点将日志输入到Logstash中 3、Logstash将该日志格式化为json格式，根据每天创建不同的索引，输出到ElasticSearch中 4、浏览器使用安装Kibana查询日志信息 logstash配置 logstash配置 input { # 从文件读取日志信息 输送到控制台 file { path => \"/home/my/elasticsearch-6.4.3/logs/elasticsearch.log\" codec => \"json\" ## 以JSON格式读取日志 type => \"elasticsearch\" start_position => \"beginning\" } } # filter { # # } output { # 标准输出 # stdout {} # 输出进行格式化，采用Ruby库来解析日志 stdout { codec => rubydebug } elasticsearch { hosts => [\"127.0.0.1:9200\"] index => \"es-%{+YYYY.MM.dd}\" } } 启动es 启动logstash./logstash -f log.conf 启动kibana 问题 每台机器就需要有一台logstash 非实时 使用ELK+Kafka 1.那些日志信息需要输入logstash （error级别） 2.AOP 异常通知 服务与服务之间如何区分日志索引文件（服务名称） 3.在分布式日志收集中，相同的服务集群的话是不需要区分日志索引文件。 4.目的为了 统一管理相同节点日志我信息。 5.相同的服务集群的话，是是不需要区分日志索引文件 搜索日志的时候，如何定位服务器节点信息呢？ 同步数据库 input { jdbc { jdbc_driver_library => \"/home/my/mysql-connector-java-5.1.46.jar\" jdbc_driver_class => \"com.mysql.jdbc.Driver\" jdbc_connection_string => \"jdbc:mysql://192.168.123.1:3306/shopa_member\" jdbc_user => \"root\" jdbc_password => \"123\" schedule => \"* * * * *\" statement => \"SELECT * FROM tb_user WHERE update_time >= :sql_last_value\" use_column_value => true tracking_column_type => \"timestamp\" tracking_column => \"update_time\" last_run_metadata_path => \"syncpoint_table\" } } output { elasticsearch { # ES的IP地址及端口 hosts => [\"127.0.0.1:9200\"] # 索引名称 可自定义 index => \"user\" # 需要关联的数据库中有有一个id字段，对应类型中的id document_id => \"%{USER_ID}\" document_type => \"user\" } stdout { # JSON格式输出 codec => json_lines } } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-04-05 06:38:22 "},"软件工程/微服务/ServiceMesh/ServiceMesh.html":{"url":"软件工程/微服务/ServiceMesh/ServiceMesh.html","title":"ServiceMesh","keywords":"","body":"Service Mesh SpringCloud Dubbo 等微服务框架的痛点： 侵入性强 业务代码与框架代码混合在一起 升级成本高 一旦框架升级，就需要重新进行测试 重新部署上线而跟业务没有太大的关系 版本碎片化严重 服务自己独立演化 线上中间件或者框架版本不一，难以统一治理 中间件演变困难 由于需要兼容老版本 历史包袱沉重 学习曲线不够平滑 单单一个SpringCloud就有大大小小几十个组件 功能不全 一些功能现有的微服务框架并没有 痛点往往是技术发展到一定的程度必然要经历的阶段，这些痛点促使技术不断发展、不断前进 基本概念 Service Mesh 是一个专门处理服务通讯的基础设施层。它的职责是在由云原生应用组成服务的复杂拓扑结构下进行可靠的请求传送。在实践中，它是一组和应用服务部署在一起的轻量级的网络代理，并且对应用服务透明 控制平面： 不直接解析数据包 与控制平面中的代理通信，下发策略和配置 负责网络行为的可视化 常提供 API 或者命令行工具可用于配置版本化管理，便于持续集成和部署 数据平面： 直接处理入站（业务应用）和出站数据包，转发、路由、健康检查、负载均衡、认证、鉴权、产生监控数据等 对应用透明 服务网格带来的变革： SDK轻量化 由于只需要少量的SDK 微服务治理与业务逻辑的解耦 同样由于SDK轻量 异构系统的统一治理，编写不同语言的SDK更加轻松 服务网格相比传统微服务框架的优势： 由于服务网格是一个基础设施层 所有的服务间通信都要通过它 所以带来了良好的可观察性 通过服务网格 可以很好地通过这个基础设施来对服务间的流量进行控制或者进行故障模拟 服务网格提供了保护网络调用的能力和基础设施 服务网格带来的问题： 复杂度更高 对运维要求更高 增加了一个中间层 肯定会有延迟问题 平台适配的侵入性 ServiceMesh K8S Istio Kubernetes vs Service Mesh K8S通过kube-proxy组件进行流量转发 Istio Service Mesh 可以沿用 Kubernetes 中的 service 做服务注册，还可以通过控制平面的平台适配器对接其他服务发现系统 Service Mesh的劣势：为了细粒度地进行流量管理，必将添加一系列新的抽象，从而会进一步增加用户的学习成本 Service Mesh的优势：kube-proxy 的设置都是全局生效的，无法对每个服务做细粒度的控制， Service Mesh 通过 sidecar proxy 的方式将 Kubernetes 中对流量的控制从 service 一层抽离出来，可以做更多的扩展 xDS 协议 Envoy Envoy 是 Istio Service Mesh 中默认的 Sidecar Istio Service Mesh Istio 它是一个完全开源的服务网格，以透明的方式构建在现有的分布式应用中。它也是一个平台，拥有可以集成任何日志、遥测和策略系统的 API 接口。Istio 多样化的特性使你能够成功且高效地运行分布式微服务架构，并提供保护、连接和监控微服务的统一方法。 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-24 07:56:50 "},"软件工程/微服务/SpringCloud/SpringCloud.html":{"url":"软件工程/微服务/SpringCloud/SpringCloud.html","title":"SpringCloud","keywords":"","body":"SpringCloud 为什么选择SpringCloud SpringCloud 提供了一套完整的微服务解决方案，不像其他框架只是解决了微服务中某个问题 demo demo MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-04 08:49:41 "},"软件工程/微服务/SpringCloud/注册中心.html":{"url":"软件工程/微服务/SpringCloud/注册中心.html","title":"注册中心","keywords":"","body":"注册中心 服务治理 如果服务与服务之间的依赖关系非常多的情况下，服务URL管理起起来非常复杂。在这时候可以使用服务治理技术，管理每个服务与服务之间的依赖关系.可以本地负载均衡、实现服务发现与注册、容错等。 服务注册原理 Eureka Eureka是Netflix开发的服务发现框架,Eureka包含两个组件： Eureka Server和Eureka Client. 各个节点启动后，会在Eureka Server中进行注册，这样Eureka Server中的服务注册表中将会存储所有可用服务节点的信息 在应用启动后，将会 向Eureka Server发送心跳,默认周期为30秒 保证AP，eureka在设计时优先保证可用性，每一个节点都是平等的，一部分节点挂掉不会影响到正常节点的工作，不会出现类似zk的选举leader的过程 流程 依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-server 配置 spring.application.name=eureka-server server.port=8001 #是否将自己注册到注册中心 eureka.client.register-with-eureka=false #是否从注册中心获取注册信息 eureka.client.fetch-registry=false eureka.client.serviceUrl.defaultZone=http://localhost:${server.port}/eureka/ @SpringBootApplication @EnableEurekaServer public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } } 服务注册 获取读锁 在注册表查找instance info 租约是否存在 不存在：创建新租约 存在：判断最后更新时间 如果更新时间比较大，则更新时间戳 设置上线时间 服务续约 eureka: instance: lease-expiration-duration-in-seconds: 10 # 10秒即过期 lease-renewal-interval-in-seconds: 5 # 5秒一次心跳 接收服务心跳 失效剔除与自我保护 失效剔除 有些时候，我们的服务实例并不一定会正常下线，可能由于内存溢出、网络故障等原因使得服务不能正常工作，而服务注册中心并未收到“服务下线”的请求。为了从服务表中将这些无法提供服务的实例剔除，Eureka Server 在启动的时候会创建一个定时任多默认每隔一一段时间(默认为60秒)将当前清单中超时(默认为90秒)没有续约的服务除出去 自我保护 默认情况下,EurekaClient会定时向EurekaServer端发送心跳，如果EurekaServer在一定时间内没有收到EurekaClient发送的心跳，便会把该实例从注册服务列表中剔除（默认是90秒）,为了防止只是EurekaClient与EurekaServer之间的网络故障，在短时间内丢失大量的实例心跳，这时候EurekaServer会开启自我保护机制，EurekaServer不会踢出这些服务 在开发中，由于会重复重启服务实例，所以经常会出现以下警告： EMERGENCY!EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY'RE NOT.RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEGING EXPIRED JUST TO BE SAFE. 所以开发时需要关闭自我保护 eureka: server: enable-self-preservation: false # 关闭自我保护模式（缺省为打开） eviction-interval-timer-in-ms: 1000 # 扫描失效服务的间隔时间（缺省为60*1000ms） 服务下线 是否有租约 没有租约下线失败 否则从注册表中移除 设置下线时间 添加下线记录 Eureka集群 Eureka 满足AP 牺牲了 C 配置 # eureka1 spring.application.name=spring-cloud-eureka server.port=8001 eureka.client.serviceUrl.defaultZone=http://localhost:8002/eureka/ # eureka2 spring.application.name=spring-cloud-eureka server.port=8002 eureka.client.serviceUrl.defaultZone=http://localhost:8001/eureka/ 根据两个配置文件启动两个实例 客户端配置 eureka.client.service-url.defaultZone=http://localhost:8001/eureka,http://localhost:8002/eureka 集群同步 注册中心Consul 工作原理 安装 https://www.consul.io/downloads.html 启动 consul agent -dev 生产者配置 依赖 org.springframework.boot spring-boot-starter-actuator org.springframework.boot spring-boot-starter-web org.springframework.cloud spring-cloud-starter-consul-discovery 配置 spring.application.name=consul-producer server.port=8503 spring.cloud.consul.host=localhost spring.cloud.consul.port=8500 #注册到consul的服务名称 spring.cloud.consul.discovery.serviceName=producer 消费者 依赖同生产者 配置 spring.application.name=consul-consumer server.port=8504 spring.cloud.consul.host=127.0.0.1 spring.cloud.consul.port=8500 #设置不需要注册到 consul 中 spring.cloud.consul.discovery.register=false 使用 @RestController public class ServiceController { @Autowired LoadBalancerClient loadBalancerClient; @Autowired DiscoveryClient discoveryClient; // 获取相关服务实例 @RequestMapping(\"/services\") public Object services(){ return discoveryClient.getInstances(\"producer\"); } // 自动选择服务实例 @RequestMapping(\"/discover\") public Object discover(){ return loadBalancerClient.choose(\"producer\").getUri().toString(); } @RequestMapping(\"/hi\") public String hi(){ ServiceInstance instance = loadBalancerClient.choose(\"producer\"); return new RestTemplate().getForObject(instance.getUri().toString()+\"/hi\",String.class); } } 注册中心Zookeeper SpringCloud把Zookeeper作为注册中心 保证CP，即任何时刻对zookeeper的访问请求能得到一致性的数据结果，同时系统对网络分割具备容错性，但是它不能保证每次服务的可用性 启动zk 服务依赖 org.springframework.cloud spring-cloud-starter-zookeeper-discovery 服务配置 server.port=8101 spring.application.name=zk-producer spring.cloud.zookeeper.connect-string=127.0.0.1:2181 @EnableDiscoveryClient MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-06 06:55:45 "},"软件工程/微服务/SpringCloud/服务提供与调用.html":{"url":"软件工程/微服务/SpringCloud/服务提供与调用.html","title":"服务提供与调用","keywords":"","body":"服务提供与调用 生产者 引入依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client 配置 spring.application.name=producer server.port=9000 eureka.client.serviceUrl.defaultZone=http://localhost:8001/eureka/ @SpringBootApplication @EnableDiscoveryClient public class ProducerApplication { public static void main(String[] args) { SpringApplication.run(ProducerApplication.class, args); } } 消费者 org.springframework.boot spring-boot-starter-web org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.cloud spring-cloud-starter-openfeign @EnableDiscoveryClient @EnableFeignClients public class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); } } @FeignClient(\"producer\") public interface HelloRemote { @RequestMapping(\"/hello\") String hello(@RequestParam String name); } 使用 @RestController public class ConsumerController { @Autowired HelloRemote helloRemote; @RequestMapping(\"/hi\") public String hi(){ return helloRemote.hello(\"my\"); } } 请求压缩 feign: compression: request: enabled: true # 开启请求压缩 response: enabled: true # 开启响应压缩 负载均衡 分别启动两个生产者，则两个生产者同时提供服务 客户端负载均衡 从注册中心服务器端上获取服务注册信息列表，缓存到本地。后在本地实现轮训负载均衡策略 服务端负载均衡 客户端所有请求统一交给一台服务器，由这台服务器进行实现负载均衡请求转发 本地负载均衡的实现 // 随机负载均衡 List list = discoveryClient.getInstances(\"producer\"); Random random = new Random(); ServiceInstance serviceInstance = list.get(random.nextInt(list.size())); // 使用Ribbon @RestController public class Controller { @Autowired LoadBalancerClient client; @RequestMapping(\"/user\") public String user(){ return new RestTemplate().getForObject( client.choose(\"user-service\").getUri().toString()+\"/user\",String.class); } } // 另外一种方法 @Autowired RestTemplate restTemplate; @RequestMapping(\"/user\") public String user(){ return restTemplate.getForObject(\"http://user-service/user\",String.class); } @Bean @LoadBalanced public RestTemplate restTemplate(){ return new RestTemplate(); } 负载均衡策略 # 修改负载均衡策略 user-service.ribbon.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.RandomRule MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-06 01:49:52 "},"软件工程/微服务/SpringCloud/熔断器与熔断监控.html":{"url":"软件工程/微服务/SpringCloud/熔断器与熔断监控.html","title":"熔断器与熔断监控","keywords":"","body":"熔断器 雪崩效应 基础服务的故障可能会导致级联故障， 进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程 请求堆积 在大量请求到来时，处理器有一个线程池来处理请求，当请求到达量远远大于处理量，请求就会在线程池中堆积，从而导致大量请求被阻塞 服务隔离 当有故障发生时，能将问题和影响隔离在某个模块内部，而不扩散风险，不波及其它模块，不影响整体的系统服务 服务降级 当调用的服务不可用时，服务调用方不会继续等待，而是(服务调用方)使用一个预设好的结果返回 服务熔断 一般是某个服务故障或者是异常引起的，类似现实世界中的‘保险丝’，当某个异常条件（通常是请求量过高）被触发，直接熔断整个服务，而不是一直等到此服务超时 Hystrix 断路器机制 当Hystrix Command请求后端服务失败数量超过一定比例(默认50%), 断路器会切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认5秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况, 如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN) 统计器（Metrics）：滑动窗口（metrics.rollingStats.timeInMilliseconds）以及桶（metrics.rollingStats.numBuckets） Hystrix 并不是只要有一条请求经过就去统计，而是将整个滑动窗口均分为 numBuckets 份，时间每经过一份就去统计一次。在经过一个时间窗口后，才会判断断路器状态要不要开启 Fallback 相当于是降级操作. 对于查询操作, 我们可以实现一个fallback方法, 当请求后端服务出现异常的时候, 可以使用fallback方法返回的值. fallback方法的返回值一般是设置的默认值或者来自缓存 资源隔离 在Hystrix中, 主要通过线程池来实现资源隔离. 通常在使用的时候我们会根据调用的远程服务划分出多个线程池 每个外部依赖用一个单独的线程池，这样的话，如果对那个外部依赖调用延迟很严重，最多就是耗尽那个依赖自己的线程池而已，不会影响其他的依赖调用 线程池机制的缺点 多了一些管理线程，增加了CPU的开销 整体流程 添加熔断机制 熔断只是作用在服务调用这一端 开启配置 feign.hystrix.enabled=true 编写fallback @Component public class HelloRemoteHystrix implements HelloRemote { @Override public String hello(String name) { return \"sorry,service call failed\"; } } 在远程调用接口上添加fallback @FeignClient(value = \"producer\",fallback = HelloRemoteHystrix.class) public interface HelloRemote { @RequestMapping(\"/hello\") String hello(@RequestParam String name); } 这样一旦producer挂掉了，将会返回默认结果 添加服务隔离机制 引入依赖 org.springframework.cloud spring-cloud-starter-netflix-hystrix @RequestMapping(\"/user\") // 添加这个注解之后，hystrix会开启服务隔离，访问这个接口的线程独属于某一个线程池 @HystrixCommand public String user(){ return restTemplate.getForObject(\"http://user-service/user\",String.class); } 接口添加@HystrixCommand这个注解之后，该接口默认的超时时间是1秒，需要设置超时时间，否则超时后hystrix会抛出一个异常，不会等到fegin返回 超时时间 @RequestMapping(\"/user\") @HystrixCommand(commandProperties = {@HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\",value = \"5000\")}) public String user(){ return restTemplate.getForObject(\"http://user-service/user\",String.class); } 信号量隔离 hystrix有两种隔离方式，线程池和信号量 线程池通过线程池来实现限流的，信号量则是通过维护一个计数器来限制 一些概念 command key 代表了一类 command，一般来说，代表了下游依赖服务的某个接口 command group 默认情况下，就是通过 command group 来定义一个线程池的，而且还会通过 command group 来聚合一些监控和报警信息，同一个 command group 中的请求，都会进入同一个线程池中 熔断监控 Hystrix-dashboard 通过Hystrix Dashboard我们可以在直观地看到各Hystrix Command的请求响应时间, 请求成功率等数据 单个应用的熔断监控 添加依赖 org.springframework.cloud spring-cloud-starter-netflix-hystrix org.springframework.cloud spring-cloud-starter-netflix-hystrix-dashboard org.springframework.boot spring-boot-starter-actuator 打开自动配置 @EnableCircuitBreaker @EnableHystrixDashboard 如果发生404则添加如下配置 @Bean public ServletRegistrationBean getServlet() { HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings(\"/hystrix.stream\"); registrationBean.setName(\"HystrixMetricsStreamServlet\"); return registrationBean; } 访问 http://127.0.0.1:10000/hystrix/ Turbine 添加依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.cloud spring-cloud-starter-netflix-hystrix org.springframework.cloud spring-cloud-starter-netflix-hystrix-dashboard org.springframework.cloud spring-cloud-starter-netflix-turbine 配置 spring.application.name=hystrix-dashboard-turbine server.port=11000 turbine.appConfig=node1,node2 turbine.aggregator.clusterConfig= default turbine.clusterNameExpression= new String(\"default\") eureka.client.serviceUrl.defaultZone=http://localhost:8001/eureka/ @EnableTurbine @EnableHystrixDashboard MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-03 02:08:41 "},"软件工程/微服务/SpringCloud/配置中心.html":{"url":"软件工程/微服务/SpringCloud/配置中心.html","title":"配置中心","keywords":"","body":"配置中心 在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库 中。在spring cloud config 组件中，分两个角色，一是config server，二是config client 配置中心应该提供的功能 服务端与客户端支持 集中管理各环境的配置文件 修改之后可以快速生效 版本管理 并发查询 多语言支持 服务端 依赖 org.springframework.cloud spring-cloud-config-server 配置 server: port: 8003 spring: application: name: spring-cloud-config-server cloud: config: server: git: uri: https://github.com/0xcaffebabe/config/ # 配置git仓库的地址 search-paths: config1 # git仓库地址下的相对地址，可以配置多个，用,分割。 @EnableConfigServer 仓库中的文件 这时候访问 server/config/dev即可获取配置信息 客户端 依赖 org.springframework.cloud spring-cloud-starter-config 配置 application.properties server.port=8004 spring.application.name=config-client bootstrap.properties spring.cloud.config.name=config spring.cloud.config.profile=dev spring.cloud.config.uri=http://localhost:8003/ spring.cloud.config.label=master 获取 @Value(\"${config.hello}\") private String port; 配置刷新 添加依赖 org.springframework.boot spring-boot-starter-actuator 开启更新机制 @RestController // 一定要加这个 @RefreshScope public class MyController { @Value(\"${config.hello}\") private String port; @RequestMapping(\"/hello\") public String hello(){ return port; } } 配置 management.endpoints.web.exposure.include=refresh,health,info 当配置文件发生更新时，调用客户端接口刷新配置 curl -X POST http://localhost:8004/actuator/refresh 发起对该地址的请求可让客户端去向配置中心获取最新配置并应用到相关成员变量上 配置中心服务化 添加依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client 配置 eureka: client: serviceUrl: defaultZone: http://localhost:8001/eureka/ # 注册中心eureka地址 @EnableDiscoveryClient 客户端改造 添加依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client 删除 spring.cloud.config.uri 添加 spring.cloud.config.discovery.enabled spring.cloud.config.discovery.serviceId eureka.client.serviceUrl.defaultZone @EnableDiscoveryClient 高可用 启动多个配置中心实例 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-07 01:23:39 "},"软件工程/微服务/SpringCloud/消息总线.html":{"url":"软件工程/微服务/SpringCloud/消息总线.html","title":"消息总线","keywords":"","body":"消息总线 微服务架构中，通常会使用轻量级的消息代理来构建一个共用的消息主题来连接各个微服务实例，它广播的消息会被所有在注册中心的微服务实例监听和消费，也称消息总线 使用 添加依赖（服务端与客户端 org.springframework.cloud spring-cloud-starter-bus-amqp 配置服务端 rabbitmq: host: 127.0.0.1 port: 5672 username: guest password: guest management: endpoints: web: exposure: include: bus-refresh endpoint: bus-refresh: enabled: true 配置客户端 # 记得rabbitmq服务器信息 # 刷新时，关闭安全验证 management.endpoints.web.exposure.include=bus-refresh # 开启消息跟踪 spring.cloud.bus.trace.enabled=true 当配置发生更新时，post调用配置中心 http://config_server:8003/actuator/bus-refresh 新配置就会传播到所有客户端 局部刷新 在调用webhook的时候，可以指定参数来指定更新要传播到哪些微服务 总线事件 访问http://127.0.0.1:8003/actuator/trace可以追踪 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-17 05:24:05 "},"软件工程/微服务/SpringCloud/消息驱动.html":{"url":"软件工程/微服务/SpringCloud/消息驱动.html","title":"消息驱动","keywords":"","body":"消息驱动 SpringCloud Stream消息驱动可以简化开发人员对消息中间件的使用复杂度，让系统开发人员更多尽力专注与核心业务逻辑的开发 使用 依赖 org.springframework.cloud spring-cloud-stream org.springframework.cloud spring-cloud-starter-stream-rabbit 配置 spring.rabbitmq.host=192.168.182.130 spring.rabbitmq.username=my spring.rabbitmq.password=123 @EnableBinding(MessageService.class) 生产者 public interface MessageService { @Output(\"msg1\") SubscribableChannel send(); } 发送消息 messageService.send().send(MessageBuilder.withPayload(\"cxk\"+ UUID.randomUUID()).build()); 消费者 public interface MessageService { @Input(\"msg1\") SubscribableChannel receive(); } 接收消息 @StreamListener(\"msg1\") public void listen(String msg){ System.out.println(\"消费者接收到消息:\"+msg); } 消费者组 # 配置相同组的消费者会对消息进行轮询消费 spring.cloud.stream.bindings.msg1.group=group1 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-17 06:44:12 "},"软件工程/微服务/SpringCloud/服务网关.html":{"url":"软件工程/微服务/SpringCloud/服务网关.html","title":"服务网关","keywords":"","body":"服务网关 API网关统一服务入口，可方便实现对平台众多服务接口进行管控，对访问服务的身份认证、防报文重放与防数据篡改、功能调用的业务鉴权、响应数据的脱敏、流量与并发控制，甚至基于API调用的计量或者计费等等 网关分类 开放api 服务网关 接口设计 接口权限(开放接口|内部接口)、考虑幂等性、安全性(Https )防止篡改数据(验证签名)、使用网关拦截 接口实现黑名单和白名单、接口使用http协议+json格式restful 目的为了跨平台。 考虑高并发对接口服务实现保护服务降级、熔断、隔离之类，最后使用统一API管理平台api swagger 应用场景 黑白名单 日志 协议适配 身份认证 计流限流 路由 网关部署架构 nginx面向服务器 网关面向服务 Spring Cloud Zuul zuul与nginx Nginx是采用服务器负载均衡进行转发 Zuul依赖Ribbon和eureka实现本地负载均衡转发 Nginx功能比Zuul功能更加强大，能够整合其他语言比如lua脚本实现强大的功能，同时Nginx可以更好的抗高并发，Zuul网关适用于请求过滤和拦截 使用 添加依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client org.springframework.cloud spring-cloud-starter-netflix-zuul 配置 server.port=8010 spring.application.name=gateway # 这里的配置表示，访问/bd/** 直接重定向到http://baidu.com/** zuul.routes.baidu.path=/bd/** zuul.routes.baidu.url=http://baidu.com/ eureka.client.serviceUrl.defaultZone=http://localhost:8001/eureka/ @EnableZuulProxy 默认路由规则 http://ZUUL_HOST:ZUUL_PORT/微服务在Eureka上的serviceId/** 比如访问http://localhost:8010/producer/ 则gateway就会把请求转发到producer服务上面去 简化路由配置 zuul: routes: user-service: /user-service/** # 这里是映射路径 Zuul的核心 Fliter 场景 请求鉴权：一般放在pre类型，如果发现没有访问权限，直接就拦截了 异常处理：一般会在error类型和post类型过滤器中结合来处理。 服务调用时长统计 自定义Filter 实现ZuulFilter @Component public class MyFilter extends ZuulFilter { @Override public String filterType() {return FilterConstants.PRE_TYPE;} @Override public int filterOrder() {return FilterConstants.PRE_DECORATION_FILTER_ORDER;} @Override public boolean shouldFilter() {return true;} @Override public Object run() throws ZuulException { RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); String token = request.getParameter(\"token\"); if (\"my\".equals(token)){ ctx.setSendZuulResponse(true); ctx.setResponseStatusCode(200); ctx.set(\"isSuccess\",true); }else{ ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(400); ctx.setResponseBody(\"error token\"); ctx.set(\"isSuccess\",false); } return null; } } 这样当通过网关访问服务时，不符合条件的请求将会被过滤掉 整合配置中心 依赖 org.springframework.cloud spring-cloud-starter-config org.springframework.boot spring-boot-starter-actuator 手动配置zuul配置对象 @RefreshScope @ConfigurationProperties(\"zuul\") public ZuulProperties zuulProperties() { return new ZuulProperties(); } 进行跨域配置 @Configuration public class CorsConfig { @Bean public CorsFilter corsFilter() { final UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); final CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); // 允许cookies跨域 config.addAllowedOrigin(\"*\");// #允许向该服务器提交请求的URI，*表示全部允许，在SpringMVC中，如果设成*，会自动转成当前请求头中的Origin config.addAllowedHeader(\"*\");// #允许访问的头信息,*表示全部 config.setMaxAge(18000L);// 预检请求的缓存时间（秒），即在这个时间段里，对于相同的跨域请求不会再预检了 config.addAllowedMethod(\"*\");// 允许提交请求的方法，*表示全部允许 source.registerCorsConfiguration(\"/**\", config); return new CorsFilter(source); } } 忽略 # 忽略该服务 zuul.ignored-services: upload-servie 路由熔断 自定义fallback @Component public class MyFallback implements FallbackProvider { @Override public String getRoute() { return \"producer\"; } @Override public ClientHttpResponse fallbackResponse(String route, Throwable cause) { cause.printStackTrace(); return new ClientHttpResponse() { @Override public HttpStatus getStatusCode() throws IOException { return HttpStatus.valueOf(500); } @Override public int getRawStatusCode() throws IOException { return 500; } @Override public String getStatusText() throws IOException { return \"SERVER ERROR\"; } @Override public void close() { } @Override public InputStream getBody() throws IOException { return new ByteArrayInputStream(\"service is unavailable\".getBytes()); } @Override public HttpHeaders getHeaders() { HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.TEXT_PLAIN); return headers; } }; } } 当producer挂掉时，将会返回相关信息 路由重试 添加依赖 org.springframework.retry spring-retry 配置 #是否开启重试功能 zuul.retryable=true #对当前服务的重试次数 ribbon.MaxAutoRetries=2 #切换相同Server的次数 ribbon.MaxAutoRetriesNextServer=0 当相同的服务挂掉一部分后，如果多次请求不成功，则接下来的请求则会转发到其他服务上 也就是说,自动的寻找到正确响应的服务上去.错误的实例被抛弃 zuul高可用 启动两个网关实例8000和7000 配置nginx负载均衡 upstream gateway { server 127.0.0.1:8000; server 127.0.0.1:7000; } server { listen 6060; location / { proxy_pass http://gateway; proxy_connect_timeout 1s; proxy_send_timeout 1s; proxy_read_timeout 1s; } } Spring Cloud Gateway 路由 断言 过滤器 vs zuul ZuuL网关属于Netflix公司开源框架，属于第一代微服务网关. GateWay属于SpringCloud自己研发的网关框架，属于第二代微服务网关. gateway不依赖servlet api，所以性能更强 gateway的转发是在tcp层 配置 org.springframework.cloud spring-cloud-starter-gateway 定义路由规则 @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder) { return builder.routes() .route(\"path_route\", r -> r.path(\"/hi\") .uri(\"http://localhost:8503\")) .build(); } 通过时间匹配 builder.routes() .route(\"path_route\", r -> r.before(ZonedDateTime.now()) .uri(\"http://localhost:8503\")) .build(); 通过Cookie匹配 builder.routes() .route(\"path_route\", r -> r.cookie(\"key\",\"value\") .uri(\"http://localhost:8503\")) .build(); 通过header属性匹配 通过Host匹配 通过请求方式匹配 通过请求路径匹配 通过请求参数匹配 通过请求IP匹配 服务化 依赖 org.springframework.cloud spring-cloud-starter-netflix-eureka-client 配置 server: port: 8888 spring: application: name: gateway cloud: gateway: discovery: locator: enabled: true eureka: client: service-url: defaultZone: http://localhost:8001/eureka/ logging: level: org.springframework.cloud.gateway: debug 默认转发规则 http://网关/服务serviceId/具体的url Filter PRE 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等 POST 这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的 HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等 简单过滤器实例 配置 server: port: 8888 spring: application: name: gateway cloud: gateway: routes: - id: add_request_parameter_route uri: http://localhost:9003 filters: - AddRequestParameter=name, my predicates: - Method=GET discovery: locator: enabled: true eureka: client: service-url: defaultZone: http://localhost:8001/eureka/ logging: level: org.springframework.cloud.gateway: debug 在上面的配置中，添加了一个路由过滤规则：对9003端口的get请求添加一个请求参数name:my 服务化配置 改成uri: lb://producer 则路由配置只会对producer服务生效 修改路径的过滤器 StripPrefix Filter - id: nameRoot uri: lb://producer predicates: - Path=/name/** filters: - StripPrefix=2 如果访问/name/my/hello，网关就会将路径修改为/hello PrefixPath Filter - id: prefixpath_route uri: lb://producer predicates: - Path=* filters: - PrefixPath=/mypath 自动给URL加上mypath前缀 自定义Filter @Component public class TokenFilter implements GlobalFilter { @Override public Mono filter(ServerWebExchange exchange, GatewayFilterChain chain) { var token = exchange.getRequest().getQueryParams().get(\"token\"); if (!CollectionUtils.isEmpty(token)){ return chain.filter(exchange); } ServerHttpResponse response = exchange.getResponse(); response.setStatusCode(HttpStatus.FORBIDDEN); return response.writeWith( Mono.just( response.bufferFactory().wrap(\"token is null\".getBytes()) ) ); } } 限速路由器 熔断路由器 依赖 org.springframework.cloud spring-cloud-starter-netflix-hystrix - id: hystrix_route uri: http://localhost:9001 predicates: - Path=/* filters: - Hystrix=myCommandName 重试路由器 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-04-09 00:50:08 "},"软件工程/微服务/SpringCloud/链路追踪.html":{"url":"软件工程/微服务/SpringCloud/链路追踪.html","title":"链路追踪","keywords":"","body":"链路追踪 Spring Cloud Sleuth为服务之间调用提供链路追踪。通过Sleuth可以很清楚的了解到一个服务请求经过了哪些服务，每个服务处理花费了多长 Sleuth ZipKin Zipkin 是一个开放源代码分布式的跟踪系统，由Twitter公司开源，它致力于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现 搭建服务端 spring boot2.x之后不推荐执行搭建服务端，而是使用编译好的版本 curl -sSL https://zipkin.io/quickstart.sh | bash -s 完成之后会得到一个jar包 java -jar zipkin.jar 访问http://127.0.0.1:9411 客户端添加zipkin支持 org.springframework.cloud spring-cloud-starter-zipkin spring.zipkin.base-url=http://localhost:9411 spring.sleuth.sampler.rate=1 原理 当请求发送到分布式系统的入口端点时，只需要服务跟踪框架为该请求创建一个唯的跟踪标识，这个标识将随着服务调用在各个服务间传递，这样就可以根据这个标识得到各个服务间的调用，从而组合成一条完整的调用链 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-25 00:39:27 "},"软件工程/微服务/SpringCloud/开放平台.html":{"url":"软件工程/微服务/SpringCloud/开放平台.html","title":"开放平台","keywords":"","body":"开放平台 SpringCloudOAuth2 使用 授权服务端 依赖 org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-security org.springframework.cloud spring-cloud-starter-oauth2 配置 @Configuration @EnableAuthorizationServer public class AuthorizationServerConfig extends AuthorizationServerConfigurerAdapter { // accessToken有效期 private int accessTokenValiditySeconds = 7200; // 两小时 // 添加商户信息 @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { // withClient appid clients.inMemory().withClient(\"client_1\") .redirectUris(\"http://www.baidu.com\") .secret(passwordEncoder().encode(\"123456\")) .authorizedGrantTypes(\"password\",\"client_credentials\",\"refresh_token\",\"authorization_code\").scopes(\"all\").accessTokenValiditySeconds(accessTokenValiditySeconds); } // 设置token类型 @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) { endpoints.authenticationManager(authenticationManager()).allowedTokenEndpointRequestMethods(HttpMethod.GET, HttpMethod.POST); } @Override public void configure(AuthorizationServerSecurityConfigurer oauthServer) { // 允许表单认证 oauthServer.allowFormAuthenticationForClients(); // 允许check_token访问 oauthServer.checkTokenAccess(\"permitAll()\"); } @Bean AuthenticationManager authenticationManager() { return authentication -> daoAuhthenticationProvider().authenticate(authentication); } @Bean public AuthenticationProvider daoAuhthenticationProvider() { DaoAuthenticationProvider daoAuthenticationProvider = new DaoAuthenticationProvider(); daoAuthenticationProvider.setUserDetailsService(userDetailsService()); daoAuthenticationProvider.setHideUserNotFoundExceptions(false); daoAuthenticationProvider.setPasswordEncoder(passwordEncoder()); return daoAuthenticationProvider; } // 设置添加用户信息,正常应该从数据库中读取 @Bean UserDetailsService userDetailsService() { InMemoryUserDetailsManager userDetailsService = new InMemoryUserDetailsManager(); userDetailsService.createUser(User.withUsername(\"user_1\").password(passwordEncoder().encode(\"123456\")) .authorities(\"ROLE_USER\").build()); userDetailsService.createUser(User.withUsername(\"user_2\").password(passwordEncoder().encode(\"123456\")) .authorities(\"ROLE_USER\").build()); return userDetailsService; } @Bean PasswordEncoder passwordEncoder() { // 加密方式 return new BCryptPasswordEncoder(); } } @Component public class SecurityConfig extends WebSecurityConfigurerAdapter { // 授权中心管理器 @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } // 拦截所有请求,使用httpBasic方式登陆 @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests().antMatchers(\"/**\").fullyAuthenticated().and().httpBasic(); } } 通过 http://localhost:9000/oauth/authorize?response_type=code&client_id=client_1&redirect_uri=http://www.baidu.com&scope=all获取code 根据code获取获取access_token http://localhost:9000/oauth/token?grant_type=authorization_code&code=zCn8Gl&redirect_uri=http://www.baidu.com&scope=all&password=123456 资源端 依赖同授权服务端 配置 security: oauth2: resource: ####从认证授权中心上验证token tokenInfoUri: http://localhost:9000/oauth/check_token preferTokenInfo: true client: accessTokenUri: http://localhost:9000/oauth/token userAuthorizationUri: http://localhost:9000/oauth/authorize ###appid clientId: client_1 ###appSecret clientSecret: 123456 @Configuration @EnableResourceServer public class ResourceServerConfiguration extends ResourceServerConfigurerAdapter { @Override public void configure(HttpSecurity http) throws Exception { // 对 api 请求进行拦截 http.authorizeRequests().antMatchers(\"/api\").authenticated(); } } @EnableOAuth2Sso MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-18 11:28:05 "},"软件工程/微服务/SpringCloudAlibaba/SpringCloudAlibaba.html":{"url":"软件工程/微服务/SpringCloudAlibaba/SpringCloudAlibaba.html","title":"SpringCloudAlibaba","keywords":"","body":"SpringCloudAlibaba Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务 SpringCloud 第二代 项 Spring Cloud第一代 Spring Cloud第二代 网关 Spring Cloud Zuul Spring Cloud Gateway 注册中心 eureka(不再更新)，Consul,ZK 阿里Nacos，拍拍贷radar等可选 配置中心 spring cloud config 阿里Nacos，携程Apollo，随行付Config Keeper 客户端软负载均衡 Ribbon spring-cloud-loadbalancer 熔断器 Hystrix spring-cloud-r4j(Resilience4J)，阿里Sentinel Nacos 服务发现和服务健康监测 动态配置服务 动态DNS服务 服务即其元数据管理 概念 地域 物理的数据中心，资源创建成功后不能更换 可用区 同一地域内，电力和网络互相独立的物理区域 接入点 地域的某个服务的入口域名 命名空间 不同的命名空间下，可以存在相同的 Group 或 Data ID 的配置。Namespace 的常用场景之一是不同环境的配置的区分隔离 配置 配置管理 系统配置的编辑、存储、分发、变更管理、历史版本管理、变更审计等 配置项 一个具体的可配置的参数与其值域，通常以 param-key=param-value 的形式存在 配置集 一组相关或者不相关的配置项的集合 配置集ID 配置分组 配置快照 Nacos 的客户端 SDK 会在本地生成配置的快照 类似于缓存 服务 服务名 服务注册中心 服务发现 对服务下的实例的地址和元数据进行探测 元信息 服务或者配置的描述信息 应用 服务分组 虚拟集群 同一个服务下的所有服务实例组成一个默认集群 实例 权重 健康检查 健康保护阈值 止因过多实例不健康导致流量全部流向健康实例 架构 注册中心 使用 生产者 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery spring.application.name=provider spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 消费者 @FeignClient(\"provider\") public interface ProviderClient { @GetMapping(\"/name\") String name(); } @RestController public static class Api { @Autowired private ProviderClient client; @GetMapping(\"/\") public String home() { return client.name(); } } vs Zookeeper & Eureka 不同点: Zookeeper采用CP保证数据的一致性的问题 Eureka采用ap的设计理念架构注册中心，完全去中心化思想 Nacos.从1.0版本支持CP和AP混合模式集群，默认是采用Ap保证服务可用性，CP的形式底层集群raft协议保证数据的一致性的问题。 最主要的是Eureka集群中的各个节点是对等的，而Nacos则有主从之分 配置中心 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config # bootstrap.properties spring.cloud.nacos.config.server-addr=127.0.0.1:8848 spring.cloud.nacos.config.name=provider-config # 指定配置文件后缀名 spring.cloud.nacos.config.file-extension=properties 默认格式：${config-name}-${profile}.#{file-extension} 使用 applicationContext.getEnvironment().getProperty(\"app.name\") 自定义namespace 不同的命名空间下，可以存在相同的 Group 或 Data ID 的配置。Namespace 的常用场景之一是不同环境的配置的区分隔离 通过指定 ${spring.cloud.nacos.config.namespace} 配置来实现 自定义Group ${spring.cloud.nacos.config.group} 自定义data-id spring.cloud.nacos.config.extension-configs[0].data-id=xxx # 配置支持刷新 spring.cloud.nacos.config.extension-configs[0].refresh=true 配置的优先级 高：通过内部相关规则(应用名、应用名+ Profile )自动生成相关的 Data Id 配置 中：通过 spring.cloud.nacos.config.extension-configs[n].data-id 的方式支持多个扩展 Data Id 的配置 低：通过 spring.cloud.nacos.config.shared-dataids 支持多个共享 Data Id 的配置 配置中心集群 Sentinel 基本概念 资源：可以是 Java 应用程序中的任何内容 规则：包括流量控制规则、熔断降级规则以及系统保护规则 流量控制：Sentinel 作为一个调配器，可以根据需要把随机的请求调整成合适的形状 流量控制可以从以下角度切入： 资源的调用关系，例如资源的调用链路，资源和资源之间的关系 运行指标，例如 QPS、线程池、系统负载等 控制的效果，例如直接限流、冷启动、排队等 熔断降级： Hystrix 通过线程池的方式，来对依赖(在我们的概念中对应资源)进行了隔离。这样做的好处是资源和资源之间做到了最彻底的隔离。缺点是除了增加了线程切换的成本 sentinel 通过使用以下方式限制： 并发线程数 同计数器 当线程数达到一定数量 新的请求就会被拒绝 响应时间 当资源响应时间超过阈值 对该资源的访问会直接拒绝 基本原理 所有的资源都对应一个资源名称以及一个 Entry。Entry 可以通过对主流框架的适配自动创建，也可以通过注解的方式或调用 API 显式创建 通过一系列的Slot来实现相对应的功能 vs hystrix item Sentinel Hystrix 隔离策略 信号量隔离 线程池隔离/信号量隔离 熔断降级策略 基于响应时间或失败比率 基于失败比率 实时指标实现 滑动窗口 滑动窗口（基于 RxJava） 规则配置 支持多种数据源 支持多种数据源 扩展性 多个扩展点 插件的形式 基于注解的支持 支持 支持 限流 基于 QPS，支持基于调用关系的限流 有限的支持 流量整形 支持慢启动、匀速器模式 不支持 系统负载保护 支持 不支持 控制台 开箱即用，可配置规则、查看秒级监控、机器发现等 不完善 常见框架的适配 Servlet、Spring Cloud、Dubbo、gRPC 等 Servlet、Spring Cloud Netflix 基本使用 com.alibaba.cloud spring-cloud-starter-alibaba-sentinel @GetMapping(\"/name\") @SentinelResource(value = \"resource1\",blockHandlerClass = {ServiceFallback.class}) public String name() { return \"provider\"+port; } sentinel-dashboard 添加流控规则 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-28 08:42:01 "},"计算机系统/nav.html":{"url":"计算机系统/nav.html","title":"计算机系统","keywords":"","body":"计算机系统 冯·诺依曼计算机的工作原理 存储程序 将程序存放在计算机的存储器中 程序控制 按指令地址访问存储器并取出指令，经译码依次产生指令执行所需的控制信号，实现对计算的控制，完成指令的功能 硬件系统 软件系统 可运行的思想和内容的数字化 软件的表现形式: 程序和数据（以二进制表示的信息） 软件的核心: 算法 性能评价 非时间指标 机器字长: 指机器一次能处理的二进制位数 总线宽度：数据总线一次能并行传送的最大信息的位数 主存容量与存储带宽 时间指标 主频f/时钟周期T , 外频、倍频 CPI (Clock cycles Per Instruction) MIPS (Million Instructions Per Second) CPU时间 反映CPU全速工作时完成该进程所花费的时间 性能测试 计算机系统中配置了大量的传感器和寄存器，系统运行的相关参数保存在对应的寄存器中 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-12 13:57:08 "},"计算机系统/程序结构和执行/数据的表示.html":{"url":"计算机系统/程序结构和执行/数据的表示.html","title":"数据的表示","keywords":"","body":"数据的表示 组织数据,方便计算机硬件直接使用 机器内的数据表示 原码 原码(true form)是一种计算机中对数字的二进制定点表示方法。原码表示法在数值前面增加了一位符号位（即最高位为符号位）：正数该位为0，负数该位为1（0有两种表示：+0和-0），其余位表示数值的大小 反码 反码跟原码是正数时，一样；负数时，反码就是原码符号位除外，其他位按位取反 补码 在计算机系统中，数值一律用补码来表示和存储。原因在于，使用补码，可以将符号位和数值域统一处理；同时，加法和减法也可以统一处理 移码 对补码的符号位取反 定点与浮点数据表示 定点数据 可表示定点小数和整数 浮点数据 不同系统可能根据自己的浮点数格式从中提取不同位数的阶码 IEEE 754格式 S 8位偏指数E 23位有效尾数M 单精度 S 11位偏指数E 52位有效尾数M 双精度 数据校验 受元器件的质量、电路故障或噪音干扰等因素的影响，数据 在被处理、传输、存储的过程中可能出现错误，若能设计硬件层面的错误检测机制，可以减少基于软件检错的代价 基本原理 增加冗余码 码距 同一编码中，任意两个合法编码之间不同二进数位数的最小值 校验码中增加冗余项的目的就是为了增大码距 1) 码距≥e+1:可检测e个错误 2) 码距≥2t+1:可纠正t个错误 3) 码距≥e+t+1:可纠正t个错误，同时检测e个错误(e >= t) 奇偶校验 编码与检错简单 编码效率高 不能检测偶数位错误, 无错结论不可靠，是一种错误检测码 不能定位错误，因此不具备纠错能力 CRC校验 海明校验 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-11 07:38:34 "},"计算机系统/程序结构和执行/运算方法与运算器.html":{"url":"计算机系统/程序结构和执行/运算方法与运算器.html","title":"运算方法与运算器","keywords":"","body":"运算方法与运算器 定点数运算及溢出检测 定点数加法运算 定点数减法运算 溢出 溢出:运算结果超出了某种数据类型的表示范围 溢出只可能发生在同符号数相加时 方法1：对操作数和运算结果的符号位进行检测,当结果的符号位与操作数的符号不相同时就表明发生了溢出 方法2：对最高数据位进位和符号进位进行检测 方法3：用变型补码 int tadd_ok(int x,int y) { int sum=x+y; int neg_over=x=0; int pos_over=x>=0&&y>=0&&sum 无符号数加法的溢出可用ALU的进位表示 无符号数减法的溢出也可用带加/减功能的ALU的进位取反后表示 原码一位乘法 移位操作 逻辑左移 数据整体左移一位，最低位补0 算术左移 操作与逻辑左移一样，但是意义是等于数据乘2 逻辑右移 数据整体右移一位，最高位补0，最低位被移出 算术右移 数据整体右移一位，最高位被复制填补 ，最低位被移出 相当于除2 乘法 补码一位乘法 乘法器 定点数除法 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-14 07:48:33 "},"计算机系统/程序结构和执行/汇编.html":{"url":"计算机系统/程序结构和执行/汇编.html","title":"汇编","keywords":"","body":"程序编码 在编译时指定'-Og'选项让GCC产生符合原始程序结构的机器代码 机器级代码 对C语言隐藏， 但对汇编代码可见的： 程序计数器 整数寄存器文件 条件码寄存器 向量寄存器 输出c源码的机器表示 gcc -Og -S mstore.c 机器代码与反汇编的特性： x86-64的指令长度从1-15字节不等 指令设计的格式， 从某个给定位置， 能将字节唯一解码成机器指令 哈夫曼编码 反汇编无需访问源代码 反汇编与gcc的命名规则有些许差别 比如movq的q在反汇编中会被省略 关于格式的注解 .file \"mstore.c\" .text .globl mulstore .type mulstore, @function mulstore: .LFB0: .cfi_startproc pushq %rbx .cfi_def_cfa_offset 16 .cfi_offset 3, -16 movq %rdx, %rbx call mult2 movq %rax, (%rbx) popq %rbx .cfi_def_cfa_offset 8 ret .cfi_endproc .LFE0: .size mulstore, .-mulstore .ident \"GCC: (GNU) 4.8.5 20150623 (Red Hat 4.8.5-36)\" .section .note.GNU-stack,\"\",@progbits 以上是gcc完整生成的.s文件 所有. 开头的是伪指令， 可以忽略 ATT汇编代码格式 .file \"mstore.c\" .text .globl mulstore .type mulstore, @function mulstore: .LFB0: .cfi_startproc pushq %rbx .cfi_def_cfa_offset 16 .cfi_offset 3, -16 movq %rdx, %rbx call mult2 movq %rax, (%rbx) popq %rbx .cfi_def_cfa_offset 8 ret .cfi_endproc .LFE0: .size mulstore, .-mulstore .ident \"GCC: (GNU) 4.8.5 20150623 (Red Hat 4.8.5-36)\" .section .note.GNU-stack,\"\",@progbits 数据格式 16位： 字(w) 32位： 双字(l) 64位： 四字(q) moveb： 传送字节 movew： 传送字 movel： 传送双字 moveq： 传送四字 访问信息 x86-64的CPU包含一组16个存储64位的通用目的寄存器 16位操作可以访问2位字节 32位操作可以访问4位字节 ... 栈指针（%rsp） 操作数指示符 立即数： 代表常数 $后面接c语言表示法的整数 寄存器： 表示寄存器里的内容 r a 用来表示寄存器a 用R[r a ]表示里面的内容 内存引用： 指定内存地址里的内容 M[地址] 数据传送指令 压入栈和弹出栈数据 . 将四字压入栈 pushq S . 将四字弹出栈 popq D %rsp 是栈指针 %rax是返回值 算术和逻辑操作 加载有效地址 . x= y+x*4 leaq (%rdi,%rsi,4), %rax 一元和二元操作 . 从%edi中减去%esi subl %esi, %edi 移位操作 . 将x左移四位 salq $4, %rax 特殊的算术操作 控制 条件码 CF:进位标志 ZF:零标志 SF:符号标志 OF:溢出标志 读取条件码 跳转指令 用条件控制实现分支控制 cmpq %rsi, %rdi jg .L4 movq %rdi, %rax subq %rsi, %rax ret .L4: leaq (%rdi,%rsi), %rax ret 对应的c代码： if (x > y){ return x+y; }else{ return x-y; } 用条件传送实现条件分支 分支预测 循环 do-while while guarded-do for switch语句 跳转表 过程 传递控制 传递数据 分配和释放内存 运行时栈 转移控制 保存当前程序地址，将程序计数器设置为新过程地址 返回时读取保存的地址，继续执行 数据传送 传递函数参数的寄存器 栈上的局部存储 寄存器中的局部存储空间 被调用者保存寄存器 调用者保存寄存器 递归过程 数组的分配和访问 基本原则 T A[N] 指针运算 &D [ i ] [ j ] = X D L(Ci+j) 定长数组 变长数组 异质的数据结构 都是对地址进行偏移得到的 结构 联合 数据对齐 在机器级程序中将控制与数据结合起来 理解指针 在计算机科学中，指针（Pointer）是编程语言中的一个对象，利用地址，它的值直接指向（points to）存在电脑存储器中另一个地方的值 GDB调试器 UNIX及UNIX-like下的调试工具 内存越界引用和缓冲区溢出 对抗缓冲区溢出攻击 栈随机化 栈破坏检测 限制可执行代码区域 变长帧 浮点代码 %ymm0 ~ %ymm15 浮点传送和转换操作 过程中的浮点代码 使用XMM寄存器来传递浮点参数 浮点运算操作 定义和使用浮点常数 浮点操作不能把立即数作为操作数 编译器必须为所有浮点常量初始化存储空间 在浮点代码中使用位级操作 浮点比较操作 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-15 02:59:02 "},"计算机系统/程序结构和执行/处理器体系架构.html":{"url":"计算机系统/程序结构和执行/处理器体系架构.html","title":"处理器体系架构","keywords":"","body":"处理器体系架构 中央处理器 组成 运算器 数据加工 控制器 程序执行/指令执行 主要功能 主要寄存器 操作控制器 取指令，将机器指令译码并生成执行部件控制信号序列 ，建立正确的数据通路，从而完成指令的正确执行 数据通路 执行部件间传送信息的路径 不同指令、同一指令在执行的不同阶段的数据通路不同 分类 共享通路（总线） 主要部件都连接在公共总线上，各部件间通过总线进行数据传输 结构简单，实现容易，但并发性较差，需分时使用总线，效率低 专用通路 并发度高，性能佳，设计复杂，成本高 可以看做多总线结构 数据通路抽象模型（寄存器传输） 单总线结构：2个锁存器，3个时钟周期 双总线结构：1个锁存器，2个时钟周期 三总线结构：0个锁存器，1个时钟周期 总线越多，性能越好 指令周期 不同指令功能不同，数据通路不同，执行时间不同，如何安排时序 基本概念 时钟周期 = 节拍脉冲 = 震荡周期 能完成一次微操作 机器周期 = CPU周期 从主存读出一条指令的最短时间 可完成 复杂操作 指令周期：从主存取一条指令并执行指令的时间 指令控制同步 定长指令周期：早期三级时序系统 变长指令周期：现代时序系统 现代时许系统 总线结构与CPU指令周期 取指令 LOAD指令 MOVE指令 ADD指令 STORE指令 JMP指令 硬布线控制器设计 将控制器看成产生固定时序控制信号的逻辑电路 输入信号：指令译码，时钟信号，反馈信号 输出信号：功能部件控制信号序列 设计目标：最少元件，最快速度 理论基础：布尔代数 组成器件：门电路，触发器 定长指令周期时序产生器 时序产生器状态机 硬布线控制器基本架构 现代时序系统指令执行状态转换图 微程序控制器 硬布线：同步逻辑、繁，快，贵，难改 适合RISC计算机，如MIPS，ARM 微程序：存储逻辑、简、慢、廉，易改 适合CISC等功能较复杂的系列机 X86、IBM S/360、 DEC VAX 可写控存方便修复出厂故障 Intel Core 2 、Intel Xeon 工作原理 微程序是利用软件方法来设计硬件的技术 存储技术和程序设计相结合，回避复杂的同步时序逻辑设计 微程序设计 用规整的存储逻辑代替不规则的硬接线逻辑来实现计算机控制器功能的技术 微指令格式 设计原则 有利于缩短微指令字长度 有利于减少控制存储器容量 有利于提高微程序执行速度 有利于对微指令进行修改 有利于提高微程序设计的灵活性 水平型微指令 并行操作能力强，效率高，灵活性强， 微指令字较长，微程序短，控存容量大，性能佳 垂直型微指令 字长短，微程序长，控存容量小，性能差 垂直型与指令相似，易于掌握 基本被淘汰 单周期MIPS CPU 指令格式 多周期MIPS CPU 数据通路 不再区分指令存储器和数据存储器，分时使用部分功能部件 主要功能单元输出端增加寄存器锁存数据 传输通路延迟变小，时钟周期变短 Y86-64 指令集体系结构 程序员可见的状态 Y86 指令 Y86-64 异常 1 AOK 2 HLT 3 ADR 4 INS 逻辑设计和硬件控制语言HCL 逻辑门 组合电路和HCL布尔表达式 限制： 输入必须连接到下列之一： 系统输入 某个存储单元的输出 某个逻辑门的输出 逻辑门的输出不能连接到一起 网必须无环 多路复用器： 字级的组合电路和HCL整数表达式 [ select1:expr1; select2:expr2: ... ] 集合关系 存储器和时钟 Y86-64的顺序实现 将处理组织成阶段 取指 译码 执行 访存 写回 更新PC SEQ硬件结构 SEQ时序 流水线的通用原理 未流水线化 流水线化 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-17 08:12:17 "},"计算机系统/程序结构和执行/优化程序性能.html":{"url":"计算机系统/程序结构和执行/优化程序性能.html","title":"优化程序性能","keywords":"","body":"编写高效程序需要注意的： 合适的算法与数据结构 编写出能让编译器转换为高效机器代码的源代码 优化编译器的能力和局限性 编译器优化级别与安全的优化 函数内联 内存读写带来的开销 函数调用带来的开销 表示程序性能 每元素周期数(CPE) 循环展开 编译器可以自动进行 消除循环的低效率 代码移动 void f1(int a[]){ int i = length(a); int j; for(j=0;j 减少过程调用 消除不必要的内存引用 void sum1(int a[],int n,int *ret){ int i=0; for(;i 理解现代处理器 整体操作 分支预测 寄存器重命名 功能单元的性能 处理器操作的抽象模型 提高并行性 多个累积变量 void sum1(int a[],int n,int *ret){ int i=0; int limit = n/2; int tmp1=0; int tmp2=0; for(;i 重新结合变换 tmp = (tmp + a[i]) +a[i+1] // 1 tmp = tmp + (a[i] +a[i+1]) // 2 限制因素 寄存器溢出 如果寄存器不够用，将会使用内存存放临时变量，造成性能下降 分支预测和预测错误处罚 不必过分关心 编写适合用条件传送码实现的代码 理解内存性能 加载性能 存储性能 应用：性能提高技术 高级设计：算法与数据结构 基本编码原则 消除连续的函数调用 消除不必要的内存引用 低级优化 展开循环 多个累积变量与重新结合 使得编译采用条件数据传送 确认和消除性能瓶颈 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-15 02:59:02 "},"计算机系统/程序结构和执行/存储器层次结构.html":{"url":"计算机系统/程序结构和执行/存储器层次结构.html","title":"存储器层次结构","keywords":"","body":"存储器层次结构 基本存储体系 1)输入设备将程序与数据写入主存； 2) CPU取指令； 3) CPU执行指令期间读数据； 4) CPU写回运算结果； 5) 输出设备输出结果； 主存速度慢的原因 主存增速与CPU增速不同步； 指令执行期间多次访问存储器； 主存容量不足的原因 存在制约主存容量的技术因素 CPU、主板等相关技术指标确定 应用对主存的需求不断扩大 价格原因 存储体系的层次结构 L1 Cache集成在CPU中，分数据Cache(D-Cache)和指令Cache(I-Cache） 早期L2 Cache在主板上或与CPU集成在同一电路板上。随着工艺的提高，L2Cache被集成在CPU内核中，不分D-Cache和I-Cache 局部性 时间局部性 现在被访问的信息2在不久的将来还将再次被访问 时间局部性的程序结构体现： 循环结构 空间局部性 现访问信息2 ，下一次访问2附近的信息。 空间局部性的程序结构体现：顺序结构 主存中的数据组织 主存的一个存储单元所包含的二进制位数 目前大多数计算机的主存按字节编址，存储字长也不断加大,如16位字长、32位字长和64位字长 ISA设计时要考虑的两个问题： 字的存放问题 字的边界对齐问题 数据存储与边界 按边界对齐的数据存储：浪费一些空间 未按边界对齐存放：虽节省了空间，但增加了访存次数 需要在性能与容量间权衡 双字长数据边界对齐的起始地址的最末三位为000(8字节整数倍； 单字长边界对齐的起始地址的末二位为00(4字节整数倍)； 半字长边界对齐的起始地址的最末一位为0(２字节整数倍)。 大端与小端存储 小端存储 就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端 大端存储 就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端 无论是大端还是小端，每个系统内部是一致的，但在系统间通信时可能会发生问题！因为顺序不同，需要进行顺序转换 存储技术 随机访问存储器 静态RAM(SRAM) 工作原理 读 写 保持 结构 静态存储器的不足 晶体管过多 存储密度低 功耗大 动态RAM(DRAM) DRAM与SRAM不同的是，需要间隔一段时间执行刷新操作 读写 保持 刷新 集中刷新 分散刷新 异步刷新 其它结构的DRAM存储单元 单管 传统DRAM 内存模块 增强DRAM 非易失性存储器 访问主存 存储扩展 位扩展 用16K X 8 的存储芯片构建16K X 32的存储器 字扩展 用16K X 8 的存储芯片构建128k X 8的存储器 字位扩展 用16K X 8 的存储芯片构建128K X 32的存储器 无论哪种类型的存储扩展都要完成CPU与主存间地址线、数据线、控制线的连接 磁盘存储 磁盘构造 磁盘容量 记录密度 磁道密度 面密度 磁盘操作 寻道时间 旋转时间 传送时间 逻辑磁盘块 （盘面，磁道，扇区） 连接IO设备 通用串行总线（USB） 图形卡 主机总线适配器 访问磁盘 内存映射 固态硬盘 raid 将数据条带化后的存放在不同磁盘上，通过多磁盘的并行操作提高磁盘系统的读写速率 使用基于异或运算为基础的校验技术恢复损坏的数据 raid0 数据以条带方式均匀分散在各磁盘 raid1 数据采用镜像的冗余方式，同一数据有多份拷贝 RAID 3/4 数据按 位/条带 并行传输到多个磁盘上，同时校验数据存放到专用校验盘上 RAID5 数据按条带分布在不同磁盘上，校验信息被均匀分散到各磁盘上 RAID10 结合RAID1和RAID0，先镜像，再条带化 RAID01 结合RAID0和RAID1，先条带化, 再镜像 只能容忍一个磁盘故障，如0号盘损坏，左边RAID0失效，只能使用右边的RAID0，不能再有盘损坏，故冗余度为1 实现方式 软件RAID 功能都依赖于主机CPU完成,没有第三方的控制处理器和I/O芯片 硬件RAID 专门RAID控制处理器和I/O处理芯片处理RAID任务，不占用主机CPU资源 比较 存储技术的趋势 价格和性能折中 不同存储技术的价格与属性以不同的速率变化 对程序数据引用的局部性 取指令的局部性 多体交叉存储器 其基本思想是在不提高存储器速率、不扩展数据通路位数的前提下，通过存储芯片的交叉组织，提高CPU单位时间内访问的数据量，从而缓解快速的CPU与慢速的主存之间的速度差异。 高位多体交叉存储器 低位多体交叉存储器 高速缓存存储器 cache的工作过程 如何判断数据在Cache中? Cache中的数据是有效吗？（DMA【直接存储访问】修改主存） cache地址映射机制 cache的结构 Cache被分成若干行，每行的大小与主存块相同 Cache每行包含四部分，是Cache要保存的信息。Tag从CPU访问主存的地址中剥离得到、Data是与主存交换的数据块、Valid表示Cache中的数据是否有效、 Dirty表示主存中的数据是最新 相联存储器 如何快速地查找 如何快速地判断数据是否存在 Cache地址映射与变换方法 主存数据如何迁至Cache才能实现快速查找 全相联映射 主存分块，Cache行 （Line），两者大小相同 设每块4个字，主存大小为1024个字，则第61个字的主存地址为： 00001111 01 （块号 块内地址） 主存分块后地址就从一维变成二维 映射算法：主存的数据块可映射到Cache任意行，同时将该数据块地址对应行的标记存储体中保存 特点 Cache利用率高 块冲突率低 淘汰算法复杂 所以应用在小容量cache 直接映射 主存分块，Cache行 （Line），两者大小相同 主存分块后还将以Cache行数为标准进行分区 设每块4个字，主存大小为1024个字，Cache分为4行，第61个字的主存地址为 000011 11 01 （区号，区内块号，块内地址） 主存地址从一维变成三维 映射算法：Cache共n行，主存第j块号映射到Cache 的行号为 i=j mod n 即主存的数据块映射到Cache特定行 特点 Cache利用率低 块冲突率高 淘汰算法简单 应用在大容量cache 组相联映射 主存分块，Cache行 （Line），两者大小相同； Cache分组（每组中包k行），本例假定K=4 主存分块后还将以Cache组数为标准进行分组； 设每块4个字，主存大小为1024个字，Cache分为4行，第61个字的主存地址为： 0000111 1 01 （组号，组内块号，块内地址） 主存地址从一维变成三维； 映射算法： Cache共n组，主存第j块号映射到Cache 的组号为：i=j mod n 即主存的数据块映射到Cache特定组的任意行 替换算法 程序运行一段时间后，Cache存储空间被占满，当再有新数据要调入时，就需要通过某种机制决定替换的对象 先进先出法-FIFO 最不经常使用法---LFU 近期最少使用法--- LRU 替换算法的抖动 刚刚淘汰的块在下一时刻又被访问... 虚拟存储器 计算机能执行比主存空间大的程序吗？ 概述 处于主存 –辅存存储层次 解决主存容量不足的问题，为程序设计者提供比主存空间大的编程空间 分类：页式虚拟存储器、段式虚拟存储器 、段页式虚拟存储器 必须解决的问题 CPU访问存储系统的地址属性（采用MMU(Memory Management Unit):管理虚拟存储器与物理存储器） 如何判断CPU要访问的信息是否在主存中（采用页表来判断） 地址划分 虚拟地址 = 虚页号+页偏移量 逻辑地址与物理地址的转换 TLB (Translation Lookaside Buffer) 虚实地址转换过程中存在的问题 缺页异常 工作原理 TLB类似页表，也是PTE的集合。为实现对TLB的快速访问，类似于Cache中的映射方法，对来自于CPU的虚页号进行逻辑划分，得到相应的标记和索引字段 缓存写 高速缓存参数的性能影响 不命中率 命中率 命中时间 不命中处罚 存储器层次结构中的缓存 缓解快速CPU与慢速的主存之间的速度差异 工作工程 缓存命中 缓存不命中 冷不命中 冲突不命中 缓存管理 编写高速缓存友好的代码 高速缓存对程序性能的影响 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-08 13:01:32 "},"计算机系统/程序结构和执行/指令系统.html":{"url":"计算机系统/程序结构和执行/指令系统.html","title":"指令系统","keywords":"","body":"指令系统 指令 计算机能直接识别、执行的操作命令（机器指令）； 冯诺依曼结构计算机 \"程序控制\"原理实现的载体 指令字长 指令中包含的二进制位数 与机器字长相比: 单字长、双字长、半字长等长度指令 多字长指令 解决寻址较大存储空间的问题 取指多次访问内存，影响速度，占用空间大 等长指令: 指令字长度固定。 变长指令: 指令字长度根据需要可变 指令的分类 根据计算机层次结构分类 根据指令中地址码字段的个数分类 根据指令中操作数的物理位置分类 存储器－存储器（SS）型 寄存器－寄存器（RR）型 寄存器－存储器（RS）型 根据指令的功能分类 传送指令 MOV 、PUSH/POP、 IN/OUT等 定点算术运算指令 ADD、SUB、INC、CMP、MUL等 位运算指令 NOT、AND、OR、SHL、SAL等 控制转移指令 JMP 、JNE、CALL、RET等 指令的格式 指令要求计算机完成什么功能？ => 设置操作码 指令要求计算机处理什么数据？ => 设置数据源/目 计算机怎样得到要处理的数据？ => 设置寻址方式 操作码字段的位数与支持的最大指令数量有关 支持变长操作码时，操作码向不用的地址码字段扩展 寻址方式字段的位数与支持的寻址方式种类有关 地址码字段的作用及影响与其位数和寻址方式有关 指令系统 一台计算机中所有机器指令的集合 系列机：同一公司不同时期生产，基本系统结构和指令系统相同的计算机 兼容机：不同公司生产，基本系统结构和指令系统相同的计算机 寻址方式 根据冯诺依曼计算机的工作原理，需要根据物理地址从内存中去取指令和数据。如何获得指令和数据的物理地址？ 指令的寻址方式 顺序寻址 程序的指令序列在主存顺序存放。执行时从第一条指令开始，逐条取出并执行 CPU中设置程序计数器（PC）对指令的顺序号进行计数。PC开始时存放程序的首地址，每执行一条指令，PC 加\"1\"，指出下条指令的地址，直到程序结束 需要深刻理解 \"+1\" => 存储1条指令占用的字节单元数与存储字长有关！ 跳跃寻址 操作数的寻址方式 当数据在主存中时， 需要计算其有效地址E 立即数寻址 地址码字段是操作数本身 特点： 取指操作将数据与指令一并读入CPU内部的寄存器，指令执行速度快 便于程序设计（变量赋初值） 数据大小受字段位数限制 寄存器寻址 操作数在CPU的内部寄存器中 特点： 操作数在寄存器中，指令执行速度快 能访问的数据大小一般与计算机字长有关 地址字段的位数与计算机通用寄存器数量相关 直接寻址 地址码字段直接给出操作数在内存的地址 提供访问主存的操作 获得数据要访问主存，指令执行速度慢 地址字段的位数决定了访存空间大小 间接寻址 地址码字段给出的是操作数主存地址的地址 解决了直接寻址方式下地址字段的位数限制访存范围大小的问题 获得数据要访问主存2次，指令执行速度太慢 寄存器间接寻址 地址码字段给出的是寄存器编号R 解决了直接寻址方式下地址字段的位数限制访存范围大小的问题 获得数据只需访问主存1次 相对寻址 E=D + (PC), D为指令中地址字段的值 可节省指令中的地址位数，便于程序在内存中成块移动 注意PC的改变对计算E的影响 基址寻址 指定一个基址寄存器B，与本指令地址无关 E= D + (B), D为指令中地址字段的值 变址寻址 指定一个变址寄存器X，与本指令地址无关, 内容可随要求改变，E= D + (X), D为指令中地址字段的值 不改变指令即可改变数据的有效地址，可在循环中使用 在字符串处理，向量运算等等成批数据处理中非常有用 使用寻址方式的好处 ： 有利于缩短指令字长、方便程序设计、扩展访存空间 指令格式设计 根据指令数量的要求及是否支持操作码扩展，确定操作码字段的位数 根据对操作数的要求确定地址码字段的个数 根据寻址方式的要求，为每个地址码字段确定寻址方式字段位数 确定采用定长指令还是变长指令 MIPS指令 早期主要用于嵌入式系统，如Windows CE的设备，路由器，家用网关和视频游戏机，现在已经在PC机、服务器中得到广泛应用 特点 简单的Load/Store结构 易于流水线CPU设计 易于编译器开发 MIPS指令的寻址方式非常简单，每条指令的操作也非常简单 指令格式 R型指令 操作数和保存结果均通过寄存器进行 op：操作码，所有R型指令中都全为0； rs：寄存器编号，对应第1个源操作数； rt：寄存器编号，对应第2个源操作数； rd：寄存器编号，据此保存结果； shamt：常数，在移位指令中使用； funct：功能码，指定指令的具体功能 I 型指令 操作数中涉及立即数，结果保存到寄存器 op：标识指令的操作功能； rs：第1个源操作数，是寄存器操作数； rt：目的寄存器编号，用来保存运算结果； imm：第2个源操作数，立即数 J 型指令 寻址方式 R型指令：由op和funct字段共同隐含说明当前的寻址方式 I型和J型指令：由op字段隐含说明当前指令使用的寻址方式 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-10 11:46:29 "},"计算机系统/程序结构和执行/总线.html":{"url":"计算机系统/程序结构和执行/总线.html","title":"总线","keywords":"","body":"总线 是计算机体系结构的重要组成部分，通过它可以将计算机系统中各个功能部件连接起来，构成一个完整的系统 作用 是各功能部件间传递各类信息的通道； 是系统中各部件间的物理接口，能够减少各部件通信的复杂程度； 提供信息交换时所需的数据、地址、时序和控制信息； 提供一个共同遵循的协议或标准； 不应成为整个计算机性能的瓶颈； 方便计算机系统的集成、扩展和进化 分类 按用途分类 存储总线：短距离、高速总线，与存储器的特性相匹配，尽最大可能提高处理器与存储器之间的数据带宽，针对Cache块数据传输进行性能优化 系统总线：又称内部总线或板级总线，是计算机系统中最重要的总线，也是连接存储总线和I/O总线的中间总线 I/O总线：通常连接距离较远、速度相对较慢，用于连接多种外部设备，同时与系统总线或存储总线连接 按位置分类 外部总线：USB、火线（IEEE-1394）等 内部总线：PCI、AGP等 片内总线：AMBA 组成 数据总线：用于传送数据信息，通常是双向三态形式的总线 地址总线：专门用来传送地址，地址总线总是单向三态的 控制总线：用来传送控制信号和时序信号 电源线和地线 性能参数 总线频率：反映总线工作的速率（f），通常单位是MHz 总线宽度：数据总线的位数（w），单位是b（位），通常与处理器的字长相一致 总线传输速率：总线上可传输的数据总量（BW），单位是MB/s，总线传输速率＝（总线宽度÷8位）×总线频率 其他性能参数 同步方式 多路复用 信号线数量 控制方式 总线事务 从请求总线到完成总线使用的操作序列称为总线事务（Bus Transaction），它是在一个总线周期中发生的一系列活动 主设备和从设备 主设备（master）：能够提出申请并获得总线控制权的设备； 从设备（slave） ：只能被动接受总线控制传送数据的设备。 传输操作过程 完成一次数据传输操作，一般经过如下四个阶段： 申请与仲裁阶段 寻址阶段 传输阶段 结束阶段 常见的总线操作 读 写 读修改写 写后读 块操作 总线连接方式 单级总线结构 访问存储器和访问外设指令相同，由地址来区分； 总线简单，使用灵活，易于扩展； 任意两设备之间理论上都可以直接交换信息； 所有设备分时工作，仅适用于慢速的计算机系统中 双级总线结构 由于外设和内存分处于不同的总线，需要增加I/O指令； 存储总线的增加减轻了系统总线的负担，提高了并行性； 仍然保持了单总线结构的系统简单、易于扩充的优点 多级总线结构 在双级总线结构的基础上增加I/O总线构成； 并行性进一步提高，并可以通过增加通道或IO处理机来分担部分CPU的I/O功能，但是总线结构得越来越复杂 桥 是不同速率总线之间的连接器件，起信号速度缓冲、电平转换、控制协议转换等作用 总线结构对计算机性能的影响 对最大存储容量的影响：单总线结构有影响，双总线和多总线结构没有 对指令系统的影响：双总线和多总线结构需要增加IO指令 吞吐量：单总线结构的吞吐量小，多总线结构的吞吐量大，双总线结构的吞吐量居中 总线仲裁 菊花链式串行总线仲裁 集中式并行总线仲裁 常用的总线仲裁策略 固定优先级总线仲裁 轮询式总线仲裁（Round Robin） LRG总线仲裁（Least Recently Granted） 混合式总线仲裁 总线时序 同步定时：信息传送由公共时钟控制，总线中包含时钟线 时序关系简单，实现简单 在设备速度不一致时按最坏情况确定，传输线不能太长 异步定时：信息传送的每一个操作都是由主设备或从设备特定信号的跳变所确定，总线上每一个事件的发生取决于前一个事件的发生 数据传输可靠，适用于传输周期不同的设备，对通讯线的长度没有严格的要求 速度较慢 半同步定时：总线上各操作之间的时间间隔可以变化，但仅允许为公共时钟周期的整数倍。信号的出现、采样和结束仍以公共时钟为基准 数据传输方式 并行传送 同时并行传送的二进位数就是数据宽度 通常采用应答式的联络信号来协调双方的数据传送操作 串行传送 只使用一根传输线，采用脉冲方式传送信息 每次传送1位信息 一次新的传送，一定是以一个电平的跳变开始 串并传送 一次传送多个二进制位，但是同时传送的二进制位数小于数据宽度 按照串行的方式将整个数据宽度传送完 总线标准 计算机系统的各部件之间利用总线进行信息传输时应遵守的协议和规范，包括硬件和软件两个方面 常见的总线标准 ISA（Industrial Standard Architecture）：最早制定的总线技术标准，总线宽度8/16位，总线频率5~8MHz，总线带宽5~8MB/s。 EISA（Extended Industry Standard Architecture）总线：在ISA总线的基础上为32位微机开发。 VESA（Video Electronics Standard Association)总线：1992年推，它的推出为微机系统总线体系结构的革新奠定了基础，该总线系统考虑到CPU与主存和Cache的直接相连。标准定义了32位数据线，且可通过扩展槽扩展到64位，使用33MHz时钟频率，最大传输率为128MB/s~132MB/s。 PCI（Peripheral Component Interconnect）总线：PCI是由Intel公司1991年推出的总线规范，用于取代ISA；不同于ISA总线，PCI总线的地址总线与数据总线是分时复用的，支持插即用。 支持10台外设，总线宽度32/64位，总线时钟频率33.3MHz/66MHz，最大数据传输速率 133/264MB/s，时钟同步方式，且与CPU的时钟频率无关 AGP（AcceleratedGraphics Port）总线：是Intel公司1997年推出的一种3D标准图像接口，基于PCI2.1版规范并进行扩充修改而成，它采用点对点通道方式，能够提供四倍于PCI的传输速度。 PCIe（Peripheral Component Interconnect Express）总线：是Intel公司2001年推出的一种高速串行计算机扩展总线标准，用于替代PCI、PCI-X和AGP总线 USB（Universal Serial Bus）总线：是由Intel、Compaq、IBM、Microsoft等多家公司1994年联合提出的一种通用串行总线 采用四线电缆，其中两根是用来传送数据的串行通道，另两根为下游设备提供电源 采用级联星型拓扑，由三个基本部分组成：主机（Host），集线器（Hub）和功能设备 AMBA（Advanced Microcontroller Bus Architecture）总线：是ARM公司推出的片上总线；AMBA提供了一种特殊的机制，可将RISC处理器集成在其它IP核和外设中。 InfiniBand总线：解决了PCI总线中设备的距离问题，外部设备可以放到距离服务器很远的地方工作 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-18 03:26:03 "},"计算机系统/在系统上运行程序/链接.html":{"url":"计算机系统/在系统上运行程序/链接.html","title":"链接","keywords":"","body":"链接 链接是将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可被加载到内存并执行 大致过程如下 预处理阶段：处理以 # 开头的预处理命令 编译阶段：翻译成汇编文件 汇编阶段：将汇编文件翻译成可重定位目标文件 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件 编译器驱动程序 链接的原因 模块化 效率 静态链接 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置 目标文件 可重定位目标文件（.o文件）：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件 可执行目标文件（.out文件）：可以直接在内存中执行 共享目标文件（.so文件）：一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接 可重定位目标文件 符号和符号表 全局符号 外部符号 局部符号 符号解析 处理多重定义的全局符号 不允许有多个同名的强符号 如果强符号和弱符号同名，则选择强符号 如果多个弱符号同名，则随意选择一个 与静态库链接 链接器使用静态库解析引用 重定位 重定位节和符号定义 重定位节中的符号引用 重定位条目 R_X86_64_PC32 R_X86_64_32 重定位符号引用 可执行目标文件 加载可执行目标文件 动态链接共享库 so文件 ddl文件 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享 从应用程序中加载和链接共享库 JNI 位置无关代码 可以加载而无需重定位的代码称为位置无关代码 PIC数据引用 PIC函数调用 \"延迟绑定\" 库打桩机制 编译时打桩 链接时打桩 运行时打桩 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-02 11:22:07 "},"计算机系统/在系统上运行程序/异常控制流.html":{"url":"计算机系统/在系统上运行程序/异常控制流.html","title":"异常控制流","keywords":"","body":"异常 异常处理 异常表 异常处理程序运行在内核模式下 异常的类别 Linux/X86-64系统中的异常 除法错误 一般保护故障 缺页 机器检查 Linux 中的系统调用 进程 一个执行中程序的实例 逻辑控制流 并发流 一个逻辑流的执行在时间上与另一个流重叠 私有地址空间 进程为每个程序提供一个假象，好像它独占使用了系统的全部内存 用户模式与内核模式 寄存器中的一个模式位，设置该模式位可以用来切换用户模式或是内核模式 上下文切换 内核使用上下文切换来实现多任务 系统调用错误处理 包装系统调用进行错误处理 进程控制 获取进程ID 创建和终止进程 void exit(int status); // 终止 pid_t fork(void); // 创建新子进程 回收子进程 pid_t waitpid(pid_t pid,int *statusp,int options); 让进程休眠 unsigned int sleep(unsigned int secs); int pause(void); 加载并运行程序 execve(cont char *filename,const char *argv[],const char *envp[]); // 使用当前的进程运行新的程序 信号术语 发送信号 进程组 pid_t getpgrp(void); 用kill发送信号 /bin/kill -9 1235 用kill函数发送信号 int kill(pid_t pid,int sig); 用alarm函数 unigned int alarm(unsigned int secs); 接收信号 sighandler_t signal(int signum,sighandler_t handler); 阻塞信号和解除阻塞信号 隐式阻塞 显式阻塞 编写信号处理程序 安全 正确 可移植 同步流 显式等待信号 非本地跳转 用户级异常控制流形式 // 保存当前调用环境，供后面的longjmp调用 int setjmp(jmp_buf env); int sigsetjmp(sigjmp_buf env,int savesigs); void longjmp(jmp_buf env,int retval); void siglongjmp(sigjmp_buf env,int retval); MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-16 04:33:12 "},"计算机系统/在系统上运行程序/虚拟内存.html":{"url":"计算机系统/在系统上运行程序/虚拟内存.html","title":"虚拟内存","keywords":"","body":"物理和虚拟寻址 内存管理单元（MMU） 地址空间 非负整数地址的有序集合 虚拟地址空间 物理地址空间 虚拟内存作为缓存的工具 未分配 缓存的 未缓存的 DRAM缓存的组织结构 与存储器的层次结构 页表 页命中 系统通过页表获取到物理内存当中的页 缺页 物理内存缓存不命中成为缺页 分配页面 局部性原理 局部性原理是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。 虚拟内存作为内存管理工具 简化链接 简化加载 简化共享 简化内存分配 虚拟内存作为内存保护的工具 地址翻译 通过虚拟地址找到页表(page table)中对应的条目 检查有效位(valid bit)，是否需要触发页错误(page fault) 然后根据页表中的物理页编号找到内存中的对应地址 最后把虚拟页偏移和前面的实际地址拼起来，就是最终的物理地址 当页面命中时： 当缺页时： 结合高速缓存和虚拟内存 利用TLB加速地址翻译 多级页表 内存映射 将虚拟内存区域与一个磁盘对象关联起来，以初始化这个虚拟内存区域的内容 普通文件 匿名文件 共享对象 写时复制 用户级内存映射 void *mmap(void *start,size_t length,int prot, int flags,int fd,off_t offset) 动态内存分配 显式分配 程序员手动释放内存 隐式分配 垃圾收集器回收 malloc与free函数 void *malloc(size_t size); void free(void *p); 使用动态内存分配的原因 程序运行的未知性 分配器的要求和目标 处理任意请求序列 立即响应请求 只使用堆 对齐块 不修改已分配的块 目标 最大化吞吐率 最大化内存利用率 碎片 内部碎片 外部碎片 实现问题 如何记录空闲块 如何选择一个合适的空闲块放置一个新分配的块 如何处理空闲块被分配后剩余的部分 如何处理一个被释放的块 隐式空闲链表 放置已分配的块 首次适配 下次适配 最佳适配 分割空闲块 将空闲块分为两部分，一部分变成分配块，另一部分变成空闲块 获取额外的堆内存 合并空闲块 假碎片 块合并 带边界标记的合并 显式空闲链表 分离的空闲链表 简单分离存储 分离适配 伙伴系统 垃圾收集 基本知识 标记-清扫垃圾收集器 C程序常见的与内存有关的错误 间接引用坏指针 读未初始化的内存 栈缓冲区溢出 假设指针与指针所指向的对象大小相同 错位错误 引用了指针，而不是指针所指的对象 误解指针运算 引用不存在的变量 引用空闲堆块中的数据 内存泄漏 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-17 05:33:25 "},"计算机系统/程序间的交互和通信/输入输出系统.html":{"url":"计算机系统/程序间的交互和通信/输入输出系统.html","title":"输入输出系统","keywords":"","body":"输入输出系统 概述 外部设备、接口部件、总线以及相应的管理软件统称为计算机的输入/输出系统，简称I/O系统 基本功能 完成计算机内部二进制信息与外部多种信息形式间的交流 保证CPU能够正确选择输入输出设备并实现对其控制，传输大量数据、 避免数据出错 利用数据缓冲、选择合适的数据传送方式等，实现主机与外设间速度的匹配 特点 异步性：外围设备相对于处理机通常是异步工作的 实时性：当外围设备与处理机交互时，由于设备的类型不同，它们的工作步调是不同的，处理机必须按照不同设备所要求传送方式和传输速率不失时机地为设备提供服务，这就要求实时性控制 与设备无关性：各种外部设备必须根据其特点和要求选择一种标准接口和处理机进行连接，它们之间的差别必须由设备本身的控制器通过硬件和软件来填补；这样，处理机本身无须了解外设的具体细节，可以采用统一的硬件和软件对其管理 交换数据的过程 输入过程： CPU把一个地址值放在地址总线上，这一步将选择某一输入设备 CPU等候输入设备的数据成为有效 CPU从数据总线读入数据，并放在一个相应的寄存器中 输出过程： CPU把一个地址值放在地址总线上，选择输出设备 CPU把数据放在数据总线上 输出设备认为数据有效，从而把数据取走 性能 按照主要完成的工作可以分为以下二类： 存储I/O 通信I/O I/O系统的性能对CPU的性能有很大的影响，若两者的性能不匹配，I/O系统就有可能成为整个系统的瓶颈 评价参数 连接特性：哪些I/O设备可以和计算机系统相连接 I/O系统的容量：I/O系统可以容纳的I/O设备数 响应时间：从用户输入命令开始，到得到结果所花费的时间，单位s 吞吐率：单位时间完成的I/O操作次数，单位IOP 输入输出方式 输入输出系统用什么与计算机进行交互 无条件IO 在程序的适当位置直接安排I/O指令，当程序执行到这些I/O指令时，CPU默认外设始终是准备就绪的（I/O总是准备好接收CPU的输出数据，或总是准备好向CPU输入数据），无需检查I/O的状态，就进行数据的传输； 硬件接口电路和软件控制程序都比较简单。输入时，必须确保CPU执行I/O指令读取数据时，外设已将数据准备好；输出时，必须确保外部设备的数据锁存器为空，即外设已将上次的数据取走，等待接收新的数据，否则会导致数据传送出错，但一般的外设难以满足这种要求 程序控制I/O 一种早期计算机采用的输入/输出方式，数据在计算机和外设之间的传送全部靠计算机程序控制；计算机执行I/O指令时，先获取外设状态，并根据外设的状态决定下一步操作 何时对何设备进行输入输出操作完全受CPU控制，外围设备与CPU处于异步工作关系，数据的输入/输出都要经过CPU 优点： 计算机和外设之间能够同步，控制简单，硬件简单。 缺点： CPU的大量时间用来查询外设的状态。 设备状态字寄存器 用来标志设备的工作状态，以便接口对外部设备进行监视 中断I/O 当外设准备好后，主动通知CPU并进行接收或输出数据的方法 CPU接到外设的通知后暂停现行的工作，转入中断服务程序，和外设交换数据，等中断程序处理完毕后，再返回到被中断的原程序中继续以前被暂停的工作 优点： 节约CPU时间，实时性好。 缺点： 控制电路相对复杂，服务开销较大（现场和断点的保护）。 应用场合： 实时性要求高，且数据传输量又不大的场合。 DMA 完全由硬件执行的I/O交换方式 当外设准备好后，通知DMA控制器，DMA控制器从CPU接管总线，并完成外设和内存之间的大量数据传输；传输完成后DMA控制器将总线控制权交还给CPU，整个数据交换的过程不需要CPU参与 优点： 既有中断的优点，同时又降低了服务开销。 缺点： 控制电路更加复杂。 应用场合： 高速、大批量数据传输。 DMA控制器的两种工作状态 被动态（受控器）：未取得总线控制权，受CPU的控制 主动态（主控器）：接管并取得总线控制权，取代CPU而成为系统的主控者。 传输步骤 申请阶段：一个设备接口试图通过总线直接向另一个设备发送数据(一般是大批量的数据)，它会先向CPU发送DMA请求信号 响应阶段：CPU收到DMA请求信号后，在当前的总线周期结束后，会按DMA信号的优先级和提出DMA请求的先后顺序响应DMA信号 数据传送阶段：CPU对某个设备接口响应DMA请求时，会让出总线控制权；于是在DMA控制器的管理下，外设和存储器直接进行数据交换，而不需CPU干预 传送结束阶段：数据传送完毕后，设备接口会向CPU发送DMA结束信号，交还总线控制权 操作类型 数据传送：把源地址的数据传输到目的地址去（存储器或I/O） 数据校验：不进行数据传输，只对数据块内部的每个字节进行某种校验；这种数据校验一般安排在读数据块之后，以便校验所读的数据是否有效 数据检索：不进行数据传输，只是在指定的内存区域内查找某个关键字节或某几个数据位是否存在 操作方式 单字节传输模式 块传输模式 请求参数模式 级联传输模式 通道和I/O处理机 在复杂的计算机系统中，外围设备的台数一般比较多，设备的种类、工作方式和工作速度的差别很大，为了把对外围设备的管理工作从CPU中分离出来，采用通道或I/O处理机方式 通道是能够专门执行I/O指令的处理机，它可以实现对外围设备的统一管理，以及外设与主存之间的数据传输 I/O处理机是通道方式的进一步发展，它的结构更接近于一般处理机。 中断请求与响应 中断： 是指CPU在正常运行程序时，由于内部/外部事件（或由程序）引起CPU中断正在运行的程序，而转到为中断事件服务的程序中去，服务完毕，再返回执行原程序的这一过程。中断具有 随机性 中断的作用 实现主机与外设之间的并行工作 故障处理 实时处理 中断的类型 内部中断 软件中断 异常 故障(Fault) 陷阱(Trap) 终止(Abort) 外部中断 可屏蔽中断INTR：由外设通过中断请求线向处理器申请而产生的中断，处理器可以用指令来屏蔽（禁止），即不响应它的中断请求 不可屏蔽中断NMI：由系统内部硬件引发的中断，优先级高于外部硬件中断，且不受中断允许标志位的影响，所以是不可屏蔽中断 中断的基本功能 中断请求信号保持与清除 中断源识别 中断号： 是系统分配给每个中断源的代号，以便识别和处理。中断号在中断处理过程中起到很重要的作用。 中断控制 中断触发方式： 是指外设以什么逻辑信号去申请中断，即边沿触发和电平触发两种方式 中断排队方式： 当系统有多个中断源时，就可能出现同时有几个中断源都申请中断，而处理器在一个时刻只能响应并处理一个中断请求；为此，要进行中断排队。处理器按“优先级高的先服务”的原则提供服务 当CPU正在处理某个中断时，会出现优先级更高的中断源申请中断；为了使更紧急的、级别更高的中断源及时得到服务，需要暂时打断（挂起）当前正在执行的中断服务程序，去处理级别更高的中断请求，处理完成后再返回被打断了的中断服务程序继续执行 但级别相同或级别低的中断源不能打断级别高的中断服务，这就是所谓的中断嵌套 可屏蔽中断可以进行中断嵌套。NMI不可以进行中断嵌套 中断屏蔽 处理器用指令来控制中断屏蔽触发器的状态，从而控制是否接受某个特殊外设的中断请求 处理器内部也有一个中断允许触发器，只有当其为“1”（即开中断），CPU才能响应外部中断 中断优先级 指CPU响应和处理中断请求的先后次序 硬件响应优先序：未被屏蔽的几个中断源同时提出申请时，CPU选择服务对象的顺序由硬件电路实现，用户不能修改 软件服务优先序：在各中断服务程序开头，用软件设置自己的中断屏蔽字，以此改变实际服务顺序 中断的处理 当CPU收到外设的中断请求后，如果当前一条指令已执行完，且允许中断，CPU进入中断响应周期，发出中断应答信号完成一个中断响应周期 读取中断源的中断号，完成中断申请与中断响应的握手过程 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-20 11:50:30 "},"计算机系统/程序间的交互和通信/系统级IO.html":{"url":"计算机系统/程序间的交互和通信/系统级IO.html","title":"系统级IO","keywords":"","body":"系统级 IO 磁盘IO工作机制 标准IO 数据写入高速页缓存 应用就认为写入已经完成 此时操作系统再异步写入磁盘或者调用sync强制写入 直接IO DBMS就采用的此种方式读写数据 这种方式如果访问的数据不在应用缓存中 则每次都需要访问磁盘 同步IO 只有当数据被成功写入磁盘方法才会返回 一般用在对数据安全性较高的场景 异步IO 读数据写数据不会阻塞 读数据调用之后会马上返回 应用需要通过轮询等方式来询问数据是否就绪以获取 内存映射IO 将内存中的一块区域与磁盘中的文件关联起来 将应用对内存的访问映射为对磁盘的访问 同步异步 阻塞非阻塞 异步与非阻塞虽然能能提高IO性能 但是线程数量的增加会增加CPU的消耗 并且会导致设计复杂度的上升 UNIX IO 通过将设备映射为一个文件来操作设备 打开文件 内核返回一个非负整数 叫做描述符 shell创建的进程都有三个文件 0 1 2 分别是标准输入 标注输出 错误输出 改变当前文件位置 应用程序可以显式通过seek设置当前文件偏移量 读写文件 读文件时 程序读到一个EOF 代表文件已经读完 关闭文件 应用完成对文件的访问 通知内核关闭这个文件 描述符会被回收 文件类型： 普通文件 目录 套接字 打开和关闭 int open(char *filename,int flags,mode_t mode); int close(int fd); int fd; fd = open(\"foo.txt\", O_RDONLY, 0); close(fd); /* O_RDONLY 只读 O_WRONLY 只写 O_RDWR 可读可写 第二个参数还可以配合： | O_CREAT 如果文件不存在 那就创建空文件 | O_TRUNC 如果文件存在 那就清空这个文件 | APPEND 写操作以追加的方式 第三个参数代表了新文件的访问权限 */ 读写文件 ssize_t read(int fd,void *buf,size_t n); // 最多复制buf的n个字节到fd 返回-1代表出错 返回0代表eof ssize_t write(int fd,const void *buf,size_t n); // 最多复制buf的n个字节到fd // 在 x86-64 size_t 为unsigned long // ssize_t 为 long RIO包 自动处理 EOF 终端读取文本行 socket读取等 无缓冲的输入输出函数 直接将内存与文件之间传送数据 没有应用缓存 ssize_t rio_readn(int fd, void *usrbuf, size_t n); ssize_t rio_writen(int fd, void *usrbuf, size_t n); 带缓冲的输入函数 拥有应用级缓存 void rio_readinitb(rio_t *rp, int fd); ssize_t rio_readnb(rio_t *rp, void *usrbuf, size_t n); ssize_t rio_readlineb(rio_t *rp, void *usrbuf, size_t maxlen); #include \"csapp.h\" #include \"csapp.c\" // 读取标准输入写到标准输出 void main(){ int n; rio_t rio; char buf[100]; Rio_readinitb(&rio, STDIN_FILENO); while((n = Rio_readlineb(&rio, buf, 100)) != 0){ Rio_writen(STDOUT_FILENO, buf, n); } } rio_read 是核心函数 语义同Linux read函数 读取文件元数据 int Stat(const char *filename,struct stat *buf); int fstat(int fd,struct stat *buf); struct stat stat; char *fileName = \"foo.txt\"; Stat(fileName, &stat); if (S_ISREG(stat.st_mode)) printf(\"普通文件\"); if (S_ISDIR(stat.st_mode)) printf(\"目录\"); if (stat.st_mode & S_IRUSR) printf(\"可以访问\"); else printf(\"无法访问\"); 读取目录内容 DIR *opendir(const char *name); struct dirent*readdir(DIR *dirp); #include #include #include #include #include #include #include int main(){ DIR *streamp; struct dirent *dep; //调用函数返回DIR* 指针 streamp = opendir(\"./\"); //设置错误号为0 errno = 0; //不断调用readdir函数, 然后打印结构中的文件名和inode, inode是long类型 while ((dep = readdir(streamp)) != NULL) { printf(\"Found file: %s, INODE is %ld\\n\", dep->d_name, dep->d_ino); } //循环结束后检查错误号 if (errno != 0) { printf(\"readdir error\"); } closedir(streamp); exit(0); } 共享文件 IO重定向 int dup2(int ofd,int nfd); C语言标准IO 标准IO库将一个打开的文件看做一个流 某种意义上这个流式全双工的 你可以在这个流上读写 所以在进行读或写后 必须执行一些操作 切换流的模式 才能进行另外一种操作 所以socket编程不适合用标准IO库 而是使用RIO 如果有可能 就使用标准IO 不要使用scanf readline等读二进制文件 IO调优 磁盘IO 缓存 优化磁盘管理系统 RAID TCP网络 网络IO 减少网络交互的次数 减少网络传输数据量的大小 减少编码转换 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-07 12:52:41 "},"计算机系统/程序间的交互和通信/网络编程.html":{"url":"计算机系统/程序间的交互和通信/网络编程.html","title":"网络编程","keywords":"","body":"网络编程 CS编程模型 网络 全球IP因特网 IP地址 IP地址（Internet Protocol Address）是指互联网协议地址，又译为网际协议地址。IP地址是IP协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。 因特网域名 因特网连接 套接字接口 /*通用的socket地址结构 (用于connect, bind, 和accept) */ struct sockaddr { unsigned short sa_family; /* 协议家族 */ char sa_data[14]; /* 地址数据 */ }; /* 因特网形式的socket地址结构 */ struct sockaddr_in { unsigned short sin_family; /* 地址家族，一般都是AF_INET */ unsigned short sin_port; /* 网络字节顺序（大端表示法）的端口号 */ struct in_addr sin_addr; /* 网络字节顺序（大端表示法）的IP地址 */ unsigned char sin_zero[8]; /* 对sizeof(struct sockaddr)的填补 */ }; socket 函数 #include #include int socket(int domain,int type,int protocol); // 使用此函数创建一个套接字描述符 int connect(int clientfd,const struct socketaddr *addr,socklen_t addrlen);　// 建立与服务端的连接 int bind(int sockfd,const struct sockaddr *addr,socklen_t addrlen);　// 服务器用来绑定fd与网络地址 int listen(int sockfd,int backlog); // 服务器将socketfd转换为一个监听socketfd 从而接受客户端的连接请求 int accept(int listenfd,struct sockaddr *addr,int *addrlen); // 返回已连接描述符 为什么需要区分监听描述符与已连接描述符　答案是为了并发　服务器端可以通过多进程或者多线程的方式处理多个已连接描述符　从而对多个用户提供服务 主机和服务的转换 #include #include #include int getaddrinfo(const char *host,const char *service, const struct addrinfo *hints, struct addrinfo **result); // 将主机名端口号等信息转换为套接字地址结构 void freeaddrinfo(struct addrinfo *result); const char *gai_strerror(int errorcode); int getnameinfo(const struct sockaddr *sa,socklen_t salen, char *host,size_ hostlen, char *service,size_t servlen,int flags); WEB服务器 WEB内容 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-09 00:37:03 "},"数字逻辑电路/nav.html":{"url":"数字逻辑电路/nav.html","title":"数字逻辑电路","keywords":"","body":"数字逻辑电路 数字系统 处理二进制离散信息的系统 模拟信号、离散信号和数字信号 数字电子学 布尔代数 + 电子管 => 数字电子学 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"数字逻辑电路/数字逻辑电路基础.html":{"url":"数字逻辑电路/数字逻辑电路基础.html","title":"数字逻辑电路基础","keywords":"","body":"数字逻辑电路基础 数制 十进制 (1) 计数符号: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. (2) 进位规则: 逢十进一. 二进制 (1) 计数符号: 0, 1 。 (2) 进位规则: 逢二进一 十六进制 （1）计数符号: 0,1,......,9,A,B,C,D,E,F （2）进位规则: 逢十六进一。 八进制 （1）计数符号: 0,1,......,6,7。 （2）进位规则: 逢八进一。 二进制转十进制 十进制转二进制 二进制算术元算 二进制加法规则 0 + 0 = 0 0 + 1 = 1 1 + 0 = 1 1 + 1 = 10 产生进位1 二进制减法规则 0 - 0 = 0 1 - 1 = 0 1 - 0 = 1 10 - 1 = 1 产生借位1 二进制乘法规则 0 × 0 = 0 0 × 1 = 0 1 × 0 = 0 1 × 1 = 1 二进制除法 补码 加法 当两个正数或者两个负数相加时，如果相加结果的符号位与两个相加数的符号位不同，则产生了溢出 二-十进制码（BCD码） 用四位二进制码来表示一位十进制数字 格雷码（Gray码） 相邻两个代码之间仅有一位不同,其余各位均相同 应用：轴角编码器 ASCII码 美国信息交换标准代码：ASCII 扩展ASCII码(0-255) 奇偶校验码 在原码组的基础上增加一个码位使码组中含1的个数为奇数（称为奇校验）或偶数（称为偶校验）。 逻辑代数 在逻辑代数中,变量常用字母A，B，C, ......，X，Y，Z，a, b, c ,......x，y，z 等表示，变量的取值只能是\"0\"或\"1\"，这种变量称为逻辑变量 逻辑代数中只有三种基本逻辑运算,即\"与\"、\"或\"、\"非\" 与逻辑运算 定义：只有决定一事件的全部条件都具备时，这件事才成立；如果有一个或一个以上条件不具备，则这件事就不成立。这样的因果关系称为\"与\"逻辑关系 或逻辑运算 定义：在决定一事件的各种条件中,只要有一个或一个以上条件具备时，这件事就成立；只有所有的条件都不具备时,这件事才不成立。这样的因果关系称为\"或\"逻辑关系 非逻辑运算 定义:假定事件F成立与否同条件A的具备与否有关,若A具备,则F不成立；若A不具备,则F成立。F和A之间的这种因果关系称为\"非\"逻辑关系 复合逻辑运算 与非逻辑 !(a&&b) 或非逻辑 !(a||b) 与或非逻辑 !((a&&b)||(c&&d)) 异或逻辑 (!a&&b) || (a&&!b) 同或逻辑 !a&&!b || a&&b 逻辑电平 正逻辑 高电平VH表示逻辑\"1\",低电平VL表示逻辑\"0\" 负逻辑 高电平VH表示逻辑\"0\",低电平VL表示逻辑\"1\" VH和VL的具体值,由所使用的集成电路品种以及所加电源电压而定 基本定律 两个函数的真值表相等,则这两个函数一定相等 三条规则 代入规则 任何一个含有变量x的等式,如果将所有出现x的位置,都用一个逻辑函数式F代替,则等式仍然成立 反演规则 对于任意一个函数表达式Y，如果把Y中所有的“与”换成“或”，“或”换成“与”；“0”换成“1”，“1”换成“0”；原变量换成反变量，反变量换成原变量，即得到一个新的函数表达式Y非，称Y非为原函数Y的反函数 对偶规则 对于任何一个逻辑表达式F,如果将式中所有的“·”换成“+”,“+”换成“·”,“0”换成“1”,“1”换成“0”,而变量保持不变就得到表达式F'，这个表达式F'称为F的对偶式，这一变换方式称为对偶规则 常用公式 消去律 吸收律1 吸收律2 包含律 逻辑表达式 “与或”式 指一个函数表达式中包含若干个“与”项，这些“与”项的“或”表示这个函数 F(A,B,C,D)=A+BC+ABCD “或与”式 指一个函数表达式中包含若干个“或”项，这些“或”项的“与”表示这个函数 F(A,B,C,D)=(A+C+D)(B+D)(A+B+D) 最小项与最大项 如果一个具有n个变量的函数的“与项”包含全部n个变量，每个变量以原变量或反变量形式作为因子出现一次，而且仅出现一次，则这种“与项”被称为最小项 如果一个具有n个变量的函数的“或项”包含全部 n个变量，每个变量以原变量或反变量形式作为因子出现一次，而且仅出现一次，则这种“或项”被称为最大项。 标准与或式 如果一个逻辑表达式为与或式，而且其中每个与项都是最小项，则称该逻辑表达式为标准与或式 标准或与式 如果一个逻辑表达式为或与式，而且其中每个或项都是最大项，则称该逻辑表达式为标准或与式 真值表 逐个代入 求最小项取值为1的组合 根据函数表达式F的含义，直接填表 化简 节省元器件,降低电路实现成本 提高电路工作可靠性 化简的方式 公式法 卡诺图法 最简与或式的标准 所得与或表达式中，乘积项（与项）数目最少 每个乘积项中所含的变量数最少 卡诺图 卡诺图是一种包含一些小方块的几何图形,图中每个小方块称为一个单元,每个单元对应一个最小项。两个相邻的最小项在卡诺图中也必须是相邻的 不完全确定的逻辑函数 在某些实际数字电路中,逻辑函数的输出只和一部分最小项有确定对应关系,而和余下的最小项无关。把这些最小项称为无关项 包含无关项的逻辑函数称为不完全确定的逻辑函数 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-12 01:11:21 "},"数字逻辑电路/逻辑门电路.html":{"url":"数字逻辑电路/逻辑门电路.html","title":"逻辑门电路","keywords":"","body":"逻辑门电路 噪声容限 噪声妨碍了对微小数值的区分能力 简单的离散方法 高 == 5V == true 低 == 0V == false 但是会出现2.5V无法区分的情况 所以引入一个禁区 对输出更加严格 数字门内部 mos管 逻辑门消耗的功率 在大部分商用里，使用的是CMOS CMOS TTL门电路 CMOS技术进步飞速，反应速度已经超越TTL；而且CMOS内部不具有制作麻烦的电阻，所以TTL可说几乎没有发展和明显的优势 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-12 12:09:27 "},"数字逻辑电路/组合逻辑电路.html":{"url":"数字逻辑电路/组合逻辑电路.html","title":"组合逻辑电路","keywords":"","body":"组合逻辑电路 电路在任一时刻的输出仅由该时刻的输入信号决定,而与该时刻以前的输入信号无关 组合电路通常由一些逻辑门构成,许多具有典型功能的组合电路已集成为商品电路（加法器，译码器） 竞争冒险 实际上，由于门电路延迟时间的关系，可能会使逻辑电路产生错误输出。通常把这种现象称为竞争冒险。 静态功能冒险 当有多个变量发生变化时，稳态输出不应该发生变化，但实际输出产生了毛刺 静态逻辑冒险 单个变量变化时，稳态输出不应该发生变化，但实际输出产生了毛刺 消除方法 修改逻辑设计 只适用于逻辑冒险 接入滤波电容 如果逻辑电路在较慢速度下工作，为了消去竞争冒险，可以在输出端并联一电容，其容量在几十~几百皮法之间，该电容和门的输出电阻构成RC低通网络，对窄脉冲起平滑作用 加选通脉冲 在包含时序电路的复杂数字系统中，可以用时钟信号的适当形式作为选通脉冲，消除数字系统中的竞争冒险 常用组合逻辑功能器件 编码器 将信息(如数和字符等)转换成符合一定规则的二进制代码 二进制编码器 输入互相排斥的编码器 优先编码器 对输入信号按轻重缓急排序, 当有多个信号同时输入时, 只对优先权高的一个信号进行编码 二－十进制编码器 输入: I0 ，I1，I2 ，…，I9, 表示10个要求编码的信号 输出: BCD码。 译码器 译码是编码的逆过程，将一组码转换为确定信息 二进制译码器 二－十进制译码器 数据分配器 数据分配是将一个数据源输入的数据根据需要送到不同的输出端上去，实现数据分配功能的逻辑电路称为数据分配器。分配器又叫多路复用器 显示译码器 七段数码显示器 半导体数码管 液晶显示器 反射式液晶显示器：使用的可见光是环境光线 背光式液晶显示器：可见光由在显示器内特制的小光源提供 译码器应用 器实现组合逻辑函数 计算机输入/输出接口 数据选择器 从多路输入数据中选择其中的一路送至输出端 动态显示电路 七段数码管驱动电路可分为两种，一种称为静态显示（每一个数码管由单独的七段显示译码器驱动），另一种称为动态显示（使用数据选择器的分时复用功能，将任意多个数码管的显示驱动，由一个七段显示译码器来完成） 加法器 算术运算电路的核心为加法器 半加器 仅考虑两个一位二进制数相加，而不考虑低位的进位，称为半加 全加器 在多位数相加时，除考虑本位的两个加数外，还须考虑低位向本位的进位 串行进位加法器 当有多位二进制数相加时，可模仿笔算，用全加器构成串行进位加法器，结构简单，运算速度慢 全并行加法器 速度最快，电路复杂 超前进位加法器 由两个加数，首先求得各位的进位，然后再经全加器算出结果 数值比较器 用来判断两个二进制数的大小或相等 比较两个多位数，应首先从高位开始，逐位比较 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-16 02:51:59 "},"数字逻辑电路/时序逻辑电路.html":{"url":"数字逻辑电路/时序逻辑电路.html","title":"时序逻辑电路","keywords":"","body":"时序逻辑电路 电路在任何时候的输出稳定值，不仅与该时刻的输入信号有关，而且与该时刻以前的电路状态有关；电路结构具有反馈回路 存储电路 存储电路由存储器件组成，能存储一位二值信号的存储器件称为存储单元电路。存储单元电路大多是双稳态电路 锁存器 触发器 分类 按存储电路中存储单元状态改变的特点分类 同步时序电路 异步时序电路 按输出信号的特点分类 米里(Mealy)型: 输出信号不仅仅取决于存储电路的状态，而且还取决于外部输入信号 摩尔(Moore)型: 输出信号仅仅取决于存储电路的状态，而和该时刻的外部输入信号无关 按逻辑功能分类 计数器 寄存器 移位寄存器 RS锁存器 或非门构造的锁存器 与非门 SD —置位端(置1端) RD —复位端(置0端) 门控锁存器 当C=1时: 门控RS锁存器功能和RS锁存器完全相同 当C=0时: RD=SD=0，锁存器状态保持不变 门控 D 锁存器 当C=0时，RD=SD=1，电路处于保持状态; 当C=1时，RD=D, SD=D，电路的新状态为D 触发器 利用一个称为“时钟”的特殊定时控制信号去限制存储单元状态的改变时间,具有这种特点的存储单元电路称为触发器（FF：Flip-Flop） 边沿D触发器 负边沿JK触发器 触发器脉冲工作特性 建立时间 为使触发器做好触发准备，要求输入信号在时钟脉冲的边沿到来之前，提前一段时间到来，提前的这段时间叫建立时间，用tset表示。 保持时间 为了保证触发器可靠翻转，在时钟脉冲到达后，输入信号必须维持一段时间不变。这段时间称为保持时间，用th表示 传输延迟时间 从时钟脉冲边沿到触发器的新状态稳定建立起来，所需要的时间叫做传输延迟时间 最高时钟频率 在保证触发器可靠翻转的条件下， 所允许的时钟频率有一个上限值 （最高频率） ，该上限值即为触发器的最高时钟频率，用fmax表示 锁存器应用 消颤开关 触发器应用 单脉冲发生器 同步时序电路 分析 只要知道了在当前状态下各触发器的输入（即驱动信号），就能根据触发器的特性方程，求得电路的下一个状态，最终找到电路的状态转换规律 设计 根据逻辑功能要求，建立原始状态表或原始状态图; 利用状态化简技术，简化原始状态表，消去多余状态; 状态分配或状态编码，即将简化后的状态用二进制 代码表示; 选择触发器类型，并根据编码后的状态表求出驱动方程和输出方程; 检查自启动性, 若所设计电路中存在无效状态, 则必须检查电路能否自启动, 如果不能自启动, 则需修改设计; 画出逻辑图。 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-17 11:54:25 "},"数字逻辑电路/时序逻辑功能模块.html":{"url":"数字逻辑电路/时序逻辑功能模块.html","title":"时序逻辑功能模块","keywords":"","body":"时序逻辑功能模块 计数器 计数器除了直接用于计数外, 还可以用于实现定时器、分频器、程序控制器、信号发生器等时序电路 异步二进制计数器 二进制加法计数规则:如果低位已经为1,则再记入1时就应回到0,同时向高位送出进位信号 异步十进制计数器 同步二进制计数器 n位二进制计数器用n个存储单元电路组成，存储单元的状态表示二进制数，存储单元由触发器实现 同步十进制计数器 可逆计数器 有加减控制的可逆计数器: 这种电路有一个CLK脉冲输入端, 有一个加减控制端, 电路作何种计数, 由加减控制端的控制信号来决定 双时钟可逆计数器: 这种电路有两个CLK脉冲输入端,电路作不同计数时, 分别从不同的CLK端输入 应用 在数字信号的传输和数字系统的测试中，有时需要用到一组特定的串行数字信号。通常把这种串行数字信号称为序列信号。产生序列信号的电路称为序列信号发生器 寄存器 暂时存放一组二进制数码的数字电路或器件 移位寄存器 除了寄存器的功能外，存放的二进制数码可以进行移位 移位寄存器型计数器 是指在移位寄存器的基础上加反馈电路而构成的具有特殊编码的同步计数器 移位寄存器型序列信号发生器 将移位寄存器和外围组合电路构成一个移位寄存器型计数器，使该计数器的模和要产生的序列信号的长度相等，并使移位寄存器的串行输入信号F（即组合电路的输出信号）和所要产生的序列信号相一致 应用 可编程分频器 串行加法器 串行累加器 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-19 12:04:28 "},"数字逻辑电路/半导体存储器.html":{"url":"数字逻辑电路/半导体存储器.html","title":"半导体存储器","keywords":"","body":"半导体存储器 基础 内存以单位存储数据，二进制数据最小的单位是位； 许多应用中，以8位（或者多个8位）的单元处理数据，8位单元称为字节 ； 内存阵列中数据单元的位置称为地址； 内存可以存储的数据单位总数称为容量； 基本的内存操作分为写和读 操作 写操作 读操作 随机存取存储器 随机存取 (random access)：指的是当存储器中的消息被读取或写入时，所需要的时间与这段信息所在的位置无关 易失性 (volatile memory) ：当电源关闭时RAM不能保留数据 RAM的结构 SRAM Static Random Access Memory, SRAM 所谓的“静态”，是指这种存储器只要保持通电，里面储存的数据就可以一直保持 SRAM基本存储单元由两个CMOS反相器组成。两个反相器的输入、输出交叉连接。这就能实现两个反相器的输出状态的锁定、保存，即储存了1个位元的状态 基本的SRAM阵列 DRAM Dynamic Random Access Memory, DRAM DRAM利用电容存储电荷的多寡来代表二进制比特1或0。 由于电容会有漏电的现象，导致电位差不足而使记忆消失，因此除非电容经常周期性地充电，否则无法确保记忆长存 所谓的“动态”，是指这种这种需要定时刷新的特性 SRAM vs. DRAM DRAM结构简单，一般都拥有非常高的密度，成本较低。但DRAM也有访问速度较慢，耗电量较大的缺点。适合用于高储存密度低成本的场合，例如最常见的PC内存 SRAM比DRAM占用面积更大，因此更为昂贵；但更为快速，且功耗非常低（特别是在空闲状态）。一般用于CPU或者GPU的高速缓存 只读存储器 ROM存储的内容任何情况下都不会改变 (Nonvolatile) 电脑与用户只能读取保存在ROM的指令，使用存储在ROM的数据，但不能变更或存入数据 ROM被存储在一个非易失性芯片上，也就是说，即使在关机之后记忆的内容仍可以被保存 ROM可以用来实现逻辑函数 ROM家族 ROM存储单元 ROM阵列 可编程只读存储器 PROM 需要存0时，通过编程，烧断熔丝；当需存1时，保留熔丝 编程为一次性的，烧断的熔丝不能再接上 可擦除可编程只读存储 Erasable Programmable Read Only Memory, EPROM 一组浮栅晶体管，被一个电子电路中常用电压更高电压的电子器件分别编程 一旦编程完成后，EPROM只能用强紫外线照射来擦除 电子抹除式可编程只读存储器 Electrically-Erasable Programmable Read-Only Memory，EEPROM 通过电子方式多次复写的半导体存储设备 相比EPROM，EEPROM不需要用紫外线照射，也不需取下，就可以用特定的电压，来抹除芯片上的信息，以便写入新的数据 广泛用于需要经常擦除的BIOS芯片以及闪存芯片，它与高速RAM成为当前（21世纪00年代后）最常用且发展最快的两种存储技术 快闪存储器 Flash Memory 在技术上属于EEPROM 一种特殊的、以宏块抹写的EEPROM 成本较可以字节为单位写入的EEPROM低很多 存储器地址译码 RAM的二维译码结构 一个64kDRAM的地址复用示意 存储器扩展 位扩展 字扩展 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-20 01:21:50 "},"数字逻辑电路/可编程逻辑器件.html":{"url":"数字逻辑电路/可编程逻辑器件.html","title":"可编程逻辑器件","keywords":"","body":"可编程逻辑器件 通用性强，但逻辑功能较简单、且固定不变 ;构成的系统功耗体积大、可靠性差;中、小规模数字集成电路都属于通用型 为某种专门用途而设计的集成电路；成本较高、周期较长 PLD器件的连接 可编程逻辑阵列(PLA) 可编程阵列逻辑(PAL) PLA又慢又贵又大； 或阵列固定，与阵列可编程； Programmable logic plane与Output logic两部分 速度快，费用低，易于编程； 使用硬体描述语言，例如Data I/O的ABEL，或MMI的 PALASM编程 现场可编辑门阵列 Field Programmable Gate Array，缩写为FPGA 半定制，既解决了全定制电路的不足，又克服了原有可编程逻辑器件门电路数有限的缺点 硬件描述语言（Verilog或VHDL）描述逻辑电路，可以利用综合和布局、布线工具软件，快速地烧录至FPGA上； 设计师可以根据需要，通过可编辑的连接，把FPGA内部的逻辑块连接起来 好像一个电路试验板被放在了一个芯片里 FPGA设计流程 设计输入 原理图 硬件描述语言 功能仿真和综合 验证设计是否满足设计功能要求 优化 布局布线和时序仿真 映射到具体的目标硬件上，也称布局、布线 实现之后，下载之前，考虑实际门的延迟，来防止时序错误。功能仿真可以不指定硬件，时序仿真必须指定 下载 写入到设备 硬件描述语言HDL 描述电子电路（特别是数字电路）功能、行为的语言 寄存器传输级、行为级、逻辑门级等对数字电路系统进行描述 硬件描述语言和传统的软件编程语言最大的区别是，前者能够对于硬件电路的时序特性进行描述 硬件描述语言是构成电子设计自动化(EDA)体系的重要部分 可以描述小到简单的触发器，大到复杂的超大规模集成电路 常见的硬件描述语言：Verilog、VHDL Verilog 模型 模块是Verilog语言的基本组成单元，模块可以用下面任何一种建模方法（或一个组合）来描述 用实例化(instantiation)预定义基本逻辑门(primitive gates)或用户自定义的门电路进行门级建模(Gate level modeling) 用关键字为assign的连续赋值(continuous assignment)语句进行数据流建模(Dataflow modeling)；描述布尔方程 用关键字为always的过程赋值(procedural assignment)语句进行行为建模(Behavioral modeling)； 门级建模 两个或多个模块可以组合起来对一个设计分层描述：自顶向下和自底向上的设计方法 模块可以被嵌套（引入），但是模块的说明不可以嵌套（一个模块不能插入另一个模块的module和endmodule之间） 实现在一个模块中插入另一个模块的唯一方法是例化 数据流建模 门级建模：通过确定个逻辑门以及它们之间的相互连接来描述电路 数据流建模：使用大量运算符用于二进制操作数来产生所需的结果 采用连续赋值的方法，关键字是assign 连续赋值语句是对wire型数据赋值的说明 wire型用来反映元件之间的物理连接 行为建模 行为建模：在功能和算法层次上描述数字电路 使用关键字always，主要用于描述时序电路，但也可以描述组合电路 采用过程赋值的方法，目标输出的数据类型必须声明为reg型 时序电路的Verilog模型 initial 和 always 两种抽象行为语句 initial只用于testbench中的激励信号 lways模块使用过程赋值，赋值语句左边的变量一定要声明为reg型 阻塞赋值和非阻塞赋值 两种过程赋值语句： 阻塞赋值 B = A 和 非阻塞赋值 B MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-20 03:01:28 "},"数字逻辑电路/数模与模数转换.html":{"url":"数字逻辑电路/数模与模数转换.html","title":"数模与模数转换","keywords":"","body":"数模与模数转换 实现模数转换的电路称模数转换器，Analog to Digital Converter A/D转换 采样： 将时间上连续变化的模拟量转换成时间上离散的模拟量过程 保持： 保持取样信号，使其有充分时间转换为数字信号 量化： 把取样保持电路的输出信号用单位量化电压的整数倍表示。一般有两种方法：只舍不入、有舍有入 编码： 把量化的结果用二进制代码表示 D/A转换 实现数模转换的电路称数模转换器，简称 D/A 转换器或 DAC（Digital to Analog Converter） 权电阻网络DAC 不同电阻值的数目； 必须确保各个电阻的阻值精确； 在输入信号的个数较多时，难以生产 A/D转换 直接A/D转换 快速（并行/同步）A/D转换器 快速，转换时间小于50纳秒； 转换一次仅需一个时钟周期； 将一个模拟量转换为一个n-bit的数字量，需要 2^n-1个比较器； 应用于雷达信号处理，软件无线电技术等高速场合； 逐次逼近型ADC 间接A/D转换 先把输入电压转化为时间T2 ，使得T2与输入电压成正比； 再把时间T2转化为数字量D，使得数字量D与T2成正比； 双积分型A/D转换 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 01:27:24 "},"网络安全/网络安全.html":{"url":"网络安全/网络安全.html","title":"网络安全","keywords":"","body":"网络安全 信息 信息是以信息形态为表现形式，以物理介质为载体，以适合于计算机进行表达、传输、存储或处理的表达形式来表示的知识 信息技术 在计算机和通信技术的支持下，对信息进行获取、传递、存储、处理、使用、分配和控制的方法和技术的总称 信息安全 通信安全：研究如何对信息进行编码后在通信信道上传输，从而防止攻击者通过窃听通信信道而获取信息 信息安全：保证信息的安全属性（机密性、完整性和可用性等） 信息保障：信息安全的主动防御（如保护、检测、反应、恢复等） 网络空间安全：国家安全（包括信息基础设施的安全、信息系统和数据的安全等） 体系 安全服务是由安全机制来实现的 安全服务：提供数据处理和数据传输安全性的方法 认证 访问控制 数据保密 数据完整性 不可抵赖 安全机制：保护信息与信息系统安全措施的总称 加密 数字签名 访问控制 数据完整性 认证交换 业务填充 路由控制 公正 安全服务的分层部署 应用层与传输层提供的安全服务只能在通信两端的主机系统上实施 网络层提供的安全服务在端系统和路由器上都可以实现 但是层次越低，能获取到的数据语义越少 安全威胁 泄漏 欺骗 破坏 入侵 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-02 05:21:20 "},"网络安全/网络协议安全.html":{"url":"网络安全/网络协议安全.html","title":"网络协议安全","keywords":"","body":"网络协议安全 ARP ARP窃听 从ARP的协议过程来看，ARP请求消息将通过交换机或集线器以广播形式进行发送，因此网络上所有主机均可以收到ARP请求消息 ARP欺骗 如果某个ARP消息中的IP-MAC对是不真实的，则造成ARP欺骗攻击（ARP Spoofing），或称为ARP污染攻击（ARP Poisoning） GARP滥用攻击 者利用GARP技术，主动发送虚假的GARP请求消息（即伪造的IP地址和MAC地址的映射） 防御 采用静态绑定的方式防止ARP欺骗 手工绑定IP-MAC映射 采用ARP代理服务器 以引入可信的ARP代理服务器（Proxy ARP），对本网络中或跨网段的ARP请求提供服务 在网络设备上对ARP消息进行检测和控制 禁用GARP功能 IP IP窃听 IP协议在传输过程中没有加密 IP地址假冒攻击 任意节点均可以构造IP分组 IP碎片攻击 攻击者可以利用IP协议的拆包合包，将IP包切分为非常小的碎片，然后发送给被攻击目标 防御 入口过滤 过滤掉进来的非法IP地址的分组 出口过滤 过滤掉发出去的非法IP地址的分组 IP回溯 追踪IP分组的路径 TCP SYN泛洪攻击（SYN Flooding） ACK泛洪攻击（ACK Flooding）-随机IP ACK泛洪攻击（ACK Flooding）-伪造IP 序列号预测攻击 LAND攻击 UDP 假冒 劫持 泛洪 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-04 02:24:31 "},"网络安全/网络安全隔离技术.html":{"url":"网络安全/网络安全隔离技术.html","title":"网络安全隔离技术","keywords":"","body":"网络安全隔离技术 通过对具有不同安全需求的应用系统进行分类保护，从而有助于将风险较大的应用系统与其它应用系统隔离，达到安全保护的目的。 集线器隔离 工作在物理层，隔离作用不大 交换机隔离 vlan划分 路由器隔离 防火墙 访问控制 审计 不足 无法防御内部攻击 包过滤技术 是一种访问控制机制，它控制哪些数据包可以进出网络而哪些数据包应被网络拒绝 状态监测技术 是指根据协议数据的状态来实现包过滤功能的访问控制技术 应用代理技术 在应用层提供代理服务的代理 防火墙隔离 堡垒主机结构 防火墙是唯一一个防护点 屏蔽主机结构 使用路由器与防火墙配合完成工作 屏蔽子网结构 使用了两个路由器 物理隔离 如果用户在同一时间访问公网专网，会带来很多安全隐患 物理隔离（physical isolation）是指处于不同安全域的网络之间不能以直接或间接的方式相连接 物理断开：物理断开卡 单向隔离：单向隔离卡 网闸隔离：只有被系统明确要求传输的信息可以通过 网络地址转换 NAT技术可以对内部网络起到隔离与隐藏作用 NAT技术可以提供详细的安全审计功能 NAT技术破坏了端到端的网络通信 NAT影响防火墙系统的设计和部署 网络地址转换（NAT：Network Address Translation）是一种将一个或多个IP地址转换为另外一个IP或多个地址的技术 静态NAT 内部每个非法IP地址被固定地映射为外部的某个合法IP地址 动态NAT 内部每个非法IP地址被临时地映射为外部的某个合法IP地址 端口转换 端口转换NAT是将内部主机的IP地址映射为外部IP地址和一个特定端口号的技术 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-06 02:00:28 "},"网络安全/网络安全技术.html":{"url":"网络安全/网络安全技术.html","title":"网络安全技术","keywords":"","body":"网络安全技术 网络安全模型 PDR模型 P2DR模型 PDRR安全模型 APPDRR模型 PADIMEE模型 网络安全预警 实时网络数据流跟踪 网络攻击模式识别 网络安全违规活动捕获 对将要发生的或已发生的网络攻击进行预警 对攻击的下一步动作进行合理的推测 过程 数据采集 检测信息、设备操作信息、流量变化情况 数据提取 格式转换 事件分析 分类、挖掘 安全预警 生成未来可能发生的事件 结果 响应方案 常见预警模型 基于入侵事件 基于攻击过程 基于流量监控 宏观网络 威胁情报技术 战略性威胁情报是从威胁的全貌及未来发展动态的知识信息，主要提供给高层战略决策者使用。 操作性威胁情报是针对特定攻击的可付诸行动的知识信息。 战术性威胁情报是关于网络攻击战术性的知识信息（如攻击技巧、方法等）。 技术性威胁情报是关于攻击的技术细节的知识信息，包括攻击的工具、命令、控制渠道、基础架构等技术信息。 基于威胁情报的网络安全预警 加密保护技术 数据传输加密 数据存储加密 数据完整性鉴别 传输加密模式 链路加密 保护通信链路中所有节点之间的链路信息安全 节点加密 保护明文不在节点中出现的加密技术 端到端加密 用于向源节点到目的节点的数据提供端到端加密保护 VPN技术 隧道技术 隧道将将其它协议的数据重新封装然后通过隧道发送 内网监管技术 针对局域网内的用户终端和网络设备进行监视和控制，规范内部网络用户的行为、防止敏感信息的泄漏 合理划分和管理内网与外网的边界 限制VPN的访问 实时、自动跟踪安全策略的变化 严格限制网络服务和外设服务，防止攻击者从外部渗透入内部网络 严格限制无线网络连接访问 建立完善的用户账号管理机制 入侵检测技术 主机入侵检测 网络入侵检测 入侵检测方法 误用检测 根据己知的攻击方法，预先定义入侵特征，通过判断这此特征是否出现来完成检测任务 异常检测 根据用户的行为或资源的使用状况的正常程度来判断 入侵防御系统 漏洞检测技术 脆弱性扫描 是采用模拟攻击者攻击的方式对目标可能存在的已知安全漏洞进行逐项检测 源代码扫描 反汇编扫描 环境错误注入技术 安全响应技术 前期 对事件进行确认、初步分析评估及相应的准备工作 中期 对事件进行处理，包括抑制进一步扩散、根除事件的影响及恢复相关系统 后期 要包括进一步提供系统的安全性和对事件及其处理过程的分析总结等 蜜网技术 吸引攻击者对其发起攻击，同时完整地且不被察觉地将他们的活动记录下来 捕获僵尸网络 捕获垃圾邮件 捕获蠕虫病毒 捕获钓鱼网络 灾难恢复技术 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-09 00:39:42 "},"网络安全/安全协议技术.html":{"url":"网络安全/安全协议技术.html","title":"安全协议技术","keywords":"","body":"安全协议技术 安全协议是在消息交换和处理过程中使用了若干密码算法的协议 分类 按目的 密钥交换协议 认证协议 电子商务协议 按参与者 仲裁协议 借助于一个称之为仲裁者的可信第三方（Trusted Third Party）来完成消息交换 裁决协议 裁决人必须是协议主体均信赖的可信第三方，但是它不需要参与协议的整个过程，只有当协议中出现争议之后，裁决人才参与到协议中来 自动执行协议 议不需要任何第三方（如仲裁者和裁决者）的参与，在协议主体之间完成协议过程 安全协议缺陷 攻击者模型 由于存在攻击者，因此设计一个安全的协议是非常困难的 常见缺陷 基本协议缺陷：协议中没有或者很少考虑对攻击者的防范而引发的协议缺陷（如TCP/IP协议的安全缺陷问题等） 陈旧消息缺陷：在协议设计过程中，未考虑消息的时效性（即新鲜性），从而使得攻击者可以利用协议过程中产生的过时消息来对协议进行重放攻击 并行会话缺陷：协议设计对仅考虑单个协议执行的情况，对多个协议（或同一个协议的多个运行实例）并行会话缺乏考虑，使得攻击者可以相互交换适当的协议消息来获得更为重要的消息 内部协议缺陷：协议中缺少足够的信息让协议参与者能够区分消息的真实性而导致缺陷 密码系统缺陷：协议中使用的密码算法的安全强度问题导致协议缺陷 中间人攻击 攻击者位于协议通信双方中间而发动的攻击 重放攻击 指攻击者利用其消息再生能力生成诚实用户所期望的消息格式，并重新发送，从而达到破坏协议安全性的目的 协议轮内攻击 协议轮外攻击 对策 挑战应答机制 挑战者能够通过他自己输入消息的新鲜性来验证应答者通信的真实性 时间戳机制 指发送者在消息中嵌入发送消息的本地时刻，而接收者在消息达到后，通过对比消息中所包含的时间信息和本地时间信息的差值，来决定该消息是否为新鲜消息 序列号机制 协议主体之间首先协商一个一致的初始序列号协议过程中每条协议消息均带上序列号，每条消息的序列号必须进行保护 交错攻击 平行会话攻击 反射攻击 当一个诚实的主体给某个意定的通信方发送消息时，攻击者截获该消息，并将该消息返回给消息的发送者 类型错误攻击 攻击者欺骗某个主体，使得他把一次性随机数、时戳或者身份等信息嵌入到某个密钥中去，从而导致协议安全性被破坏 姓名遗漏攻击 如果与消息相关的主体的名字不能从消息中推断出来，则攻击者利用此缺陷所发动的攻击称之为“归因与姓名遗漏攻击” 安全协议设计原则 消息独立性原则 即消息的含义应该是一目了然，且消息含义的翻译直接通过该消息就可以完成 消息前提准确原则 消息所依赖的条件必须明确地定义出来，从而使得协议的评价者知道这些条件是否可以接受。 协议主体身份标识原则 如果协议主体的身份对于理解消息的含义是必须的，那么协议主体身份就应该在消息中明确地标识出来 加密目的明确原则 必须使用加密，则必须明确加密在协议安全中的作用和目的 签名原则 如果在一个安全协议中需要同时进行加密和签名，一般的原则是先加密后签名 随机数使用原则 对抗重放攻击，还是用来绑定时间上邻接的两条消息 IPSec 一种由IETF设计的端到端的确保IP层通信安全的机制 SSL 安全套接层（SSL：Secure Sockets Layer Protocol），是为网络通信提供安全及数据完整性的一种安全协议 https MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-17 00:54:41 "},"网络安全/踩点.html":{"url":"网络安全/踩点.html","title":"踩点","keywords":"","body":"踩点 攻击者对某个组织进行有计划，有步骤的踩点，收集整理出一份关于该组织的安全剖析图 因特网踩点 web网页 相关组织 地理信息 员工信息 近期重大事件 安全策略 搜索引擎 whois 通过whois，可以查询到域名拥有者信息 DNS 通过nslookup查询该组织的相关dns服务器信息 网络侦查 traceroute可以侦查到目的主机传输路径经过的网际跳远 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-09 02:49:09 "},"网络安全/扫描.html":{"url":"网络安全/扫描.html","title":"扫描","keywords":"","body":"扫描 使用扫描来发现目标系统有哪些服务对外监听以及能直接从因特网访问 ARP主机发现 使用arp-scan arp-scan时在局域网内最合理最快的扫描工具 my@my-PC:~$ sudo arp-scan 192.168.43.0/24 Interface: wlp3s0, datalink type: EN10MB (Ethernet) Starting arp-scan 1.9 with 256 hosts (http://www.nta-monitor.com/tools/arp-scan/) 192.168.43.1 82:92:e3:d0:7f:d4 (Unknown) 1 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.9: 256 hosts scanned in 2.531 seconds (101.15 hosts/sec). 1 responded 使用nmap也能同样进行扫描 sudo nmap -sn -PR 192.168.43.0/24 Starting Nmap 7.40 ( https://nmap.org ) at 2019-12-09 09:00 CST Nmap scan report for 192.168.43.1 Host is up (0.0047s latency). MAC Address: 82:92:E3:D0:7F:D4 (Unknown) Nmap scan report for 192.168.43.242 Host is up. Nmap done: 256 IP addresses (2 hosts up) scanned in 3.82 seconds ICMP主机发现 ICMP协议是一种面向无连接的协议，用于传输出错报告控制信息。它是一个非常重要的协议，它对于网络安全具有极其重要的意义 响应报文 使用ping 使用nmap扫描 my@my-PC:~$ sudo nmap -sn -PE zbq.ismy.wang Starting Nmap 7.40 ( https://nmap.org ) at 2019-12-09 10:04 CST Nmap scan report for zbq.ismy.wang (120.79.6.172) Host is up (0.067s latency). Nmap done: 1 IP address (1 host up) scanned in 0.43 seconds 使用hping my@my-PC:~$ sudo nping -c 2 --icmp --icmp-type time zbq.ismy.wang Starting Nping 0.7.40 ( https://nmap.org/nping ) at 2019-12-09 10:07 CST SENT (0.0627s) ICMP [192.168.43.242 > 120.79.6.172 Timestamp request (type=13/code=0) id=52393 seq=1 orig=0 recv=0 trans=0] IP [ttl=64 id=34535 iplen=40 ] SENT (1.0630s) ICMP [192.168.43.242 > 120.79.6.172 Timestamp request (type=13/code=0) id=52393 seq=2 orig=0 recv=0 trans=0] IP [ttl=64 id=34535 iplen=40 ] Max rtt: N/A | Min rtt: N/A | Avg rtt: N/A Raw packets sent: 2 (80B) | Rcvd: 0 (0B) | Lost: 2 (100.00%) Nping done: 1 IP address pinged in 2.09 seconds windows 下可以使用superScan TCP/UDP主机发现 使用nmap my@my-PC:~$ nmap -Pn 192.168.43.1 Starting Nmap 7.40 ( https://nmap.org ) at 2019-12-09 10:11 CST Nmap scan report for 192.168.43.1 Host is up (0.026s latency). Not shown: 999 closed ports PORT STATE SERVICE 53/tcp open domain Nmap done: 1 IP address (1 host up) scanned in 0.46 seconds 只扫描开启特定端口的主机 my@my-PC:~$ sudo nmap -Pn -sS -p 53 192.168.43.0/24 Starting Nmap 7.40 ( https://nmap.org ) at 2019-12-09 10:13 CST Nmap scan report for 192.168.43.1 Host is up (0.0079s latency). PORT STATE SERVICE 53/tcp open domain MAC Address: 82:92:E3:D0:7F:D4 (Unknown) Nmap scan report for 192.168.43.242 Host is up (0.000052s latency). PORT STATE SERVICE 53/tcp closed domain Nmap done: 256 IP addresses (2 hosts up) scanned in 4.36 seconds 使用nping my@my-PC:~$ sudo nping -c 2 --tcp -p 53 --flags syn 192.168.43.1 Starting Nping 0.7.40 ( https://nmap.org/nping ) at 2019-12-09 10:14 CST SENT (0.0368s) TCP 192.168.43.242:30555 > 192.168.43.1:53 S ttl=64 id=55281 iplen=40 seq=2174361648 win=1480 RCVD (0.2232s) TCP 192.168.43.1:53 > 192.168.43.242:30555 SA ttl=64 id=0 iplen=44 seq=2937135821 win=65535 SENT (1.0373s) TCP 192.168.43.242:30555 > 192.168.43.1:53 S ttl=64 id=55281 iplen=40 seq=2174361648 win=1480 RCVD (1.2432s) TCP 192.168.43.1:53 > 192.168.43.242:30555 SA ttl=64 id=0 iplen=44 seq=2952774060 win=65535 Max rtt: 205.814ms | Min rtt: 186.441ms | Avg rtt: 196.127ms Raw packets sent: 2 (80B) | Rcvd: 2 (88B) | Lost: 0 (0.00%) Nping done: 1 IP address pinged in 1.28 seconds 预防 密切留意ping活动 根据需求决定放行哪些ICMP请求 端口扫描 端口扫描是指某些别有用心的人发送一组端口扫描消息，试图以此侵入某台计算机，并了解其提供的计算机网络服务类型（这些网络服务均与端口号相关） sS (TCP SYN扫描) 这种扫描也叫做半开扫描，不会建立一条tcp连接，所以很隐蔽 my@my-PC:~$ sudo nmap -sS 192.168.43.1 Starting Nmap 7.40 ( https://nmap.org ) at 2019-12-09 10:26 CST Nmap scan report for 192.168.43.1 Host is up (0.050s latency). Not shown: 999 closed ports PORT STATE SERVICE 53/tcp open domain MAC Address: 82:92:E3:D0:7F:D4 (Unknown) Nmap done: 1 IP address (1 host up) scanned in 1.95 seconds 添加Ｄ选项，可以假冒其他源IP发送请求，混杂在扫描请求当中 my@my-PC:~$ sudo nmap -sS 192.168.43.1 -D 10.1.1.1 Starting Nmap 7.40 ( https://nmap.org ) at 2019-12-09 10:33 CST Nmap scan report for 192.168.43.1 Host is up (0.062s latency). Not shown: 999 closed ports PORT STATE SERVICE 53/tcp open domain MAC Address: 82:92:E3:D0:7F:D4 (Unknown) Nmap done: 1 IP address (1 host up) scanned in 5.55 seconds FTP反弹扫描 它允许用户连接到一台FTP服务器，然后要求文件送到一台第三方服务器。 这个特性在很多层次上被滥用，所以许多服务器已经停止支持它了。其中一种就是导致FTP服务器对其它主机端口扫描。 只要请求FTP服务器轮流发送一个文件到目标主机上的所感兴趣的端口。 错误消息会描述端口是开放还是关闭的。 这是绕过防火墙的好方法 使用netcat扫描 my@my-PC:~$ nc -v -z -w2 192.168.43.1 1-140 192.168.43.1: inverse host lookup failed: Unknown host (UNKNOWN) [192.168.43.1] 53 (domain) open 预防 使用入侵检测系统(IDS) 关闭不必要服务 操作系统检测 使用nmap -O 选项，探测操作系统类型(主动式探测) my@my-PC:~$ sudo nmap -O ip Starting Nmap 7.40 ( https://nmap.org ) at 2019-12-09 16:25 CST Nmap scan report for zbq.ismy.wang (120.79.6.172) Host is up (0.070s latency). Not shown: 990 filtered ports ... Aggressive OS guesses: Linux 3.10 - 4.2 (91%), Linux 3.2 - 4.6 (90%), Linux 2.6.32 (89%), Linux 3.16 (89%), Linux 4.4 (88%), OpenWrt Kamikaze 7.09 (Linux 2.6.22) (88%), Linux 3.11 - 3.12 (87%), Linux 3.18 (87%), Crestron XPanel control system (87%), HP P2000 G3 NAS device (87%) No exact OS matches for host (test conditions non-ideal). OS detection performed. Please report any incorrect results at https://nmap.org/submit/ . Nmap done: 1 IP address (1 host up) scanned in 81.44 seconds MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-09 09:27:14 "},"网络安全/查点.html":{"url":"网络安全/查点.html","title":"查点","keywords":"","body":"查点 服务指纹分析 使用nmap 使用amap分析服务版本 漏洞扫描 nessus 标语抓取 netcat或telnet my@my-PC:~$ netcat zbq.ismy.wang 80 ss HTTP/1.1 400 Bad Request Server: nginx/1.12.2 Date: Mon, 09 Dec 2019 08:41:25 GMT Content-Type: text/html Content-Length: 173 Connection: close 400 Bad Request 400 Bad Request nginx/1.12.2 常用服务查点 FTP 应该不再使用FTP服务 telnet查点 应使用更安全的ssh替代 smtp 应该不再使用 dns 使用dig查询有关dns服务器的信息 tftp tftp不够安全，没有提供任何认证手段，攻击者能获取到许多敏感文件 finger HTTP查点 SNMP查点 BGP查点 RPC查点，查看主机有哪些端口正在监听rpcrpcinfo -p 127.0.0.1 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-09 09:27:14 "},"网络安全/攻击Windows.html":{"url":"网络安全/攻击Windows.html","title":"攻击Windows","keywords":"","body":"攻击Windows 取得身份前的攻击手段 认证欺骗 弱口令 暴力破解 口令猜测 中间人欺骗 远程非授权漏洞发掘 metasploit漏洞发掘 网络服务漏洞 应用程序漏洞 驱动程序漏洞 取得合法身份后的攻击手段 权限提升 密码哈希获取 密码文件存放在/system32/config的一个sam文件下 还是通过暴力破解 远程控制后门 远程保留一个shell，来供攻击者远程访问 端口重定向 掩盖入侵痕迹 关闭审核 清理日志 隐藏文件 Windows安全功能 防火墙 自动更新 安全中心 安全策略与群组策略 微软安全软件 Windows资源保护 UAC DEP(数据执行保护，对付缓冲区溢出) MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-10 12:08:10 "},"网络安全/攻击Unix.html":{"url":"网络安全/攻击Unix.html","title":"攻击Unix","keywords":"","body":"攻击unix root 权限获取 弱点映射 通过在公共信息获得漏洞资源 远程访问 暴力破解攻击 缓冲区溢出攻击 return to libc 字符串格式化攻击 用户的输入被当做指令执行 输入验证攻击 整数溢出攻击 由于无符号跟有符号的区别，可能被利用为漏洞 悬摆指针攻击 废弃的指针又被重新利用 获取一个shell 反向通道 攻击者的主机开启监听服务，利用远程主机的漏洞，连接到攻击者主机 预防的措施包括关闭不必要的服务&使用防火墙 常见的远程攻击 FTP 权限过大导致系统敏感文件被读取 溢出攻击 email软件 rpc 溢出攻击 NFS 权限配置问题 DNS 毒化 ssh openssl 通过非对称加密计算让服务端过载 apache dos 本地访问 离线口令破解 本地缓冲溢出攻击 内核缺陷 获取root权限之后 Rootkit 特洛伊木马 签名校验 嗅探程序 日志清理 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-19 12:09:46 "},"网络安全/APT.html":{"url":"网络安全/APT.html","title":"APT","keywords":"","body":" 高级长期威胁（英语：Advanced Persistent Threat，缩写：APT），又称高级持续性威胁、先进持续性威胁等，是指隐匿而持久的电脑入侵过程，通常由某些人员精心策划，针对特定的目标 gh0st 证据收集 内存分析 主文件表 网络进程 宿主文件 进程监控 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-22 12:39:02 "},"网络安全/拨号攻击.html":{"url":"网络安全/拨号攻击.html","title":"拨号攻击","keywords":"","body":" 战争拨号器 踩点 软件 WarVOX TeleSweep PhoneSweep VPN攻击 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-23 01:09:27 "},"网络安全/无线攻击.html":{"url":"网络安全/无线攻击.html","title":"无线攻击","keywords":"","body":"发现 主动发现 被动发现 aircrack-ng sudo airmon-ng start wlan0 # 查看网卡接口 sudo airodump-ng wlp3s0 # 扫描AP 监听数据传输 wireshark 拒绝服务攻击 消除认证攻击 假冒服务端或客户端发起连接断开请求 加密攻击 wep 重放攻击 离线破解 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-23 08:50:40 "},"网络安全/硬件攻击.html":{"url":"网络安全/硬件攻击.html","title":"硬件攻击","keywords":"","body":" ATA设备访问 移动设备autorun 默认配置带来的危险 硬件电路图探测，嗅探数据 后门代码 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-23 08:50:40 "},"网络安全/web与数据库攻击.html":{"url":"网络安全/web与数据库攻击.html","title":"web与数据库攻击","keywords":"","body":" demo文件攻击 源代码暴露 规范化漏洞 文件路径 扩展程序漏洞 缓冲区溢出 拒绝服务 漏洞扫描器 nikto nessus 攻击 查点 google 爬虫 漏洞挖掘 fiddler webscarab burp suite 常见漏洞 XSS SQL注入 CSRF HTTP应答注入 隐藏标签 ssi导致的命令执行 数据库攻击 查点 漏洞 监听程序 数据库引擎 口令 间接攻击 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-23 11:42:20 "},"网络安全/移动设备攻击.html":{"url":"网络安全/移动设备攻击.html","title":"移动设备攻击","keywords":"","body":"android rooting 本地(native)文件 远程shell漏洞 数据窃取 能力泄露 恶意软件 应用程序漏洞 便携式网络攻击器 ios MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-24 01:21:56 "},"网络安全/KALI/渗透测试方法论.html":{"url":"网络安全/KALI/渗透测试方法论.html","title":"渗透测试方法论","keywords":"","body":"渗透测试 种类 白盒测试 黑盒测试 方法论 渗透测试方法论有许多，著名的有OWASP(开放式web应用安全项目) ISSAF(信息系统安全评估框架) OSSTMM(开源安全测试方法论) 盲测 双盲测 灰盒测试 双灰盒测试 串联测试 逆向测试 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-24 11:53:08 "},"网络安全/KALI/信息收集.html":{"url":"网络安全/KALI/信息收集.html","title":"信息收集","keywords":"","body":" 域名注册信息 # 并不止局限于使用命令行whois程序 whois -h whois.crsnic.net \"domain google.com\" DNS记录分析 查询dns地址 host -a ismy.wang 使用dig达到同样的效果 dig ismy.wang any 路由信息 traceroute ismy.wang tcptraceroute ismy.wang 搜索引擎 善用搜索引擎搜索相关主机的邮箱或者用户名 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-24 11:53:08 "},"网络安全/KALI/目标识别.html":{"url":"网络安全/KALI/目标识别.html","title":"目标识别","keywords":"","body":"主机识别 ping arping arping 192.168.43.1 # 局域网主机识别 fping fping -g 192.168.43.0/24 # 扫描局域网主机 hping3 nping nbtscan 操作系统识别 被动式识别 p0f 主动式 nmap MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-24 11:53:08 "},"网络安全/KALI/服务枚举.html":{"url":"网络安全/KALI/服务枚举.html","title":"服务枚举","keywords":"","body":"nmap 扫描目标指定 普通点分十进制(192.168.1.1) CIDR标记法(192.168.1.0/24) 十进制ip区间(192.168.1.1-255) 多个ip(ip1,ip2) 扫描方式 sT：会进行三次握手 sS:只会进行一次握手 sN,sF,sX:通过判断目标有无回应确定端口状态 sM:同上 sA:判断是否有防火墙过滤 sW:窗口扫描 sI:通过僵尸网络 端口选项 p:端口范围 F:快速扫描 r:顺序扫描 时间选项 T:指定扫描模式 服务版本识别 nmap -sV 192.168.43.0/24 强力选项A 会开启服务版本识别，操作系统识别，脚本扫描，路由追踪 nbtscan 可以扫描主机netbios信息 NetBIOS，为网上基本输入输出系统（英语：Network Basic Input/Output System）的缩写，它提供了OSI模型中的会话层服务，让在不同计算机上运行的不同程序，可以在局域网中，互相连线，以及分享数据。严格来说，NetBIOS不是一种网上协议，而是应用程序接口（API nbtscan 192.168.43.1-254 snmap枚举 onesixtyone snmpcheck VPN枚举 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-27 12:12:53 "},"网络安全/KALI/漏洞映射.html":{"url":"网络安全/KALI/漏洞映射.html","title":"漏洞映射","keywords":"","body":" 本地漏洞 远程漏洞 漏洞分类 设计类 实施类 运营类 工具 OpenVAS OpenVAS是功能齐全的漏洞扫描程序 Cisco分析工具 模糊分析工具 通过发送有问题的数据来检测问题 SNMP分析 SMB分析 web程序分析 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-27 12:12:53 "},"网络安全/KALI/社会工程.html":{"url":"网络安全/KALI/社会工程.html","title":"社会工程","keywords":"","body":" 冒名顶替 利益交换 工具 SET MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-27 12:12:53 "},"网络安全/KALI/漏洞利用.html":{"url":"网络安全/KALI/漏洞利用.html","title":"漏洞利用","keywords":"","body":"exploit资料库 发布了部分已知漏洞的利用方法 工具 metasploit exploit 漏洞利用模板 payload 包含恶意程序的有效载荷 shell bind shell reverse shell meterpreter MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-27 12:12:53 "},"网络安全/KALI/权限提升.html":{"url":"网络安全/KALI/权限提升.html","title":"权限提升","keywords":"","body":" 横向提权 纵向提权 本地漏洞利用 密码攻击 离线攻击工具 hash-identifier Hashcat RainbowCrack samdump2 john Ophcrack Crunch 在线破解工具 CeWL Hydra Medusa 网络欺骗工具 DNSChef 可以伪造假DNS应答地址 arpspoof Ettercap 截取会话与密码 网络嗅探器 Dsniff 密码捕获 tcpdump Wireshark MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-28 08:11:03 "},"网络安全/KALI/访问维护.html":{"url":"网络安全/KALI/访问维护.html","title":"访问维护","keywords":"","body":"操作系统后门 Cymothoa Intersect Meterpreter后门 隧道工具 dns2tcp iodine ncat proxychains ptunnel socat sslh stunnel4 web后门 WeBaCoo 通信采用了cookie weevely php meterpreter MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-28 08:11:03 "},"网络安全/Web安全/nav.html":{"url":"网络安全/Web安全/nav.html","title":"Web安全","keywords":"","body":"原则 黑名单与白名单思想 最小权限原则 纵深防御 数据与代码分离 不可预测原则 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"网络安全/Web安全/浏览器安全.html":{"url":"网络安全/Web安全/浏览器安全.html","title":"浏览器安全","keywords":"","body":"浏览器安全 同源策略 同源策略限制了从同一个源加载的文档或脚本如何与来自另一个源的资源进行交互 URL 结果 原因 http://store.company.com/dir2/other.html 成功 只有路径不同 http://store.company.com/dir/inner/another.html 成功 只有路径不同 https://store.company.com/secure.html 失败 不同协议 ( https和http ) http://store.company.com:81/dir/etc.html 失败 不同端口 ( http:// 80是默认的) http://news.company.com/dir/other.html 失败 不同域名 ( news和store ) 同源策略一旦出现漏洞被绕过，将会出现严重的后果 浏览器沙箱 沙箱设计的目的是为了让不可信的代码运行在一定的环境中，从而限制这些代码访问隔离区之外的资源。如果因为某种原因，确实需要访问隔离区外的资源，那么就必须通过的指定的通道，这些通道会进行严格的安全检查，来判断请求的合法性。通道会采取默认拒绝的策略，一般采用封装 API 的方式来实现 恶意网址拦截 大部分都是通过识别上传到云，浏览器厂商共享数据库，从而识别恶意网站 防盗链 盗链是指服务提供商自己不提供服务的内容，通过技术手段绕过其它有利益的最终用户界面（如广告），直接在自己的网站上向最终用户提供其它服务提供商的服务内容，骗取最终用户的浏览和点击率。受益者不提供资源或提供很少的资源，而真正的服务提供商却得不到任何的收益 实现原理 通过判断HTTP请求头referer（访问的来源）字段，服务端再根据该字段是否返回资源 public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) request; String referer = req.getHeader(\"Referer\"); if (StringUtils.isEmpty(referer)) { request.getRequestDispatcher(\"/imgs/error.png\").forward(request, response); return; } String domain = getDomain(referer); if (!domain.equals(domainName)) { request.getRequestDispatcher(\"/imgs/error.png\").forward(request, response); return; } chain.doFilter(request, response); } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-28 05:34:20 "},"网络安全/Web安全/XSS攻击.html":{"url":"网络安全/Web安全/XSS攻击.html","title":"XSS攻击","keywords":"","body":"跨站脚本攻击(XSS) XSS攻击通常指的是通过利用网页开发时留下的漏洞，通过巧妙的方法注入恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序 XSS类型 反射型XSS 需要构造一个恶意URL，诱导用户访问 存储型XSS 数据存储在服务端，当数据被渲染到客户端的时候，恶意代码会被执行 DOM based XSS 恶意数据注入导致dom节点被改变 XSS payload 获取cookie 通过生成img节点发起get请求 构造from表单发起post请求 伪造页面进行钓鱼 浏览器及插件识别 防御 使用http-only 禁止js读取cookie 输入检查 输出检查 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-29 11:47:53 "},"网络安全/Web安全/CSRF.html":{"url":"网络安全/Web安全/CSRF.html","title":"CSRF","keywords":"","body":"跨站请求伪造（CSRF） 跨站请求攻击，简单地说，是攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并运行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品） 防御 验证码 发生csrf时，用户一般都不知道，当引入验证码的时候，则就是强制用户与应用交互 检查referer 页面一般具有逻辑关系，如下单之前的页面一般是购物车，如果不符合条件，则是很可疑的 token 要实施一次csrf，攻击者需要构造出操作的请求数据，如果在这个过程中引入一个随机变量，URL就无法构造，更谈不上攻击了 接口幂等性设计 MVVC 多版本并发控制 通过一个版本号来达到避免冲突，但是会有一定的重试 去重表 利用数据库的唯一索引特性，保证唯一的逻辑 悲观锁 整个执行过程中锁定该订单对应的记录 token 数据提交前要向服务的申请 token，token 放到 redis 或内存，token 有效时间提交后后台校验 token，同时删除 token，token只有一次有效性 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-28 06:24:04 "},"网络安全/Web安全/点击劫持.html":{"url":"网络安全/Web安全/点击劫持.html","title":"点击劫持","keywords":"","body":"点击劫持 flash劫持 图片覆盖攻击 通过修改图片的style属性能让图片出现在页面任何位置 拖拽劫持 通过隐藏控件，让用户在不知情的情况下拖拽网页数据到另外一个页面 触屏劫持 防御 禁止本网站被位于本网站之外的iframe所嵌套 HTTP X-Frame-Options MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-30 12:53:45 "},"网络安全/Web安全/HTML5安全.html":{"url":"网络安全/Web安全/HTML5安全.html","title":"HTML5安全","keywords":"","body":"HTML5安全 新标签 新的标签出现导致之前的XSS防御失效 iframe增加sandbox属性将大大提高安全性 a标签的rel可以指定不发送referer canvas的应用 其他安全问题 跨域请求头 window对象不受同源策略限制 web storage MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-30 12:53:45 "},"网络安全/Web安全/注入攻击.html":{"url":"网络安全/Web安全/注入攻击.html","title":"注入攻击","keywords":"","body":"注入攻击 注入攻击的本质，还是因为数据跟代码没有相分离，把用户输入的数据作为代码的一部分执行 SQL注入 盲注 通过在条件拼接条件来查看页面返回结果 timeing attack 通过在条件加上耗时函数，查看最终页面返回时间，来确定是否存在注入漏洞 属于边信道攻击的一种 数据库攻击技巧 读写文件 命令执行 字符集问题 防御 预编译 检查数据类型 安全编码函数 OWASP ESAPI 其他注入攻击 XML注入 用户输入的数据改变了XML的结构 代码函数 使用了代码执行函数执行了包含用户输入的代码 CRLF注入 有些使用CRLF换行符分割的地方，如果用户输入的数据包含CRLF，则会造成问题 log HTTP header MY all right reserved，powered by Gitbook该页面最后修改于： 2019-12-31 02:42:10 "},"网络安全/Web安全/文件上传漏洞.html":{"url":"网络安全/Web安全/文件上传漏洞.html","title":"文件上传漏洞","keywords":"","body":"文件上传漏洞 用户上传的文件被web容器解释执行 上传的是跨域配置文件，导致同源策略失效 上传的文件是木马病毒被管理员下载执行 上传的图片含有木马与脚本，被某些浏览器执行 文件上传检查绕过 通过\\0字符截断 apache文件解析 apache对不认识的文件类型的处理 IIS文件解析 nginx对php cgi的执行问题 安全的文件上传 上传目录设置为不可执行 白名单文件类型检查 后缀名+文件头 文件存放加上随机数 单独的文件服务器 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-29 01:58:55 "},"网络安全/Web安全/认证与会话管理.html":{"url":"网络安全/Web安全/认证与会话管理.html","title":"认证与会话管理","keywords":"","body":"认证与会话管理 密码 密码的强度导致的问题 多因素认证 Session Session：在计算机中，尤其是在网络应用中，称为“会话控制”。Session对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的Web页之间跳转时，存储在Session对象中的变量将不会丢失，而是在整个用户会话中一直存在下去 session id 泄漏 session fixation 如果登录后session id不改变，则攻击者可以诱导用户登录某个攻击者的session id session 保持攻击 不断刷新，使session一直保持有效 访问控制 基于URL 基于方法 基于数据 垂直权限管理 水平权限管理 水平越权访问 用户访问到不属于它的其他用户信息 Oauth MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-01 08:05:08 "},"网络安全/Web安全/加密算法与随机数.html":{"url":"网络安全/Web安全/加密算法与随机数.html","title":"加密算法与随机数","keywords":"","body":"加密算法与随机数 流加密攻击 有些加密算法是将流中的每个字节逐个进行异或 这导致只需要知道两个加密后的密文，便解密密文 ECB模式的曲线 分组加密算法改变分组密文的顺序，也将改变解密后的明文顺序，这很有可能将导致数据传输过程中关键数据被伪造 密钥管理 密码学里的原则：密码系统的安全性应该依赖于密钥的复杂性，而非算法的保密性 web应用的密钥可以存放在配置文件或数据库中，但对密钥的获取要有严格的权限管理 伪随机数问题 弱随机数 时间戳当随机数 随机数种子猜测 加密算法 对称加密 发件人和收件人使用其共同拥有的单个密钥 ,这种密钥既用于加密，也用于解密 常见的对称加密算法：DES、3DES、DESX、Blowfish、IDEA、RC4、RC5、RC6和AES 优点 只需记忆一个密钥，就可用于加密、解密； 与非对称加密方法相比，加密解密的计算量小，速度快，简单易用，适合于对海量数据进行加密处理 缺点 如果密钥交换不安全，密钥的安全性就会丧失 非对称加密 密钥依据性质划分，将其中的一个向外界公开，称为公钥；另一个则自己保留，称为私钥。公钥(Public key)常用于数据加密（用对方公钥加密）或签名验证（用对方公钥解密），私钥(Private key)常用于数据解密（发送方用接收方公钥加密）或数字签名（用自己私钥加密） 常见的对称加密算法：RSA、Elgamal、背包算法、Rabin、D-H、ECC 优点 难破解 缺点 加密速度慢 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-02 01:08:49 "},"网络安全/Web安全/Web框架安全.html":{"url":"网络安全/Web安全/Web框架安全.html","title":"Web框架安全","keywords":"","body":"Web框架安全 模板引擎与XSS 使用默认的设置 CSRF 通过框架自动化添加token与token校验 HTTP Headers 谨慎用户数据操作HTTP 头 通过web框架提供的统一接口来跳转页面 持久层 变量绑定与SQL注入 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-03 12:38:02 "},"网络安全/Web安全/应用层拒绝服务攻击.html":{"url":"网络安全/Web安全/应用层拒绝服务攻击.html","title":"应用层拒绝服务攻击","keywords":"","body":"应用层拒绝服务攻击 DDOS 是指处于不同位置的多个攻击者同时向一个或数个目标发动攻击，或者一个攻击者控制了位于不同位置的多台机器并利用这些机器对受害者同时实施攻击 SYN flood 这是一种利用TCP协议缺陷，发送大量伪造的TCP连接请求，使被攻击方资源耗尽(CPU满负荷或内存不足)的攻击方式 应用层DDOS CC攻击 主要针对消耗资源大的web页面发起大量请求 使用限制请求频率来防御，但本质还是需要通过做好性能优化与架构优化来对抗 也可以通过验证码来阻止大量的机器请求 防御应用层DDOS 区分请求的是人还是机器 IP请求频率限制 资源耗尽攻击 slowloris攻击 以极低的速率发送数据，占用服务器资源 server limit dos 往正常的客户端写入超长数据，导致客户端请求被服务器拒绝 正则 一些正则表达式的处理是非常耗费资源的 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-04 08:11:51 "},"网络安全/Web安全/web服务器配置安全.html":{"url":"网络安全/Web安全/web服务器配置安全.html","title":"web服务器配置安全","keywords":"","body":"web服务器配置安全 模块安全问题 运行身份问题 jboss与tomcat 注意这些web容器的管理入口 web服务器对同名参数的解析问题 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-04 08:17:26 "},"网络安全/Web安全/业务安全.html":{"url":"网络安全/Web安全/业务安全.html","title":"业务安全","keywords":"","body":"业务安全 业务逻辑存在漏洞 账户是如何被盗的 数据传输被嗅探 木马 钓鱼网站 暴力破解 业务逻辑 XSS SQL注入 密码找回漏洞 验证接口没有做限制 防御 忘记密码验证码最好在6-8位（字母加数字） 一旦频繁调用接口验证时，应该使用图形验证码拦截，防止机器模拟 使用黑名单和白名单机制，防御攻击 互联网垃圾 处理 识别与拦截 钓鱼 高仿网站 邮件钓鱼 用户隐私保护 做好数据权限管理 用户具有知情权与选择权 do not track MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-29 01:04:20 "},"网络安全/Web安全/安全开发与安全运营.html":{"url":"网络安全/Web安全/安全开发与安全运营.html","title":"安全开发与安全运营","keywords":"","body":"安全开发与运营 安全开发流程（SDL） 黑名单与白名单 去除代码开发辅助信息 关闭错误回显 安全运营 漏洞修复 建立完善的漏洞跟踪机制 安全监控 探测应用是否被攻击 入侵检测 紧急响应流程 邮件报警 IM报警 短信报警 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-01-29 02:07:59 "},"网络安全/密码学/密码学.html":{"url":"网络安全/密码学/密码学.html","title":"密码学","keywords":"","body":"密码学 密码学能做什么？ 机密性：如何使得某个数据自己能看懂，别人看不懂 认证：如何确保数据的正确来源，如何保证通信实体的真实性 完整性：如何确保数据在传输过程中没有被删改 不可否认性：如何确保用户行为的不可否认性 基本概念 明文 ——要处理的数据 密文 ——处理后的数据 密钥 ——秘密参数 加密函数 解密函数 密码算法分类 根据用途 加密算法 杂凑函数 数字签名 根据密钥 对称 非对称 密码分析学 密码体制的攻击 唯密文攻击 已知密文攻击 无条件安全与计算安全 流密码 明文消息按字符或比特逐位加密 主要是基于硬件实现 密钥流产生器 参数为k的有限状态自动机 二元序列的伪随机性 反馈移位寄存器 非线性序列 A5流密码算法 用于蜂窝式移动电话系统语音和数字加密 分组密码 混淆原则 敌手即使获得了密文和明文，也无法求出密钥的任何信息；即使获得了密文和明文的统计规律，也无法求出明文的新的信息 扩散原则 明文中的每一位影响密文中的尽可能多的位 SP网络 代换 Feistel密码 乘积密码指顺序地执行两个或多个基本密码系统，使得最后结果的密码强度高于每个基本密码系统产生的结果 DES 分组长度为64 bits (8 bytes) 密文分组长度也是64 bits。 密钥长度为64 bits，有8 bits奇偶校验，有效密钥长度为56 bits。 安全性 DES的密钥长度可能会对安全性产生威胁 3DES 多重DES就是使用多个密钥利用DES对明文进行多次加密。使用多重DES可以增加密钥量，从而大大提高抵抗穷举密钥搜索攻击的能力 工作模式 根据不同的数据格式和安全性要求, 以一个具体的分组密码算法为基础构造一个分组密码系统的方法 AES 明文分组可变，128、192、256比特 密钥长度可变，各自可独立指定为128、192、256比特。 SM4 是一个分组密码算法，分组长度和密钥长度均为128比特。加密算法与密钥扩展算法都采用32轮非线性迭代结构 公钥密码 每个用户生成一个密钥对：一个公钥pk和一个对应的私钥 sk 私钥由用户本人使用，而公钥则由系统中其他用户使用 RSA 密钥生成 选择两个大素数P，q。(例如:每个1024位) 计算n= Pq:，z=(p-1)(q- 1)。 随机选取e (其中e 选取d.使得ed- 1能够被z完全整除。(换言之:ed mod z= 1) 加解密 ElGamal 椭圆曲线密码 哈希函数 将任意长的消息M映射为较短的、固定长度的一个值H(M) 安全条件 单向性 抗弱碰撞性 抗强碰撞性 生日攻击 随机取一个值，该值的hash值与某个特定x的hash值相同的概率为50时，应该要取多少个值 SHA-1 算法的输入：小于264比特长的任意消息，分为512比特长的分组。 算法的输出：160比特长的消息摘要。 数字签名 接收者能够核实发送者对文档的签名； 发送者事后不能否认对文档的签名； 不能伪造对文档的签名 RSA签名 使用私钥签名，公钥进行验证 ElGamal签名 DSS签名 密钥协议 Diffie-Hellman密钥交换协议 Shamir秘密共享 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-17 01:12:02 "},"计算机网络/计算机网络与因特网.html":{"url":"计算机网络/计算机网络与因特网.html","title":"计算机网络","keywords":"","body":"计算机网络与因特网 因特网 端系统：连接入网络的各种终端设备 通信链路：如电缆、或者无线电波 分组交换机：传送分组的机器，有路由器、链路层交换机 因特网服务提供商 协议 定义两个实体通信时所交换的报文的格式与顺序，以及接受报文产生的事件动作 网络边缘 接入网 家庭接入 DSL（数字用户线）:本地电话公司接入 电缆：DSL利用电话线，而电缆利用的是有线电视基础设施 FTTH：光纤到户 企业接入 以太网 WIFI 广域无线接入 物理媒体 导引型 双绞铜线 同轴电缆 光纤 非导引型 陆地无线信道 卫星无线信道 网络核心 分组交换 每个分组都有首部和尾部，包含了源地址和目的地址等控制信息，在同一个传输线路上同时传输多个分组互相不会影响 时延 排队时延：分组在路由器的输入队列和输出队列中排队等待的时间 处理时延：主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据、进行差错检验或查找适当的路由等 传输时延与传播时延 传输时延是路由器推出分组所需要的时间，传播时延则是两个路由器之间的传播时间 丢包 如果路由器排队时延过大，那么新到来的分组就无地方存放，则路由会丢掉这个分组，称为丢包 电路交换 电路交换用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低 链路中的电路是通过频分复用（FDM）或时分复用(TDM)实现的 网络的网络 ISP 互联网服务提供商 ISP 可以从互联网管理机构获得许多 IP 地址，同时拥有通信线路以及路由器等联网设备，个人或机构向 ISP 缴纳一定的费用就可以接入互联网 协议层次及服务模型 五层协议 应用层：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等协议。数据单位为报文 传输层：为进程提供通用数据传输服务,udp与tcp，数据单位为报文段 网络层：为主机提供数据传输服务，网络层把传输层传递下来的报文段或者用户数据报封装成分组 数据链路层：就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧 物理层 ：考虑的是怎样在传输媒体上传输数据比特流 OSI 表示层 ：数据压缩、加密以及数据描述 会话层 ：建立及管理会话 TCP/IP 它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层 网络攻击与网络安全 DDOS 网络蠕虫 网络嗅探 IP欺骗 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-06 03:26:06 "},"计算机网络/应用层.html":{"url":"计算机网络/应用层.html","title":"应用层","keywords":"","body":"应用层协议 体系结构 CS架构 P2P架构 进程通信 两个端系统之间的通信，本质是两个进程之间的通信，进程通过使用操作系统提供的接口与另一个端系统上的进程进行通信，这个接口是套接字 套接字=（IP，端口号） 运输服务 TCP UDP 应用层协议 HTTP SMTP POP3 IMAP DNS 提供了主机名和 IP 地址之间相互转换的服务 DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性 只有当返回的响应超过512字节或者主域名服务器向辅助域名服务器传送变化的数据时采用TCP协议 根域名 -> gTLD Server -> Name Server 域名解析记录： A记录(Address) 用来指定域名对应的IP地址 MX记录(Mail Exchange) 用来指定邮件服务器 CNAME记录(Canonical Name) 别名解析就是为一个域名设置多个别名 NS记录 为某个域名指定DNS解析服务器 TXT记录 添加一段文字说明 FTP FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件: 控制连接：客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答 数据连接：用来传送一个文件数据 主动模式 客户端与服务器建立控制连接之后 由服务器主动发起一条从服务器到客户端的连接 被动模式 客户端与服务器建立控制连接之后 由客户端再发起一条从客户端到服务器的连接 DHCP Dynamic Host Configuration Protocol 工作过程 远程登录协议 TELNET 电子邮件协议 SMTP SMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则 POP3 从服务器上读取了邮件，就把该邮件删除 IMAP 客户端和服务器上的邮件保持同步 常用端口 应用 应用层协议 端口号 传输层协议 备注 域名解析 DNS 53 UDP/TCP 长度超过 512 字节时使用 TCP 动态主机配置协议 DHCP 67/68 UDP 简单网络管理协议 SNMP 161/162 UDP 文件传送协议 FTP 20/21 TCP 控制连接 21，数据连接 20 远程终端协议 TELNET 23 TCP 超文本传送协议 HTTP 80 TCP 简单邮件传送协议 SMTP 25 TCP 邮件读取协议 POP3 110 TCP 网际报文存取协议 IMAP 143 TCP 一个web页面请求过程 DHCP配置主机信息 主机刚开始没有IP地址信息，首先通过DHCP来获取IP地址 主机生成一个DHCP UDP请求报文 该请求报文被放入一个具有广播地址的IP数据报中 后该IP数据报被封装在MAC帧中，这个帧的目的地址是一个广播地址 当DHCP服务器接收到这个广播帧后不断向上分解得到主机信息，并将相关信息放入报文中，发送给主机 交换机通过自学习，因此现在交换机就可以直接知道应该向哪个接口发送该帧 主机收到该帧之后，配置自己的IP地址，子网掩码等信息 ARP解析MAC地址 主机需要跟网关路由器通信，但是DHCP 过程只知道网关路由器的 IP 地址 为了获取MAC地址，主机需要生成一个包含网关路由器地址的ARP查询报文，并将它广播出去 网关路由器接收到这个广播报文之后，向主机回送网关路由器自己的MAC地址 DNS解析域名 此时，主机可以直接通过网关路由器发送一个DNS请求报文 路由器收到这个DNS查询报文的帧后，抽取出IP数据报，根据转发表决定应该转发给哪台路由器 路由器通过内部网关协议和外部网关协议来实现路由选择 这个DNS请求到达服务器之后，DNS进行查询，发送DNS回答报文，回送给主机 HTTP请求页面 此时，主机就得到HTTP服务器的IP地址 会经过三次握手生成一个TCP套接字 TCP连接建立后，客户端生成一个HTTP请求报文，发送给服务器 服务器接收到之后，返回一个响应报文 客户端接收到响应之后，进行渲染，显示web页面 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-27 03:26:20 "},"计算机网络/rpc.html":{"url":"计算机网络/rpc.html","title":"RPC","keywords":"","body":"rpc RPC : Remote Procedure Call ,即远程过程调用。 是分布式系统常见的一-种通信方法,从跨进程到跨物理机已经有几十年历史。 从一个方法调用开始 System.our.println(\"hello world\"); 在本机上，完成这么样的一次方法调用需要： 传递方法参数：将字符串hello world的引用地址压栈 确定方法版本：像在JVM上 这个过程使用invokexxx指令来完成 执行被调方法：从栈中弹出Parameter的值或引用，以此为输入，执行Callee内部的逻辑 返回执行结果：将Callee的执行结果压栈 为了完成这些过程，就需要通过内存来传递数据 如果两个方法不在同一个进程，要如何传递数据？ 管道（Pipe）或者具名管道（Named Pipe）：通过管道在进程间传递少量的字符流或字节流。普通管道只用于有亲缘关系进程（由一个进程启动的另外一个进程）间的通信ps aux | grep tomcat 信号（Signal）:用于通知目标进程有某种事件发生kill -9 666 信号量（Semaphore）:相当于操作系统提供的一个特殊变量 消息队列（Message Queue）:POSIX标准中定义了消息队列用于进程间数据量较多的通讯 共享内存（Shared Memory）：是效率最高的进程间通讯形式 套接字接口（Socket）:当仅限于本机进程间通讯时，套接字接口是被优化过的，不会经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等操作 通信的成本 通过网络进行分布式运算的8宗罪 The network is reliable —— 网络是可靠的。 Latency is zero —— 延迟是不存在的。 Bandwidth is infinite —— 带宽是无限的。 The network is secure —— 网络是安全的。 Topology doesn't change —— 拓扑结构是一成不变的。 There is one administrator —— 总会有一个管理员。 Transport cost is zero —— 不必考虑传输成本。 The network is homogeneous —— 网络是同质化的。 RPC的三个基本问题 如何表示数据 如何传递数据 如何确定方法 跨进程交互形式: RESTful、 WebService、 HTTP、 基于DB做数据交换、基于MQ做数据交换,以及RPC。 交互形式 依赖中间做数据交互 直接交互 核心原理 另外一个角度 如果跳出程序方法调用的视角 不再以传递参数-调用方法-获取结果这样的思路思考 就会有焕然一新的视角 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-09 07:23:51 "},"计算机网络/HTTP.html":{"url":"计算机网络/HTTP.html","title":"HTTP","keywords":"","body":"HTTP协议 基础概念 URI 请求报文 响应报文 HTTP方法 GET 获取资源 HEAD 与GET类似，但不返回报文的实体主体 POST 主要用来传输数据 PUT 上传文件 PATCH 对资源进行部分修改 DELETE 删除文件 OPTIONS 查询指定的 URL 能够支持的方法 CONNECT 要求在与代理服务器通信时建立隧道 TRACE 服务器会将通信路径返回给客户端 状态码 分类 分类描述 1** 信息，服务器收到请求，需要请求者继续执行操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 4** 客户端错误，请求包含语法错误或无法完成请求 5** 服务器错误，服务器在处理请求的过程中发生了错误 1XX 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应 2XX 200 OK 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用 206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容 3XX 301 Moved Permanently ：永久性重定向 302 Found ：临时性重定向 303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源 304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码 307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法 4XX 400 Bad Request:语法错误 401 Unauthorized:需要认证 403 Forbidden:请求被拒绝 404 Not Found 5XX 500 Internal Server Error ：服务器正在执行请求时发生错误 503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求 具体应用 连接管理 短连接 每进行一次 HTTP 通信就要新建一个 TCP 连接 长连接 从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close 在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive 流水线 流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟 Cookie Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一客户端 用途 会话状态管理 个性化设置 浏览器行为跟踪 创建过程 服务的响应头Set-Cookie头部： Set-Cookie: yummy_cookie=choco Set-Cookie: tasty_cookie=strawberry 客户端之后对同一服务器发送请求时，都会在请求头Cookie头部带上这个Cookie Cookie: yummy_cookie=choco; tasty_cookie=strawberry 分类 会话期Cookie：浏览器关闭之后它会被自动删除，没有指定过期时间就是会话期Cookie 持久性 Cookie：指定过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2020 07:28:00 GMT; 作用域 Domain 标识Cookie在哪些域名下有效，如果不指定，默认是当前文档的主机 如果指定了Domain，则一般包括子域名，如baidu.com，包含map.baidu.com JS访问 JavaScript可以通过document.cookie来创建cookie或者访问非HttpOnly的Cookie HttpOnly 标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用 Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2020 07:28:00 GMT; Secure; HttpOnly Secure 标记为 Secure 的 Cookie 只能通过被 HTTPS 协议加密过的请求发送给服务端 Session Session是通过在服务端生成一个key，使用这个key为索引在服务器端存放用户信息，后将这个key作为cookie返回给客户端，让客户端使用这个key来操作 应该注意 Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，还需要使用二重验证的方式 特点 基于TCP/IP的高级协议 默认端口号:80 基于请求/响应模型的:一次请求对应一次响应 无状态的：每次请求之间相互独立，不能交互数据 浏览器禁用cookie 当浏览器无法使用Cookie，只能使用session，此外，session id也不能通过cookie来传递，而是需要通过URL传参的方式来传递，如wap时代的sid Cookie与Session 比较类别 Session Cookie 存储方式 服务端 客户端 大小限制 无 有 安全 较安全 较不安全 缓存 优点 缓解服务器压力 提升客户端速度 实现方法 代理服务器缓存 客户端缓存 Cache-Control 禁止进行缓存 Cache-Control: no-store 强制确认缓存 只有当缓存资源有效时，才能使用这个响应 Cache-Control: no-cache 私有缓存 只能单独给用户使用，一般用在浏览器 Cache-Control: private 公共缓存 可以被多个用户使用，一般存储在代理服务器中 Cache-Control: public 缓存过期 出现在响应报文，超过这个时间 缓存就被认为过期 Cache-Control: max-age=31536000 Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期 Expires: Wed, 04 Jul 2012 08:26:05 GMT 缓存验证 ETag 是资源的唯一标识 If-None-Match: \"82e22293907ce725faf67773957acd12\" 如果服务器接收到ETage后，判断资源没有发生改变，会返回一个304 Last-Modified 首部字段也可以用于缓存验证，如果响应首部字段里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有实体主体的 304 Not Modified 响应报文 内容协商 服务端驱动 客户端设置Accept、Accept-Charset、Accept-Encoding、Accept-Language等首部，服务端根据这些首部返回特定资源 代理驱动 服务器返回 300 Multiple Choices 或者 406 Not Acceptable，客户端从中选出最合适的那个资源 vary 一个客户端发送了一个包含 Accept-Language 首部字段的请求之后，源服务器返回的响应包含 Vary: Accept-Language 内容，缓存服务器对这个响应进行缓存之后，在客户端下一次访问同一个 URL 资源，并且 Accept-Language 与缓存中的对应的值相同时才会返回该缓存 内容编码 内容编码有：gzip、compress、deflate、identity 浏览器发送 Accept-Encoding 首部，其中包含有它所支持的压缩算法，以及各自的优先级。服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知浏览器它选择了哪一种算法 范围请求 Range 请求报文中添加 Range 首部字段指定请求的范围 Range: bytes=0-1023 成功的话服务器返回的响应包含 206 Partial Content 请求的范围越界的情况下，服务器会返回 416 Requested Range Not Satisfiable 状态码 不支持范围请求的情况下，服务器会返回 200 OK 状态码 Accept-Range 用于告知客户端是否能处理范围请求，可以处理使用 bytes，否则使用 none 分块传输 Chunked Transfer Encoding，可以把数据分割成多块，让浏览器逐步显示页面 多部分对象集合 一份报文主体内可含有多种类型的实体同时发送，每个部分之间用 boundary 字段定义的分隔符进行分隔 如 Content-Type: multipart/form-data; boundary=AaB03x --AaB03x Content-Disposition: form-data; name=\"submit-name\" Larry --AaB03x Content-Disposition: form-data; name=\"files\"; filename=\"file1.txt\" Content-Type: text/plain ... contents of file1.txt ... --AaB03x-- 虚拟主机 HTTP/1.1 使用虚拟主机技术，使得一台服务器拥有多个域名，并且在逻辑上可以看成多个服务器 通信数据转发 代理 目的 缓存 负载均衡 网络访问控制 访问日志记录 正向代理 用户可以察觉正向代理的存在 反向代理 反向代理一般位于内部网络中，用户察觉不到 网关 网关服务器会将 HTTP 转化为其它协议进行通信，从而请求其它非 HTTP 服务器的服务 隧道 使用 SSL 等加密手段，在客户端和服务器之间建立一条安全的通信线路 重定向原理 当服务端对客户端进行重定向时，会设置一个Location响应头，并将状态码设置为302 客户端（浏览器）接收到这样的响应之后，就会跳转到Location里面的网址 HTTPS HTTP的问题 明文通信 无法确认通信方 无法验证报文完整性 原理 客户端向服务端发送HTTPS请求 服务端收到HTTPS请求返回公钥证书 客户端收到服务端的公钥证书，验证是否有效（验证颁发机构、过期时间等等） 如果有效，生成一个随机数用公钥加密，然后发送给服务端 服务端使用私钥将该随机数解密，然后用该随机数作为密钥加密一串字符给客户端 如果客户端解密这串字符成功，这串字符将作为接下来客户端与服务端通信的密钥 这个过程的关键在于密钥传递使用了非对称加密，数据传输采用了对称加密 所以这就保证了对称加密的密钥不会通过网络直接传输，之所以数据传输采用了对称加密，主要是因为非对称加密性能很低 证书 通过使用 证书 来对通信方进行认证 数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构 服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起 完整性保护 SSL 提供报文摘要功能来进行完整性保护 HTTPS的缺点 加解密有性能损失 证书授权需要高额费用 nginx配置证书 server { .... ssl on; ssl_certificate fullchain.pem; ssl_certificate_key privkey.pem; } ### HTTP/2.0 HTTP/1.x缺陷 使用多个连接提升性能 没有压缩请求与响应 不支持资源优先级 二进制分帧 只会有一个TCP连接，一个连接会有任意数量的双向数据流 一个数据流会有一个一个唯一的标识符，一个数据流可以承载一来一回双向信息 消息是请求消息或者响应消息 帧是最小的通信单位，不同数据流的帧可以交错发送，然后根据唯一标识符来重新组装 服务端推送 HTTP/2.0 在客户端请求一个资源时，服务端会把相关的资源一起发送给客户端 首部压缩 HTTP/2.0 要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输 不仅如此，HTTP/2.0 也使用 Huffman 编码对首部字段进行压缩 GET与POST GET 用于获取资源，而 POST 用于传输实体主体。 参数 GET是通过URL携带参数的，而 POST 的参数存储在实体主体中 安全 GET语义来说是安全的，因为GET操作只是获取资源 而POST的语义是不安全的，因为POST是上传数据 幂等性 幂等方法不应该具有副作用，所有的安全方法也都是幂等的 在正确实现的条件下，GET，HEAD，PUT 和 DELETE 等方法都是幂等的 可缓存 一般来说GET和HEAD是可缓存的，PUT和DELETE不可缓存，POST在大多数情况下不可缓存 CDN CDN加速意思就是在用户和我们的服务器之间加一个缓存机制,动态获取IP地址根据地理位置，让用户到最近的服务器访问 原理 1) 用户向浏览器提供要访问的域名； 2) 浏览器调用域名解析库对域名进行解析，由于CDN对域名解析过程进行了调整，所以解析函数库一般得到的是该域名对应的 CNAME记录，为了得到实际IP地址，浏览器需要再次对获得的CNAME域名进行解析以得到实际的IP地址；在此过程中，使用的全局负载均衡DNS解析，如根据地理位置信息解析对应的IP地址，使得用户能就近访问； 3) 此次解析得到CDN缓存服务器的IP地址，浏览器在得到实际的IP地址以后，向缓存服务器发出访问请求； 4) 缓存服务器根据浏览器提供的要访问的域名，通过Cache内部专用DNS解析得到此域名的实际IP地址，再由缓存服务器向此实际IP地址提交访问请求； 5) 缓存服务器从实际IP地址得得到内容以后，一方面在本地进行保存，以备以后使用，二方面把获取的数据返回给客户端，完成数据服务过程； 6) 客户端得到由缓存服务器返回的数据以后显示出来并完成整个浏览的数据请求过程。 CDN 动态加速 通过动态的链路探测来寻找回源最好的一条路径 跨域问题 同源策略限制了从同一个源加载的文档或脚本如何与来自另一个源的资源进行交互，所以通常情况下一个源无法通过ajax与另外一个源进行交互 解决方案 JSONP（缺陷很多） 服务端将返回数据封装成js函数调用并返回，客户端js通过动态加载script标签加载服务器的js数据，加载完成后执行封装的js函数获取数据 所以jsonp这种请求方式与ajax有着本质的不同 被调服务端设置响应头允许跨域 response.setHeader(\"Access-Control-Allow-Origin\",\"*\"); 后端请求转发 前端所在的服务端调用被调服务端，将结果返回给前端 nginx反向代理 server { listen 80; server_name api.domain; location /api1 { proxy_pass http://outter_server; } } 使用应用网关 使可以通过一个统一入口访问各个项目 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-27 03:45:46 "},"计算机网络/RESTful.html":{"url":"计算机网络/RESTful.html","title":"RESTful","keywords":"","body":"RESTful 一套关于设计请求的规范，本质上谈不上规范，更多的是一种风格 资源：代表一个抽象实体 表征（表现层）：资源的表现形式 状态：在特定上下文下产生的信息 转移：状态发生了变化 超文本驱动：通过服务端返回的超文本来决定客户端行为 URI代表一种资源、客户端与服务器，传递资源的某种表现层、客户端通过HTTP动词，对服务器资源进行操作 GET： 获取数据 POST： 添加数据 PUT： 更新数据 DELETE： 删除数据 常见错误 URI包含动词 URI包含版本 范例 请求方式 URL 含义 GET： http://www.example.com/users 获取用户列表数据 POST： http://www.example.com/users 创建(添加)用户数据 GET： http://www.example.com/users/1 获取用户ID为1的用户信息 PUT： http://www.example.com/users/1 修改用户ID为1的用户信息 DELETE： http://www.example.com/users/1 删除用户ID为1的用户信息 RESTful的系统 服务端与客户端分离 无状态 可缓存 分层系统 统一接口 按需代码 REST风格的好处 降低服务接口的学习成本 资源之间有天然的集合或者层次结构 RMM成熟度 The Swamp of Plain Old XML：完全不REST。另外，关于Plain Old XML这说法，SOA表示感觉有被冒犯到。 Resources：开始引入资源的概念。 HTTP Verbs：引入统一接口，映射到HTTP协议的方法上。 Hypermedia Controls：超媒体控制在本文里面的说法是“超文本驱动” 不足 面向资源（也就是REST）更适合做CRUD，面向过程面向对象才能表达更加复杂的逻辑 REST绑定HTTP 既是优点，同时也是缺点，不适合用于高性能的场景 REST本身没有传输可靠性支持 需要自己做好幂等性处理 REST缺乏对资源进行“部分”和“批量”的处理能力 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-10 06:46:01 "},"计算机网络/运输层.html":{"url":"计算机网络/运输层.html","title":"运输层","keywords":"","body":"运输层 运输层的功能：为不同主机上的进程提供逻辑通信 运输层与网络层的关系：网络层为运输层提供服务，运输层构建在网络层之上 运输层协议 TCP UDP 运输层通过Socket端口来实现多路复用与多路分解 UDP 对发送时间以及发送内容控制能力更强 无连接 无状态 分组首部小 支持一对一、一对多、多对一和多对多的交互通信 虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等 UDP首部 TCP 面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流，每一条 TCP 连接只能是点对点的 TCP首部 序号：对字节流进行编号，序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401 确认号：期望收到的下一个报文段的序号，例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701 数据偏移：也就是首部的长度 RST/SYN/FIN 用于连接的建立与拆除 URG 代表是上层紧急数据 ACK 确认 PSH 尽快交给应用层 窗口：窗口值作为接收方让发送方设置其发送窗口的依据 RTT 估计 一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT 均值RTT = 0.875 * 均值RTT + 0.125 * 样本RTT 可靠数据传输 TCP使用以下方式保证可靠传输： 应用数据被分割成 TCP 认为最适合发送的数据块。 TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 TCP 的接收端会丢弃重复的数据。 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制） 拥塞控制： 当网络拥塞时，减少数据的发送。 ARQ协议： 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 ARQ协议 通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输 停止等待ARQ协议 每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组 连续ARQ协议 发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认 流量控制 滑动窗口 接收方通过在报文段中添加接口窗口字段来进行双方之间的速度匹配 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据 拥塞控制 拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载 为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化 原则 报文段丢失时发送方降低速率 未确认报文段确认到达时，发送方增加速率 带宽探测 慢启动 慢开始算法的思路是当主机开始发送数据时 较好的方法是先探测一下，即由小到大逐渐增大发送窗口 不断增加直到超时，超时后将cwnd/2 拥塞避免 让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送放的cwnd加1. 快重传与快恢复 公平性 UDP源有可能压制TCP流量 明确拥塞通知：由路由器在报文中插入当前路由器的拥塞情况 连接管理 三次握手 客户端–发送带有 SYN 标志的数据包–一次握手–服务端 服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端 客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端 第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常 第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常 第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常 所以三次握手就能确认双发收发功能都正常，缺一不可 客户端：A 服务端: B 为什么要回传SYN： 接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了 同样 使用ACK服务端就能验证客户端 四次挥手 客户端发起一个关闭连接的请求，服务器响应这个关闭请求 此时，客户端不能再向服务端发送数据，但是服务器可以发送数据给客户端，当服务器的数据传送完毕，向客户端发送一个关闭连接的请求 客户端接收到服务端的关闭请求后，再发送一个确认消息，等待2MSL的时间，关闭 服务端接收到客户端的最后一个关闭请求后，关闭 等待2MSL时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文 TCP状态转化 影响网络传输的因素： 网络带宽 传输距离造成的时延 拥塞控制 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-28 06:48:29 "},"计算机网络/网络层.html":{"url":"计算机网络/网络层.html","title":"网络层","keywords":"","body":"网络层 网络层是整个互联网的核心，因此应当让网络层尽可能简单。网络层向上只提供简单灵活的、无连接的、尽最大努力交互的数据报服务 IP协议可以将异构的物理网络连接起来，看起来就像是一个统一的网络 数据平面：控制数据报从路由器输入链路转发到输出链路 控制平面：控制数据在端到端之间的路由方式 路由器工作原理 分组转发流程 输入 线路链接 对数据报进行拆封 查找转发排队 交换 通过内存转发 通过总线转发 通过互联网络转发 前两种在同一时刻内只有一个分组能被处理，最后一种如果输出端口不同，则能并行转发 分组调度 先进先出 优先权排队 即分为两个队列，一个优先级较高，较高优先级的队列如果有分组，则立马处理 循环和加权公平排队 优先级队列不固定，在各个队列之间的轮流 网际协议 IP数据报格式 IPV4 分片 由于某些链路的帧可承载的字节有限，故在路由器会将数据载荷分为几个部分，后一一发送，并把组装数据的任务交给接收端 IPV4编址 分类 由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的 子网划分 通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址 无分类 CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀 通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为 构成超网 网络地址转换NAT IPV6 IPV4到IPV6之间的过渡：建隧道 通用转发 跨越网络层-链路层 路由选择算法 集中式 迪杰斯特拉算法得出最短路径 分散式 距离向量算法 内部网关协议RIP RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址 内部网关协议OSPF 自治系统内部的路由选择 集中式算法，使用Dijkstra 算法 每台路由器都有整个自治系统的完整链路图 外部网关协议BGP 自治系统之间的路由选择协议 SDN控制平面 软件定义网络（Software Defined Network，SDN）是由美国斯坦福大学CLean State课题研究组提出的一种新型网络创新架构，是网络虚拟化的一种实现方式。其核心技术OpenFlow通过将网络设备的控制面与数据面分离开来，从而实现了网络流量的灵活控制，使网络作为管道变得更加智能，为核心网络及应用的创新提供了良好的平台 特征 基于流的转发 横跨多个协议层 数据平面与控制平面分离 网络控制 可编程网络 ICMP 差错报告 询问报文 ping Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文 traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文 当TTL为0时，路由器将不会继续转发报文，traceroute通过第一次将TTL设为1，然后把报文发送给下一台路由器，路由器将ttl-1之后告诉主机报文不可达，这样以此类推得到整个路由链路 SNMP 简单网络管理协议 一般使用UDP 虚拟专用网VPN MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-06 03:26:06 "},"计算机网络/链路层.html":{"url":"计算机网络/链路层.html","title":"链路层","keywords":"","body":"链路层 提供的服务 封装成帧 透明传输 帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，就会造成帧的首尾错误判断，此时就需要在传输的时候在数据部分插入转义字符，在接收端去掉转义字符，使用户察觉不到这个变化 链路接入 可靠交付 差错检测与纠正 奇偶校验 循环冗余检测（CRC） 信道分类 广播信道 一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到 如果所有的节点再同一时间发送数据，就会产生碰撞，解决碰撞的方法有两种，一种是信道复用技术，一种是CSMA/CD协议 点对点通信链路 不会发生碰撞，使用PPP协议 PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议 多路访问链路和协议 信道划分协议 TDM（时分复用） FDM（频分复用） 统计时分复用 由于TDM和FDM即使主机没有数据复用，也会占用固定的资源，于是统计时分复用就不固定每个用户在时分复用帧中的位置，只要有数据就集中起来组成统计时分复用帧然后发送 波分复用 就是对光的频分复用 CDMA（码分多址） 为所有通信用户分配一个码片，当某个用户需要发送数据时，如果要发送1时，就发送这个码片，如果要发送0时，就发送这个码片的反码。 当接收端收一串信号后，可以使用这串信号与发送方码片做一个运算，如果发现结果是0，则表明这串信号是其他用户发送，否则如果是1，代表发送方发送了1，如果是-1.代表发送方发送了0 随机接入协议 时隙ALOHA 载波侦听多路访问（CSMA） 具有碰撞检测的载波侦听多路访问（CSMA/CD） 多点接入 ：说明这是总线型网络，许多主机以多点的方式连接到总线上 载波监听 ：每个主机都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待 碰撞检测：如果发送的过程中，监测到其他主机发送了数据，就代表发生了碰撞 轮询协议 交换局域网 局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限 MAC地址 链路层地址，长度为 6 字节（48 位），用于唯一标识网络适配器（网卡） ARP协议 由 IP 地址得到 MAC 地址 以太网 以太网是一种计算机局域网技术。IEEE组织的IEEE 802.3标准制定了以太网的技术标准，它规定了包括物理层的连线、电子信号和介质访问层协议的内容 以太网是一种星型拓扑结构局域网 帧格式 类型：上层使用的协议 长度在46-1500之间 FCS:帧检验序列，使用CRC 链路层交换机 转发与过滤 自学习功能 交换机具有自学习能力，学习的是交换表的内容，交换表中存储着 MAC 地址到接口的映射 刚开始，交换机的交换表是空的，如果连接交换机的一台主机A想要给另外一台主机B发送数据，会先经过交换机，交换机此时发现交换表没有关于主机B的数据，于是就会向所有主机广播这条消息，只有主机B会响应这条消息，其他主机会忽略，此时交换机就得到到主机B的接口，并把它记录到交换表中 虚拟局域网VLAN 链路虚拟化 把一个网络当做链路 数据中心网络 负载均衡 等级体系结构 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-06 03:26:06 "},"计算机网络/无线网络.html":{"url":"计算机网络/无线网络.html","title":"无线网络","keywords":"","body":"与有线链路区别 信号强度随距离递减 会受干扰 多径传播 WIFI 蜂窝因特网 移动管理 永久地址与外部地址 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-11-01 11:24:57 "},"计算机网络/网络安全.html":{"url":"计算机网络/网络安全.html","title":"网络安全","keywords":"","body":"安全通信 机密性 报文加密 报文完整性 避免被篡改 端点鉴别 运行安全性 密码学 对称密钥体系 公开密钥加密（非对称） 数字签名 端点鉴别 不重数 SSL 安全套接字层 建立在传输层之上，应用层之下的加密协议 防火墙与入侵检测系统 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-11-01 11:24:57 "},"计算机网络/多媒体网络.html":{"url":"计算机网络/多媒体网络.html","title":"多媒体网络","keywords":"","body":"流式存储视频 UDP流 实时传输协议RTP 实时流协议RTSP HTTP流 预取视频 客户缓存与TCP缓存 适应性HTTP流 IP语音 支持多媒体的网络 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-11-01 11:24:57 "},"计算机网络/云计算.html":{"url":"计算机网络/云计算.html","title":"云计算","keywords":"","body":"云计算 背景 提高资源利用率 基础 并行计算 分布式计算 网格计算 生态系统 硬件 软件 服务 网络 安全 部署模式 公有云 私有云 混合云 数据中心 数据集中存储、计算、交换的中心 软件定义数据中心 虚拟化技术 虚拟化技术的核心思想是利用软件或固件管理程序构成虚拟化层，把物理资源映射为虛拟资源 服务器虚拟化 寄居虚拟化 裸机虚拟化 虚拟机迁移 存储虚拟化 存储虚拟化是指将存储网络中各个分散且异构的存储设备按照一定的策略映射成一个统一的连续编址的逻辑存储空间，称为虚拟存储池，并将虚拟存储池的访问接口提供给应用系统。 网络虚拟化 网卡虚拟化 硬件设备虚拟化 链路虚拟化 云安全技术 可信访问控制 数据存在与可使用性证明 数据隐私保护 虚拟安全技术 云资源访问控制 开源云计算管理平台 open stack MY all right reserved，powered by Gitbook该页面最后修改于： 2020-05-28 07:37:25 "},"编程语言/编程语言.html":{"url":"编程语言/编程语言.html","title":"编程语言","keywords":"","body":"编程语言 语言的类型模型 强类型弱类型 静态类型静态类型 语言的泛型 面向对象 函数式 过程式 怎样与语言交互 编译还是解释 判断结构与数据结构 核心特性 语言学习 在比较中学习：编程语言的规则并不具有普遍意义，只是因为“在当前的特定情况下，做此规定能更方便 在历史中学习：了解历史条件，以及历史变迁，能加深理解 编程语言的历史 从纸条打孔到高级语言 各种各样编程语言出现的原因：懒惰 急躁 傲慢 语法 语法是语言设计者制定的规则，怎么方便就怎么来 基于栈： 1 2 + 3 * 基于树： (+ 1 2) 设计不存在任何解析矛盾的语法体系是十分困难的。随后要再融入新的语法时不与既有的语法发生冲突，这个尤其困难 流程控制 else语句的：goto 的危害 while语句的：让反复执行的if更加简洁 for语句：让数值建增的while语句更简洁 for-wach语句：让for遍历更简洁 函数 作用：缩小关注点 代码复用 返回：调用栈 递归：递归完成的操作都可以转换为迭代操作 错误处理 程序所依赖的外部总会出错 方式：返回值 统一跳转 异常 异常的使用： 何时抛出异常 异常的出口 异常的传递 名字与作用域 为什么要名字？可读性 为什么要作用域？管理名字 作用域的演变： 全局作用域 $i 动态作用域 local $i 静态作用域 my $x 类型 类型是数据的元数据 cvtsi2ssq %rax, %xmm1 类型的扩展： 用户自定义（结构体） 面向对象 泛型或模板 动态类型 类型推断 容器与字符串 并发处理 交替运行： 协作式 抢占式 对象与类 面向对象在不同语言下不一样 模型的建立方法： 模块/包 函数 闭包 类 继承与代码复用 继承的实现策略： 一般化与特殊化 提取共同部分 差异实现 多重继承带来命名冲突的解决: 禁止 按某种顺序搜索 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-27 11:13:18 "},"编程语言/C/nav.html":{"url":"编程语言/C/nav.html","title":"C语言","keywords":"","body":"C语言 C 语言是一种通用的、面向过程式的计算机程序设计语言。1972 年，为了移植与开发 UNIX 操作系统，丹尼斯·里奇在贝尔电话实验室设计开发了 C 语言。 C 语言是一种广泛使用的计算机语言，它与 Java 编程语言一样普及，二者在现代软件程序员之间都得到广泛使用。 当前最新的C语言标准为 C11 ，在它之前的C语言标准为 C99 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/C/类型运算符与表达式.html":{"url":"编程语言/C/类型运算符与表达式.html","title":"类型运算符与表达式","keywords":"","body":"变量名 变量名的开头必须是字母或下划线，不能是数字 变量名中的字母是区分大小写的 变量名绝对不可以是C语言关键字 变量名中不能有空格 数据类型及长度 常量 字符常量 常量表达式 枚举常量 声明 算术运算符 关系运算符与逻辑运算符 类型转换 自动转换 强制转换 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/C/函数与程序结构.html":{"url":"编程语言/C/函数与程序结构.html","title":"函数与程序结构","keywords":"","body":"函数的基本知识 函数的定义形式 返回值类型 函数名（参数声明表）{ 声明和语句 } 外部变量 作用域规则 头文件 静态变量 static int a; 寄存器变量 register int x; register变量将放在机器的寄存器中 程序块结构 初始化 外部变量和静态变量都将被初始化为0 递归 C预处理器 文件包含 #include \"文件名\" #include 宏替换 #define a b 不会替换字符串中的内容 带参数的宏 #undef 双井号嵌套 条件包含 #ifndef HDR #define HDR #endif MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/C/指针与数组.html":{"url":"编程语言/C/指针与数组.html","title":"指针与数组","keywords":"","body":"指针与地址 p = &c; // p为指向c的指针 y = *p; // 现在y的值的c的值 指针与函数参数 void swap(int *x,int *y){ int tmp = *x; *x = *y; *y = tmp; } 指针与数组 数组本质也是一个指针 但是指针是一个变量，数组名不是一个变量 地址算术运算 相同类型指针之间的赋值运算 同整数间的加减法运算 指向相同数组的两个指针减法或比较运算 将指针赋值为0 字符串与指针 void reverse(char *s,int n){ if (n 指针数组以及指向指针的指针 char *sa[20]; int main(){ int x; int *xp = &x; int **xpp = &xp; **xpp=15; printf(\"%d\",x); } 多维数组 int a[i][j]; 指针数组的初始化 指针与多维数组 char *s[]={\"123\",\"321\",\"1111\"}; 命令行参数 int main(int argc,char *s[]){return 0;} 指向函数的指针 复杂声明 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/C/结构.html":{"url":"编程语言/C/结构.html","title":"结构","keywords":"","body":"基本知识 struct{ int x; int y; } point; struct poinit p; p.x=1; 结构与函数 结构指针 struct point *pp; (*pp).x=5; y = pp->x; 结构数组 struct poinit ps[20]; 结构指针 结构体中的数据对齐问题 自引用结构 struct{ int x; int y; struct point *p; } poinit; 表查找 类型定义 typedef char* String String s = \"123\"; 联合 union ut{ char a; int b; long c; }u; u.c=1L; 位字段 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/C/输入与输出.html":{"url":"编程语言/C/输入与输出.html","title":"输入与输出","keywords":"","body":"标准输入输出 getchar putchar 格式化输出-printf 变长参数表 格式化输入-scanf 文件访问 错误处理 stdout stderr 行输入和行输出 fgets fputs 其他函数 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/C/UNIX系统接口.html":{"url":"编程语言/C/UNIX系统接口.html","title":"UNIX系统接口","keywords":"","body":"文件描述符 内核（kernel）利用文件描述符（file descriptor）来访问文件。 文件描述符是非负整数。 打开现存文件或新建文件时，内核会返回一个文件描述符。 读写文件也需要使用文件描述符来指定待读写的文件。 低级IO-read/write open creat close unlink 随机访问-lseek MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/nav.html":{"url":"编程语言/JAVA/nav.html","title":"Java","keywords":"","body":"JAVA JAVA编程语言 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/语言基础.html":{"url":"编程语言/JAVA/语言基础.html","title":"语言基础","keywords":"","body":"语言基础 JAVA运行环境 JVM Java 虚拟机（JVM）是运行 Java 字节码的虚拟机。 JDK JDK 是 Java Development Kit，它是功能齐全的 Java SDK。它拥有 JRE 所拥有的一切，还有编译器（javac）和工具，能够创建和编译程序。 JRE JRE 是 Java 运行时环境。它是运行已编译 Java 程序所需的所有内容的集合，包括 Java 虚拟机（JVM），Java 类库，java 命令和其他的一些基础构件。但是，它不能用于创建新程序。 oracle jdk与openjdk Oracle JDK由Oracle公司开发，Oracle JDK采用了商业实现 OpenJDK是Java SE平台版的开源和免费实现，虽然OpenJDK的部分功能有所缺失，但整体相差不大 关键字 完全小写的字母 被高亮的单词 标识符 类的名称 变量名称 方法名称 常量与变量 常量 在程序运行期间，固定不变的量 数据类型 基本数据类型 整数型 byte short int long 这些类型的包装类型的valueOf都作了缓存 浮点型 float double 字符型 char 布尔型 boolean 引用数据类型 浮点数的表示 指数 = $X + 2^{x的二进制位数-1}$ 有效数字 = 使用原码存储 由于某些数字不能由有限二进制位精确表示 所以会出现1f-0.9f != 0.1 这种情况 变量 程序运行期间，内容可以发生改变的量 数据类型转换 隐式转换 数据范围从小到大 显式转换 范围小的类型 范围小的变量名 = (范围小的类) 原本范围大的数据; 数据溢出 当被转换的数值范围大于目标类型时，就会发生数据溢出，导致一部分数据丢失 byte short char 在运算时都会被提升为int类型 ASCII 码表 使用数字表示某些字符 运算符 进行特定操作的符号 算术运算符 + - * / % 加号的三种用法： 数值加法 字符计算 字符串连接 优先级问题 String s = \"123\" + 20 + 30; 自增自减运算符 单独使用 混合使用 赋值运算符 基本 复合 比较运算符 > = 逻辑运算符 && || ! 短路 当 a && b 中的a为false时 就不会去计算b表达式 位运算符 // 以下所有操作都代表的是在2进制操作下 System.out.println(2 > 1); // 右移 2 System.out.println(0xffffffff >>> 3); // 无符号右移（忽略掉符号位，对符号位也会移动） System.out.println(8 | 0); // 位或 8 System.out.println(8 & 0); // 位与 0 System.out.println(8 ^ 0); // 异或 8 System.out.println(~8); // 位非 -9 方法 方法签名包括方法名称与参数列表 是方法的唯一标识 方法调用 直接调用 赋值调用 递归调用 参数的传递 在JAVA中 参数都是通过值来进行传递的 形参：方法定义阶段 实参：方法调用阶段 要避免使用Object作为可变参数 入参保护：对于入参数据量进行判断控制 处理不了 直接返回错误 参数校验：对于外部的输入 都需要校验 基于防御式编程理念 但是对于一些底层的方法就不必校验 越靠近外部 越需要校验 修饰符 访问权限修饰符 private public protected static 静态方法 属于类本身 final 无法被子类重写 default 接口默认方法 abstract 抽象方法 synchronized 同步 方法重载 指在同一个类中，允许存在一个以上的同名方法，只要它们的参数列表不同即可，与修饰符和返 回值类型无关 重载可以在编译时确定调用的方法 也被称为静态绑定 void test(){ f(1); } // 重载方法的选择： void f(int i){} // 1. 精确匹配 void f(long i){} // 2. 基本类型会自动转换成更大的数据类型 void f(Integer i){} // 3. 自动装箱拆箱 void f(Object i){} // 4. 向上转型进行匹配 void f(Integer... i){} // 5. 最终通过可变参数匹配 方法重写 对于子类 其可以改变父类的方法实现 父类无法调用在父类没有定义的方法 父类可以调用到子类重写的父类的方法 子类重写的条件： 只能针对非静态 非final 非构造方法 访问权限不能变小 重写方法的返回值类型要 T super 父类的返回值类型 受检异常的类型同上 方法签名需要与父类一致 构造方法 不能继承 不能覆写 不能直接调用 方法名称必须与类名相同 没有返回类型 默认提供了一个无参构造 可以为private 类内方法 外部使用静态成员时 尽量使用 类名.静态成员 来调用 静态方法： 不能使用实例成员 不能使用super与this关键字 getter 与 setter 为什么使用： 满足面向对象的封装特性 利于统一控制 权限... 几种情况警惕： 在方法中添加了业务逻辑会增加排查问题的难度 同时定义getxxx与isxxx会迷惑程序员 方法参数名称与成员变量名称相同 这点在IDE的使用下不是什么问题 特殊方法 finalize方法 main方法 同步异步 异步处理的任务是非时间敏感的 异步调用需要通过诸如轮询的方式获取执行结果 轮询会增加机器的压力 流程控制 顺序结构 分支结构 if if-else if-else if-else switch 循环结构 for循环 for(初始化表达式①; 布尔表达式②; 步进表达式④){ 循环体③ } while循环 初始化表达式① while(布尔表达式②){ 循环体③ 步进表达式④ } do...while循环 初始化表达式① do{ 循环体③ 步进表达式④ }while(布尔表达式②) for 和 while 的小区别： 控制条件语句所控制的那个变量，在for循环结束后，就不能再被访问到了，而while循环结束还可以继 续使用，如果你想继续使用，就用while，否则推荐使用for。原因是for循环结束，该变量就从内存中消 失，能够提高内存的使用效率。 在已知循环次数的时候使用推荐使用for，循环次数未知的时推荐使用while 跳出语句 continue break 用在循环中 用在switch中 死循环 嵌套循环 数组 数组就是存储数据长度固定的容器，保证多个数据的数据类型要一致。 定义 int arr = new int[3]; int arr = new int[]{1,2,3}; 访问 int a = arr[2]; int l = arr.length; == 与 equals == 运算符比较的是两个对象的地址 equals默认实现也是比较地址，如果重写了equals，可以根据相应的逻辑来判断两个对象是否相等 hashCode 与 equals 如果两个对象相等，则 hashcode 一定也是相同的 两个对象相等,对两个对象分别调用 equals 方法都返回 true 两个对象有相同的 hashcode 值，它们也不一定是相等的 因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖 hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） final关键字 修饰类：类无法继承 修饰变量：赋值之后无法修改 修饰方法：无法被子类重写 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-16 07:24:42 "},"编程语言/JAVA/Java谜题.html":{"url":"编程语言/JAVA/Java谜题.html","title":"Java谜题","keywords":"","body":"Java 谜题 表达式 奇数性 x % 2 == 1 // 用来判断x是否为奇数 当 x 为负数时, 该表达式永不成立 当取余操作返回一个非零结果时 与左操作数拥有相同的正负符号 -1 % 2 == -1 找零时刻 浮点数问题 2.00 - 1.10 != 0.9 // true 2.00 - 1.10 == 0.8999999999999999 // true 长整除 long a = 24*60*60*1000*1000 long b = 24*60*60*1000 a / b == 5 // true 原因在于a的表达式计算时溢出了 它以int的方式计算最后才存入a a = 24L*60*60*1000*1000 a / b == 1000 // true 初级问题 12345 + 5432l == 17777 // true 主要小写l 与数字1的区别 多重转型 (int)(char)(byte)-1 == 65535 // true 1.从int的-1转为byte的-1 2.从byte的-1转为char 发生了符号扩展（char是无符号的 -1会被转为65535） 3.从char转为int 如果通过观察不能确定成行将要做什么 那么它做的很有可能就不是你想要的 互换内容 x ^= y^= x^= y // 什么垃圾代码? 在单个表达式中不要对相同的变量赋值两次 Dos int i = 0 true ? 'X' : 0 // 'X' true ? 'X' : i // 88 三元表达式的如果第二个操作数与第三个操作数类型相同 则这个类型就是表达式的类型 否则如果类型不同 较小的类型会被提升为范围较大的那个类型 条件表达式的操作数类型应该相同 半斤 short x = 0 int i =123456 x = x+i // 编译错误 x+=i // 会自动转型-7616 不要将复合赋值操作用于int类型以下的 用在int类型上 确保右侧类型不比int类型大 字符串 最后的笑声 System.out.println('H' + 'A'); // 137 加号运算符在两个操作数都不是字符串的情况下, 执行的将会是加法 而非字符串连接, 两个char变量被提升为int了 转义字符的溃败 System.out.println(\"a\\u0022.length()) // 正常运行 \\u0022 等同于 \" 选择转义字符 而非转义unicode 可恶的unicode /** * F:\\user\\data 下存放了xxx * @author MY * @date 2020/9/15 10:38 */ public class Main { public static void main(String[] args) { System.out.println(\"hello\"); } } 这段代码无法通过编译 原因在第一行路径的\\u 编译器会认为其是一个unicode编码 找不到\\uxxx这个编码 编译就会出错 字符串奶酪 byte[] bytes = new byte[256]; for(int i=0;i 这段代码所产生出的字符串是在不停的平台上是不确定的, 主要是编码的问题 即在使用比特数组生成字符串时要显式指定编码 斜杠的受害者 \"note.ismy.wang\".replaceAll(\".\",\"/\") // 输出结果：////////////// 问题在于replaceAll 传递的第一个参数是一个正则表达式 正则表达式的受害者 String.class.getName().replaceAll(\"\\\\.\",File.separator) 上面的代码会抛出异常：IllegalArgumentException：character to be escaped is missing 原因在于replaceAll第二个参数会对字符串进行转义, 如果输入\\ 就代表字符串未结束 解决方法是使用replace方法： String.class.getName().replace(\".\",File.separator) URL的愚弄 https://javascript System.out.println(\"hello world\"); 上面这段代码编译 运行没问题 原因在与https:被识别为一个标签 后面的// 则被识别为注释 某些东西看起来过于奇怪 以至于不想对的 那么极有可能是错的 不劳而获 Random rnd = new Random(); StringBuffer word = null; switch(rnd.nextInt(2)){ case 1:word = new StringBuffer('P'); case 2: word = new StringBuffer('G'); default:word = new StringBuffer('M'); word.append('a'); word.append('i'); word.append('n'); System.out.println(word); } System.out.println(word); 最终只会打印出ain 三个bug: nextInt最终的取值范围是0-1 创建StringBuffer传入char时会变成int 导致变成创建char大小的缓冲区 case不加break 循环 尽情享受循环 for(byte b = Byte.MIN_VALUE;b 这段代码什么也不会打印 主要是因为0x90 是十六机制 代表的是十进制的144 这已经超出了byte的表示范围（-128 - 127） 无情的++ int j = 0; for (int i = 0; i j的最终结果为0, j = j++等同于： int t = j; j = j + 1; j = t; 在循环中 int count = 0; for (int i = 0; i 循环结束时 count等于多少？ 答案是这个循环永远不会停止, 循环继续条件永远为真, 因为i溢出了 变幻莫测的值 int i=0; while(0xffffffff 这个循环也会无限循环, 移位操作符只会用其右操作数的低五位做移位操作,对于long变量 是低六位 所以不论i多大, 这里i能做移位操作的最大只能达到32 如果可能的话 移位长度应该是常量 循环者 double i = Double.POSITIVE_INFINITY; while(i == i + 1); // 无限循环 无穷大+1还是无穷大 一个浮点数值越大, 它和其后继数值间隔越大 浮点数使用了固定的有效位来表示, 所以一个很大的数+1不会改变它的值 循环者的新娘 double i = Double.NaN; while (i != i); // 无限循环 Nah != Nah 循环者的爱子 String i = \"cccc\"; while (i != i + 0); // 无限循环 循环者的鬼魂 short i = -1; while (i != 0){ i >>>=1; } // 无限循环 short会被提升为int 0xffffffff 右移之后 变成int的0x7fffffff 后又变成short 被砍掉高4为 变成 0xffff 回到了-1 死循环 循环者的诅咒 Integer i = 129; Integer j = 129; while (i 当两个数都是包装类型时 比较操作符执行的是值比较 判等操作符执行的是引用比较 循环者遇到了狼人 Integer i = Integer.MIN_VALUE; while (i != 0 && i == -i); // 死循环 还是整数溢出搞的鬼 被计数击倒了 int count = 0; for(float f = Integer.MAX_VALUE; f f的值太大了 以至于+50 还是等于f 不要使用浮点数作为循环索引 分分钟 int count = 0; for (int i=0;i 运算符优先级问题：取模与乘法优先级相同 异常 优柔寡断 boolean f(){ try { return true; }finally { return false; } } 这段代码返回false finally语句总是在离开try后执行 finally不要使用 return break continue throw 极端不可思议 try { System.out.println(\"hw\"); } catch (IOException e){} // 1.编译错误 try { }catch (Exception e){} // 2. 正常编译 // 3.正常编译 interface i1{ void f() throws ClassNotFoundException,InterruptedException; } interface i2 { void f() throws IOException,InterruptedException; } interface i3 extends i1,i2{ } new i3(){ @Override public void f() throws InterruptedException {} }; 对于受检异常, 如果catch到的异常没有在try代码块声明, 则无法编译 但是JLS规定Exception与Throwable除外, 这些异常可以没有在try中声明 一个方法可以抛出的异常是其所有父类/父接口声明的异常类型的交集 不受欢迎的i private static final int i; static { try { f(); }catch (Exception e){ i=-1; } } static void f() throws Exception{ throw new Exception(\"eee\"); } 这段代码会因为编译器无法确定i是否只被赋值一次而编译失败 不辞而别 try { System.out.println(\"hello\"); System.exit(-1); }finally { System.out.println(\"world\"); } System.exit会立即停止所有的程序线程 try代码块压根就不会完成 也就不会执行finally了 不情愿的对象 class Object{ private Object obj = new Object(); public Object() {} } 这个对象new的时候会抛出栈溢出异常 繁琐的流关闭 FileInputStream in1 = null; FileInputStream in2 = null; try { in1 = new FileInputStream(\"xxx\"); in2 = new FileInputStream(\"xxx\"); }finally { if (in1 != null) in1.close(); if (in2 != null) in1.close(); } 这个程序的问题在于in1 close抛出异常就会导致in2不会关闭 解决方法使用JDK7 的自动关闭特性 循环中抛出异常 使用异常来控制循环 不仅代码难以阅读 并且速度十分慢 可怕的递归 public static void main(String[] args){ work(); System.out.println(\"done\"); } static void work(){ try { work(); }finally { work(); } } 这个程序会的调用会从根节点生成一颗完全二叉树 树的深度为虚拟机的栈深度 这个递归虽然不是无限的 但对人类的生命而言也近乎无穷了 类 迷惑的重载 public static void main(String[] args){ new Main().confusing(null); } public void confusing(Object obj){ System.out.println(\"obj\"); } public void confusing(double[] doubles){ System.out.println(\"doubles\"); } 最终会打印出doubles 方法的选择是从窄到宽的 狸猫换狗子 class Animal{ private static int count; public void incr(){count++;} } class Dog extends Animal{ public Dog() { incr();} } class Cat extends Animal{ public Cat() { incr();} } 这段程序dog与cat的count会相互影响 会飞的复读鸭 class Duck{ public static void fly(){ System.out.println(\"i fly!\"); } } class RepeatDuck extends Duck{ public static void fly(){} } Duck duck = new RepeatDuck(); duck.fly(); // print i fly! 静态方法的调用不存在多态 或许静态方法之所以叫静态就是因为不存在动态的分派机制 错误的时间 public class Main { private static final Main instance= new Main(); private static final long i = System.currentTimeMillis(); private final long initTime; public Main() { initTime = i; System.out.println(initTime); } } 这个类会循环初始化 导致initTime第一次是为0 当心这种情况 不是你的类型 String s = null; s instanceof Object; // false 左操作符为null就会返回false new Date() instanceof String; // 编译错误 如果两个操作数都是类 其中一个必须是另外一个的子类型 (String)new Object(); // 抛出运行时异常 发育不良 class Father{ private final String name; public Father() { name = makeName(); } protected String makeName(){ return \"i am your father\"; } @Override public String toString() { return name; } } class Son extends Father{ String pname; public Son(String name) { this.pname = name; } @Override protected String makeName() { return \"i am \" + pname; } } 创建一个Son对象 最终会打印出 i am null ,关键在于子类还没初始化完全 name就已经完成初始化 null class Null{ public static void print(){ System.out.println(\"hello world\"); } } ((Null)null).print(); // 可以打印 静态方法的调用只与类型相关 这或许是Java的设计缺陷 静态方法压根就不能通过对象实例调用 创建对象 for (int i = 0; i 这段代码无法通过编译 一个本地变量声明作为一条语句只能出现在语句块中 库 大问题 BigInteger one = new BigInteger(\"1\"); BigInteger two = new BigInteger(\"2\"); one.add(two); System.out.println(one); // print 1 BigInteger的实例是不可变的 算术操作只会返回新实例而非直接修改对象 分不清人 class Person { public final String name; public Person(String name) { this.name = name; } @Override public boolean equals(Object o){ if (o instanceof Person p) return p.name.equals(this.name); return false; } } Set personSet = new HashSet<>(); personSet.add(new Person(\"cxk\")); System.out.println(personSet.contains(new Person(\"cxk\"))); // false 任何时候 只要重写了equals方法 就必须重写hashCode方法 equals相等的对象hashCode必须相等 但hashCode相等不代表equals相等 六亲不认 class Person { public final String name; public Person(String name) { this.name = name; } public int hashCode(){ return name.hashCode();} public boolean equals(Person p){ return p.name.equals(this.name); } } 这个类声明虽然声明了hashCode 但是还是和上面一例一样 返回false 原因在与我们重载了equals方法 而非重写 重载为错误和混乱提供了机会 为避免犯这种错误 加上@Override 混乱的代价 766 - 066 == 712 // true 以0开头的整型字面常量会被解释为八进制 不要这么做！！！ 一行代码解决 // 去除list中的重复元素并保持顺序 return new ArrayList<>(new LinkedHashSet<>(originList)); // 以,后面跟随者0-n个空格分割文本 str.split(\",\\\\S*\"); // 以字符串形式展示数组 Arrays.toString(...); // 判断一个整数的二进制表示有多少1 Integer.bitCount(xxx); 了解类库可以节省大量时间与精力 可怕的日期API Calendar cal = Calendar.getInstance(); cal.set(2019,12,31); System.out.println(cal.get(Calendar.YEAR));//2020 Calendar 或 Date 使用时一定要注意文档 名字游戏 Map map1 = new IdentityHashMap<>(); map1.put(new String(\"111\"),\"kk\"); map1.put(new String(\"111\"),\"dd\"); System.out.println(map1.size()); // 2 Map map2 = new IdentityHashMap<>(); map2.put(\"111\",\"kk\"); map2.put(\"111\",\"dd\"); System.out.println(map2.size()); // 1 IdentityHashMap 是基于引用判断两个key是否相等的 Java 语言规范规定了字符串常量会进行复用 会有相同的引用 不生效的绝对值 Math.abs(Integer.MIN_VALUE) * Note that if the argument is equal to the value of * {@link Integer#MIN_VALUE}, the most negative representable * {@code int} value, the result is that same value, which is * negative. 奇葩的排序 Integer[] a = new Integer[100]; Random rnd = new Random(); for (int i = 0; i (){ @Override public int compare(Integer o1, Integer o2) { return o1-o2; } }); System.out.println(Arrays.toString(a)); 打印出来的数组基本是无序的(有序的可能性非常小) 原因在于使用的这个比较器 这个比较器通过减法来实现 在数值比较小的情况下没有 但一旦数组元素极大或极小则会发生溢出 导致结果不正确 类(升级版) 私人领域 class Base { public String name = \"cxk\";} class D extends Base {private String name = \"jntm\";} System.out.println(new D().name); // 无法编译 对于成员变量 通过这种子类权限比父类更小的方式来隐藏 但对于成员方法 这种写法是非法的 违反了LSP 隐藏会带来混乱 李鬼替代了李逵 public class Main { public static void main(String[] args) { } } class String{} 这个程序将无法启动 报错：在类 Main 中找不到 main 方法 原因就是因为这个自定义的 String 避免重用平台类的名字 并且不要复用java.lang中的类名 阴影中的类 class X{ static class Y { String Z = \"Z1\";} static C Y = new C(); } class C {String Z = \"Z2\";} System.out.println(X.Y.Z); // print Z2 当一个变量和一个类型具有相同名字 变量名的优先级更高 无法覆写的方法 package p1; public class Click { public void click(){print();} void print(){ System.out.println(\"print\"); } } package p2; public class Main { public static void main(String[] args) { new Click(){ void click() { System.out.println(\"click\"); } // 无法覆写 }.click(); } } 一个包内私有的方法不能被位于另一个包的某个方法直接覆写 方法遮蔽 import static java.util.Arrays.toString; public class Main { static void print(){System.out.println(toString(new int[]{1,2,3}));} // 编译错误 找不到这样的toString方法 } 编译失败的原因在于本身就属于某个范围的成员的优先级比静态导入的优先级更高 静态导致使用应该十分克制 名字重用 覆写 class Base {public void f(){}} class D {public void f(){}} // 覆写Base.f 隐藏 class Base {public static void f(){}} class D {public static void f(){}} // 隐藏Base.f 重写 class Base { public void f(){} public void f(int i){} // 重载f } 遮蔽 class Base { static String name = \"cxk\"; static void f(){ String name = \"jntm\"; // 变量遮蔽 } } // 经常使用的遮蔽: class Main { private String name; public Main(String name){ this.name = name; } } 遮掩 class Main { static String System; // 遮掩 java.lang.System } 库(升级版) 乒乓 public static synchronized void main(String[] args) { new Thread(()->{ pong(); }).start(); System.out.println(\"ping\"); } static synchronized void pong(){ System.out.println(\"pong\"); } 这段程序ping pong总会按照顺序打印出来 重点就在于main与pong都是同步方法 不会并发执行 反射的污染 Iterator iterator = new HashSet<>().iterator(); Method method = iteraor.getClass().getMethod(\"hasNext\"); System.out.println(method.invoke(iterator)); // IllegalAccessException 原因在于这个迭代器的实际实现类是某个内部类 Java语言规范规定访问位于其他包中的非公共类型的成员是不合法的 这个问题在使用了反射之后 就更加难以发现 吃饭睡觉打豆豆 class Cat { void eat(){ System.out.println(\"eat\"); } void sleep(){ System.out.println(\"sleep\"); } void live(){ new Thread(){ @Override public void run() { while (true){ eat(); sleep(); // 编译错误 } } }.start(); } } 这个类无法通过编译 原因在于Cat的sleep被Thread.sleep 遮蔽了 事实证明 使用Runnable创建线程比继承Thread要更方便 丢失的构造器 class Outer { public class Inner{} } Outer.Inner.class.newInstance(); // NoSuchMethodException: Outer$Inner.() 如果一个类为非静态内部类 那么它的默认构造函数就会变成变成一个携带着隐藏参数的构造器 这个参数就是外围的对象实例 同时 newInstance这个方法现在也已经被废弃了 不推荐使用 应该优先使用静态成员类 hello 不 world String str = \"hello world\"; for (int i = 0; i 这里在write的时候 char被转为int了 write(int) 这个方法只有在遇到\\n的byte表示时才会自动flush 线程中断 Thread.currentThread().interrupt(); System.out.println(Thread.interrupted()); // true System.out.println(Thread.interrupted()); // false Thread.interrupted 会清除中断状态 复杂的初始化 public class Main { private static boolean init = false; static { var t = new Thread(){ @Override public void run() { init = true; } }; t.start(); try { t.join(); } catch (InterruptedException e) { e.printStackTrace(); } } public static synchronized void main(String[] args) { System.out.println(init); } } 这段代码会造成死锁 主线程使用的时候 会对类进行初始化 初始化时 启动了新线程 新线程也会检查类的初始化 接着就卡死在了这里 要让类的初始化尽可能简单 高级 有害的括号 int i = -(2147483648); // 错误：整数太大 2147483648 只能作为一元操作符的右操作数使用 奇怪的关系 long x = Long.MAX_VALUE; double y = (double) Long.MAX_VALUE; long z = Long.MAX_VALUE - 1; x == y; // true y == z; // true x == z; // false == 运算符会进行二进制数据类型提升 也就说如果两个类型不相同 则较低的那个类型会被转换到较高的类型 原生类型的锅 class List{ java.util.List iterator(){ return new ArrayList(); } } List list = new List(); for(String s: list.iterator()){ // 编译错误：不兼容的类型 System.out.println(s); } 原生类型：支持泛型但是没有使用泛型 原因在于原生类型的泛型丢失了 这个时候iterator返回的是ArrayList() 避免编写原生类型 泛型遮蔽 内部类中也可以访问到外部类中的泛型参数 避免这个问题 序列化杀手 HashSet 或者 HashMap 在反序列化的时候会调用对象自身的方法 所以使用这些集合的时候 注意不要让这些集合的元素内部又指向这些集合 否则就会发生一些非预期结果 剪不断理还乱 public class Main { private String name = \"\"; public Main(String name) { this.name = name; } private String name(){return name;} private void run(){ new Main(\"cxk\"){ void print(){ System.out.println(name()); } }.print(); } public static void main(String[] args) { new Main(\"main\").run(); } } 这个程序乍一看会由于调用了Main不存在的print方法无法通过编译 但其实发现他可以访问print方法 重点在于最终打印的出来是main 而非cxk 原因在于私有成员变量是无法被继承的 所以这里调用name方法打印的是main方法里Main传递的main 类常量的编译处理 public class Client { public static void main(String[] args) { System.out.println(Server.one); System.out.println(Server.two); System.out.println(Server.three); } } public class Server { public static final String one = \"1\"; public static final String two = \"2\"; public static final String three = \"3\"; } 这里如果Server被重新编译 会打印出什么？ 答案还是和原来一样 Java 语言规范规定常量在编译时都会直接被转化为常量值 而不会被间接引用 这个时候就算把Server.class 删掉 Client也能正常运行 假随机 打乱数组时用Random是不正确的 使用Collection.shuffle 餐后甜点 int count = 0; for(int =0;i Integer[]array = {3，1，4，1，5，9 }; Arrays.sort(array, new Comparator({ public int compare(Integer i1，Integer i2）{ return i1i1 ?1:O); }); System.out.println(Arrays.tostring(array)); true?false:true == true?false:true MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-24 12:24:17 "},"编程语言/JAVA/JAVA编程规范.html":{"url":"编程语言/JAVA/JAVA编程规范.html","title":"JAVA编程规范","keywords":"","body":"JAVA编程规范 编码 Integer缓存问题 【强制】所有整型包装类对象之间值的比较，全部使用 equals 方法比较。 说明：对于 Integer var = ? 在 - 128 至 127 范围内的赋值，Integer 对象是在 IntegerCache.cache 产 生，会复用已有对象，这个区间内的 Integer 值可以直接使用 == 进行判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用 equals 方法进行判断 Integer a = 100, b = 100, c = 150, d = 150; System.out.println(a == b); // true System.out.println(c == d); // false 直接创建包装类时，是通过valueOf方法来进行转换的，但是这个方法这里做了缓存，在某个区间内的同一个整数都会用同一个对象来表示 if (i >= IntegerCache.low && i 所以也就会造成上面那段代码的情况 同样，Long、Character、 Short 、Boolean都有这个问题 但是Boolean本来就取值范围就是true与false，所以这个包装类本身是使用了两个成员变量来缓存true与false 序列化 【强制】当序列化类新增属性时，请不要修改 serialVersionUID 字段，以避免反序列失败；如果完全不兼容升级，避免反序列化混乱，那么请修改 serialVersionUID 值。 说明：注意 serialVersionUID 值不一致会抛出序列化运行时异常。 序列化的目的：持久化、传输 一些序列化方案 原生序列化 Hessian 序列化 跨语言的序列化方案 Kryo 序列化 JSON 序列化 json存在的一个问题是可能存在类型丢失 对象拷贝 【推荐】慎用 Object 的 clone 方法来拷贝对象。 说明：对象 clone 方法默认是浅拷贝，若想实现深拷贝需覆写 clone 方法实现域对象的深度遍历式拷贝。 java天生就对原型模式做了很好的支持，这个支持就是Object中的clone方法 Object 的 clone 函数默认是浅拷贝 分层领域模型的使用 【参考】分层领域模型规约 DO (Data Object): 此对象与数据库表结构一一对应，通过 DAO 层向上传输数据源对象。 DTO (Data Transfer Object): 数据传输对象，Service 或 Manager 向外传输的对象。 BO (Business Object): 业务对象，由 Service 层输出的封装业务逻辑的对象。 AO (Application Object): 应用对象，在 Web 层与 Service 层之间抽象的复用对象模型，极为贴 近展示层，复用度不高。 VO (View Object): 显示层对象，通常是 Web 向模板渲染引擎层传输的对象。Query: 数据查询对象，各层接收上层的查询请求。 注意超过 2 个参数的查询封装，禁止使用 Map 类来传输。 分成这么多层的一个重要原因就是要隔离变更，避免一个层的修改扩散到其他层 贫血模型 贫血模型是指领域对象里只有get和set方法（POJO），所有的业务逻辑都不包含在内而是放在Business Logic层 【参考】不提倡在 DTO 中写逻辑，强制不要在 RPC 返回对象的 DTO 中封装逻辑。 public class xxDTO{ // 各种属性 // 逻辑代码 public boolean canXXX(){ // 各种判断 } } 属性映射 各种领域模型之间的转换是繁琐的 常用的一些工具类库： org.apache.commons.beanutils.BeanUtils#copyProperties org.springframework.beans.BeanUtils#copyProperties(java.lang.Object, java.lang.Object) org.dozer.Mapper#map(java.lang.Object, java.lang.Class) net.sf.cglib.beans.BeanCopier#copy ma.glasnost.orika.MapperFacade#map(S, D) mapstruct 有些是通过反射的方式来进行属性复制，但这样会失去编译期检查的好处，更容易出错 过期处理 接口过时必须加 @Deprecated 注解，并清晰地说明采用的新接口或者新服务是什么。 接口提供方既然明确是过时接口，那么有义务同时提供新的接口；作为调用方来说，有义务去考证过时方法的新实现是什么。 一般来说，加了@Deprecated的接口，必须在该接口的注释上加上替换的新接口并说明废弃原因，变更之后要进行单元测试 空指针 【强制】Object 的 equals 方法容易抛空指针异常，应使用常量或确定有值的对象来调用 equals。 【推荐】防止 NPE，是程序员的基本修养，注意 NPE 产生的场景: 返回类型为基本数据类型，return 包装数据类型的对象时，自动拆箱有可能产生 NPE。 反例:public int f () { return Integer 对象}， 如果为 null，自动解箱抛 NPE。 数据库的查询结果可能为 null。 集合里的元素即使 isNotEmpty，取出的数据元素也可能为 null。 远程调用返回对象时，一律要求进行空指针判断，防止 NPE。 对于 Session 中获取的数据，建议进行 NPE 检查，避免空指针。 级联调用 obj.getA ().getB ().getC (); 一连串调用，易产生 NPE。 【强制】当 switch 括号内的变量类型为 String 并且此变量为外部参数时，必须先进行 null判断 异常类结构层次 java8 switch 支持的表达式 预防 枚举 【参考】枚举类名带上 Enum 后缀，枚举成员名称需要全大写，单词间用下划线隔开。 说明: 枚举其实就是特殊的类，域成员均为常量，且构造方法被默认强制是私有。 【推荐】如果变量值仅在一个固定范围内变化用enum类型来定义。 【强制】二方库里可以定义枚举类型，参数可以使用枚举类型，但是接口返回值不允许使用枚举类型或者包含枚举类型的 POJO 对象。 接口返回值不允许使用枚举类型的原因是如果类库没有及时升级，在反序列化的时候当根据序列化数据序列相应枚举的话很可能找不到相应枚举。从而抛异常 subList与asList 【强制】ArrayList 的 subList 结果不可强转成 ArrayList，否则会抛出 ClassCastException 异 常，即 java.util.RandomAccessSubList cannot be cast to java.util.ArrayList。 【强制】在 SubList 场景中，高度注意对原集合元素的增加或删除，均会导致子列表的遍历、增加、删除产生 ConcurrentModificationException 异常。 【强制】使用工具类 Arrays.asList () 把数组转换成集合时，不能使用其修改集合相关的方法，它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。 两个类的类结构层次 ArrayList的subList方法会返回一个list视图，对这个SubList的修改都会映射到原来的list 而Arrays.asList返回的arrays包下的ArrayList，这个类并没有重写add,remove等方法，所以修改时会抛出异常 注释 【强制】所有类都必须添加创建者和日期。 【强制】所有的枚举类型字段都必须有注释，说明每个数据项的用途。 【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑等修改。 【参考】特殊标记，请注明标记人与标记时间。 注释的目的是让读者更快理解代码的含义 可变参数 【强制】相同参数类型，相同业务含义，才可以使用 Java 的可变参数，避免使用 Object 。说明:可变参数必须放置在参数列表的最后。(提倡同学们尽量不用可变参数编程) 正例: public List listUsers(String type, Long... ids) {...} 为什么要可变参数？ 变长参数适应了不定参数个数的情况，避免了手动构造数组，提高语言的简洁性和代码的灵活性 当可变参数与方法重载出现时，就有些令人混乱，但整体方法参数匹配流程是这样的： 集合去重 【参考】利用 Set 元素唯一的特性，可以快速对一个集合进行去重操作，避免使用 List 的 contains 方法进行遍历、对比、去重操作。 原因：使用list的contains进行去重，时间复杂度为O(N^2) 【强制】关于 hashCode 和 equals 的处理，遵循如下规则: 只要覆写 equals，就必须覆写 hashCode；因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行判断，所以 Set 存储的对象必须覆写这两个方法； 如果自定义对象作为 Map 的键，那么必须覆写 hashCode 和 equals。说明：String 已覆写 hashCode 和 equals 方法，所以我们可以愉快地使用 String 对象作为 key 来使用。 至于这条，则是因为有些数据结构比较两个元素相同时是先进行hashcode比较，然后才是equals 线程池 【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。 实现ThreadFactory接口 newThread方法中传入一个Runnable，可以在创建线程的时候指定线程名字，最后访问这个线程 【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程 创建一个线程耗费的代价是很大的 【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这 样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 线程池处理任务的流程： 如果线程池中小于 corePoolSize 个执行的线程，则新建线程将当前任务作为第一个任务来执行 如果任务成功入队，我们仍然需要 double-check 判断是否需要往线程池中新增线程（因为上次检查后可能有一个已经存在的线程挂了）或者进入这段函数时线程池关闭了 如果不能入队，则创建一个新线程。如果失败，我们就知道线程池已经被关闭或已经饱和就需要调用拒绝策略来拒绝当前任务 为什么不能用Executors？ Execotors的newFixedThreadPool中创建线程池使用的阻塞队列是LinkedBlockingQueue，这个队列是无限大的（int的最大值），这样任务可能会不断入队，从而导致资源耗尽 退出虚拟机 平台相关的一些方法：kill... 调用System.exit方法 所有非守护线程运行完毕 条件语句 表达分支时，如果非要使用 if ()…else if ()…else… 方式表达逻辑，避免后续代码维护困难，不允许超过三层。 如果超过 3 层可以使用卫语句、策略模式、状态模式等来实现。 其中卫语句代码逻辑优先考虑失败、异常、中断、退出等直接返回的情况 卫语句 如果某个条件极其罕见，就应该单独检查该条件，并在条件为真时立即从函数中返回。这样的单独检查常常被称为 “卫语句”。 卫语句要不就从函数中返回，要不就抛出一个异常 if (condition1){ return true; } if (condition2 && condition3){ return false; } //... 异常 【强制】异常不要用来做流程控制，条件控制。 【强制】有 try 块放到了事务代码中，catch 异常后，如果需要回滚事务，一定要注意手动回滚事务。 如果由于 “吞掉” 了接口的异常，有些业务异常中包含的错误原因，无法传给上层再封装给前端，可能会造成出错后用户懵逼 实际开发中，一般都不会吞掉异常，遇到 “吞掉” 异常的场景要慎重思考是否合理 【参考】特别注意循环的代码异常处理的对程序的影响 循环体的代码抛出异常会导致后续的所有代码都无法执行，所以要注意在循环外或者循环内进行捕捉，具体看业务场景 【建议】要理解好受检异常和非受检异常的区别，避免误用 通常开发中自定义的业务异常（BusinessException）属于非受检异常 如果定义的受检异常，则一旦异常发生变更，则依赖该层的所有上层全都要发生变更 【建议】努力使失败保持原子性 对参数进行检查，对不满足的条件抛出适当的异常 【建议】如果忽略异常，请给出理由 日志 【强制】应用中不要直接使用日志系统的 API，而是应该依赖日志架构 SLF4J 中的 API，使用门面模式的日志架构，有利于维护各个类的日志处理方式统一。 【强制】日志至少要保留 15 天，因为有些异常具备以 \"周\" 为频次的特点。 【强制】避免重复打印日志，浪费磁盘空间，务必在 log4j.xml 中设置 additivity =false。 【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。 目的 打印日志的主要目的是为了监测系统状态、方便测试、方便排查问题 slf4j SLF4J 的全称为： The Simple Logging Facade for Java 日志级别 ERROR 日志的使用场景是：影响到程序正常运行或影响到当前请求正常运行的异常情况。比如打开配置失败、调用二方或者三方库抛出异常等 WARN 日志 的使用场景是：不应该出现，但是不影响程序正常运行，不影响请求正常执行的情况。如找不到某个配置但是使用了默认配置，比如某些业务异常 INFO 日志的使用场景是：需要了解的普通信息，比如接口的参数和返回值，异步任务的执行时间和任务内容等 DEBUG 日志的使用场景是：所有调试阶段想了解的信息。比如无法进行远程 DEBUG 时，添加 DEBUG 日志在待研究的函数的某些位置打印参数和中间数据等 TRACE 日志 的使用场景是：非常详细的系统运行信息，比如某个中间件读取配置，启动完成等 【推荐】在自测或提测之后上线前一定要注意 warn 级别以上的日志，特别是 error 日志 ERROR 日志专门输出到一个 error.log 文件。调试时通过 tail -f error.log 随时监控出现的错误日志 日志打印 【强制】在日志输出时，字符串变量之间的拼接使用占位符的方式 因为 String 字符串拼接会使用 StringBuilder 的 append () 方式，有一定的性能损耗。使用占位符可以有效提高性能 【强制】不要用 System.out.println 代替日志框架 该函数底层使用了 java.io.PrintStream#println(java.lang.Object) 内部使用了同步代码块，非常影响性能 【强制】不要打印敏感信息，如果需要打印可以考虑对敏感信息脱敏处理 【推荐】除非业务需要，尽量不要打印大文本 (含富文本)。如果要打印可以截取前 M 个字符 果同步打印大文本日志非常影响性能,很多大文本对排查问题帮助不大，打印该信息的意义不大，因此尽量避免打印该内容或只截取一部分关键信息 该在哪里打印日志 【推荐】用切面或 Filter 在 dubbo 或 Controller 层做切面来打印调用的参数、返回值和响应时间以及捕捉和打印异常日志 【推荐】在依赖的二方或三方接口的参数、返回值和异常处打印日志 【推荐】 在接收消息的地方打印日志 【推荐】 在定时任务的开始和结束的地方 【推荐】 在异步任务的开始和结束的地方 【推荐】面向测试打印日志 在没有日志的情况下排查问题 Alibaba Java 诊断利器 Arthas 启动之后可以监控某个JAVA进程的返回值、抛出的异常、入参等 错误的日志形式 e.printStackTrace() 参数类型错误导致占位符不生效 打印导致的空指针异常 单元测试 单元测试与集成测试 集成测试运行通常更慢，很难编写，很难做到自动化，需要配置，通常一次测试的东西过多，并且集成测试会使用真实的依赖，而单元测试则把被测试的单元和其依赖隔离，以保证单元测试的高度稳定，还可以轻易控制和模拟被测试单元的行为方面 重要性 更早发现BUG 重构时有保障 方法 单元测试的传统方法 测试驱动开发（Test-Driven Development, TDD） 优秀的单元测试 被检验的函数或类的逻辑行为满足预期功能 AIR 原则 自动执行 保持彼此独立 可以重复执行 编写容易，运行快速 构造数据 手动 半自动 依赖开发工具插件或者外部数据源 自动 java-faker 和 easy-random java-faker 能生成具体有意义的字符串 easy-random easy-random 可以轻松构造复杂对象，支持定义对象中集合长度，字符串长度范围，生成集合等 对哪些代码写单测 数据访问层 一般要设置自动回滚。除此之外，还可以整合H2等内存数据库来对数据访问层代码进行测试 服务层 一般要依赖 mock 工具，将服务的所有依赖都 mock 掉 工具类 因为工具类一般在服务内共用，如果有 BUG，影响面很大，很容易造成线上问题或故障。一般需要构造正常和边界值两种类型的用例，对工具类进行全面的测试，才可放心使用 单元测试的结构 准备阶段（Given） 主要负责创建测试数据、构造mock 方法的返回值，准备环节的编码是单元测试最复杂的部分。需要注意的是 Mockito 库中以 when 开头的函数其实是在准备阶段 执行阶段（When） 一般只是调用测试的函数，此部分代码通常较短 验证阶段（Then） 通常验证测试函数的执行的结果、 准备阶段 mock 函数的调用次数等是否符合预期 命名 不要将太多描述放到测试函数命名中，应该放到函数的注释中 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-16 08:33:48 "},"编程语言/JAVA/高级/常用API.html":{"url":"编程语言/JAVA/高级/常用API.html","title":"常用API","keywords":"","body":"常用API Scanner Scanner scanner = new Scanner(System.in); int a = scanner.nextInt(); int b = scanner.nextInt(); System.out.println(\"max:\" + (a > b ? a : b)); Random Random random = new Random(); System.out.println(random.nextInt()); 基本类型与相对应的包装类型 基本类型 基本类型包装类 byte Byte short Short int Integer long Long ﬂoat Float double Double char Character boolean Boolean String 特点： 字符串不变：字符串的值在创建后不能被更改。 String内部是实现byte数组实现的 因为String对象是不可变的，所以它们可以被共享。 StringBuilder 线程不安全(效率更高) StringBuffer 线程安全 乱码问题 Arrays 常用方法： toString sort asList Math abs：取绝对值 ceil：返回大于等于参数的小的整数（向上取整） floor：返回小于等于参数大的整数（向下取整） roud：四舍五入 Object toString equals hashCode wait notify LocalDateTime LocalDateTime.now() System currentTimeMillis arraycopy StringBuilder StringBuilder sb = new StringBuilder(\"hello\"); sb.append(\" \") .append(\"world\"); System.out.println(sb.toString()); 包装类 装箱拆箱 自动装箱拆箱 选择包装类还是基本数据类型： POJO类属性全部使用包装类 RPC方法参数与返回值全部使用包装类 局部变量尽可能使用基本类型 基本类型与字符串的转换 System.out.println(Double.toString(1.6)); System.out.println(Double.parseDouble(\"1.5\")); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-16 07:35:24 "},"编程语言/JAVA/高级/继承与多态.html":{"url":"编程语言/JAVA/高级/继承与多态.html","title":"继承与多态","keywords":"","body":"继承与多态 类的定义 先定义变量 后定义方法 公有方法 保护方法 私有方法 getter/setter方法 继承 就是子类继承父类的属性和行为，使得子类对象具有与父类相同的属性、相同的行为。子类可以直接 访问父类中的非私有的属性和行为。 class 父类 { ... } class 子类 extends 父类 { ... } 继承后的特点 成员变量 成员方法 构造方法 super与this super ：代表父类的存储空间标识(可以理解为父亲的引用)。 this ：代表当前对象的引用(谁调用就代表谁)。 子类默认的空构造方法默认调用super(), 也就是父类的默认构造函数, 如果父类没有无参构造函数, 则编译会出错. 这个时候需要手动调用父类的构造函数() class Father{ public Father(int i) {} } class Son extends Father{ public Son(){ super(1); } } 如果用this()或者super() 调用构造器, 则必须在构造函数内的第一行调用(必须保证父类在子类之前初始化) 特点 单继承 多层继承 抽象类 抽象方法 ： 没有方法体的方法。 抽象类：包含抽象方法的类。 public abstract class Animal { public abstract void run()； } 接口 接口，是Java语言中一种引用类型，是方法的集合，如果说类的内部封装了成员变量、构造方法和成员方法，那么 接口的内部主要就是封装了方法，包含抽象方法（JDK 7及以前），默认方法和静态方法（JDK 8），私有方法 （JDK 9） public interface 接口名称 { // 抽象方法 // 默认方法 // 静态方法 // 私有方法 } class 类名 implements 接口名 { // 重写接口中抽象方法【必须 // 重写接口中默认方法【可选】 } 默认方法 public interface LiveAble { public default void fly(){ System.out.println(\"天上飞\"); } } 静态方法 public interface LiveAble { public static void run(){ System.out.println(\"跑起来~~~\"); } } 私有方法 私有方法：只有默认方法可以调用。 私有静态方法：默认方法和静态方法可以调用。 多实现 class 类名 [extends 父类名] implements 接口名1,接口名2,接口名3... { // 重写接口中抽象方法【必须】 // 重写接口中默认方法【不重名时可选】 } 如果默认方法有重名的，必须重写一次。 抽象类与接口 抽象类是is-a关系, 是模板式设计 接口是 can-do关系, 是契约式设计 优先定义接口, 避免直接使用继承 多态 父类类型 变量名 = new 子类对象； 变量名.方法名(); 多态的好处 final关键字 修饰类 修饰方法 修饰局部变量 修饰成员变量 访问权限控制 不允许从外部创建对象时 使用private修饰构造方法 工具类不允许有public 或 default 构造器 成员变量非static 需要与子类共享 必须为protected 成员变量非static 仅在内部使用 使用private static成员变量 仅在内部使用 使用 private 定义static成员变量时 考虑加final修饰 成员方法 仅在内部使用 使用private 成员方法仅对继承类公开 使用 protected MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-15 02:50:40 "},"编程语言/JAVA/高级/嵌套类.html":{"url":"编程语言/JAVA/高级/嵌套类.html","title":"嵌套类","keywords":"","body":"嵌套类 静态嵌套类，类前面有static修饰符 非静态嵌套类，又称内部类 普通内部类 局部内部类 匿名内部类 public class Main { // 静态嵌套类 static class Inner1{ } /* 包内静态内部类的好处： 1. 作用域不会扩散到包外 2. 可使用 外部类.内部类 方式直接访问 3. 内部类可以直接访问所有静态属性及方法 */ // 普通内部类 class Inner2{} public void f(){ // 局部内部类 class Inner3{} // 匿名内部类 new Object(){}; } } 使用理由 细粒度访问控制 避免过多类定义 匿名内部类 没有正式类名 没有构造函数 可以继承、改写、增加父类的方法 不能定义静态成员（静态常量除外） 可以访问外部类的成员 局部内部类 编译后名称：外部类名+$+序号+内部类名 可以继承其他类，或者实现其他接口 非静态的类，不能包含静态成员(变量和方法)，除了常量 可以访问外部包围类的成员 如果定义在静态方法中，只能访问包围类的静态成员 局部内部类不能是一个接口，即接口不能定义在代码块中 普通内部类 编译后名称：外部类名+$+内部类名 可以继承其他类，或者实现其他接口 可以用private/package private(不写)/protected/public控制外界访问 非静态的类，不能包含静态变量/方法，除了常量 和外部包围类的实例相关，一个普通内部类实例肯定是在一个外部包围类的实例中，且可以访问外部包围类的所有成员 在第三方类中，需要先创建外部包围类实例，才能创建普通内部 类的实例，不允许单独的普通内部类对象存在！！！ 静态嵌套类 需要加修饰符static 可以定义静态成员和非静态成员 不能直接访问包围类的非静态成员，可直接访问包围类的静态成员 可通过包围类的对象进行访问非静态成员 外界可以通过静态嵌套类名访问其静态成员，通过对象访问其非静态成员 外界需要通过包围类才可以访问到静态嵌套类，并创建其对象，不需要外部包围类的实例 对比 变量遮蔽 以离得近作为优先原则 优先级高的变量会遮蔽优先级低的变量 外部包围类.this.变量名，可以访问到外部包围类的成员变量 静态嵌套类不能访问非静态变量 Java 7及以前，匿名内部类和局部内部类只能访问外部包围类的final成员变量 Java 8及以后，匿名内部类和局部内部类可访问外部包围类的final成员变量和 事实意义上的final变量(effectively final, 一个变量定值后，再也没有改过值) 应用 匿名内部类 无需类名，用过即焚，使用广泛 该类的对象只要一个，且方法只有一个，代码短 Android中常用匿名内部类 局部内部类 定义在方法体内，只能在当前方法内使用，代码短 使用较少 介于匿名内部类和普通内部类之间 迭代器 普通内部类 广泛使用在具有母子结构的类，内部类对象和外围类保持联系 如Map和Map.Entry，ZipFile和ZipFile.ZipEntryIterator等 静态嵌套类 和外围类没有太多的联系 节省普通内部类和外围类的联系开销 使得外围类对象更容易被垃圾回收器回收 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-15 02:27:09 "},"编程语言/JAVA/高级/集合.html":{"url":"编程语言/JAVA/高级/集合.html","title":"集合","keywords":"","body":"集合 集合是java中提供的一种容器，可以用来存储多个数据 List 存储一组不唯一（可以有多个元素引用相同的对象），有序的对象 Set 不允许重复的集合。不会有多个元素引用相同的对象 Queue 被设计用来可以以某种优先级处理元素的集合 Map 使用键值对存储。Map会维护与Key有关联的值 Iterator迭代器 Iterator it = coll.iterator(); while(it.hasNext()){ //判断是否有迭代元素 String s = it.next();//获取迭代出的元素 System.out.println(s); } List List 集合的遍历结果是稳定的 ArrayList 非线程安全 内部使用数组 快速随机访问 插入删除慢 LinkedList 本质双向链表 插入删除快 随机访问慢 内存利用率较高 常用方法 public void add(int index, E element) : 将指定的元素，添加到该集合中的指定位置上。 - public E get(int index) :返回集合中指定位置的元素。 public E remove(int index) : 移除列表中指定位置的元素, 返回的是被移除的元素。 public E set(int index, E element) :用指定元素替换集合中指定位置的元素,返回值的更新前的元素 Queue FIFO 阻塞队列阻塞的特性与FIFO结合 适合做Buffer Map集合 常用子类 在任何Map中 都要避免KV设置为null HashMap 并发场景下 数据丢失 死链问题：并发情况下链表修改导致的不一致问题 ConcurrentHashMap JDK11后取消了分段锁机制 引入了红黑树结构 put remove size等操作都是用了CAS LinkedHashMap TreeMap key有序 基于红黑树实现 并非一定要覆写hashCode与equals 其内部元素时通过Comparable与Comparator来实现key去重排序的 常用方法 public V put(K key, V value) : 把指定的键与指定的值添加到Map集合中。 public V remove(Object key) : 把指定的键 所对应的键值对元素 在Map集合中删除，返回被删除元素的 值。 public V get(Object key) 根据指定的键，在Map集合中获取对应的值。 public Set keySet() : 获取Map集合中所有的键，存储到Set集合中。 public Set> entrySet() : 获取到Map集合中所有的键值对对象的集合(Set集合)。 Set集合 不允许出现重复 HashSet 底层使用hashmap 存储自定义类型元素时，需要重写对象中的hashCode和equals方法 TreeSet 底层使用TreeMap 保证Key有序 LinkedHashSet 有序的哈希集合 Collections 工具类 public static boolean addAll(Collection c, T... elements) :往集合中添加一些元素。 public static void shuffle(List list) 打乱顺序 :打乱集合顺序。 public static void sort(List list) :将集合中元素按照默认规则排序。 public static void sort(List list，Comparator ) :将集合中元素按照指定规则排序 集合初始化 ArrayList的初始值为10 每次扩容以1.5倍的速度进行扩容 HashMap的初始值为16 每次扩容以2的幂进行扩容 这样如果存放在集合的元素比较多 就会造成不断扩容 影响性能 所以集合初始化时应该指定好默认值 数组与集合 new int[-1]; // 运行时异常：NegativeArraySizeException：-1 数组遍历优先使用foreach方式 数组转集合 注意转集合的过程中是否使用了视图的方式： Arrays.asList(...)这个方法返回了一个不可变的ArrayList（Arrays的内部类）,不能进行修改操作 否则会抛出异常 集合转数组 Object[] objects = list.toArray();// 泛型丢失 String[] arr1 = new String[2]; list.toArray(arr1); // arr1为[null,null] String[] arr2 = new String[3]; list.toArray(arr2); // arr2为[1,2,3] 当toArray传入的数组容量比size小时 该方法就会弃用这个数组 而是自己创建一个数组返回 当数组容量等于size时 运行时最快的,空间效率也是最高的 集合与泛型 //第一段:泛型出现之前的集合定义方式 List al = new ArrayList(); al.add (new Object()); al.add (new Integer(111)); al.add(new String(\"hello alal\")); //第二段:把a1引用赋值给a2，注意a2与al的区别是增加了泛型限制 List a2 = al; a2.add (new Object()); a2.add (new Integer(222)); a2.add(new String(\"hello a2a2\")）; //第三段:把a1引用赋值给a3，注意a3与al的区别是增加了泛型 List a3 = al; a3.add(new Integer (333)）; 下方两行编译出错，不允许增加非Integer类型进入集合 a3.add(new object()); a3.add(new String(\"hello a3a3\")); //第四段:把a1引用赋值给a4，al与a4的区别是增加了通配符 Lista4 = al; //允许副除和清除元素 al.remove(O); a4.clear(); // 编译出错。不允许增加任何元素 a4.add (new Object()); put功能受限 ?只能是T及T的子类型 get 功能受限 ?只能是T及T的父类型 元素的比较 Comparable和Comparator两个接口的区别： Comparable：自己与别人比较 Comparator：第三方比较两个对象 hashCode 与 equals 通过哈希将数据分散开来 equals相等 则hashCode必须相等 覆写equals 必须覆写hashCode // HashMap 判断两个key是否相等 if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) 快速失败机制 当前线程维护一个expectedModCount 遍历之前这个值等于modCount 如果在遍历的过程中发现 expectedModCount != modCount 就代表集合被别的线程修改了 这时候会跑出一个ConcurrentModificationException 这个时候得使用迭代器来实现在遍历中修改集合的功能 并发集合都是使用快速失败机制实现的 集合修改与遍历没有任何关系 但这种机制会导致读取不到最新的数据 也是CAP理论中 A与P的矛盾 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-23 05:40:12 "},"编程语言/JAVA/高级/异常.html":{"url":"编程语言/JAVA/高级/异常.html","title":"异常","keywords":"","body":"异常 指的是程序在执行过程中，出现的非正常的情况，终会导致JVM的非正常停止 异常体系 Error（错误）:是程序无法处理的错误，表示运行应用程序中较严重问题 Exception（异常）:是程序本身可以处理的异常 分类 编译时期异常:checked异常。在编译时期,就会检查,如果没有处理异常,则编译失败。(如日期格式化异常) 无能为力,引起注意类型的异常 此类异常需要完整保存异常现场 供事后排查 可以处理的异常 如未授权异常 运行时期异常:runtime异常。在运行时期,检查异常.在编译时期,运行异常不会编译器检测(不报错)。(如数学异常) 可预测异常 应在编码时注意边界条件 空指针判断等来避免 需要捕获的异常 如超时异常 可以进行降级或者重试 可忽略异常 对于某些异常 框架或者系统会自行处理 这类异常可以不用管 使用 try{ // do something }catch (Throwable t){ t.printStackTrace(); throw new RuntimeException(t); }finally { // resource recycle /*以下情况finally不会执行 前面的代码中用了 System.exit(int)已退出程序 try代码块出现了死循环或者死锁 CPU关闭 */ } 注意事项 多个异常一次捕获多次处理 运行时异常被抛出可以不处理。即不捕获也不声明抛出。 如果ﬁnally有return语句,永远返回ﬁnally中的结果,避免该情况、 如果父类抛出了多个异常,子类重写父类方法时,抛出和父类相同的异常或者是父类异常的子类或者不抛出异 常。 父类方法没有抛出异常，子类重写父类该方法时也不可抛出异常。此时子类产生该异常，只能捕获处理，不 能声明抛出 关于系统设计中的异常 远程服务调用应该使用result对象来封装错误码与描述 主要是因为： 防止调用方没有捕获 异常对调用方的帮助不会很大 基于防御式编程, 服务提供方可以返回null, 调用方要进行事先判断 防止NPE MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-19 03:18:59 "},"编程语言/JAVA/高级/日志.html":{"url":"编程语言/JAVA/高级/日志.html","title":"日志","keywords":"","body":"日志 记录操作 监控系统 回溯故障 日志规范 文件命名：appName_logType_logName.log 日志文件的保存时间衡量因素： 重要程度 文件大小 磁盘空间 日志级别： DEBUG 对调试有帮助的信息 INFO 未发生错误 但对其他错误排查有指导作用 WARN 偏向于此处有出现错误的可能 ERROR 发生了错误需要被关注 但没有影响系统运行 FATAL 严重错误 程序中断 日志使用 预先判断日志级别 避免使用字符串的形式连接打印日志 log.debug(\"user \" + id + \"create new order \" + orderId) // bad if (log.enableDebug){ // good log.debug(...) } log.debug('user {} create new order {}', id, orderId) // good 主要是防止无谓的字符串连接消耗系统资源 避免无效日志打印 对于debug log 等低级别的日志 一定要控制好输出量 避免磁盘空间被快速吞掉 区别对待错误日志 不能将所有错误一股脑归类为ERROR级别 ERROR级别就代表是需要人工介入处理的级别 日志记录的内容 一定要输出异常堆栈 输出对象实例时 要确保对象重写了 toString 方法 日志框架 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-19 03:54:17 "},"编程语言/JAVA/高级/IO.html":{"url":"编程语言/JAVA/高级/IO.html","title":"IO","keywords":"","body":"IO BIO (Blocking I/O): 同步阻塞 I/O 模式，数据的读取写入必须阻塞在一个线程内等待其完成 NIO (Non-blocking/New I/O): NIO 是一种同步非阻塞的 I/O 模型,支持面向缓冲的，基于通道的 I/O 操作方法 AIO (Asynchronous I/O):异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作 网络IO模型： 网络框架设计模式： Reactor模式：主动模式 应用程序不断轮询 询问底层IO是否准备就绪 Proactor模式：被动模式 read write都交给底层 通过回调完成操作 服务器网络编程 1 + N + M 模型 1个监听线程 N个IO线程 M个worker线程 架构 大体分为两类： 字节操作流 InputStream 与 OutputStream等 字符操作流 Writer 与 Reader 磁盘IO File 网络操作 Socekt等 字节到字符的转换十分耗时 非常容易出现乱码问题 这是字符流的用处 InputStreamReader 与 OutputStreamWriter 是字节流与字符流之间的桥梁 File类 File并不代表一个真实存在的真实对象 FileDescriptor才是代表一个真实文件对象 从磁盘读取文件： 构造方法 public File(String pathname) ：通过将给定的路径名字符串转换为抽象路径名来创建新的 File实例。 public File(String parent, String child) ：从父路径名字符串和子路径名字符串创建新的 File实例。 public File(File parent, String child) ：从父抽象路径名和子路径名字符串创建新的 File实例 静态成员变量 获取 public String getAbsolutePath() ：返回此File的绝对路径名字符串。 public String getPath() ：将此File转换为路径名字符串。 public String getName() ：返回由此File表示的文件或目录的名称。 public long length() ：返回由此File表示的文件的长度。 判断 public boolean exists() ：此File表示的文件或目录是否实际存在。 public boolean isDirectory() ：此File表示的是否为目录。 public boolean isFile() ：此File表示的是否为文件。 创建删除 public boolean createNewFile() ：当且仅当具有该名称的文件尚不存在时，创建一个新的空文件。 public boolean delete() ：删除由此File表示的文件或目录。 public boolean mkdir() ：创建由此File表示的目录。 public boolean mkdirs() ：创建由此File表示的目录，包括任何必需但不存在的父目录。 目录遍历 public String[] list() ：返回一个String数组，表示该File目录中的所有子文件或目录。 public File[] listFiles() ：返回一个File数组，表示该File目录中的所有的子文件或目录。 文件过滤器 FileFilter FileNameFilter IO 顶级父类 - 输入流 输出流 字节流 字节输入流 InputStream 字节输出流 OutputStream 字符流 字符输入流 Reader 字符输出流 Writer 字节输出流【OutputStream】 public void close() ：关闭此输出流并释放与此流相关联的任何系统资源。 public void flush() ：刷新此输出流并强制任何缓冲的输出字节被写出。 public void write(byte[] b) ：将 b.length字节从指定的字节数组写入此输出流。 public void write(byte[] b, int off, int len) ：从指定的字节数组写入 len字节，从偏移量 oﬀ开始输 出到此输出流。 public abstract void write(int b) ：将指定的字节输出流。 FileOutputStream FileOutputStream fos = new FileOutputStream(\"fos.txt\"); for (int i =0;i 数据追加续写 FileOutputStream fos = new FileOutputStream(\"fos.txt\",true); 字节输入流【InputStream】 public void close() ：关闭此输入流并释放与此流相关联的任何系统资源。 public abstract int read() ： 从输入流读取数据的下一个字节。 public int read(byte[] b) ： 从输入流中读取一些字节数，并将它们存储到字节数组 b中 。 FileInputStream 构造方法 FileInputStream(File file) ： 通过打开与实际文件的连接来创建一个 FileInputStream ，该文件由文件系 统中的 File对象 ﬁle命名。 FileInputStream(String name) ： 通过打开与实际文件的连接来创建一个 FileInputStream ，该文件由文件 系统中的路径名 name命名。 FileInputStream fis = new FileInputStream(\"fos.txt\"); int c = -1; while ((c = fis.read()) != -1) { System.out.print((char)c); } fis.close(); 字符流 Reader public void close() ：关闭此流并释放与此流相关联的任何系统资源。 public int read() ： 从输入流读取一个字符。 public int read(char[] cbuf) ： 从输入流中读取一些字符，并将它们存储到字符数组 cbuf中 。 FileReader FileReader reader = new FileReader(\"fos.txt\"); int c = -1; while ((c = reader.read()) != -1){ System.out.print((char)c); } Writer void write(int c) 写入单个字符。 void write(char[] cbuf) 写入字符数组。 abstract void write(char[] cbuf, int off, int len) 写入字符数组的某一部分,oﬀ数组的开始索引,len 写的字符个数。 void write(String str) 写入字符串。 void write(String str, int off, int len) 写入字符串的某一部分,oﬀ字符串的开始索引,len写的字符个 数。 void flush() 刷新该流的缓冲。 void close() 关闭此流，但要先刷新它。 FileWriter FileWriter writer = new FileWriter(\"fos.txt\"); writer.append(\"hh种\"); writer.flush(); writer.close(); flush与close的区别 JDK7中IO的异常处理 // JDK7 try (FileWriter writer = new FileWriter(\"fos.txt\")) { writer.append(\"hh种\"); writer.flush(); } catch (IOException e) { e.printStackTrace(); } // JDK9 FileWriter writer = new FileWriter(\"fos.txt\"); try (writer) { writer.append(\"hh种\"); writer.flush(); } catch (IOException e) { e.printStackTrace(); } Properties public Object setProperty(String key, String value) ： 保存一对属性。 public String getProperty(String key) ：使用此属性列表中指定的键搜索属性值。 public Set stringPropertyNames() ：所有键的名称的集合。 与流相关的方法 store load 缓冲流 字节缓冲流： BufferedInputStream ， BufferedOutputStream 字符缓冲流： BufferedReader ， BufferedWriter 编码 字符编码 Character Encoding : 就是一套自然语言的字符与二进制数之间的对应规则。 字符集 Charset ：也叫编码表。是一个系统支持的所有字符的集合，包括各国家文字、标点符号、图形符 号、数字等。 常用编码 ASCII 码 使用7bit来表示 范围从0-127 ISO-8859-1 单字节编码 总共能表示256字符 GB2312 双字节编码 GBK 扩展了GB2312 增加了更多的汉字 UTF-16 两个字节表示一个字符 大大简化了字符串操作 是Java内存的存储格式 UTF-8 使用变长存储 不同的字符可以由1~6个字符组成 GBK与GB2312对比：GBK范围更大 UTF8与UTF16对比：16编码效率高 但不适合网络传输 8的容错性比16强 IO 操作中的编解码 InputStreamReader reader = new InputStreamReader(new FileInputStream(\"gbk.txt\"),\"gbk\"); OutputStreamWriter writer = new OutputStreamWriter(new FileOutputStream(\"utf8.txt\"), StandardCharsets.UTF_8); int c = -1; while ((c= reader.read()) != -1){ writer.write(c); } writer.close(); 内存编解码 \"蔡徐坤\".getBytes(\"gbk\"); new String(new byte[]{ -78, -52, -48, -20, -64, -92 },\"gbk\"); String 编码时序图： Web 中的编解码 URL编解码 /页面?name=页面 这个URL被编码成%2f%e9%a1%b5%e9%9d%a2%3fname%3d%e9%a1%b5%e9%9d%a2 不同浏览器的编码可能并不一致 那么服务端是如何解析的？ tomcat中有一个配置： 这个配置就是用来对路径部分进行解码的 至于queryString 要不是body中的charset 要不就是ISO-8859-1 并且如果使用要body的charset的话 需要配置 HTTP header 编解码 对于request.getHeader() 默认是使用的ISO-8859-1编码 且无法指定编码 不要再Header中传递非ASCII 字符 表单编解码 浏览器会根据ContentType的Charset对表单参数进行编码 服务端可以在Servlet容器中获取参数之前调用request.setCharacterEncoding()来指定服务器解码方式 如果没有调用此方法 那么会按照系统默认的编码方式解析 Body 编解码 服务端通过response.setCharacterEncoding来设置 这个方法的本质是设置响应头ContentType 浏览器端按照以下顺序进行解码： ContentType的charset html meta标签的charset属性 浏览器默认方式 js文件编码问题 如果外部引入的js文件与当前html不一致 需要 常见编码问题 序列化 ObjectOutputStream ObjectInputStream ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(\"object\")); oos.writeObject(new Person(\"jav\",15)); ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"object\")); Person p = (Person)ois.readObject(); 序列化的类需要实现 Serializable 接口 最好手动设置 serialVersionUID 的值, 类修改时根据是否兼容来调整这个值 transient关键字修饰的变量不会被序列化 其他方式的序列化： Hessian 效率很高 跨语言 JSON 序列化一些复杂对象： 父类继承Serializable接口 所有子类都可以序列化 子类实现Serializable接口 序列化后父类的属性会丢失 成员变量如果要被序列化 需要实现Serializable接口 否则会报错 反序列化时 成员如果发生修改 则发生修改的这些成员变量数据会丢失 如果 serialVersionUID 被修改 反序列化会失败 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-29 05:20:00 "},"编程语言/JAVA/高级/泛型.html":{"url":"编程语言/JAVA/高级/泛型.html","title":"泛型","keywords":"","body":"泛型 泛型类 泛型接口 泛型方法 关于泛型的几点： 尖括号里的每个元素都代表一种未知类型 尖括号只能出现在类名之后或者方法返回值之前 使用泛型的好处： 类型安全 避免粗心导致的类转换异常 提升代码可读性 编码阶段即可知道对象类型 提升了代码的复用率 泛型类 class Map{ // 修饰成员变量 private K key; // 修饰参数 public Map(K key){} // 修饰返回值 public K get(){ // 修饰局部变量 K key1 = key; return key1; } } 泛型方法 // 声明的是这个方法的泛型参数 后面的T声明的是方法的返回类型 public static T run(T obj){ return obj; } 泛型限定 // 约定T必须是Comparable的子类 // 可同时指定多个父接口 通配符 // 只能接受S的自身或子类 // 能接收S自身及其超类 // 不限制类型，只能使用object接收 PESC原则 上界不能往里存，只能往外取，适合频繁往外面读取内容的场景。 下界不影响往里存，但往外取只能放在Object对象里，适合经常往里面插入数据的场景 泛型擦除 虚拟机中没有泛型，只有普通类和方法 在编译阶段，泛型参数被擦除为限定类型，并进行相关类型转换 虚拟机也会合成桥方法来保持方法多态 补救： 如果想要在运行时获取泛型的类型 那就必须通过某种手段记录泛型的 Class 对象 类型变化关系 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-16 07:21:23 "},"编程语言/JAVA/高级/注解.html":{"url":"编程语言/JAVA/高级/注解.html","title":"注解","keywords":"","body":"注解 编写文档：通过代码里标识的注解生成文档【生成文档doc文档】 代码分析：通过代码里标识的注解对代码进行分析【使用反射】 编译检查：通过代码里标识的注解让编译器能够实现基本的编译检查【Override】 JAVA提供的基本注解 @Override 限定重写父类方法。对于子类中被@Override 修饰的方法，如果存在对应的被重写的父类方法，则正确；如果不存在，则报错。@Override 只能作用于方法，不能作用于其他程序元素 @Deprecated 用于表示某个程序元素（类、方法等）已过时。如果使用了被@Deprecated修饰的类或方法等，编译器会发出警告 @SuppressWarnings 抑制编译器警告 @SafeVarargs 是JDK 7 专门为抑制\"堆污染\"警告提供的 堆污染：简单的说就是当一个泛型类型变量赋值给不是泛型类型变量，这种错误在编译期间能被编译器警告，但是可以忽略，直到运行时报错 @FunctionalIterface @FunctionalInterface就是用来指定某个接口必须是函数式接口，否则就会编译出错 自定义注解 元注解 public @interface 注解名称{ 属性列表; } 属性的返回值类型有下列取值: 基本数据类型 String 枚举 注解 以上类型的数组 元注解 用于注解的注解 @Target：描述注解能够作用的位置 ElementType取值： TYPE：可以作用于类上 METHOD：可以作用于方法上 FIELD：可以作用于成员变量上 ... @Retention：描述注解被保留的阶段 public enum RetentionPolicy { // 保留在源码级别上 SOURCE, //保留在class文件中，jvm无法读取到 CLASS, //会保留到class字节码文件中，并被JVM读取到 RUNTIME } @Documented：描述注解是否被抽取到api文档中 @Inherited：描述注解是否被子类继承 父类的注解将会传递到子类上 @Repeatable：描述是否能重复注解（JDK8之后新增的功能） 实现细节：通过一个注解容器 注解的解析 RetentionPolicy.RUNTIME ：注解在class文件中，被JVM加载，可用反射解析注解 RetentionPolicy.CLASS:注解在class文件中，但JVM没有加载，只能采用字节码工具进行特殊处理 RetentionPolicy.SOURCE ：注解在java文件中，不在class文件中，也不会被JVM加载 只有在源码级别进行注解处理 Java提供注解处理器来解析带注解的源码，产生新的文件 RUNTIME注解本质 继承Annotation接口的一个接口 实际使用中有一个代理对象实现了此接口 代理对象使用AnnotationInvocationHandler处理方法调用 AnnotationInvocationHandler使用一个map存储属性 应用 Servlet3.0 Junit Spring & Spring boot Lombok MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-04 01:22:35 "},"编程语言/JAVA/高级/反射.html":{"url":"编程语言/JAVA/高级/反射.html","title":"反射","keywords":"","body":"反射 JAVA反射机制是在运行状态中，对于任意一个实体类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制 框架 好处： 可以在程序运行过程中，操作这些对象。 可以解耦，提高程序的可扩展性。 使用反射创建对象 String s = String.class.getConstructor(String.class).newInstance(\"str\"); 关键类 应用 加载JDBC驱动 任意类型数组扩容 动态方法调用 JSON序列化与反序列化 Servlet创建 ORM Bean容器 JAVA反射增强 org.reflections 功能 get all subtypes of some type get all types/members annotated with some annotation get all resources matching a regular expression get all methods with specific signature including parameters, parameter annotations and return type MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-04 01:35:57 "},"编程语言/JAVA/JAVA并发编程/JAVA并发编程.html":{"url":"编程语言/JAVA/JAVA并发编程/JAVA并发编程.html","title":"Java 并发编程","keywords":"","body":"并发编程 并发：指两个或多个事件在同一个时间段内发生。 并行：指两个或多个事件在同一时刻发生（同时发生）。 线程安全性 超线程：一个ALU对应多个PC 当多个线程访问某个类时，这个类始终都能表现出正确的行为，则称这个类是线程安全的 线程安全问题都是由全局变量及静态变量引起的。若每个线程中对全局变量、静态变量只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步， 否则的话就可能影响线程安全。 无状态对象一定是线程安全的 JAVA API中的线程安全问题 StringBuffer Vector 原子性 if (condition){ a++; // 当此段代码运行在多线程的环境时，则会产生线程安全问题 } 并发程序的特点： 线程之间相互制约的关系 线程执行过程需要上下文切换　断断续续的 并发数设置合理时(以CPU)　才会提高并发程序的性能 观察结果的失效就是大多数竞态条件的本质 一种常见的竞态条件发生在单例构造模式中： public static Object get(){ if (instance == null){ instance = new Object(); } return instance; } 复合操作：由一系列原子操作构成 锁 非阻塞同步 互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步 悲观的并发策略：认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁 乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施 悲观锁 乐观锁 乐观锁 总是认为不会产生并发问题，每次去取数据的时候总认为不会有其他线程对数据进行修改，因此不会上锁，但是在更新时会判断其他线程在这之前有没有对数据进行修改，一般会使用版本号机制或CAS操作实现 update table set x=x+1, version=version+1 where id=${id} and version=${version}; 悲观锁 总是假设最坏的情况，每次取数据时都认为其他线程会修改，所以都会加锁（读锁、写锁、行锁等），当其他线程想要访问数据时，都需要阻塞挂起 synchronized是悲观锁 自旋锁 线程反复检查锁变量是否可用。由于线程在这一过程中保持执行，因此是一种忙等待 分布式锁 zookeeper与redis实现 线程间通信 等待-唤醒机制 要注意，wait() notify() notifyAll()都需要在synchronized中 wait() 会释放锁，sleep() 不会 Object object = new Object(); new Thread(){ @Override public void run() { synchronized (object){ System.out.println(\"要5个包子\"); // 进入等待，这时候锁会被释放 try { object.wait(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"得到了5个包子\"); } } }.start(); new Thread(){ @Override public void run() { try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (object){ System.out.println(\"包子生产完毕，告诉顾客\"); // 通知等待线程中的任意一个 object.notify(); } } }.start(); wait与notify一定要在线程同步中使用,并且是同一个锁的资源 在调用sleep()方法的过程中，线程不会释放对象锁 对象的共享 发布: 使对象能在当前代码作用域之外使用 逸出: 某个不该发布的对象被发布了 线程封闭 某个对象只能在线程之内使用 Ad-hoc线程封闭 完全由程序承担，很脆弱 栈封闭 对象只能在局部（方法内）使用 不变性 不可变对象一定是线程安全的 对象创建后其状态就不能修改 对象的所有域都是final 在对象创建的过程中this引用没有逸出 安全发布 在静态初始化函数中初始化一个对象的引用 将对象的引用保存到volatile类型的域或者 Reference对象 将对象的引用保存到正确初始化的对象的final域 将对象的引用保存到由锁保护的域 对象的组合 依赖状态的操作：某个操作包含有基于状态的先验操作 if (a== 1){ a++; } 实例封闭 将线程不安全的对象封装在某个进行良好并发控制的对象内 客户端加锁 private Object obj = new Object(); ... synchronized(obj){ obj.xxx(); } 基础构建模块 JAVA5后自带了很多有关并发编程的类库 同步容器类 迭代器与ConcurrentModificationException 当在迭代的时候，容器元素发生了修改，则会抛出这个异常 执行策略 什么线程 什么顺序 多少任务执行 多少任务等待 如何放弃以及通知放弃 任务执行前操作 取消与关闭 取消策略 通常，使用中断来取消是最合理的方式 class MyThread extends Thread{ @Override public void run() { while(!isInterrupted()){ System.out.println(\"running\"); try { Thread.sleep(1000); } catch (InterruptedException e) { break; } } System.out.println(\"my thread done\"); } } 使用Future取消 Future future = service.submit(() -> { try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } return Math.random(); }); try { Double ret = future.get(3, TimeUnit.SECONDS); System.out.println(\"result\"+ret); } catch (ExecutionException | TimeoutException e) { e.printStackTrace(); }finally { future.cancel(true); System.out.println(\"task cancel\"); } 处理不可中断的阻塞 由于如IO等的资源一旦阻塞就无法进行中断，所以可对其做关闭处理来模拟中断 停止基于线程的服务 使用生命周期管理ExecutorService 毒药对象 本质上就是一个flag，当队列读取到这个毒药时，就会停止相关操作 处理非正常的线程终止 hread.setDefaultUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() { @Override public void uncaughtException(Thread t, Throwable e) { System.out.println(t + \"something happen\" + e); } }); new Thread(){ @Override public void run() { throw new RuntimeException(\"aaaa\"); } }.start(); JVM关闭钩子 Runtime.getRuntime().addShutdownHook(new Thread(){ @Override public void run() { System.out.println(\"jvm shutdown\"); } }); 活跃性危险 死锁 静态顺序死锁 动态顺序死锁 资源死锁 死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。 诊断与避免 定时锁 获取-超时-退出 其他活跃性危险 饥饿 无法获取到需要的资源 响应性慢 活锁 线程不断重复某个操作 性能与伸缩性 引入线程的开销 上下文切换 内存同步 阻塞 如何减少锁的竞争 缩小锁的范围 缩小synchronized关键字包围的代码块 减小锁的粒度 不同的操作使用不同的锁 分段锁 替代独占锁 采取读写锁 并发程序测试 正确性测试 安全性测试 性能测试 性能测试陷阱 垃圾回收 动态编译（JIT） 编译优化 竞争程度 锁优化 自旋锁与自适应自旋 是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态 自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，如果等待时间比较短，自旋还是很划算的 自旋超过一定的阈值就不会再继续重试，自适应自旋则代表这个阈值不是固定的，会根据性能监控情况动态调整 锁消除 对于被检测出不可能存在竞争的共享数据的锁进行消除 锁细化 经历缩小锁的作用范围 锁粗化 如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗 如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部 synchronized(obj){ //... } synchronized(obj){ //... } synchronized(obj){ //... } synchronized(obj){ //... //.. //... } 轻量级锁 轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销 偏向锁 偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要 并发编程良好实践 给线程起名字 缩小同步范围 多用同步工具少用原始的wait,notify 使用阻塞队列 多用 ConcurrentHashMap 而不是 Hashtable 使用栈封闭以及不变性保证线程安全 使用线程池 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-11 01:59:06 "},"编程语言/JAVA/JAVA并发编程/leetcode.html":{"url":"编程语言/JAVA/JAVA并发编程/leetcode.html","title":"leetcode","keywords":"","body":"多线程-leetcode 按序打印 解法1 CountDownLatch class Foo { private CountDownLatch latch2 = new CountDownLatch(1); private CountDownLatch latch3 = new CountDownLatch(1); public Foo() { } public void first(Runnable printFirst) throws InterruptedException { // printFirst.run() outputs \"first\". Do not change or remove this line. printFirst.run(); latch2.countDown(); } public void second(Runnable printSecond) throws InterruptedException { latch2.await(); // printSecond.run() outputs \"second\". Do not change or remove this line. printSecond.run(); latch3.countDown(); } public void third(Runnable printThird) throws InterruptedException { latch3.await(); // printThird.run() outputs \"third\". Do not change or remove this line. printThird.run(); } } 交替打印FooBar https://leetcode-cn.com/problems/print-foobar-alternately/ 自旋 class FooBar { private int n; private volatile boolean f = false; public FooBar(int n) { this.n = n; } public void foo(Runnable printFoo) throws InterruptedException { for (int i = 0; i 打印零与奇偶数 https://leetcode-cn.com/problems/print-zero-even-odd/submissions/ class ZeroEvenOdd { private final int n; private volatile int i =1; private volatile int f= 0; public ZeroEvenOdd(int n) { this.n = n; } // printNumber.accept(x) outputs \"x\", where x is an integer. public void zero(IntConsumer printNumber) throws InterruptedException { while(true){ while(f != 0){ Thread.yield(); if (i>n){ return; } } printNumber.accept(0); if (i%2==1){ f=1; }else{ f=2; } } } public void odd(IntConsumer printNumber) throws InterruptedException { while(true){ while(f != 1){ Thread.yield(); if (i>n){ return; } } printNumber.accept(i++); f=0; } } public void even(IntConsumer printNumber) throws InterruptedException { while(true){ while(f != 2){ Thread.yield(); if (i>n){ return; } } printNumber.accept(i++); f=0; } } } H20生成 https://leetcode-cn.com/problems/building-h2o/submissions/ class H2O { private CyclicBarrier barrier; volatile boolean f = false; public H2O() { barrier = new CyclicBarrier(2,new Runnable(){ public void run(){setF(false);} }); } private void setF(boolean val){ f = val; } public void hydrogen(Runnable releaseHydrogen) throws InterruptedException { // releaseHydrogen.run() outputs \"H\". Do not change or remove this line. while(!f){Thread.yield();} releaseHydrogen.run(); try { barrier.await(); }catch(Exception e){ throw new RuntimeException(e); } } public void oxygen(Runnable releaseOxygen) throws InterruptedException { while(f){Thread.yield();} // releaseOxygen.run() outputs \"O\". Do not change or remove this line. releaseOxygen.run(); f= true; } } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-21 08:50:33 "},"编程语言/JAVA/JAVA并发编程/基础概念.html":{"url":"编程语言/JAVA/JAVA并发编程/基础概念.html","title":"基础概念","keywords":"","body":"基础概念 进程与线程 进程是所有线程的集合，每一个线程是进程中的一条执行路径 线程分类 用户线程 主线程 子线程 守护线程 守护线程当进程不存在或主线程停止，守护线程也会被停止 GC线程 HotSpot的每一个Java线程都是直接映射到一个操作系统原生线程来实现的 创建线程 继承Thread类 class MyThread extends Thread{ @Override public void run() {} } 多线程执行时，在栈内存中，其实每一个执行线程都有一片自己所属的栈内存空间。进行方法的压栈和弹栈 Thread类 public String getName() :获取当前线程名称。 public void start() :导致此线程开始执行; Java虚拟机调用此线程的run方法。 public void run() :此线程要执行的任务在此处定义代码。 public void yield():让出CPU，返回到就绪状态 join：等待被调用join的线程执行完毕再继续运行 public static void sleep(long millis) :使当前正在执行的线程以指定的毫秒数暂停（暂时停止执行）。 public static Thread currentThread() :返回对当前正在执行的线程对象的引用 InterruptedException 调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞(sleep)、限期等待或者无限期等待(wait)状态，那么就会抛出 InterruptedException，从而提前结束该线程 interrupted() 在自定义线程执行任务使，可以使用这个方法作为一个flag，作为是否继续运行的依据 while(interrupted()){ // do } // end 实现Runnable接口 实现Runnable接口比继承Thread类所具有的优势： 适合多个相同的程序代码的线程去共享同一个资源。 可以避免java中的单继承的局限性。 增加程序的健壮性，实现解耦操作，代码可以被多个线程共享，代码和线程独立。 线程池只能放入实现Runable或Callable类线程，不能直接放入继承Thread的类。 线程调度 Java 使用的抢占式调度多线程系统 可以通过Thread实例setPriority来调整优先级，不过此举总体而言不是一个文档的调节手段 线程状态 线程状态 导致状态发生条件 NEW(新建) 线程刚被创建，但是并未启动。还没调用start方法。 Runnable(可运行) 线程可以在java虚拟机中运行的状态，可能正在运行自己代码，也可能没有，这取决于操 作系统处理器。 Blocked(锁阻塞) 当一个线程试图获取一个对象锁，而该对象锁被其他的线程持有，则该线程进入Blocked状 态；当该线程持有锁时，该线程将变成Runnable状态。 Waiting(无限等待) 一个线程在等待另一个线程执行一个（唤醒）动作时，该线程进入Waiting状态。进入这个 状态后是不能自动唤醒的，必须等待另一个线程调用notify或者notifyAll方法才能够唤醒。 Timed Waiting(计时等待) 同waiting状态，有几个方法有超时参数，调用他们将进入Timed Waiting状态。这一状态 将一直保持到超时期满或者接收到唤醒通知。带有超时参数的常用方法有Thread.sleep 、 Object.wait。 Teminated(被终止) 因为run方法正常退出而死亡，或者因为没有捕获的异常终止了run方法而死亡。 线程安全 当多个线程同时访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那就称这个对象是线程安全的 不可变 不可变的对象一定是线程安全的 这种对象的接口一般需要精心设计 最简单的方式是所有成员变量设置为final 绝对线程安全 不管运行时环境如何，调用者都不需要任何额外的同步措施 相对线程安全 要保证对这个对象单次的操作是线程安全的，我们在调用的时候不需要进行额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性 线程兼容 对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用 线程对立 指不管调用端是否采取了同步措施，都无法在多线程环境中并发使用代码 线程安全的实现 互斥同步 synchronized Lock 非阻塞同步 CAS 无同步方案 可重入代码：类似于函数式编程 线程本地存储 synchronized 使用了锁对象，这个锁对象一瞬间只能被一个线程所持有 synchronized(this){ // 可以是任意一个对象 // 需要同步操作的代码 } public synchronized void method(){ // 也可以同步静态方法，等同于上面的synchronize(this) // 可能会产生线程安全问题的代码 } synchronized是可重入锁 重入：某个线程试图获得一个已经由它持有的锁 程序执行过程中发生异常，锁会被释放 不能使用String常量，以及int long等原始类型 synchronized底层 JDK早期的 使用的重量级实现 也就说在 OS 层面 后来的进行了改进 synchronized实现过程 java代码：synchronized 字节码： monitorenter monitorexit 执行过程中会进行锁升级 lock comxchg 锁升级： markword 记录这个线程ID （偏向锁） 如果线程争用，则升级为 自旋锁 10次以后，升级为重量级锁，也就是OS层面 执行时间短（加锁代码），线程数少，用自旋 执行时间长，线程数多，用系统锁 volatile 任何对被volatile关键字修饰的变量都会在主内存操作　不会操作副本 volatile变量操作时需要同步给内存变量　所以一定会使线程的执行速度变慢 而锁机制通过读入副本　释放锁写入主内存来包装可见性 保证线程可见性 MESI 缓存一致性协议 禁止指令重排序 DCL(double check lock) 单例 可见性 在没有同步的情况下，编译器或者处理器都会对一些上下文无关的指令进行重排序，这可能会导致一个线程修改了某一个数值，而另一个线程无法马上读取到修改后的数值 失效数据 非原子的64位操作 在java当中，一个64位大小的数值可以被分为2个32位的操作 加锁与可见性 之所以要在访问某个共享的可变变量时要求所有线程在锁上同步，就是为了确保读写可见性。 加锁的含义不局限与互斥行为，还包括内存可见性 volatile是比synchronized更为轻量级的同步机制，它无法进行互斥操作，但能保证内存可见性 典型用法 voatile boolean f; while (f){ // do something } CAS AtomicInteger 等原子类的实现 它包含三个参数CAS(V,E,N): V表示要更新的变量，E表示预期值，N表示新值。仅当V值等于E值时，才会将V的值设为N，如果V值和E值不同，则说明已经有其他线程做了更新，则当前线程进行自旋重复上述操作或者什么都不做。最后，CAS返回当前V的真实值 CAS是CPU原语支持 ABA问题 如果在这段期间曾经被改成B，然后又改回A，那CAS操作就会误认为它从来没有被修改过 解决方法：版本号 在大多数情况下 ABA问题并不会影响到程序的正确性 AtomicStampedReference unsafe类 直接操作JVM里的内存 JDK9之后无法使用了 allocateMemory 直接分配内存 freeMemory 释放内存 compareAndSet CAS操作 Java 与协程 Java 内核线程的局限性 内核线程1:1映射到Java上，当面对大量请求时，线程切换的成本开销远远大于计算本身的开销 协程的主要优势是轻量，一个协程的实现特例被称之为纤程 新并发模型下，一段使用纤程并发的代码会被分为两部分——执行过程（Continuation）和调度器（Scheduler）。执行过程主要用于维护执行现场，保护、恢复上下文状态，而调度器则负责编排所有要执行的代码的顺序 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-11 01:59:06 "},"编程语言/JAVA/JAVA并发编程/并发工具类.html":{"url":"编程语言/JAVA/JAVA并发编程/并发工具类.html","title":"并发工具类","keywords":"","body":"JUC J.U.C java.util.concurrent 主要分为几个类簇： 线程同步类　使进程间的协调更加容易　CountDownLatch CyclicBarrier等 并发集合类 线程管理类　线程池等 锁相关类　 锁的原理 AQS　定义了一个volatile int state 作为共享变量　如果线程获取资源失败　就进入FIFO队列等待　成功后去资源就执行临界区代码　执行完释放资源　会通知同步队列中的等待线程来获取资源后出队执行 ReentrantLock 轻量级锁与重量级锁 “轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的 ReentrantLock 和synchronized 都是 可重入锁 可重入 是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响 try { lock.lock(); // do something } catch (Exception e){ e.printStackTrace(); }finally { lock.unlock(); } 尝试加锁 lock.tryLock() // 可以进行“尝试锁定”tryLock，这样无法锁定，或者在指定时间内无法锁定，线程可以决定是否继续等待 可打断的加锁 lock.lockInterruptibly(); // 可以通过interrupt()打断 公平锁 公平锁：每个线程抢占锁的顺序为先后调用lock方法的顺序依次获取锁 非公平锁：每个线程抢占锁的顺序不定，谁运气好，谁就获取到锁，和调用lock方法的先后顺序无关 new ReentrantLock(true); // true为公平锁 synchronized vs ReentrantLock synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的 新版本java 两者性能大致相同 ReentrantLock 可中断，而 synchronized 不行 synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的 ReentrantLock 可以同时绑定多个 Condition 对象 应该优先选择synchronized: synchronized的锁释放是自动的 jvm天生支持 ReentrantReadWriteLock 当读写锁是写加锁状态时, 在这个锁被解锁之前, 所有试图对这个锁加锁的线程都会被阻塞 当读写锁在读加锁状态时, 所有试图以读模式对它进行加锁的线程都可以得到访问权, 但是如果线程希望以写模式对此锁进行加锁, 它必须直到所有的线程释放锁 class Cache { private Map cache = new HashMap<>(); private ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); public void put(String key, Object value) { ReentrantReadWriteLock.WriteLock writeLock = lock.writeLock(); writeLock.lock(); cache.put(key, value); writeLock.unlock(); } public Object get(String key) { ReentrantReadWriteLock.ReadLock readLock = lock.readLock(); readLock.lock(); Object value = cache.get(key); readLock.unlock(); return value; } } CountDownLatch(闭锁) 确保某些活动直到其他活动都完成后才继续执行 CountDownLatch latch = new CountDownLatch(5); for (int i = 0; i { Random random = new Random(); try { Thread.sleep(random.nextInt(5000)); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"线程\"+ finalI +\"完成\"); lock.latch(); }).start(); } latch.await(); System.out.println(\"all mission complete\"); CyclicBarrier（栅栏） 闭锁用于等待事件，而栅栏用于等待其他线程 CyclicBarrier barrier = new CyclicBarrier(5, () -> System.out.println(\"all thread run\")); // 调用await的线程会进行等待，直到第5个线程调用await，所有线程才会继续执行 for (int i = 0; i { Random rnd= new Random(); try { Thread.sleep(rnd.nextInt(3000)); System.out.println(Thread.currentThread()+\"run\"); barrier.await(); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } }).start(); } phaser Semaphore(信号量) 用来控制使用资源的主体数量 Semaphore semaphore = new Semaphore(5); // Semaphore semaphore = new Semaphore(5,true); 公平的信号量 // 最多只有5个线程能同时运行 for (int i = 0; i { Random rnd = new Random(); try { semaphore.acquire(); System.out.println(Thread.currentThread()+\"acquire lock\"); Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); }finally { semaphore.release(); } }).start(); } Exchanger 两个线程交换数据 Exchanger exchanger = new Exchanger<>(); new Thread(()->{ try { System.out.println(\"1st:\"+exchanger.exchange(\"1\")); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); new Thread(()->{ try { System.out.println(\"2nd:\"+exchanger.exchange(\"2\")); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); LockSupport var t = new Thread(()->{ for (int i = 0; i VarHandle 支持一些原子操作 public class Main { int x = 8; public static void main(String[] args) throws Exception{ Main main = new Main(); VarHandle varHandle = MethodHandles.lookup().findVarHandle(Main.class,\"x\",int.class); varHandle.compareAndSet(main,8,9); System.out.println(varHandle.get(main)); } } ThreadLocal ThreadLocal tl = new ThreadLocal<>(); var t1 = new Thread(()->{ tl.set(\"cxk\"); System.out.println(tl.get()); // \"cxk\" }); var t2 = new Thread(()->{ System.out.println(tl.get()); // null }); t1.start(); t1.join(); t2.start(); 使用ThreadLocal包装的对象只能在当前线程使用 原理: https://ismy.wang/java/2019/05/10/%E5%88%9D%E6%8E%A2ThreadLocal.html ThreadLocal使用了弱引用防止内存泄漏 注意：使用时，对象不再使用，必须手动remove，否则仍然会内存泄漏 副作用 线程池复用线程会导致ThreadLocal 也被重用　从而会导致脏数据的产生 如果使用static修饰ThreadLocal　这个时候弱引用就无法防止内存泄露了 解决上面这些问题只需要使用的时候注意remove即可 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-25 07:12:19 "},"编程语言/JAVA/JAVA并发编程/并发集合.html":{"url":"编程语言/JAVA/JAVA并发编程/并发集合.html","title":"并发集合","keywords":"","body":"并发集合 基本不用 Vector HashTable 所有方法都加了synchronized ConcurrentHashMap 效率主要体现在读上面 ConcurrentLinkedQueue CAS实现 ConcurrentSkipListMap TreeMap使用的红黑树 树的CAS操作很难实现 TreeMap的并发版本 CopyOnWriteArrayList 在写的时候不对原集合进行修改，而是重新复制一份，修改完之后，再移动指针 阻塞队列 BlockingQueue 该类型的队列执行take时如果没有元素则会一直阻塞，put如果超过了界限也会一直阻塞，直至有可用空间 实现类:ArrayBlockingQueue与LinkedBlockingDeque等 DelayQueue 延迟队列 PriorityQueue 取出的顺序是会根据添加的元素进行排序 SynchronousQueue 两个用来交换数据 TransferQueue 拥有普通阻塞队列的put-poll功能与SynchronousQueue的阻塞数据交换功能 transfer MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-02 04:35:05 "},"编程语言/JAVA/JAVA并发编程/线程池.html":{"url":"编程语言/JAVA/JAVA并发编程/线程池.html","title":"线程池","keywords":"","body":"线程池 作用： 线程复用　控制最大并发数 实现任务缓存策略以及拒绝策略 定期执行　周期执行 隔离不同业务的线程执行环境 Executor框架 public interface Executor { void execute(Runnable command); } ExecutorService继承了Executor，增加了一些方法 public interface ExecutorService extends Executor { // 平缓关闭 void shutdown(); // 粗暴关闭 List shutdownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; Future submit(Callable task); Future submit(Runnable task, T result); Future submit(Runnable task); List> invokeAll(Collection> tasks) throws InterruptedException; T invokeAny(Collection> tasks) throws InterruptedException, ExecutionException; } Callable 拥有返回值 Future 用来执行一些较长时间的计算，通过get来获取结果（阻塞或者超时） 用于异步获取执行结果或取消执行任务的场景 FutureTask futureTask = new FutureTask<>(() -> { int result = 0; for (int i = 0; i Future future = pool.submit(() -> { Thread.sleep(3000); return \"java\"; }); String s = future.get(); Future模式 public class Main { public static void main(String[] args) throws ExecutionException, InterruptedException { MyFuture myFuture = new MyFuture(); // 在这里 main thread 可以做其他事情 // 下一行代码将阻塞直到结果可用 System.out.println(myFuture.getData()); } } class MyFuture{ private volatile boolean FLAG = false; private String data; public MyFuture() { new Thread(new Runnable() { @Override public void run() { System.out.println(\"future 任务开始 睡眠 3000ms\"); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"future 任务结束\"); setData(\"jntm\"); } }).start(); } private synchronized void setData(String data){ if (FLAG){ return; } this.data = data; FLAG = true; notify(); } public synchronized String getData(){ while (!FLAG){ try { wait(); } catch (InterruptedException e) { e.printStackTrace(); } } return data; } } 线程池分类 ThreadPollExecutor ForkJoinPool 分解汇总的任务 用很少的线程可以执行很多的任务(子任务) TPE做不到先执行子任务 CPU密集型 ThreadPollExecutor Executors：线程池工厂（不推荐使用） newCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。这个线程池的最大线程数能达到整数的最大值 newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。 newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。同样　线程最大数也是整数最大值 newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行 newWorkSealingPool jdk8引入　使用多个队列来减少竞争 这个线程工厂大部分都使用了无界队列　如果瞬间请求量大　很有可能造成oom 原理 自定义 ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2/*实际运行线程数*/, 3/*最多可创建的线程数*/, 0L /* 让线程存活的时间 0为永久 */, TimeUnit.SECONDS, new ArrayBlockingQueue<>(4)/* 线程池的内部队列 */, Executors.defaultThreadFactory()/* 产生线程的方式 */, new ThreadPoolExecutor.DiscardOldestPolicy() /* 线程池满时的拒绝策略 */ ); 参数： corePoolSize 如果等于0 则任务执行结束后就会销毁所有线程　如果大于0　任务执行后这些线程不会被销毁 maximumPoolSize 能最大同时容纳的线程数　如果任务数量大于这个数　那么剩下的任务就要被缓存在一个阻塞队列中 keepAliveTime 表示线程池中的线程空闲时间　多于corePoolSize数量的部分线程会被销毁 时间单位 workQUeue 缓存队列 threadFactory 定义线程池线程的产生方式 handler 任务拒绝策略 如何配置： CPU密集型 IO密集型 自定义线程工厂　为线程指定有意义的名称和相应的序列号　方便出错排查 定义好拒绝策略　宁愿抛出异常　也不要使用DiscardPolicy 这个策略会静悄悄的抛弃任务 线程池的大小 Ncpu = CPU数量 Ucpu = 预期CPU使用率 W/C = 等待时间/计算时间 最优大小等于 Ncpu Ucpu (1 + W/C) ForkJoinPool MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-25 01:39:46 "},"编程语言/JAVA/JAVA并发编程/Disruptor.html":{"url":"编程语言/JAVA/JAVA并发编程/Disruptor.html","title":"Disruptor","keywords":"","body":"Disruptor 设计方案 环形数组结构 为了避免垃圾回收，采用数组而非链表。同时，数组对处理器的缓存机制更加友好。 元素位置定位 数组长度2^n，通过位运算，加快定位的速度。下标采取递增的形式。不用担心index溢出的问题。index是long类型，即使100万QPS的处理速度，也需要30万年才能用完。 无锁设计 每个生产者或者消费者线程，会先申请可以操作的元素在数组中的位置，申请到之后，直接在该位置写入或者读取数据。 开发 定义Event - 队列中需要处理的元素 定义Event工厂，用于填充队列 disruptor初始化的时候，会调用Event工厂，对ringBuffer进行内存的提前分配 GC产生频率会降低 public class StringEventFactory implements EventFactory { @Override public String newInstance() { return UUID.randomUUID().toString(); } } 定义EventHandler（消费者），处理容器中的元素 public class StringEventHandler implements EventHandler { @Override public void onEvent(String s, long l, boolean b) throws Exception { System.out.println(Thread.currentThread().getName() + \"handle \" + s); } } StringEventFactory eventFactory = new StringEventFactory(); int bufferSize = 1024; Disruptor disruptor = new Disruptor<>(eventFactory, bufferSize, Executors.defaultThreadFactory()); disruptor.handleEventsWith(new StringEventHandler()); disruptor.start(); RingBuffer ringBuffer = disruptor.getRingBuffer(); for (int i = 0; i {}); } 生产者线程模式 ProducerType有两种模式 Producer.MULTI和Producer.SINGLE 默认是MULTI，表示在多线程模式下产生sequence 如果确认是单线程生产者，那么可以指定SINGLE，效率会提升 等待策略 1，(常用）BlockingWaitStrategy：通过线程阻塞的方式，等待生产者唤醒，被唤醒后，再循环检查依赖的sequence是否已经消费。 2，BusySpinWaitStrategy：线程一直自旋等待，可能比较耗cpu 3，LiteBlockingWaitStrategy：线程阻塞等待生产者唤醒，与BlockingWaitStrategy相比，区别在signalNeeded.getAndSet,如果两个线程同时访问一个访问waitfor,一个访问signalAll时，可以减少lock加锁次数. 4，LiteTimeoutBlockingWaitStrategy：与LiteBlockingWaitStrategy相比，设置了阻塞时间，超过时间后抛异常。 5，PhasedBackoffWaitStrategy：根据时间参数和传入的等待策略来决定使用哪种等待策略 6，TimeoutBlockingWaitStrategy：相对于BlockingWaitStrategy来说，设置了等待时间，超过后抛异常 7，（常用）YieldingWaitStrategy：尝试100次，然后Thread.yield()让出cpu 8，（常用）SleepingWaitStrategy : sleep 消费者异常处理 默认：disruptor.setDefaultExceptionHandler() 覆盖：disruptor.handleExceptionFor().with() MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-08 07:05:22 "},"编程语言/JAVA/高级/网络编程.html":{"url":"编程语言/JAVA/高级/网络编程.html","title":"网络编程","keywords":"","body":"BIO Socket public InputStream getInputStream() ： 返回此套接字的输入流。 public OutputStream getOutputStream() ： 返回此套接字的输出流。 public void close() ：关闭此套接字。 public void shutdownOutput() ： 禁用此套接字的输出流。 工作机制 通信链路建立 客户端创建一个Socket实例 这个实例包含 本地地址 本地端口 远程地址 远程端口 服务端会创建一个ServerSocekt 包含监听地址 监听端口 监听地址通常情况下都是* 代表监听所有地址 当一个新的客户端进来后 进行三次握手之后, ServerSocekt 会创键一个Socekt实例 数据传输 两端的Socekt都有对应的输入输出流 这些流又有相应的缓冲区 如果缓冲区满了或者空了 读写操作就会被阻塞 ServerSocket public Socket accept() ：侦听并接受连接，返回一个新的Socket对象，用于和客户端实现通信 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-28 06:48:29 "},"编程语言/JAVA/高级/NIO.html":{"url":"编程语言/JAVA/高级/NIO.html","title":"NIO","keywords":"","body":"NIO 与BIO的区别 BIO是面向流的，NIO是面向缓冲区的； BIO流是阻塞的，NIO流是不阻塞的; NIO有选择器，而IO没有。 传统BIO模型的缺点 严重依赖于线程 线程是很昂贵的 线程内存资源 上下文切换成本 NIO 的线程模型 while(channel=Selector.select()){//选择就绪的事件和对应的连接 if(channel.event==accept){ registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器 } if(channel.event==write){ getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件 } if(channel.event==read){ getChannelHandler(channel).channelReadable(channel);//如果可以读，则执行读事件 } } } NIO 的 Reactor Proactor Reactor 步骤1：等待事件到来（Reactor负责）。 步骤2：将读就绪事件分发给用户定义的处理器（Reactor负责）。 步骤3：读数据（用户处理器负责）。 步骤4：处理数据（用户处理器负责）。 Proactor 步骤1：等待事件到来（Proactor负责）。 步骤2：得到读就绪事件，执行读数据（现在由Proactor负责）。 步骤3：将读完成事件分发给用户处理器（Proactor负责）。 步骤4：处理数据（用户处理器负责）。 Buffer DirectByteBuffer 可以减少内存从内核到用户的拷贝 但是创建消费成本更高 需要池化 HeapByteBuffer 使用堆内存 核心类 ByteBuffer 属性： capacity 缓冲区数组总长度 position 下一个要操作的数据元素位置 limit 缓冲区不可操作的下一个元素的位置 limit mark 类似于书签 NIO的文件读写 FileChannel.transferXXX: FileChannel.map: 将文件映射为内存区域 文件输出例子 FileOutputStream fos = new FileOutputStream(\"file.txt\"); FileChannel channel = fos.getChannel(); ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.put(\"20191204\".getBytes()); // 翻转缓冲区 buffer.flip(); channel.write(buffer); fos.close(); 文件输入 File file = new File(\"file.txt\"); FileInputStream fis = new FileInputStream(file); ByteBuffer buffer = ByteBuffer.allocate((int) file.length()); FileChannel channel = fis.getChannel(); channel.read(buffer); System.out.println(new String(buffer.array())); fis.close(); 文件复制 FileInputStream fis = new FileInputStream(\"file.txt\"); FileOutputStream fos = new FileOutputStream(\"file1.txt\"); FileChannel source = fis.getChannel(); FileChannel target = fos.getChannel(); target.transferFrom(source,0,source.size()); source.close(); target.close(); 网络编程 Selector 它是Java NIO核心组件中的一个，用于检查一个或多个NIO Channel（通道）的状态是否处于可读、可写。如此可以实现单线程管理多个channels,也就是可以管理多个网络链接 SelectionKey 一个SelectionKey键表示了一个特定的通道对象和一个特定的选择器对象之间的注册关系 ServerSocketChannel Java NIO 中的 ServerSocketChannel 是一个可以监听新进来的 TCP 连接的通道, 就像标准 IO 中的 ServerSocket一样 SocketChannel Java NIO 中的 SocketChannel 是一个连接到 TCP 网络套接字的通道 客户端 // 得到一个网络通道 SocketChannel channel = SocketChannel.open(); // 设置非阻塞方式 channel.configureBlocking(false); // 提供服务器IP与端口 InetSocketAddress address = new InetSocketAddress(\"127.0.0.1\", 1999); // 连接 if (!channel.connect(address)) { while (!channel.finishConnect()) { System.out.println(\"客户端：正在连接服务器\"); } } // 发送数据 ByteBuffer buffer = ByteBuffer.wrap(\"cxk 打篮球\".getBytes()); channel.write(buffer); 服务端框架 // 获取网络通道 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 获取选择器 Selector selector = Selector.open(); // 绑定端口 serverSocketChannel.bind(new InetSocketAddress(1999)); // 设置为非阻塞方式(accept时不阻塞) serverSocketChannel.configureBlocking(false); // 注册选择器，让选择器监听连接事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { // 每2000ms轮询一次，select返回的结果是客户数 if (selector.select(2000) == 0){ System.out.println(\"等待客户连接\"); continue; } // 获取准备连接的所有客户 Iterator iterator = selector.selectedKeys().iterator(); while (iterator.hasNext()){ SelectionKey key = iterator.next(); if (key.isAcceptable()){ // 客户端连接事件 System.out.println(\"客户端连接\"); SocketChannel socketChannel = serverSocketChannel.accept(); socketChannel.configureBlocking(false); // 读取客户端数据时不会阻塞 socketChannel.register(selector,SelectionKey.OP_READ, ByteBuffer.allocate(1024)); } if (key.isReadable()){ // 读取客户端数据事件 SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer buffer = (ByteBuffer) key.attachment(); channel.read(buffer); System.out.println(\"客户端发来数据:\"+new String(buffer.array())); } // 删除客户key，防止重复处理 iterator.remove(); } } 系统层面的NIO BIO模型 socket=3 bind(3,port) listen(3) accept(3)=block|5 recv(5)=block|data 弊端：每连接一线程 同步非阻塞 NIO fcntl 开启非阻塞 使用一个线程处理N个连接读写 每次循环会发生大量无用的系统调用 多路复用器 同步IO模型 (select, pselect)： 传入fd列表，内核返回准备好的fd列表 在用户空间对fd轮询 弊端：需要在内核与用户空间之间拷贝fd 多路复用 无需再拷贝fd： 调用epoll_create创建一个fd指向共享空间 将客户端fd存放在共享空间 使用 epoll_ctl_add epoll_ctl_mod epoll_ctl_del 使用epoll_wait会返回可用fd列表 程序再对fd列表操作 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-28 06:48:29 "},"编程语言/JAVA/高级/网络爬虫.html":{"url":"编程语言/JAVA/高级/网络爬虫.html","title":"网络爬虫","keywords":"","body":" 网络爬虫，是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。 HttpClient Get请求 HttpGet get = new HttpGet(\"http://www.baidu.com\"); try (CloseableHttpClient client = HttpClients.createDefault(); CloseableHttpResponse response = client.execute(get)) { String s = EntityUtils.toString(response.getEntity(), \"utf8\"); System.out.println(s); } 设置参数 URIBuilder uriBuilder = new URIBuilder(\"http://www.baidu.com/s\").addParameter(\"wd\", \"关键词\"); HttpGet get = new HttpGet(uriBuilder.build()); POST请求 var request = new HttpPost(\"http://example\"); var pairs = List.of(new BasicNameValuePair(\"keys\", \"java\"), new BasicNameValuePair(\"keys\", \"python\")); UrlEncodedFormEntity entity = new UrlEncodedFormEntity(pairs, \"utf8\"); request.setEntity(entity); 连接池 PoolingHttpClientConnectionManager manager = new PoolingHttpClientConnectionManager(); // 最大连接数 manager.setMaxTotal(100); // 每个主机最大连接数 manager.setDefaultMaxPerRoute(10); CloseableHttpClient client = HttpClients.custom().setConnectionManager(manager).build(); 请求参数 RequestConfig config = RequestConfig.custom().setConnectTimeout(1000) // 获取连接的最长时间，单位ms .setConnectionRequestTimeout(500) // 获取连接的最长时间 .setSocketTimeout(10000).build(); // 传输数据最长时间 HttpGet get = new HttpGet(); get.setConfig(config); Jsoup DOM Document doc = Jsoup.parse(new URL(\"http://www.baidu.com\"), 10000); doc.getElementByXXX(); 元素API Element e = doc.getElementById(\"login\"); System.out.println(e.id()); System.out.println(e.className()); System.out.println(e.classNames()); System.out.println(e.text()); System.out.println(e.attr(\"style\")); System.out.println(e.attributes()); 使用CSS选择器 doc.select(\"div\") .forEach(System.out::println); WebMagic 使用 实现PageProcessor public class JobProcessor implements PageProcessor { private Site site = Site.me().addHeader(\"User-Agent\",\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36\"); @Override public void process(Page page) { page.putField(\"div1\",page.getHtml().css(\"#logo-2014\").get()); page.putField(\"div2\",page.getHtml().xpath(\"//div\").get()); } @Override public Site getSite() { return site; } } 运行 Spider.create(new JobProcessor()) .addUrl(\"https://search.jd.com/Search?keyword=%E6%89%8B%E6%9C%BA&enc=utf-8&wq=%E6%89%8B%E6%9C%BA&pvid=9524dc8e0e2d45f08656f023fa60a0de\") .run(); 元素抽取 XPath Regex CSS page.putField(\"div1\",page.getHtml().css(\"#logo-2014\").get()); // 获取一条 page.putField(\"div2\",page.getHtml().xpath(\"//div[@id=logo-2014]\").all()); // 获取全部 获取链接 page.getHtml().links() 递归访问 page.addTargetRequests(page.getHtml().links().all()); 输出数据 PipeLine Spider.create(new JobProcessor()) .addUrl(\"url\") .addPipeline(new FilePipeline(\"./result.txt\")) .run(); Site Scheduler 使用布隆过滤器 Spider.create(null) .setScheduler(new QueueScheduler().setDuplicateRemover(new BloomFilterDuplicateRemover(100000))); 三种去重方式 HashSet Redis 布隆过滤器 文档 爬虫分类 通用 聚焦 增量式 深层网络 网页去重 simhash 海明距离 在信息编码中，两个合法代码对应位上编码不同的位数称为码距，又称海明距离。举例如下：10101和00110从第一位开始依次有第一位、第四、第五位不同，则海明距离为3 使用代理 downloader.setProxyProvider(new SimpleProxyProvider(List.of(new Proxy(\"116.114.19.211\",443)))); Spider.create(new ProxyProcessor()) .addUrl(\"http://ip-api.com/json/?lang=zh-CN\") .setDownloader(downloader) .run(); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/netty/netty.html":{"url":"编程语言/JAVA/框架/netty/netty.html","title":"Netty","keywords":"","body":"Netty Netty是由JBOSS提供的一个java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。 使用场景 高性能领域 多线程并发领域 异步通信领域 Reactor模型 多线程模型 一个接收线程，多个处理线程 Reactor主从多线程模型 处理高并发 一组线程接收请求，一组线程处理IO 核心API 处理流式传输 数据通过网络传输，最终会缓存在一个字节数组里 所以就会可能出现传输： 接收： 解决方案1 创建一个缓冲区，每次数据到来时，将数据放入到缓冲区，如果缓冲区超过一定大小 则就进行处理 public class TimeClientHandler extends ChannelInboundHandlerAdapter { private ByteBuf buf; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { ByteBuf m = (ByteBuf) msg; buf.writeBytes(m); // (2) m.release(); if (buf.readableBytes() >= 4) { // (3) long currentTimeMillis = (buf.readUnsignedInt() - 2208988800L) * 1000L; System.out.println(new Date(currentTimeMillis)); ctx.close(); } } } 解决方案2 使用解码器 public class TimeDecoder extends ByteToMessageDecoder { @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List out) throws Exception { // 如果缓冲区没有足够的数据，不进行处理，只有缓冲区累积一定的数据时，才将数据添加到out if (in.readableBytes() b.handler(new ChannelInitializer() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new TimeDecoder(),new TimeClientHandler()); } }); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-09 04:37:24 "},"编程语言/JAVA/框架/netty/概念及体系结构.html":{"url":"编程语言/JAVA/框架/netty/概念及体系结构.html","title":"概念及体系结构","keywords":"","body":"概念及体系结构 JAVA网络编程 BIO 同步阻塞IO 伪异步IO NIO 同步非阻塞IO AIO 异步非阻塞IO 特性 非阻塞网络调用使得我们可以不必等待一个操作的完成。完全异步的I/O正是基于这个特性构建的，并且更进一步：异步方法会立即返回，并且在它完成时，会直接或者在稍后的某个时间点通知用户。 选择器使得我们能够通过较少的线程便可监视许多连接上的事件。 阻塞与非阻塞 阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程 同步与异步 同步和异步关注的是消息通信机制 所谓同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由调用者主动等待这个调用的结果。 而异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用 核心组件 回调 netty使用回调来将事件处理交给程序 Future netty的实现：ChannelFuture ChannelFutureListener 回调的更精细版本 事件与ChannelHandler 组件和设计 Channel 它代表一个到实体（如一个硬件设备、一个文件、一个网络套接字或者一个能够执行一个或者多个不同的I/O操作的程序组件）的开放连接，如读操作和写操作 EmbeddedChannel； LocalServerChannel； NioDatagramChannel； NioSctpChannel； NioSocketChannel。 EventLoop 一个EventLoop在它的生命周期内只和一个Thread绑定 这个Thread会处理EventLoop所有的IO事件 一个Channel对应一个EventLoop 一个EventLoop有一个或多个Channel ChannelFuture 提供了另一种在操作完成时通知应用程序的方式。这个对象可以看作是一个异步操作的结果的占位符；它将在未来的某个时刻完成，并提供对其结果的访问。 属于同一个Channel的操作都能保证按调用的顺序执行 ChannelHandler ChannelHandler 为 Netty 中最核心的组件，它充当了所有处理入站和出站数据的应用程序逻辑的容器。ChannelHandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等 ChannelInboundHandler ChannelPipeline ChannelPipeline 为 ChannelHandler 链提供了一个容器并定义了用于沿着链传播入站和出站事件流的 API 在netty中，有两种消息发送方式 Channel: 消息会从头开始传递 ChannelHandlerContext 消息会从某一个Handler开始传递 编码器解码器 xxxDecoder xxxEncoder ServerBootStrap 使用服务器的ServerBootStrap，用于接受客户端的连接以及为已接受的连接创建子通道。 用于客户端的BootStrap，不接受新的连接，并且是在父通道类完成一些操作。 Server端需要两组EventLoop 异常处理 入站异常 ChannelHnadler.exceptionCaught 出站异常 ChannelFutureListener ChannelFuture 线程模型 线程模型确定了代码的执行方式 线程池模型 不能消除由上下文切换所带来的开销 EventLoop for (;;) { Runnable task = takeTask(); if (task != null) { task.run(); updateLastExecutionTime(); } if (confirmShutdown()) { break; } } 一个EventLoop 由 永远都不会变动的一个 Thread 驱动 任务调度 JDK自带的ScheduleExecutorService netty 自带的调度 Channel ch = ... ScheduledFuture future = ch.eventLoop().schedule( ← -- 创建一个Runnable以供调度稍后执行 　　new Runnable() { 　　@Override 　　public void run() { ← -- 要执行的代码 　　　　System.out.println(\"60 seconds later\");　 　　} }, 60, TimeUnit.SECONDS);　 ← -- 调度任务在从现在开始的60 秒之后执行 线程管理 所以一定不能将一个长时间运行的任务放入到执行队列中 否则EventLoop会被阻塞 线程分配 异步传输 阻塞传输 单元测试 EmbeddedChannel EmbeddedChannel channel = new EmbeddedChannel(new EchoServerHandler()); channel.writeInbound(\"hello\"); // 入站数据 assertTrue(channel.finish()); // 标记为完成 String outData = channel.readOutbound(); // 出站数据 assertEquals(\"hello\",outData); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-10 02:25:17 "},"编程语言/JAVA/框架/netty/传输.html":{"url":"编程语言/JAVA/框架/netty/传输.html","title":"传输","keywords":"","body":"传 API 核心是 Channel Channel的方法 方　法　名 描　　述 eventLoop 返回分配给Channel的EventLoop pipeline 返回分配给Channel的ChannelPipeline isActive 如果Channel是活动的，则返回true。活动的意义可能依赖于底层的传输。例如，一个Socket传输一旦连接到了远程节点便是活动的，而一个Datagram传输一旦被打开便是活动的 localAddress 返回本地的SocketAddress remoteAddress 返回远程的SocketAddress write 将数据写到远程节点。这个数据将被传递给ChannelPipeline，并且排队直到它被flush flush 将之前已写的数据刷新到底层传输，如一个Socket writeAndFlush 一个简便的方法，等同于调用write()并接着调用flush() Channel 是线程安全的 内置的传输 名　　称 包 描　　述 NIO io.netty.channel.socket.nio 使用java.nio.channels包作为基础——基于选择器的方式 Epoll[1] io.netty.channel.epoll 由JNI驱动的epoll()和非阻塞IO。这个传输支持只有在Linux上可用的多种特性，如SO_REUSEPORT，比NIO传输更快，而且是完全非阻塞的 OIO io.netty.channel.socket.oio 使用java.net包作为基础——使用阻塞流 Local io.netty.channel.local 可以在VM内部通过管道进行通信的本地传输 Embedded io.netty.channel.embedded Embedded传输，允许使用ChannelHandler而又不需要一个真正的基于网络的传输。这在测试你的ChannelHandler实现时非常有用 NIO Epoll 该传输的语义同NIO 如果要使用该传输 只需要将 EventLoop 中的 NioServerSocketChannel 替换为 EpollServerSocketChannel即可 OIO Local 没有绑定物理网络地址 Embedded 可以将一组ChannelHandler 嵌入到 其他 ChannelHandler内部 场景 应用程序的需求 推荐的传输 非阻塞代码库或者一个常规的起点 NIO（或者在Linux上使用epoll） 阻塞代码库 OIO 在同一个JVM内部的通信 Local 测试ChannelHandler的实现 Embedded MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-12 02:00:56 "},"编程语言/JAVA/框架/netty/ByteBuf.html":{"url":"编程语言/JAVA/框架/netty/ByteBuf.html","title":"ByteBuf","keywords":"","body":"ByteBuf 数据容器 可以进行扩展 零拷贝 容量按需增长 读写切换不需要调用flip 读写使用不同索引 方法链式调用 引用计数 池化 使用模式 堆缓冲区 ByteBuf将数据存储在JVM的堆空间中 ByteBuf heapBuf = ...; if (heapBuf.hasArray()) { ← -- 检查ByteBuf 是否有一个支撑数组 　　byte[] array = heapBuf.array(); ← -- 如果有，则获取对该数组的引用　 　　int offset = heapBuf.arrayOffset() + heapBuf.readerIndex(); ← -- 计算第一个字节的偏移量。 　　int length = heapBuf.readableBytes();　 ← -- 获得可读字节数 　　handleArray(array, offset, length);　 ← -- 使用数组、偏移量和长度作为参数调用你的方法 } 直接缓冲区 这种模式下的ByteBuf支持通过本地调用分配内存 所以直接缓冲区的数据在堆外，不会被GC处理 ByteBuf directBuf = ...; if (!directBuf.hasArray()) { ← -- 检查ByteBuf 是否由数组支撑。如果不是，则这是一个直接缓冲区 　　int length = directBuf.readableBytes(); ← -- 获取可读字节数 　　byte[] array = new byte[length];　 ← -- 分配一个新的数组来保存具有该长度的字节数据　　 　　directBuf.getBytes(directBuf.readerIndex(), array); ← -- 将字节复制到该数组 　　handleArray(array, 0, length); ← -- 使用数组、偏移量和长度作为参数调用你的方法 } 复合缓冲区 这种模式下允许多个ByteBuf聚合起来，提供一个ByteBuf整体视图来进行操作 字节级操作 随机访问 ByteBuf buffer = ...; for (int i = 0; i 不会改变索引的值 顺序访问 调用discardReadBytes()可以回收可丢弃字节的空间 读取所有数据 ByteBuf buffer = ...; while (buffer.isReadable()) { 　　System.out.println(buffer.readByte()); } 写入数据 ByteBuf buffer = ...; while (buffer.writableBytes() >= 4) { 　　buffer.writeInt(random.nextInt()); } 索引管理 readerIndex(int)：设置读索引位置 writerIndex(int)： 设置写索引位置 clear()：将读索引写索引重置为0 查找 // 查找回车符(\\r) ByteBuf buffer = ...; int index = buffer.forEachByte(ByteBufProcessor.FIND_CR); 派生缓冲区 duplicate() slice() slice(int, int) Unpooled.unmodifiableBuffer(…) order(ByteOrder) readSlice(int) copy() 这些方法都会返回一个新的ByteBuf实例 读/写 get和set操作，从给定的索引开始，并且保持索引不变； read和write操作，从给定的索引开始，并且会根据已经访问过的字节数对索引进行调整。 其他操作 名　　称 描　　述 isReadable() 如果至少有一个字节可供读取，则返回true isWritable() 如果至少有一个字节可被写入，则返回true readableBytes() 返回可被读取的字节数 writableBytes() 返回可被写入的字节数 capacity() 返回ByteBuf可容纳的字节数。在此之后，它会尝试再次扩展直 到达到maxCapacity() maxCapacity() 返回ByteBuf可以容纳的最大字节数 hasArray() 如果ByteBuf由一个字节数组支撑，则返回true array() 如果 ByteBuf由一个字节数组支撑则返回该数组；否则，它将抛出一个UnsupportedOperationException异常 ByteBufHolder 支持缓冲区池化 从池中复用ByteBuf 名　　称 描　　述 content() 返回由这个ByteBufHolder所持有的ByteBuf copy() 返回这个ByteBufHolder的一个深拷贝，包括一个其所包含的ByteBuf的非共享副本 duplicate() 返回这个ByteBufHolder的一个浅拷贝，包括一个其所包含的ByteBuf的共享副本 ByteBuf分配 ByteBufAllocator 池化 buffer 返回基于对或者直接缓存存储 headBuffer 返回基于堆内存 directBuffer 返回基于直接内存 compositeBuffer ioBuffer 返回套接字的IO操作buffer 实现： PooledByteBufAllocator 池化 UnpooledByteBufAllocator 每次调用都会返回一个新实例 Unpooled缓冲区 提供了一些静态方法来创建ByteBuf实例 ByteBufUtils hexdump 以16进制打印缓冲区 equals 比较两个ByteBuf 引用计数 ByteBuf 与 ByteBufHolder 都实现了引用计数 boolean released = buffer.release(); ← -- 减少到该对象的活动引用。当减少到0 时，该对象被释放，并且该方法返回true 访问一个引用计数被释放的对象 会抛出异常 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-12 02:00:56 "},"编程语言/JAVA/框架/netty/Channel相关.html":{"url":"编程语言/JAVA/框架/netty/Channel相关.html","title":"Channel相关","keywords":"","body":"Channel相关 Channel 生命周期 状　　态 描　　述 ChannelUnregistered Channel已经被创建，但还未注册到EventLoop ChannelRegistered Channel已经被注册到了EventLoop ChannelActive Channel处于活动状态（已经连接到它的远程节点）。它现在可以接收和发送数据了 ChannelInactive Channel没有连接到远程节点 ChannelHandler 生命周期 类　　型 描　　述 handlerAdded 当把ChannelHandler添加到ChannelPipeline中时被调用 handlerRemoved 当从ChannelPipeline中移除ChannelHandler时被调用 exceptionCaught 当处理过程中在ChannelPipeline中有错误产生时被调用 ChannelInboundHandler 入站消息操作 类　　型 描　　述 channelRegistered 当Channel已经注册到它的EventLoop并且能够处理I/O时被调用 channelUnregistered 当Channel从它的EventLoop注销并且无法处理任何I/O时被调用 channelActive 当Channel处于活动状态时被调用；Channel已经连接/绑定并且已经就绪 channelInactive 当Channel离开活动状态并且不再连接它的远程节点时被调用 channelReadComplete 当Channel上的一个读操作完成时被调用[1] channelRead 当从Channel读取数据时被调用 ChannelWritabilityChanged 当Channel的可写状态发生改变时被调用。用户可以确保写操作不会完成得太快（以避免发生OutOfMemoryError）或者可以在Channel变为再次可写时恢复写入。可以通过调用Channel的isWritable()方法来检测Channel的可写性。与可写性相关的阈值可以通过Channel.config(). setWriteHighWaterMark()和Channel.config().setWriteLowWater- Mark()方法来设置 userEventTriggered 当ChannelnboundHandler.fireUserEventTriggered()方法被调用时被调用，因为一个POJO被传经了ChannelPipeline 需要注意的是 在channelRead方法里面需要显式释放ByteBuf @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { ← -- 丢弃已接收的消息 　　　ReferenceCountUtil.release(msg);　 } SimpleChannelInboundHandler 会自动释放资源 ChannelOutboundHandler 出站消息操作 类　　型 描　　述 bind(ChannelHandlerContext, SocketAddress,ChannelPromise) 当请求将Channel绑定到本地地址时被调用 connect(ChannelHandlerContext, SocketAddress,SocketAddress,ChannelPromise) 当请求将Channel连接到远程节点时被调用 disconnect(ChannelHandlerContext, ChannelPromise) 当请求将Channel从远程节点断开时被调用 close(ChannelHandlerContext,ChannelPromise) 当请求关闭Channel时被调用 deregister(ChannelHandlerContext, ChannelPromise) 当请求将Channel从它的EventLoop注销时被调用 read(ChannelHandlerContext) 当请求从Channel读取更多的数据时被调用 flush(ChannelHandlerContext) 当请求通过Channel将入队数据冲刷到远程节点时被调用 write(ChannelHandlerContext,Object,ChannelPromise) 当请求通过Channel将数据写到远程节点时被调用 ChannelHandlerAdapter ResourceLeakDetector 通过分配1%的采样来检测内存泄漏 ChannelPipeline 拦截流经 Channel 的入站和出站时间的ChannelHandler 示例链 修改 名　　称 描　　述 addFirst addBefore addAfter addLast 将一个ChannelHandler添加到ChannelPipeline中 remove 将一个ChannelHandler从ChannelPipeline中移除 replace 将ChannelPipeline中的一个ChannelHandler替换为另一个Channel- Handler 访问 ChannelHandler 名　　称 描　　述 get 通过类型或者名称返回ChannelHandler context 返回和ChannelHandler绑定的ChannelHandlerContext names 返回ChannelPipeline中所有ChannelHandler的名称 出入站事件 ChannelHandlerContext 代表了 ChannelHandler 与 ChannelPipeline 之间的关联 这个类提供的一些访问在 Channel 与 ChannelPipeline 上也有 使用该类的目的是产生更短的事件流以及为了更高的性能 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-12 02:00:56 "},"编程语言/JAVA/框架/netty/引导.html":{"url":"编程语言/JAVA/框架/netty/引导.html","title":"引导","keywords":"","body":"引导 Bootstrap 客户端 名　　称 描　　述 Bootstrap group(EventLoopGroup) 设置用于处理Channel所有事件的EventLoopGroup Bootstrap channel( 　　Class) Bootstrap channelFactory( 　　ChannelFactory) channel()方法指定了Channel的实现类。如果该实现类没提供默认的构造函数[7]，可以通过调用channel- Factory()方法来指定一个工厂类，它将会被bind()方法调用 Bootstrap localAddress( 　　SocketAddress) 指定Channel应该绑定到的本地地址。如果没有指定，则将由操作系统创建一个随机的地址。或者，也可以通过bind()或者connect()方法指定localAddress Bootstrap option( 　　ChannelOption option, 　　T value) 设置ChannelOption，其将被应用到每个新创建的Channel的ChannelConfig。这些选项将会通过bind()或者connect()方法设置到Channel，不管哪个先被调用。这个方法在Channel已经被创建后再调用将不会有任何的效果。支持的ChannelOption取决于使用的Channel类型。参见8.6节以及ChannelConfig的API文档，了解所使用的Channel类型 Bootstrap attr( 　　Attribute key, T value) 指定新创建的Channel的属性值。这些属性值是通过bind()或者connect()方法设置到Channel的，具体取决于谁最先被调用。这个方法在Channel被创建后将不会有任何的效果。参见8.6节 Bootstrap handler(ChannelHandler) 设置将被添加到ChannelPipeline以接收事件通知的ChannelHandler Bootstrap clone() 创建一个当前Bootstrap的克隆，其具有和原始的Bootstrap相同的设置信息 Bootstrap remoteAddress( 　　SocketAddress) 设置远程地址。或者，也可以通过connect()方法来指定它 ChannelFuture connect() 连接到远程节点并返回一个ChannelFuture，其将会在连接操作完成后接收到通知 ChannelFuture bind() 绑定Channel并返回一个ChannelFuture，其将会在绑定操作完成后接收到通知，在那之后必须调用Channel. connect()方法来建立连接 String host = \"127.0.0.1\"; int port = 1234; EventLoopGroup workerGroup = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); // 指定线程工作池 b.group(workerGroup); // 指定实例化channel的方式 b.channel(NioSocketChannel.class); // 连接参数 b.option(ChannelOption.SO_KEEPALIVE, true); b.handler(new ChannelInitializer() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new TimeClientHandler()); } }); // Start the client. ChannelFuture f = b.connect(host, port).sync(); // (5) // Wait until the connection is closed. f.channel().closeFuture().sync(); } catch (InterruptedException e) { e.printStackTrace(); } finally { workerGroup.shutdownGracefully(); } ServerBootStrap 服务端 名　　称 描　　述 group 设置ServerBootstrap要用的EventLoopGroup。这个EventLoopGroup将用于ServerChannel和被接受的子Channel的I/O处理 channel 设置将要被实例化的ServerChannel类 channelFactory 如果不能通过默认的构造函数[8]创建Channel，那么可以提供一个Channel- Factory localAddress 指定ServerChannel应该绑定到的本地地址。如果没有指定，则将由操作系统使用一个随机地址。或者，可以通过bind()方法来指定该localAddress option 指定要应用到新创建的ServerChannel的ChannelConfig的Channel- Option。这些选项将会通过bind()方法设置到Channel。在bind()方法被调用之后，设置或者改变ChannelOption都不会有任何的效果。所支持的ChannelOption取决于所使用的Channel类型。参见正在使用的ChannelConfig的API文档 childOption 指定当子Channel被接受时，应用到子Channel的ChannelConfig的ChannelOption。所支持的ChannelOption取决于所使用的Channel的类型。参见正在使用的ChannelConfig的API文档 attr 指定ServerChannel上的属性，属性将会通过bind()方法设置给Channel。在调用bind()方法之后改变它们将不会有任何的效果 childAttr 将属性设置给已经被接受的子Channel。接下来的调用将不会有任何的效果 handler 设置被添加到ServerChannel的ChannelPipeline中的ChannelHandler。更加常用的方法参见childHandler() childHandler 设置将被添加到已被接受的子Channel的ChannelPipeline中的Channel- Handler。handler()方法和childHandler()方法之间的区别是：前者所添加的ChannelHandler由接受子Channel的ServerChannel处理，而childHandler()方法所添加的ChannelHandler将由已被接受的子Channel处理，其代表一个绑定到远程节点的套接字 clone 克隆一个设置和原始的ServerBootstrap相同的ServerBootstrap bind 绑定ServerChannel并且返回一个ChannelFuture，其将会在绑定操作完成后收到通知（带着成功或者失败的结果） // 接收到来的连接 EventLoopGroup bossGroup = new NioEventLoopGroup(); // 处理已建立连接的流量 EventLoopGroup workerGroup = new NioEventLoopGroup(); try { // 复制启动服务器 ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) // 使用 NioServerSocketChannel 将到来的连接实例化为Channel .channel(NioServerSocketChannel.class) // 指定处理器来处理 channel 与 channel 的事件 .childHandler(new ChannelInitializer() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new DiscardServerHandler()); } }) // 指定一些参数（针对到来的连接） .option(ChannelOption.SO_BACKLOG, 128) // 指定一些参数（针对channel） .childOption(ChannelOption.SO_KEEPALIVE, true); // Bind and start to accept incoming connections. ChannelFuture f = b.bind(port).sync(); // Wait until the server socket is closed. // In this example, this does not happen, but you can do that to gracefully // shut down your server. f.channel().closeFuture().sync(); } finally { workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } 尽可能重用 EventLoop , 减少先创创建所带来的的开销 ChannelOption bootstrap.option(ChannelOption.SO_KEEPALIVE,true) 　　.option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000); ChannelOption.SO_BACKLOG ChannelOption.SO_BACKLOG对应的是tcp/ip协议listen函数中的backlog参数，函数listen(int socketfd,int backlog)用来初始化服务端可连接队列，服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接，多个客户端来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理，backlog参数指定了队列的大小 ChannelOption.SO_KEEPALIVE Channeloption.SO_KEEPALIVE参数对应于套接字选项中的SO_KEEPALIVE，该参数用于设置TCP连接，当设置该选项以后，连接会测试链接的状态，这个选项用于可能长时间没有数据交流的连接。当设置该选项以后，如果在两小时内没有数据的通信时，TCP会自动发送一个活动探测数据报文 关闭 Future future = group.shutdownGracefully();　 ← -- shutdownGracefully()方法将释放所有的资源，并且关闭所有的当前正在使用中的Channel // block until the group has shutdown future.syncUninterruptibly(); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-12 02:00:56 "},"编程语言/JAVA/框架/netty/编解码器.html":{"url":"编程语言/JAVA/框架/netty/编解码器.html","title":"编解码器","keywords":"","body":"编解码器 解码器 ByteToMessageDecoder public class TimeDecoder extends ByteToMessageDecoder { @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List out) throws Exception { // 如果缓冲区没有足够的数据，不进行处理，只有缓冲区累积一定的数据时，才将数据添加到out if (in.readableBytes() ReplayingDecoder 使用了一个自定义的ByteBuf 支持更简单的操作 MessageToMessageDecoder 编码器 扩展了MessageToByteEncoder public class ShortToByteEncoder extends MessageToByteEncoder { ← -- 扩展了MessageToByteEncoder 　　@Override 　　public void encode(ChannelHandlerContext ctx, Short msg, ByteBuf out) 　　　　throws Exception { 　　　　out.writeShort(msg);　 ← -- 将Short 写入ByteBuf 中 　　} } MessageToMessageEncoder 编解码器 xxxCodec netty 内置的 Handler 以及 编解码器 SslHandler SSL/TLS Http HttpResponseDecoder HttpRequestEncoder HttpServerCodec pipeline.addLast(\"aggregator\",new HttpObjectAggregator(512 * 1024)); 压缩:HttpContentCompressor WebSocket 　　@Override 　　protected void initChannel(Channel ch) throws Exception { 　　　　ch.pipeline().addLast( 　　　　　　new HttpServerCodec(), 　　　　　　new HttpObjectAggregator(65536), ← -- 为握手提供聚合的HttpRequest 　　　　　 new WebSocketServerProtocolHandler(\"/websocket\"), ← -- 如果被请求的端点是\"/websocket\"，则处理该升级握手　 　　　　　　new TextFrameHandler(),　 ← -- TextFrameHandler 处理TextWebSocketFrame 　　　　　 new BinaryFrameHandler(),　← -- BinaryFrameHandler 处理BinaryWebSocketFrame　 　　　　　 new ContinuationFrameHandler());　← -- ContinuationFrameHandler 处理ContinuationWebSocketFrame　 　　} 检测空闲连接或超时 IdleStateHandler ReadTimeoutHandler WriteTimeoutHandler 根据分隔符分割字节流 DelimiterBasedFrameDecoder LineBasedFrameDecoder 根据长度分割字节流 FixedLengthFrameDecoder LengthFieldBasedFrameDecoder 写大型数据 FileInputStream in = new FileInputStream(file); ← -- 创建一个FileInputStream FileRegion region = new DefaultFileRegion(　 ← -- 以该文件的完整长度创建一个新的DefaultFileRegion 　　in.getChannel(), 0, file.length()); channel.writeAndFlush(region); pipeline.addLast(new ChunkedWriteHandler());　 ← -- 添加Chunked-WriteHandler以处理作为ChunkedInput传入的数据 　　　　pipeline.addLast(new WriteStreamHandler()); ← -- 一旦连接建立，WriteStreamHandler就开始写文件数据 序列化 JDK 名　　称 描　　述 CompatibleObjectDecoder [9] 和使用JDK序列化的非基于Netty的远程节点进行互操作的解码器 CompatibleObjectEncoder 和使用JDK序列化的非基于Netty的远程节点进行互操作的编码器 ObjectDecoder 构建于JDK序列化之上的使用自定义的序列化来解码的解码器；当没有其他的外部依赖时，它提供了速度上的改进。否则其他的序列化实现更加可取 ObjectEncoder 构建于JDK序列化之上的使用自定义的序列化来编码的编码器；当没有其他的外部依赖时，它提供了速度上的改进。否则其他的序列化实现更加可取 JBoss Marshalling 名　　称 描　　述 CompatibleMarshallingDecoder CompatibleMarshallingEncoder 与只使用JDK序列化的远程节点兼容 MarshallingDecoder MarshallingEncoder 适用于使用JBoss Marshalling的节点。这些类必须一起使用 Protocol Buffers 名　　称 描　　述 ProtobufDecoder 使用protobuf对消息进行解码 ProtobufEncoder 使用protobuf对消息进行编码 ProtobufVarint32FrameDecoder 根据消息中的Google Protocol Buffers的“Base 128 Varints”a整型长度字段值动态地分割所接收到的ByteBuf ProtobufVarint32LengthFieldPrepender 向ByteBuf前追加一个Google Protocal Buffers的“Base 128 Varints”整型的长度字段值 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-13 03:23:23 "},"编程语言/JAVA/高级/Lambda表达式.html":{"url":"编程语言/JAVA/高级/Lambda表达式.html","title":"Lambda 表达式","keywords":"","body":"Lambda 表达式 (参数列表) ‐> { 代码语句 } 类似于匿名方法，一个没有名字的方法 可以忽略写参数类型 坚决不声明返回值类型 没有修饰符 单句表达式，将直接返回值，不用大括号 带return语句， 算多句，必须用大括号 无参数，仅保留括号 一个参数，可省略括号 带返回值 String[] sa = {\"ss\",\"assas\",\"sdw\",\"11\",\"8568\"}; Arrays.sort(sa,(s1,s2)->s1.compareTo(s2)); System.out.println(Arrays.toString(sa)); 使用前提 使用Lambda必须具有接口，且要求接口中有且仅有一个抽象方法。 无论是JDK内置的 Runnable 、 Comparator 接口还是自定义的接口，只有当接口中的抽象方法存在且唯一 时，才可以使用Lambda。 使用Lambda必须具有上下文推断。 也就是方法的参数或局部变量类型必须为Lambda对应的接口类型，才能使用Lambda作为该接口的实例。 有且仅有一个抽象方法的接口，称为\"函数式接口\"。 函数式接口 是一个接口，符合Java接口的定义 只包含一个抽象方法的接口 可以包括其他的default方法、static方法、private方法 由于只有一个未实现的方法，所以Lambda表达式可以自动填上这个尚未实现的方法 采用Lambda表达式，可以自动创建出一个(伪)嵌套类的对象(没有实际的嵌套类class文件产生)，然后使用，比真正嵌套类更加轻量，更加简洁高效 @FunctionalInterface注解 一旦使用该注解来标记接口，编译器将会强制检查该接口是否确实有且仅有一个抽象方法，否则编译将会报错。 @FunctionalInterface public interface SuperRunnable { void superRun(); } public static void main(String[] args) { superRun(()-> System.out.println(\"hello world\")); } private static void superRun(SuperRunnable sr){ sr.superRun(); } 尽量使用系统自带的函数式接口，不要自己定义 接口 参数 返回值 示例 Predicate T Boolean 接收一个参数，返回一个布尔值 Consumer T void 接受一个参数，无返回 Function T R 接受一个参数，返回一个值 Supplier None T 无参数 返回一个值 方法引用 Class::staticMethod，如 Math::abs方法 Math::abs 等价于 x -> Math.abs(x) Class::instanceMethod，如String::compareToIgnoreCase方法 String::compareToIgnoreCase等价于(x,y)->x.compareToIgnoreCase(y) object::instanceMethod，如System.out::println方法 System.out::println等价于x->System.out.println(x) 支持this::instanceMethod 调用 支持super::instanceMethod 调用 Class::new，调用某类构造函数，支持单个对象构建 Supplier sp = Object::new Class[]::new，调用某类构造函数，支持数组对象构建 Function f = Object[]::new 应用 类型信息 被赋值后，可以看作是一个函数式接口的实例(对象) 但是Lambda表达式没有存储目标类型(target type)的信息 重载调用，依据重载的规则和类型参数推理 变量遮蔽 Lambda表达式可以访问外部嵌套块的变量 但是变量要求是final或者是effectively final的 在Lambda表达式中，不可以声明与(外部嵌套块)局部变量同名的参数或者局部变量 表达式中的this，就是创建这个表达式的方法的this参数 优先级比嵌套类要高 无法创建命名实例，无法获取自身的引用(this) 方法引用比自定义Lambda表达式的优先级高 系统自带的方法引用更简洁高效 对于复杂的Lambda表达式，采用方法引用比内嵌Lambda表达式更清晰，更容易维护 坚持使用标准的函数式接口 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-04 01:43:36 "},"编程语言/JAVA/高级/Stream流.html":{"url":"编程语言/JAVA/高级/Stream流.html","title":"Stream 流","keywords":"","body":"Stream sequence of elements: 一个流对外提供一个接口，可以访问到一串特定的数据。流不存储元素，但是可以根据需要进行计算转化 source：数据来源，如数据结构，数组，文件等 aggregate operation：聚合操作，流支持像SQL操作或者其他函数式语言的操作，如filter/map/reduce/find/match/sorted等 Pipelining: 中间操作都会返回流对象本身。 这样多个操作可以串联成一个管道， 如同流式风格（ﬂuent style）。 这样做可以对操作进行优化， 比如延迟执行(laziness)和短路( short-circuiting)。 Internal Iteration： 以前对集合遍历都是通过Iterator或者增强for的方式, 显式的在集合外部进行迭代， 这叫做外部迭代。 Stream提供了内部迭代的方式，流可以直接调用遍历方法。 处理流程 流的创建 流的转换，将流转换为其他流的中间操作，可包括多个步骤(惰性操作) 流的计算结果。这个操作会强制执行之前的惰性操作。这个步骤以后，流就再也不用了 获取流 Stream类 of 方法，直接将数组转化 Stream integerStream = Stream.of(1, 2, 3); empty方法，产生一个空流 generate 方法，接收一个Lambda表达式 Stream stream = Stream.generate(Math::random); iterate方法，接收一个种子，和一个Lambda表达式 Stream iterate = Stream.iterate(BigInteger.ZERO, n -> n.add(BigInteger.ONE)); 根据Collection获取 Stream stream = list.stream(); 根据Map获取流 Stream keyStream = map.keySet().stream(); Stream valueStream = map.values().stream(); Stream> entryStream = map.entrySet().stream(); 基本类型流 IntStream，LongStream，DoubleStream 并行流 使得所有的中间转换操作都将被并行化 Collections.parallelStream()将任何集合转为并行流 Stream.parallel()方法，产生一个并行流 流的方法 延迟方法：返回值类型仍然是 Stream 接口自身类型的方法，因此支持链式调用。（除了终结方法外，其余方 法均为延迟方法。） 终结方法：返回值类型不再是 Stream 接口自身类型的方法，因此不再支持类似 StringBuilder 那样的链式调 用。本小节中，终结方法包括 count 和 forEach 方法。 转换方法 过滤filter filter(Predicate predicate) 接收一个Lambda表达式，对每个元素进行判定，符合条件留下 去重distinct 对流的元素进行过滤，去除重复，只留下不重复的元素 对象的判定，先调用hashCode方法，再调用equals方法 排序sorted 提供Comparator，对流的元素进行排序 map 利用方法引用对流每个元素进行函数计算 Stream.of(1,2,3) .map(String::valueOf) .forEach(System.out::println); // [\"1\",\"2\",\"3\"] flatMap 对结果进行展开 抽取limit 只取前n个 跳过skip 跳过前n个 连接concat Stream.concat(s1,s2); // 连接两个流 额外调试peek 可以对流操作，但是不影响它 Optional Optional 一个包装器对象 要么包装了类型T的对象，要么没有包装任何对象 如果T有值，那么直接返回T的对象 如果T是null，那么可以返回一个替代物 使用 get方法，获取值，不安全的用法 orElse方法，获取值，如果为null，采用替代物的值 orElseGet方法，获取值，如果为null，采用Lambda表达式值返回 orElseThrow方法，获取值，如果为null，抛出异常 ifPresent方法，判断是否为空，不为空返回true isPresent(Consumer), 判断是否为空，如果不为空，则进行后续Consumer操作,如果为空，则不做任何事情 map(Function), 将值传递给Function函数进行计算。如果为空，则不计算 注意事项 直接使用get，很容易引发NoSuchElementException异常 使用isPresent判断值是否存在，这和判断null是一样的低效 终结方法 聚合函数 count(), 计数 max(Comparator)，最大值，需要比较器 min(Comparator)，最小值，需要比较器 findFirst(), 找到第一个元素 findAny(), 找到任意一个元素 anyMatch(Predicate)，如有任意一个元素满足Predicate，返回true allMatch(Predicate)，如所有元素满足Predicate，返回true noneMatch(Predicate)，如没有任何元素满足Predicate，返回true 归约函数 reduce，传递一个二元函数BinaryOperator，对流元素进行计算 如求和、求积、字符串连接 迭代函数 iterator() ：获取一个迭代器 forEach(Consumer)，应用一个函数到每个元素上 收集函数 toArray()，将结果转为数组 collect(Collectors.toList()),将结果转为List collect(Collectors.toSet()),将结果转为Set collect(Collectors.toMap()), 将结果转为Map collect(Collectors.joining()), 将结果连接起来 优点 统一转换元素 过滤元素 利用单个操作合并元素 将元素序列存放到某一个集合中 搜索满足某些条件的元素的序列 类似SQL操作，遵循“做什么而非怎么做”原则 简化了串行/并行的大批量操作 与循环迭代比较 Stream广泛使用Lambda表达式，只能读取外围的final或者effectivelyfinal变量，循环迭代代码可以读取/修改任意的局部变量 在循环迭代代码块中，可以随意break/continue/return，或者抛出异常，而Lambda表达式无法完成这些事情 注意事项 一个流，一次只能一个用途，不能多个用途，用了不能再用 避免创建无限流 注意操作顺序 谨慎使用并行流 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-04 01:53:04 "},"编程语言/JAVA/高级/JAVA模块化.html":{"url":"编程语言/JAVA/高级/JAVA模块化.html","title":"Java 模块化","keywords":"","body":"模块化 模块化的访问控制通过类加载过程来完成 JDK8之前jar的缺陷 jar文件无法控制别人访问其内部的public的类 无法控制不同jar包中，相同的类名(包名+类名) Java运行时，无法判定classpath路径上的jar中有多少个不同版本 的文件。Java加载第一个符合名字的类 Java运行时，无法预判classpath路径上是否缺失了一些关键类 兼容Java9 之前 所有类路径下的JAR文件及其他资源文件，都被视为自动打包在一个匿名模块（Unnamed Module）里，这个匿名模块几乎是没有任何隔离的，它可以看到和使用类路径上所有的包、JDK系统模块中所有的导出包，以及模块路径上所有模块中导出的包 模块路径下的具名模块（Named Module）只能访问到它依赖定义中列明依赖的模块和包，匿名模块里所有的内容对具名模块来说都是不可见的 如果把一个传统的、不包含模块定义的JAR文件放置到模块路径中，它就会变成一个自动模块（Automatic Module）。尽管不包含module-info.class，但自动模块将默认依赖于整个模块路径中的所有模块 模块化下的类加载器 扩展类加载器（Extension Class Loader）被平台类加载器（Platform Class Loader）取代 新版的JDK也没了jre 现在可以用过jlink打包出一个jre： jlink -p $JAVA_HOME/jmods --add-modules java.base --output jre 平台类加载器和应用程序类加载器都不再派生自java.net.URLClassLoader 模块化原则 强封装性：一个模块必须能够对其他模块隐藏其部分代码 定义良好的接口：模块必须向其他模块公开定义良好且稳定的接口 显式依赖：明确一个模块需要哪些模块的支持才能完成工作 Java 9 Jigsaw 以模块(module)为中心 JDK 本身进行模块化 模块系统 在模块中，仍以包-类文件结构存在 每个模块中，都有一个module-info.java jlink 步骤 在src下面建立一个目录module.hello(模块名字，可自由定) 在module.hello目录下，建立cn\\hello目录，再建立HelloWorld.java 在module.hello目录下，建立一个module-info.java module-info.java module module.hello { // 模块名 requires java.base; // 需要的模块 exports module.hello.wang.ismy.module; // 导出的模块 } 单纯requires，模块依赖不会传递 requires transitive java.net.http; // 传递依赖 requires java.se; // 调用一个聚合模块 exports module.hello.wang.ismy.module to java.xml; // 导出的模块只限定java.xml用 open exports导出的包的public部分可以反射，其他权限修饰的内容和未导出的内容无法反射(setAccessible(true)也无效) opens可以打开一些包，其他模块可以反射调用这些包及内容 open module module.hello { // 开放整个模块 opens wang.ismy.module; // 开放某个包 } 服务 provides提供接口，with实现类(不导出) uses消费接口 ServiceLoader加载接口的实现类 module module1 { exports wang.ismy.module1; provides wang.ismy.module1.Service with wang.ismy.module1.impl.ServiceImpl, wang.ismy.module1.impl.ServiceImpl2; } module module2 { requires module1; uses wang.ismy.module1.Service; } 使用 ServiceLoader serviceLoader = ServiceLoader.load(Service.class); for (Service service : serviceLoader) { service.run(); } 特点 从根源上对JDK进行模块化，降低最终程序运行时负载 在jar层上增加一个module机制 引入exports/requires/opens明确模块边界和依赖关系，程序更隐私安全 引入服务provides/uses使得程序更解耦 –jlink制作运行时映像，使运维更高效 OSGI 动态JAVA模块化系统 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-27 06:32:23 "},"编程语言/JAVA/高级/JDBC.html":{"url":"编程语言/JAVA/高级/JDBC.html","title":"JDBC","keywords":"","body":"JDBC Java数据库连接，（Java Database Connectivity，简称JDBC）是Java语言中用来规范客户端程序如何来访问数据库的应用程序接口，提供了诸如查询和更新数据库中数据的方法。JDBC也是Sun Microsystems的商标。JDBC是面向关系型数据库的。 常用类 接口或类 作用 DriverManager 类 1) 管理和注册数据库驱动 2) 得到数据库连接对象 Connection 接口 一个连接对象，可用于创建 Statement 和 PreparedStatement 对象 Statement 接口 一个 SQL 语句对象，用于将 SQL 语句发送给数据库服务器。 PreparedStatemen 接口 一个 SQL 语句对象，是 Statement 的子接口 ResultSet 接口 用于封装数据库查询的结果集，返回给客户端 Java 程序 从 JDBC3 开始，目前已经普遍使用的版本。可以不用注册驱动而直接使用。Class.forName 这句话可以省略 数据类型 经典查询 try(Connection connection = DriverManager.getConnection(\"jdbc:mysql:///test?user=root&password=123\")){ ResultSet rs = connection.createStatement().executeQuery(\"select * from account\"); while (rs.next()){ System.out.println(rs.getString(\"name\")+\"|\"+rs.getDouble(\"balance\")); } }catch (SQLException e){ e.printStackTrace(); } SQL注入与PreparedStatement 使用 PreparedStatement 避免 SQL注入 事务控制 connection.setAutoCommit(false); connection.commit(); connection.rollback(); 数据库连接池 数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个；释放空闲时间超过最大空闲时间的数据库连接来避免因为没有释放数据库连接而引起的数据库连接遗漏。这项技术能明显提高对数据库操作的性能。 c3p0 druid 参数 空闲线程数：初始化线程，还没被使用 活动线程数：正在被使用的 最大线程数：限制最多只能创建的线程数 JDBCUtils 提供静态代码块加载配置文件，初始化连接池对象 提供方法 获取连接方法：通过数据库连接池获取连接 释放资源 获取连接池的方法 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-04 02:27:34 "},"编程语言/JAVA/高级/语法糖.html":{"url":"编程语言/JAVA/高级/语法糖.html","title":"语法糖","keywords":"","body":" 语法糖（Syntactic sugar）是由英国计算机科学家彼得·兰丁发明的一个术语，指计算机语言中添加的某种语法，这种语法对语言的功能没有影响，但是更方便程序员使用。语法糖让程序更加简洁，有更高的可读性。 ForEach for(type element: array){ System.out.println(element); } 枚举 public enum Size{ SMALL,MEDIUM,LARGE; } Enum的子类 有多少值，则有多少实例对象 无法直接创建 可以添加属性、构造函数、方法 构造函数只能为私有 不定项参数 public void method(String a,String...b){ } 固定参数重载优先级比不定项高 静态导入 import static org.junit.Assert.*; 导入一个类的静态方法与静态变量 自动装拆箱 Integer a = 1; 该功能由编译器提供 基础类型与封装类型运算时，会触发拆装箱 多异常并列 try{ //... }catch(Exception1 | Exception2 e){ //... } 不能有直接或间接的继承关系 数值新特性 int a = 0b11100111; // 可直接使用二进制 int b = 9999_99999; // 可使用下划线分割 接口方法 default boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { return true; } 接口静态方法 public interface Runnable { static void run(){ System.out.println(\"!111\"); } } 只能通过接口名来调用 接口私有方法 public interface Runnable { static void run(){ say(); } private static void say(){ System.out.println(\"say\"); } } try-with-resource try(FileOutputStream fos = new FileOutputStream(\"\")){ //JDK7 } catch (IOException e) { e.printStackTrace(); } FileOutputStream fos = new FileOutputStream(\"\"); // JDK9 try(fos){ } catch (IOException e) { e.printStackTrace(); } 资源类必须实现AutoCloseable接口 var var a = 1; 由编译器进行类型推断 var obj = new Object(){ public void print(){ System.out.println(\"print\"); } }; obj.print(); switch表达式 int ret= switch (a){ case 1-> 100; case 2 -> 200; default -> -1; }; MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/高级/编译器API.html":{"url":"编程语言/JAVA/高级/编译器API.html","title":"编译器API","keywords":"","body":" 对.java文件即时编译 对字符串即时编译 监听编译与错误 编译文件 JavaCompiler javaCompiler = ToolProvider.getSystemJavaCompiler(); javaCompiler.run(null,null,null,\"path\"); 编译字符串 private static Class compile(String className, String javaCodes) { //将字符串包装为SimpleJavaFileObject对象 JavaSourceFromString srcObject = new JavaSourceFromString(className, javaCodes); System.out.println(srcObject.getCode()); Iterable fileObjects = Arrays.asList(srcObject); JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); StandardJavaFileManager fileManager = compiler.getStandardFileManager(null, null, null); DiagnosticCollector diagnosticCollector = new DiagnosticCollector(); //设置编译的输出目录，并包装在options中 String flag = \"-d\"; String outDir = \"\"; try { File classPath = new File(Thread.currentThread().getContextClassLoader().getResource(\"\").toURI()); outDir = classPath.getAbsolutePath() + File.separator; System.out.println(outDir); } catch (URISyntaxException e1) { e1.printStackTrace(); } Iterable options = Arrays.asList(flag, outDir); //JavaCompiler.getTask方法：以future的任务形式(多线程)，来执行编译任务 // 第一个参数：额外输出流，null表示默认使用system.err // 第二个参数：文件管理器，null表示编译器标准文件管理器 // 第三个参数：诊断监听器，null表示使用编译器默认方法来报告诊断信息 // 第四个参数：编译器参数，null表示无参数 // 第五个参数：需要经过annotation处理的类名，null表示没有类需要annotation处理 // 第六个参数：待编译的类 JavaCompiler.CompilationTask task = compiler.getTask(null, fileManager, diagnosticCollector, options, null, fileObjects); //等待编译结束 boolean result = task.call(); if (result == true) { try { return Class.forName(className); } catch (ClassNotFoundException e) { e.printStackTrace(); } } else { //print the Diagnostic's information for (Diagnostic diagnostic : diagnosticCollector .getDiagnostics()) { System.out.println(\"Error on line: \" + diagnostic.getLineNumber() + \"; URI: \" + diagnostic.getSource().toString()); } } return null; } public class JavaSourceFromString extends SimpleJavaFileObject { private String code; public JavaSourceFromString(String name, String code) { super(URI.create(\"string:///\" + name.replace('.', '/') + Kind.SOURCE.extension), Kind.SOURCE); this.code = code; } public CharSequence getCharContent(boolean ignoreEncodingErrors) { return code; } public String getCode() { return code; } } 应用 JSP编译 在线编程 自动化构建和测试 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/高级/JAVA运行管理.html":{"url":"编程语言/JAVA/高级/JAVA运行管理.html","title":"Java 运行管理","keywords":"","body":"JAVA运行管理 OS管理 进程级别的管理(黑盒) CPU/内存/IO等具体性能监控 top命令 vmstat命令 JVM管理 线程/程序级别的管理(白盒) 查看虚拟机运行时各项信息 –跟踪程序的执行过程，查看程序运行时信息 限制程序对资源的使用 将内存导出为文件进行具体分析 JMX JMX是一个为应用程序植入管理功能的框架 用户可以在任何Java应用程序中使用这些代理和服务实现管理 MBean 代表着一个被管理的对象，类似JavaBean 对外暴露一个管理接口，即一些可读/写的属性，一些可操作的方法 Agent 外界通过Agent可以访问到MBean 优点 JMX不需要较大成本，即可管理应用程序 JMX提供一套标准化方法，来管理基于Java的应用程序/系统/网络 JMX被用来作为JVM的外在管理方式 JMX提供了一个可扩展、动态的管理架构 JMX充分利用已有的Java技术 JMX容易和现有的管理技术进行集成 JAVA运行安全 启用 System.setSecurityManager(new SecurityManager()); java –Djava.security.manager –Djava.security.policy=My.policy HelloWorld 安全策略文件 建立代码来源和访问权限的关系 permission java.io.FilePermission “/tmp/*”, “read, write” FilePermission p = new FilePermission(\"/tmp/*\",\"read,write\"); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/JAVA源码解析/JAVA源码解析.html":{"url":"编程语言/JAVA/JAVA源码解析/JAVA源码解析.html","title":"Java 源码解析","keywords":"","body":"JAVA源码解析 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 08:00:00 "},"编程语言/JAVA/JAVA源码解析/基础.html":{"url":"编程语言/JAVA/JAVA源码解析/基础.html","title":"基础","keywords":"","body":"基础 String String不可变的原因 String内部是实现byte数组实现的 private final byte[] value; 并且这个数组一旦赋上值，就无法再修改这个数组的引用了，同时String封装的很好，没有提供外部公开接口能直接操作这个数组，并且String类为final的，保证不会被继承，方法也不会被覆写，所以String不可变 equals原理 if (this == obj){ return true; } if (obj instanceof String){ if (this.value.length == obj.value.length){ for(0...obj.length){ if (this.value[i] != obj.value[i]){ return false; } } } } return false; 问：如何解决 String 乱码 选择可以表示中文的字符集 在可以指定字符集的地方指定字符集 Long Long与Integer一样，都对一定范围内的值做了缓存，所以有些Long对象，数值相同的情况下，直接用==比较会相等 问：为什么使用 Long 时，大家推荐多使用 valueOf 方法，少使用 parseLong 方法 答：valueOf有做缓存 常用关键字 static 修饰类变量 注意线程安全问题 修饰方法 方法可以通过类直接调用 修饰代码块 使用到静态变量的代码块可以在任何位置 初始化时机 父类的静态变量和静态块比子类优先初始化； 静态变量和静态块比类构造器优先初始化。 问：如何证明 static 静态变量和类实例无关 答：不需要创建该类的实例就可以使用静态变量与静态方法 问：变量和方法被 static 和 final 两个关键字修饰，为什么这么做 答：static可以直接使用这些方法与变量，final则是变量地址不可变，方法不可覆写，提升稳定性 问：atch 中发生了未知异常，finally 还会执行么 答：会，但是异常会被catch吞掉 final 被 final 修饰的类，表明该类是无法继承的； 被 final 修饰的方法，表明该方法是无法覆写的； 被 final 修饰的变量，说明该变量在声明的时候，就必须初始化完成，而且以后也不能修改其内存地址 第三点无法修改内存地址指的是无法修改引用，而不代表引用所指的对象内部无法修改 try、catch、finally 代码的执行顺序为：try -> catch -> finally volatile 常用来修饰某个共享变量，意思是当共享变量的值被修改后，会及时通知到其它线程上，其它线程就能知道当前共享变量的值已经被修改了 出现这种情况主要是因为JAVA的内存模型中的线程拥有一个工作区，线程对共享变量的读写都要先将变量从主存拉到工作区对其修改，修改后再将其写回到主存 transient 常用来修饰类变量，意思是当前变量是无需进行序列化的 default 加在接口的方法上，修饰之后该方法就代表是一个默认实现，如果其他类继承该接口，就可以不用实现该方法，直接使用这个默认实现 jdk常用工具类 Arrays sort 使用的双轴快速排序 binarySearch copyOf、copyOfRange Collections min、max 这里可以学习一下最值方法返回值泛型的定义： public static > T max 代表T必须继承自Object且实现了Comparable接口 包装线程安全的集合 synchronized打头的方法可以将指定的集合包装成线程安全的集合 具体原理是Collections内部有这些对应的线程安全集合，这些集合内部组合线程不安全的集合，通过synchronized加锁来操作内部的这些集合 不可变集合 unmodifiable 打头的方法则是会得到一些不可变集合，这些集合不能执行修改操作，否则会抛异常，也是通过对集合的包装来实现的 Objects equals Objects的equals内部的比较采用了deepEquals，这样即使两个对象是数组，也能放心比较 一些判空方法 问：如何写好一个工具类 答： static final 关键字对方法进行修饰，工具类构造器必须是私有等等手段 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-19 08:25:46 "},"编程语言/JAVA/JAVA源码解析/集合.html":{"url":"编程语言/JAVA/JAVA源码解析/集合.html","title":"集合","keywords":"","body":"集合 类层次结构 可以学习人家的接口是怎么划分的，这个类虽然接口众多，但是职责却很清晰 以及人家是如何复用已有的代码来实现新功能 注意事项 线程安全 Collections 帮我们实现了 List、Set、Map 对应的线程安全的方法 synchronized打头的方法可以将指定的集合包装成线程安全的集合 集合性能 批量新增 在 List 和 Map 大量数据新增的时候，我们不要使用 for 循环 + add/put 方法新增，这样子会有很大的扩容成本，我们应该尽量使用 addAll 和 putAll 方法进行新增 批量删除 ArrayList的remove方法，删除之后都会对被删除位置的元素进行移动，如果进行循环remove，会造成性能问题，可以采用removeAll方法，这个批量删除接口只会对数组的元素移动一次 集合的坑 Arrays.asList(array),当array被修改时，会造成list也被修改 toArray 方法如果声明的数组小于list长度，会得到一个空数组 JAVA7到JAVA8集合的升级 所有集合都新增了forEach 方法 JAVA7中ArrayList无参初始化是直接初始化10，JAVA8无参初始化则是一个空数组 JAVA7中的HashMap无参初始化的大小是16，JAVA8无参初始化则是一个空数组，并且引入了红黑树，并且增加了xxIfAbsent等方法 Arrays 提供了很多 parallel 开头的方法，这些方法支持并行计算 Guava 工厂模式初始化 HashMap map = Maps.newHashMap(); Lists ArrayList list = Lists.newArrayList(); ArrayList objects = Lists.newArrayListWithCapacity(10); // 不知道精确值，给出一个模糊值 ArrayList objects1 = Lists.newArrayListWithExpectedSize(20); // 反转一个list，并非物理反转，而是通过对传入index的处理实现的 var list = Lists.reverse(list) // list拆分 var list = Lists.partition(list,3) Maps MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 08:00:00 "},"编程语言/JAVA/JAVA源码解析/List.html":{"url":"编程语言/JAVA/JAVA源码解析/List.html","title":"List","keywords":"","body":"List源码解析 ArrayList 架构 DEFAULT_CAPACITY 表示数组的初始大小，默认是 10 size 表示当前数组的大小 modCount 统计当前数组被修改的版本次数，数组结构有变动，就会 +1 解析 初始化 一共有三种方式可以初始化ArrayList public ArrayList(Collection c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // 直接将传入的集合转成数组复制给内部数组 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { this.elementData = {}; } } public ArrayList() { this.elementData = {}; } public ArrayList(int initialCapacity) { if (initialCapacity > 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = {}; } else { throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); } } 新增与扩容 添加元素时： 判断是否需要扩展，如果需要则只需扩容 添加 // 这个版本是基于JDK13的 private void add(E e, Object[] elementData, int s) { // 当发现现在list的size跟数组容量一样大时，则进行扩容 if (s == elementData.length) // 这里扩容完，会产生一个新数组，我们要将新数组保存 elementData = grow(size+1); //添加index:size elementData[s] = e; size = s + 1; } // 扩容核心代码 private Object[] grow(int minCapacity) { int oldCapacity = elementData.length; // 只有数组不为空时，才进行扩容，否则直接创建 if (oldCapacity > 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { // 计算数组的新容量 int newCapacity = ArraysSupport.newLength(oldCapacity, minCapacity - oldCapacity, /* minimum growth */ oldCapacity >> 1 /* preferred growth */); // 复制老数组到新数组 return elementData = Arrays.copyOf(elementData, newCapacity); } else { return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)]; } } // 计算容量的方法 public static int newLength(int oldLength, int minGrowth, int prefGrowth) { // 判断list的size与elementData的差值如果大于elementData长度的一半 // 新数组长度就等于老数组长度加上list的size与elementData的差值 // 否则新数组的长度就等于老数组的1.5倍 int newLength = Math.max(minGrowth, prefGrowth) + oldLength; if (newLength - MAX_ARRAY_LENGTH 所以扩容的本质就是申请一个更大的数组，将旧数组的内容移过去 源码扩容过程值得借鉴的地方 通过自动扩容的方式，让使用者不用关心底层数据结构的变化，封装得很好 1.5 倍的扩容速度，可以让扩容速度在前期缓慢上升，在后期增速较快 扩容过程中，注意数组大小溢出的情况 删除 无论是根据Object删除还是index删除，都必须给出被删除元素的index private void fastRemove(Object[] es, int i) { modCount++; final int newSize; if ((newSize = size - 1) > i) // 将elementData 下标为i后面的全部元素往前移动一个位 System.arraycopy(es, i + 1, es, i, newSize - i); // 如果删除的是最后一个元素，置为null就行 es[size = newSize] = null; // 同时记得size-1 } 迭代器 hasNext public boolean hasNext() { return cursor != size; } next public E next() { // 有点乐观锁的意思，通过版本号来确定持有的数据是否被修改了 if (modCount != expectedModCount) throw new ConcurrentModificationException(); // 否则每次根据游标获取元素，获取完游标+1 int i = cursor; if (i >= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i >= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; } remove public void remove() { if (lastRet 线程安全 ArrayList 有线程安全问题的本质，是因为 ArrayList 自身的 elementData、size、modConut 在进行各种操作时，都没有加锁 问：对 ArrayList 的理解？ 答：底层数据结构、对数组的封装、add、remove 问：为什么说扩容会消耗性能 答：扩容底层使用的是 System.arraycopy 方法，会把原数组的数据全部拷贝到新数组上，所以性能消耗比较严重 LinkedList 架构 LinkedList 底层数据结构是一个双向链表 解析 node的结构 private static class Node { E item; Node next; Node prev; Node(Node prev, E element, Node next) { this.item = element; this.next = next; this.prev = prev; } } 尾部追加节点 void linkLast(E e) { final Node l = this.last; final Node newNode = new Node<>(l, e, null); this.last = newNode; // 如果尾节点为空，则代表当前链表是空的，直接把插入节点作为头节点 if (l == null) first = newNode; else l.next = newNode; // 否则就将插入节点设置为尾节点，并且把旧尾节点的next指向插入节点 size++; modCount++; } 头部追加节点 private void linkFirst(E e) { final Node f = this.first; final Node newNode = new Node<>(null, e, f); this.first = newNode; // 如果头节点为空，则代表当前链表是空的，直接把插入节点作为尾节点 if (f == null) last = newNode; else f.prev = newNode; // 否则就将插入节点设置为头节点，并且把旧头节点的prev指向插入节点 size++; modCount++; } 删除节点 E unlink(Node x) { // assert x != null; final E element = x.item; final Node next = x.next; final Node prev = x.prev; // 当前删除的是头节点，所以将删除节点的next变为头节点 if (prev == null) { first = next; } else { // 否则设置删除节点的上一个节点的next指向删除节点的next prev.next = next; x.prev = null; } // 当前删除的是尾节点，所以将删除节点的prev变为尾节点 if (next == null) { last = prev; } else { // 否则设置删除节点的下一个节点的prev指向删除节点的prev next.prev = prev; x.next = null; } x.item = null; size--; modCount++; return element; } 根据下标查询节点 Node node(int index) { // assert isElementIndex(index); if (index > 1)) { // 在前半部分，所以从头节点迭代查找 Node x = first; for (int i = 0; i x = last; for (int i = size - 1; i > index; i--) x = x.prev; return x; } } 迭代器 // 双向迭代器 private class ListItr implements ListIterator { private Node lastReturned;//上一次执行 next() 或者 previos() 方法时的节点位置 private Node next;//下一个节点 private int nextIndex;//下一个节点的位置 ………… } 从头到尾迭代 public boolean hasNext() { return nextIndex 从尾到头迭代 public boolean hasPrevious() { return nextIndex > 0; } public E previous() { checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); // 主要是判断next为空的情况下要选择last作为遍历节点，否则选择遍历元素的prev lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item; } 删除 public void remove() { checkForComodification(); // lastReturned 是本次迭代需要删除的值，分以下空和非空两种情况： // lastReturned 为空，说明调用者没有主动执行过 next() 或者 previos()，直接报错 // lastReturned 不为空，是在上次执行 next() 或者 previos()方法时赋的值 if (lastReturned == null) throw new IllegalStateException(); Node lastNext = lastReturned.next; //删除当前节点 unlink(lastReturned); // next == lastReturned 的场景分析：从尾到头递归顺序，并且是第一次迭代，并且要删除最后一个元素的情况下 // 这种情况下，previous() 方法里面设置了 lastReturned = next = last,所以 next 和 lastReturned会相等 if (next == lastReturned) // 这时候 lastReturned 是尾节点，lastNext 是 null，所以 next 也是 null，这样在 previous() 执行时，发现 next 是 null，就会把尾节点赋值给 next next = lastNext; else nextIndex--; lastReturned = null; expectedModCount++; } 问：ArrayList 和 LinkedList 有何不同 答：底层数据结构，数组结构导致的读写差异 问： ArrayList 和 LinkedList 应用场景 答：ArrayList 更适合于快速的查找匹配，不适合频繁新增删除，像工作中经常会对元素进行匹配查询的场景比较合适，LinkedList 更适合于经常新增和删除，对查询反而很少的场景 问：ArrayList 和 LinkedList 两者有没有最大容量 答：两个都有最大容量，是int的最大值，原因是ArrayList使用的数组容量不能超过int最大值，LinkedList则是因为size使用int表示的，所以也不能超过int的最大值 问：ArrayList 和 LinkedList 是如何对 null 值进行处理的 答：ArrayList 允许 null 值新增，也允许 null 值删除。删除 null 值时，是从头开始，找到第一值是 null 的元素删除；LinkedList 新增删除时对 null 值没有特殊校验，是允许新增和删除的 问：ArrayList 和 LinedList 是线程安全的么，为什么 答：都非线程安全，主要的问题点在于多线程环境下，所有线程任何时刻都可对数组和链表进行操作，这会导致值被覆盖，甚至混乱的情况 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-20 07:33:45 "},"编程语言/JAVA/JAVA源码解析/Map.html":{"url":"编程语言/JAVA/JAVA源码解析/Map.html","title":"Map","keywords":"","body":"Map源码解析 HashMap 允许 null 值，不同于 HashTable ，是线程不安全的 load factor（影响因子） 默认值是 0.75， 是均衡了时间和空间损耗算出来的值 如果有很多数据需要储存到 HashMap 中，建议 HashMap 的容量一开始就设置成足够的大小，这样可以防止在其过程中不断的扩容，影响性能 在迭代过程中，如果 HashMap 的结构被修改，会快速失败 架构 操作 新增 1.空数组有无初始化，没有的话初始化； 2.如果通过 key 的 hash 能够直接找到值，跳转到 6，否则到 3； 3.如果 hash 冲突，两种解决方案：链表 or 红黑树； 4.如果是链表，递归循环，把新元素追加到队尾； 5.如果是红黑树，调用红黑树新增的方法； 6.通过 2、4、5 将新元素追加成功，再根据 onlyIfAbsent 判断是否需要覆盖； 7.判断是否需要扩容，需要扩容进行扩容，结束。 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node[] tab; Node p; int n, i; // 如果数组为空，那就初始化数组 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 如果根据hashCode得到的索引位置为空，直接将新节点放到该节点 if ((p = tab[i = (n - 1) & hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node e; K k; // 如果现在索引位置的hash值与key都相等，直接将新节点放在这里 if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k)))) e = p; // 否则就需要追加节点到当前索引位置节点的后面（链表或者红黑树） // 如果是红黑树，那就调用红黑树的增加方法 else if (p instanceof TreeNode) e = ((TreeNode)p).putTreeVal(this, tab, hash, key, value); else { // 否则就是链表，进行遍历 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } // 当遍历的节点hash值与key都相等时，那新节点就是放在这里 if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) break; p = e; } } // 这里的e如果不为null，那就代表插入的这个key中是有值得，根据传入的onlyIfAbsent决定是否覆盖 if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } // 维护HashMap的其他状态信息 ++modCount; if (++size > threshold) // size达到一定的程度，就需要扩容 resize(); afterNodeInsertion(evict); return null; } 链表转为红黑树 只有当链表长度大于等于8，并且整个数组长度大于等于64时，才会进行链表转红黑树 至于为什么是8，链表查询的时间复杂度是 O (n)，红黑树的查询复杂度是 O (log (n))。在链表数据不多的时候，使用链表进行遍历也比较快，只有当链表数据比较多的时候，才会转化成红黑树，但红黑树需要的占用空间是链表的 2 倍，考虑到转化时间和空间损耗，8是最合适的 红黑树的插入 final TreeNode putTreeVal(HashMap map, Node[] tab, int h, K k, V v) { Class kc = null; boolean searched = false; // 找到根节点 TreeNode root = (parent != null) ? root() : this; // 遍历 for (TreeNode p = root;;) { int dir, ph; K pk; // 说明应该插在当前遍历节点的右子树 if ((ph = p.hash) > h) dir = -1; // 说明应该插在当前遍历节点的左子树 else if (ph q, ch; searched = true; if (((ch = p.left) != null && (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null && (q = ch.find(h, k, kc)) != null)) return q; } dir = tieBreakOrder(k, pk); } // 插入新节点 TreeNode xp = p; if ((p = (dir xpn = xp.next; TreeNode x = map.newTreeNode(h, k, v, xpn); if (dir )xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; } } } 着色是指红黑树的节点着上红色或黑色，旋转是为了让红黑树更加平衡，提高查询的效率，总的来说都是为了满足红黑树的 5 个原则： 节点是红色或黑色 根是黑色 所有叶子都是黑色 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点 从每个叶子到根的所有路径上不能有两个连续的红色节点 查找 1.根据 hash 算法定位数组的索引位置，equals 判断当前节点是否是我们需要寻找的 key，是的话直接返回，不是的话往下。 2.判断当前节点有无 next 节点，有的话判断是链表类型，还是红黑树类型。 3.分别走链表和红黑树不同类型的查找方法 链表查找 do { // 遍历，看遍历的节点的key是否与查找的key相等 if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) return e; } while ((e = e.next) != null); 红黑树查找 final TreeNode find(int h, Object k, Class kc) { TreeNode p = this; do { int ph, dir; K pk; TreeNode pl = p.left, pr = p.right, q; // hash比当前节点小，往左子树寻找 if ((ph = p.hash) > h) p = pl; // hash比当前节点大，往左右树寻找 else if (ph TreeMap TreeMap 底层的数据结构就是红黑树，TreeMap 利用了红黑树左节点小，右节点大的性质，根据 key 进行排序，使每个元素能够插入到红黑树大小适当的位置，维护了 key 的大小关系 新增 public V put(K key, V value) { Entry t = root; // 根节点为空，直接将插入节点作为根节点 if (t == null) { compare(key, key); // type (and possibly null) check root = new Entry<>(key, value, null); size = 1; modCount++; return null; } int cmp; Entry parent; // split comparator and comparable paths Comparator cpr = comparator; if (cpr != null) { // 遍历找到插入节点应该插入的位置，parent保存了该位置的父节点 do { parent = t; cmp = cpr.compare(key, t.key); if (cmp 0) t = t.right; else return t.setValue(value); } while (t != null); } else { // 实现了Comparable的情况下的比较 if (key == null) throw new NullPointerException(); @SuppressWarnings(\"unchecked\") Comparable k = (Comparable) key; do { parent = t; cmp = k.compareTo(t.key); if (cmp 0) t = t.right; else return t.setValue(value); } while (t != null); } Entry e = new Entry<>(key, value, parent); if (cmp LinkedHashMap LinkedHashMap 本身是继承 HashMap 的，所以它拥有 HashMap 的所有特性，再此基础上，还提供了两大特性： 按照插入顺序进行访问； 实现了访问最少最先删除功能 按照插入顺序新增 // 通过在创建新节点时，把这个节点加到一个链表的最尾部来维护插入顺序 Node newNode(int hash, K key, V value, Node e) { LinkedHashMap.Entry p = new LinkedHashMap.Entry<>(hash, key, value, e); linkNodeLast(p); return p; } private void linkNodeLast(LinkedHashMap.Entry p) { LinkedHashMap.Entry last = tail; tail = p; if (last == null) head = p; else { p.before = last; last.after = p; } } 按照插入顺序访问 // 跟链表的迭代器一样 final LinkedHashMap.Entry nextNode() { LinkedHashMap.Entry e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); current = e; next = e.after; return e; } 最少访问删除的实现 在get之后，LinkedHashMap会对获取到的节点执行移到链表尾部的操作 public V get(Object key) { Node e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value; } // 这段代码是负责把e移到末尾 // 这样就队头的元素就是访问最少的元素 void afterNodeAccess(Node e) { // move node to last LinkedHashMap.Entry last; if (accessOrder && (last = tail) != e) { LinkedHashMap.Entry p = (LinkedHashMap.Entry)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else { p.before = last; last.after = p; } tail = p; ++modCount; } } 问题 HashMap 底层数据结构 底层采用了数组、链表、红黑树来实现的 数组的主要作用是查找，时间复杂度为O(1)，默认大小16，元素存放的下标是根据key的hashCode计算出来的 元素存放在Node里面，当key的hashCode一样时，但是key并不相等，Node就会串起来，形成链表，链表的时间复杂度是O(N) 当链表长度大于等于8且数组长度大于等于64时，链表就会转成红黑树，红黑树的时间复杂度为O(lg n) HashMap、TreeMap、LinkedHashMap 三者有啥相同点，有啥不同点 相同点： 都使用了红黑树 hash算法相同 都非线程安全 不同点： HashMap数据结构以数组为主，查询速度快，TreeMap利用了红黑树左小右大的特点，可以实现对key的排序，LinkedHashMap则增加了链表的结构，实现了顺序访问以及最少访问删除 hash算法 n=array.length; tab[i = (n - 1) & hash] 取模算法的好处，就是可以保证计算出来的索引下标值可以均匀的分布在数组的各个索引位置上 当 b 是 2 的幂次方时，a % b = a &（b-1） 解决hash冲突的办法 好的hash算法 自动扩容 冲突后使用链表与红黑树 HashMap 是如何扩容的 put时，发现数组为空，初始化扩容，默认大小16 put成功后，发现数组大于现在数组的容量*0.75，会进行扩容，每次扩容为原来数组大小的两倍 扩容之后，需要对数组中的Node节点重新计算hash值，重新放置 对象作为 Map 的 key 时，需要注意的点 一定需要覆写 equals 和 hashCode 方法，如果是 TreeMap 的话，需要实现 Comparable 接口 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-05 01:59:24 "},"编程语言/JAVA/JAVA源码解析/Set.html":{"url":"编程语言/JAVA/JAVA源码解析/Set.html","title":"Set","keywords":"","body":"Set源码解析 HashSet、TreeSet 两个类是在 Map 的基础上组装起来的类 HashSet HashSet 使用的就是组合方式来内置 HashMap 多用组合，少用继承 操作 初始化 // 当根据传入的集合进行初始化时，会根据集合的数量计算HashMap大小 public HashSet(Collection c) { map = new HashMap<>(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); } 值得借鉴的地方 使用组合还是继承 包装复杂逻辑，暴露易用api 组合使用其他api时，要多了解组合的api TreeSet TreeSet底层组合的是 TreeMap，迭代的时候，也可以按照 key 的排序顺序进行迭代 TreeSet如何复用TreeMap的 第一种方式：直接使用 public boolean add(E e) { return m.put(e, PRESENT)==null; } 第二种方式：定义接口，交给服务提供者实现 TreeMap内部实现了NavigableSet接口来提供一些比较复杂的功能 问题 TreeSet的使用场景 一般都是在需要把元素进行排序的时候使用 TreeSet，使用时需要注意元素最好实现 Comparable 接口 如何根据 key 的新增顺序进行遍历 选择使用 LinkedHashSet 如何对 key 进行去重 使用TreeSet，TreeSet 底层使用的是 TreeMap，TreeMap 在 put 的时候，如果发现 key 是相同的，会把 value 值进行覆盖，所有不会产生重复的 key MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-20 08:04:55 "},"编程语言/JAVA/JAVA源码解析/并发集合.html":{"url":"编程语言/JAVA/JAVA源码解析/并发集合.html","title":"并发集合","keywords":"","body":"并发集合 CopyOnWriteArrayList 通过锁 + 数组拷贝 + volatile 关键字保证了线程安全，每次数组操作，都会把数组拷贝一份出来，在新数组上进行操作，操作成功之后再赋值回去 架构 在对数组进行操作的时候，基本会分四步走： 加锁； 从原数组中拷贝出新数组； 在新数组上进行操作，并把新数组赋值给数组容器； 解锁。 操作 新增 public boolean add(E e) { synchronized (lock) { // 获取真实数组 Object[] es = getArray(); int len = es.length; // 根据真实数组复制出一个数组 es = Arrays.copyOf(es, len + 1); // 在新数组上做操作 es[len] = e; // 把新数组作为真实数组 setArray(es); return true; } } 都已经加锁了，为什么需要拷贝数组？ volatile 关键字修饰的是数组，如果我们简单的在原来数组上修改其中某几个元素的值，是无法触发可见性的，我们必须通过修改数组的内存地址才行 第二个原因是get并没有加锁，通过复制一个新数组进行操作，可以防止get访问到一些数据的中间组合 在指定位置新增 public void add(int index, E element) { synchronized (lock) { Object[] es = getArray(); int len = es.length; if (index > len || index 删除 public E remove(int index) { synchronized (lock) { Object[] es = getArray(); int len = es.length; E oldValue = elementAt(es, index); int numMoved = len - index - 1; Object[] newElements; if (numMoved == 0) newElements = Arrays.copyOf(es, len - 1); else { // 复制前半部分数组同上 newElements = new Object[len - 1]; System.arraycopy(es, 0, newElements, 0, index); // 复制后半部分数组需要位置向左偏移1个单位 System.arraycopy(es, index + 1, newElements, index, numMoved); } setArray(newElements); return oldValue; } } indexOf private static int indexOfRange(Object o, Object[] es, int from, int to) { if (o == null) { // 返回第一个为null的下标 for (int i = from; i 迭代 由于CopyOnWriteArrayList的迭代器需要持有一个数组引用，所以即使在迭代的过程中对CopyOnWriteArrayList进行修改也不会抛异常 ConcurrentHashMap 操作 put final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node[] tab = table;;) { Node f; int n, i, fh; K fk; V fv; // table为空，初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 当前索引位置为空，直接存放到这里 else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { if (casTabAt(tab, i, null, new Node(hash, key, value))) break; // no lock when adding to empty bin } // 当前节点是在扩容，等待扩容完成 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else if (onlyIfAbsent // check first node without acquiring lock && fh == hash && ((fk = f.key) == key || (fk != null && key.equals(fk))) && (fv = f.val) != null) return fv; else { V oldVal = null; // 锁住当前节点 synchronized (f) { // 其他的跟HashMap差不多 if (tabAt(tab, i) == f) { // 链表添加 if (fh >= 0) { binCount = 1; for (Node e = f;; ++binCount) { K ek; if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node pred = e; if ((e = e.next) == null) { pred.next = new Node(hash, key, value); break; } } } // 红黑树添加 else if (f instanceof TreeBin) { Node p; binCount = 2; if ((p = ((TreeBin)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } else if (f instanceof ReservationNode) throw new IllegalStateException(\"Recursive update\"); } } // 新增成功 if (binCount != 0) { // 是否需要转为红黑树 if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null; } 数组初始化，如何保证只有一个线程初始化并且能初始化成功？ private final Node[] initTable() { Node[] tab; int sc; // 自旋 while ((tab = table) == null || tab.length == 0) { // 代表当前有线程在初始化，让线程调度器重新调度线程 if ((sc = sizeCtl) 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") Node[] nt = (Node[])new Node[n]; table = tab = nt; sc = n - (n >>> 2); } } finally { sizeCtl = sc; } break; } } return tab; } 新增槽点，通过自旋死循环保证一定可以新增成功。 如果当前槽点为空，通过CAS新增 槽点如果有值，会锁住当前槽点 红黑树旋转时，锁住红黑树的根节点，保证同一时刻，当前红黑树只能被一个线程旋转 扩容 首先需要把老数组的值全部拷贝到扩容之后的新数组上，先从数组的队尾开始拷贝； 拷贝数组的槽点时，先把原数组槽点锁住，保证原数组槽点不能操作，成功拷贝到新数组时，把原数组槽点赋值为转移节点； 这时如果有新数据正好需要 put 到此槽点时，发现槽点为转移节点，就会一直等待，所以在扩容完成之前，该槽点对应的数据是不会发生变化的； 从数组的尾部拷贝到头部，每拷贝成功一次，就把原数组中的节点设置成转移节点； 直到所有数组数据都拷贝到新数组时，直接把新数组整个赋值给数组容器，拷贝完成 get get跟HashMap很像 应用 流程引擎 其主要功能就是对我们需要完成的事情，进行编排和组装 通过使用List与Map来定义事件的标志与流程，这样就可以通过一个标识来获取事件的行为，可以直接调用事件行为来产生效果 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 08:00:00 "},"编程语言/JAVA/JAVA源码解析/队列.html":{"url":"编程语言/JAVA/JAVA源码解析/队列.html","title":"队列","keywords":"","body":"队列源码解析 设计思想 数据结构 入队出队方式 通信机制 强关联：take与put要互相等待 无关联：只要队列容器不满，生产者就能放成功，生产者就可以直接返回，和有无消费者一点关系都没有，生产者和消费者完全解耦 LinkedBlockingQueue 类结构层次 架构 使用链表来维护先进先出队列 分成三个部分：链表存储 + 锁 + 迭代器 操作 初始化 // 直接根据大小初始化 public LinkedBlockingQueue(int capacity) { if (capacity (null); } // 根据给定集合初始化 public LinkedBlockingQueue(Collection c) { // 初始化近乎无限的队列 this(Integer.MAX_VALUE); // put锁 final ReentrantLock putLock = this.putLock; putLock.lock(); // Never contended, but necessary for visibility try { int n = 0; // 通过循环以此对集合内的元素入列 for (E e : c) { if (e == null) throw new NullPointerException(); if (n == capacity) throw new IllegalStateException(\"Queue full\"); enqueue(new Node(e)); ++n; } // 维护队列状态信息 count.set(n); } finally { putLock.unlock(); } } 阻塞新增 public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); final int c; final Node node = new Node(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; // 可中断锁 putLock.lockInterruptibly(); try { // 当前队列满，等待 while (count.get() == capacity) { notFull.await(); } // 等待结束（此时是队列从满变为没满，被唤醒），入队 enqueue(node); // 获得上一刻队列大小 c = count.getAndIncrement(); // 如果当前队列大小仍然小于最大容量，唤醒一个put的等待线程 if (c + 1 阻塞删除 public E take() throws InterruptedException { final E x; final int c; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { // 当队列为空时，进行等待 while (count.get() == 0) { notEmpty.await(); } // 被唤醒，代表队列有数据了，出队 x = dequeue(); // 上一刻的队列大小 c = count.getAndDecrement(); // 代表队列还有数据，再唤醒一个等待take的线程 if (c > 1) notEmpty.signal(); } finally { takeLock.unlock(); } // 队列还剩一个空位，唤醒一个等待put的线程 if (c == capacity) signalNotFull(); return x; } 使用场景 适合对生产的数据大小不定（时高时低），数据量较大的场景 SynchronousQueue 其本身是没有容量大小，比如我放一个数据到队列中，我是不能够立马返回的，我必须等待别人把我放进去的数据消费掉了，才能够返回 架构 // 堆栈和队列共同的接口 // 负责执行 put or take abstract static class Transferer { // e 为空的，会直接返回特殊值，不为空会传递给消费者 // timed 为 true，说明会有超时时间 abstract E transfer(E e, boolean timed, long nanos); } // 堆栈 后入先出 非公平 // Scherer-Scott 算法 static final class TransferStack extends Transferer {} // 队列 先入先出 公平 static final class TransferQueue extends Transferer {} transfer 该方法比较复杂，总而言之，如果传进来的e是null，并且当前有一个put线程阻塞，则会返回这个put的e，并且put线程解除阻塞。否则就一直阻塞到有数据为止 反之，如果传进来的e不是null，并且有一个take线程阻塞，则将e通过节点传给take线程 DelayQueue DelayQueue 中的元素必须是 Delayed 的子类，Delayed 是表达延迟能力的关键接口，其继承了 Comparable 接口，并定义了还剩多久过期的方法 public interface Delayed extends Comparable { long getDelay(TimeUnit unit); } 操作 put public boolean offer(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { // 利用优先队列进行排序 q.offer(e); // 如果刚放进去的元素在队头 if (q.peek() == e) { leader = null; // 则会唤醒在等待可用元素的线程 available.signal(); } return true; } finally { lock.unlock(); } } take public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { // 自旋 for (;;) { // 获取队头数据 E first = q.peek(); // 队头没数据，进行等待 if (first == null) available.await(); else { // 获取队头数据的过期时间 long delay = first.getDelay(NANOSECONDS); // 以及过期了 if (delay 使用场景 用于任务不想立马执行，想等待一段时间才执行的场景 ArrayBlockingQueue 这个队列一个重要的特点是有界的阻塞数组，容量一旦创建，后续大小无法修改 操作 初始化 public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity put public void put(E e) throws InterruptedException { Objects.requireNonNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { // 当队列满时，进行等待 while (count == items.length) notFull.await(); // 被唤醒，入队 enqueue(e); } finally { lock.unlock(); } } private void enqueue(E e) { final Object[] items = this.items; // 从这里可以看出，putIndex就是当入队的时候，元素放置的位置 items[putIndex] = e; // 当下次的putInex超过数组大小时，则下次放置的位置就是0，也就说队头 if (++putIndex == items.length) putIndex = 0; count++; // 唤醒等待take的线程 notEmpty.signal(); } take public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { // 队列为空，进行等待 while (count == 0) notEmpty.await(); // 被唤醒，出队 return dequeue(); } finally { lock.unlock(); } } private E dequeue() { final Object[] items = this.items; @SuppressWarnings(\"unchecked\") // // 从这里可以看出，takeIndex就是当出队的时候，元素的位置 E e = (E) items[takeIndex]; items[takeIndex] = null; // 同样，当下一次takeIndex超过数组容量时，就从头开始 if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); // 唤醒等待put的线程 notFull.signal(); return e; } remove void removeAt(final int removeIndex) { final Object[] items = this.items; // 删除的位置等于下一次take的位置 if (removeIndex == takeIndex) { // removing front item; just advance items[takeIndex] = null; // takeIndex往后移动一位 if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); } else { // 删除的位置非takeIndex // 从删除的位置开始遍历 for (int i = removeIndex, putIndex = this.putIndex;;) { int pred = i; if (++i == items.length) i = 0; // 如果遍历到putIndex的位置，删除这个位置的元素 if (i == putIndex) { items[pred] = null; this.putIndex = pred; break; } // 将removeIndex后的元素全部往前移动一位 items[pred] = items[i]; } count--; if (itrs != null) itrs.removedAt(removeIndex); } // 通知等待put的线程 notFull.signal(); } 使用场景 一般用于生产数据固定的场景 问题 对队列的理解 首先队列本身也是个容器，底层也会有不同的数据结构，列把生产数据的一方和消费数据的一方进行解耦，生产者只管生产，消费者只管消费，队列还可以对消费者和生产者进行管理，当队列满时或者空时，会阻塞住生产者或者消费者 队列和集合的区别 队列（部分例外）和集合都提供了数据存储的功能，底层的储存数据结构是有些相似的 但两者为了完成不同的事情，提供的 API 和其底层的操作实现是不同的， 队列提供了阻塞的功能，解耦了生产者和消费者 哪些队列具有阻塞的功能，大概是如何阻塞的 LinkedBlockingQueue 链表阻塞队列和 ArrayBlockingQueue 数组阻塞队列是一类，两个阻塞队列都可以指定容量大小，当队列满时，如果有线程 put 数据，线程会阻塞住，直到有其他线程进行消费数据后，才会唤醒阻塞线程继续 put，当队列空时，如果有线程 take 数据，线程会阻塞到队列不空时，继续 take SynchronousQueue 同步队列，当线程 put 时，必须有对应线程把数据消费掉，put 线程才能返回，当线程 take 时，需要有对应线程进行 put 数据时，take 才能返回 底层是如何实现阻塞的 利用 Condition 的等待唤醒机制 经常使用队列的 put、take 方法有什么危害，如何避免 两个方法都是无限（永远、没有超时时间的意思）阻塞的方法 使用 offer 和 poll 方法来代替两者，可以设置超时阻塞时间 队列在JDK中的其他运用 线程池 public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()); } 参考JAVA编程规范中的不要用Executors创建线程池，而要手动创建 锁 同步队列 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-23 06:51:19 "},"编程语言/JAVA/JAVA源码解析/线程.html":{"url":"编程语言/JAVA/JAVA源码解析/线程.html","title":"线程","keywords":"","body":"线程源码解析 线程API之间的关系 Thread 初始化 private Thread(ThreadGroup g , Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { if (name == null) { throw new NullPointerException(\"name cannot be null\"); } this.name = name; // 当前线程作为这条线程的父线程 Thread parent = currentThread(); // 一些安全检查 SecurityManager security = System.getSecurityManager(); if (g == null) { if (security != null) { g = security.getThreadGroup(); } if (g == null) { g = parent.getThreadGroup(); } } g.checkAccess(); // 权限检查 if (security != null) { if (isCCLOverridden(getClass())) { security.checkPermission( SecurityConstants.SUBCLASS_IMPLEMENTATION_PERMISSION); } } g.addUnstarted(); // 设置线程组 this.group = g; // 继承父线程的一些属性，包括是否是守护线程、线程优先级等 this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; // 设置线程优先级 setPriority(priority); if (inheritThreadLocals && parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); // 设置线程栈大小 this.stackSize = stackSize; /* Set thread ID */ this.tid = nextThreadID(); } 启动 public synchronized void start() { // 线程并非NEW状态 if (threadStatus != 0) throw new IllegalThreadStateException(); // 通知线程组加入自身 group.add(this); boolean started = false; try { // 调用native方法启动线程 start0(); started = true; } finally { try { // 如果启动失败，通知线程组启动失败 if (!started) { group.threadStartFailed(this); } } catch (Throwable ignore) { /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ } } } join join 的意思就是当前线程(currentThread)等待另一个线程(调用join的那个线程)执行完成之后，才能继续操作 public final synchronized void join(final long millis) throws InterruptedException { if (millis > 0) { // 判断自身是否已执行完毕， if (isAlive()) { // 如果还未完毕等待一定的时间 final long startTime = System.nanoTime(); long delay = millis; do { wait(delay); } while (isAlive() && (delay = millis - TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime)) > 0); } // 无限等待 } else if (millis == 0) { // 原理就是自旋判断自身是否已经执行完毕 while (isAlive()) { // 如果还未执行完毕，则进入wait wait(0); } } else { throw new IllegalArgumentException(\"timeout value is negative\"); } } FutureTask 初始化 public FutureTask(Callable callable) { if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable } public FutureTask(Runnable runnable, V result) { // 将runnable包装成callable，内部是通过适配器的方式来实现的 this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable } RunnableAdapter(Runnable task, T result) { this.task = task; this.result = result; } public T call() { task.run(); return result; } get public V get() throws InterruptedException, ExecutionException { int s = state; if (s COMPLETING) { if (q != null) q.thread = null; return s; } // 还未完成，让线程调度器重新调度，防止占着不放 else if (s == COMPLETING) Thread.yield(); // 线程被打断，抛出异常 else if (Thread.interrupted()) { removeWaiter(q); throw new InterruptedException(); } // 第一次运行，创建一些信息 else if (q == null) { if (timed && nanos = nanos) { removeWaiter(q); return state; } parkNanos = nanos - elapsed; } // nanoTime may be slow; recheck before parking if (state run public void run() { // 状态不对 if (state != NEW || !RUNNER.compareAndSet(this, null, Thread.currentThread())) return; try { Callable c = callable; // 状态正确时进入 if (c != null && state == NEW) { V result; boolean ran; try { // 执行主体 result = c.call(); // 标记执行完成 ran = true; } catch (Throwable ex) { // 标记失败 result = null; ran = false; setException(ex); } if (ran) set(result); } } finally { runner = null; int s = state; if (s >= INTERRUPTING) handlePossibleCancellationInterrupt(s); } } cancel public boolean cancel(boolean mayInterruptIfRunning) { // 状态不对 if (!(state == NEW && STATE.compareAndSet (this, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) return false; try { // in case call to interrupt throws exception if (mayInterruptIfRunning) { try { // 通过设置中断位来停止线程 Thread t = runner; if (t != null) t.interrupt(); } finally { // final state STATE.setRelease(this, INTERRUPTED); } } } finally { finishCompletion(); } return true; } ThreadLocal 供了一种方式，让在多线程环境下，每个线程都可以拥有自己独特的数据，并且可以在整个线程执行过程中，从上而下的传递 属性 // 表示当前ThreadLocal在全局map中的存放位置 private final int threadLocalHashCode = nextHashCode(); // 它的hashCode是通过一个原子整数不断递增的形式给出的，这样可以保证每台机器的每一个ThreadLocal都有唯一的hashCode private static AtomicInteger nextHashCode = new AtomicInteger(); // 用来存放各个ThreadLocal对应的数据 static class ThreadLocalMap { ... } set public void set(T value) { Thread t = Thread.currentThread(); // 获取当前线程的一个map ThreadLocalMap map = getMap(t); // 向map里面放数据（如果map为空，则创建map） if (map != null) { map.set(this, value); } else { // 这里创建map的时候，创建后会存入value createMap(t, value); } } // 也就是说每个线程都拥有一张map，这张map的可是ThreadLocal，这样当使用ThreadLocal存取数据时，就会通过ThreadLocal来在这张map上set/get数据 get public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); // 获取map进行get if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; } } return setInitialValue(); } 应用 // 获取当前的请求 RequestContextHolder.getCurrentRquest(); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-12 12:33:59 "},"编程语言/JAVA/JAVA源码解析/锁.html":{"url":"编程语言/JAVA/JAVA源码解析/锁.html","title":"锁","keywords":"","body":"锁源码解析 AbstractQueuedSynchronizer 中文翻译叫做同步器，简称 AQS，是各种各样锁的基础，比如说 ReentrantLock、CountDownLatch 等等 整体架构 提供了一种框架，自定义了先进先出的同步队列，让获取不到锁的线程能进入同步队列中排队 同步器有个状态字段，子类需要实现一些方法，通过判断状态字段来判断能否得到锁 属性 // 这个状态用来判断是否可以获得锁，每次获得锁时+1，释放锁-1 // 当子类继承AQS来实现锁时，要根据这个状态判断能否获得锁(为0才能获得)跟释放锁(为1才能释放) private volatile int state; // 同步队列的头与尾,底层是一个双向链表，用来阻塞获取不到锁的线程，并在适当时机释放这些线程 private transient volatile Node head; private transient volatile Node tail; // 条件队列，管理获取不到锁的线程，但条件队列不直接和锁打交道，但常常和锁配合使用 public class ConditionObject implements Condition, java.io.Serializable { // Condition 可以用来代替 Object 中相应的监控方法 // 它提供了一种线程协作方式，并且都有明确语义 /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; } static final class Node { ... volatile int waitStatus; // 在共享锁中用来表示下一个等待线程，排它锁则用来表示当前节点是共享还是排它模式 Node nextWaiter; } 获取锁 排它锁 // 排它模式下，尝试获得锁 public final void acquire(int arg) { // tryAcquire让子类实现的，思路一般是根据state的值决定是否能获取到锁 if (!tryAcquire(arg) && // 如果获取不到就调用addWaiter让线程进入同步队列，然后acquireQueued这个方法代表进入之后会阻塞，直到被唤醒获得锁 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // 获取锁失败，打断自身 selfInterrupt(); } // 追加到同步队列的队尾 private Node addWaiter(Node mode) { Node node = new Node(mode); for (;;) { Node oldTail = tail; // 如果队尾不为空，就将node插入到队尾 if (oldTail != null) { // 将原来队尾的node设置为新加入node的prev node.setPrevRelaxed(oldTail); // 原子方式将node设置为队尾 if (compareAndSetTail(oldTail, node)) { oldTail.next = node; return node; } // 队尾为空，需要初始化同步队列 } else { initializeSyncQueue(); } } } // 阻塞当前线程 final boolean acquireQueued(final Node node, int arg) { boolean interrupted = false; try { for (;;) { final Node p = node.predecessor(); // 如果这个当前线程节点的前置节点是头节点，并且自己已经能获得锁了 if (p == head && tryAcquire(arg)) { // 将自己设置为头节点 setHead(node); p.next = null; // help GC // 然后返回 return interrupted; } // 前一个节点状态为SIGNAL了，那么就阻塞自己(park) if (shouldParkAfterFailedAcquire(p, node)) interrupted |= parkAndCheckInterrupt(); } } catch (Throwable t) { cancelAcquire(node); if (interrupted) selfInterrupt(); throw t; } } 共享锁 public final void acquireShared(int arg) { // 同样由子类实现 if (tryAcquireShared(arg) = 0) { setHeadAndPropagate(node, r); p.next = null; // help GC return; } } if (shouldParkAfterFailedAcquire(p, node)) interrupted |= parkAndCheckInterrupt(); } } catch (Throwable t) { cancelAcquire(node); throw t; } finally { if (interrupted) selfInterrupt(); } } 释放锁 排它锁 public final boolean release(int arg) { // 同样留给子类实现判断是否能释放锁 if (tryRelease(arg)) { Node h = head; // 后面有一些等待唤醒的节点 if (h != null && h.waitStatus != 0) // 从头开始唤醒等待锁的节点 unparkSuccessor(h); return true; } return false; } 共享锁 public final boolean releaseShared(int arg) { // 基本跟上面一样 if (tryReleaseShared(arg)) { // 唤醒后面的线程 doReleaseShared(); return true; } return false; } 条件队列 入队列等待 await 获得锁的线程，如果在碰到队列满或空的时候，就会阻塞住，这个阻塞就是用条件队列实现的，这个动作我们叫做入条件队列 单个唤醒 signal 之前队列满了，有了一些线程因为 take 操作而被阻塞进条件队列中，突然队列中的元素被线程 A 消费了，线程 A 就会调用 signal 方法，唤醒之前阻塞的线程 ReentrantLock 语义同 synchronized 锁，可重入互斥锁 构造器接受 fairness 的参数，fairness 是 ture 时，保证获得锁时的顺序，false 不保证 类层次结构 同步器 非公平地获取锁 final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); // 代表锁还没被获取 if (c == 0) { // 设置状态标记获取锁 if (compareAndSetState(0, acquires)) { // 标记获取锁的线程是当前线程 setExclusiveOwnerThread(current); return true; } } // 锁已经被获取了，并且获取锁的线程是当前线程 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc 尝试释放锁 protected final boolean tryRelease(int releases) { // 释放锁后线程持有的锁数 int c = getState() - releases; // 当前的线程没有持有锁 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 锁释放完了 if (c == 0) { // 可以让其他线程获取锁 free = true; setExclusiveOwnerThread(null); } // 如果锁没有释放完，设置state为当前线程持有的锁数 setState(c); return free; } FairSync公平锁 protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); // 锁没有被持有 if (c == 0) { // 如果当前线程处于同步队列的头节点，则获取锁成功，否则等待 if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } // 锁被当前线程持有，重入 else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc NonfairSync非公平锁 这里的非公平锁tryAcquire实现就是上面同步器sync中的实现 CountDownLatch 其最大的作用不是为了加锁，而是通过计数达到等待的功能，主要有两种形式的等待： 让一组线程在全部启动完成之后，再一起执行 主线程等待另外一组线程都执行完成之后，再继续执行 await // await方法的实现是获取共享锁，如果获得后就返回，否则就等待 public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1); } // 这里sync判断能否获得锁的标志是state是否=0 protected int tryAcquireShared(int acquires) { return (getState() == 0) ? 1 : -1; } countDown // countDown的实现就是释放一个锁 public void countDown() { sync.releaseShared(1); } // sync判断能否释放锁的标志是 释放这次锁之后，锁的个数为0 protected boolean tryReleaseShared(int releases) { // Decrement count; signal when transition to zero for (;;) { int c = getState(); // 已经没有锁了 if (c == 0) return false; int nextc = c - 1; if (compareAndSetState(c, nextc)) return nextc == 0; } } 问题 对 AQS 的理解 AQS 是一个锁框架，它定义了锁的实现机制，并开放出扩展的地方，让子类去实现，比如我们在 lock 的时候，AQS 开放出 state 字段，让子类可以根据 state 字段来决定是否能够获得锁，对于获取不到锁的线程 AQS 会自动进行管理，无需子类锁关心 使用场景 synchronized 与ReentrantLock ：可重入+排它锁 但是有几点不同：ReentrantLock功能更加丰富，ReentrantLock有公平锁和非公平锁之分synchronized都是非公平锁，synchronized使用起来更加简单 共享资源初始化 对于一些诸如配置信息等的共享资源，我们希望在项目初始化后加载，但是不希望它被重复加载 public class Service{ public void init(){ // 双重判断 if (loaded){ synchronized(this){ if (loaded){ // load resources } } } } } CountDownLatch 批量任务 我们有时会使用线程来并发地进行某些操作，等这些操作全部完成之后，再进行下一步操作 int n = 10; CountDownLatch latch = new CountDownLatch(10); for (int i =0;i{ // task i latch.countDown(); }) } latch.await(); // 后续操作 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-27 07:21:34 "},"编程语言/JAVA/JAVA源码解析/线程池.html":{"url":"编程语言/JAVA/JAVA源码解析/线程池.html","title":"线程池","keywords":"","body":"ThreadPoolExecutor 线程池 解决了两个问题： 1：通过减少任务间的调度开销 (主要是通过线程池中的线程被重复使用的方式)，来提高大量任务时的执行性能； 2：提供了一种方式来管理线程和消费，维护基本数据统计等工作 整体架构 运行状态图 Wroker 在线程池中，最小的执行单位就是 Worker private final class Worker extends AbstractQueuedSynchronizer implements Runnable { // 运行任务的线程 final Thread thread; // 任务代码块 Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; Worker(Runnable firstTask) { // 把自己作为一个代码块穿给线程 setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 线程是通过线程工程创建的 this.thread = getThreadFactory().newThread(this); } public void run() { // 这里就将任务的执行交给线程池了 runWorker(this); } ... } 任务提交 public void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); // 如果工作线程数小于coreSize if (workerCountOf(c) addWorker 方法首先是执行了一堆校验，然后使用 new Worker (firstTask) 新建了 Worker，最后使用 t.start () 执行 Worker，所以 t.start () 会执行到 Worker 的 run 方法上,到runWorker 方法里 private boolean addWorker(Runnable firstTask, boolean core) { retry: // 校验各种状态 for (int c = ctl.get();;) { // Check if queue empty only if necessary. if (runStateAtLeast(c, SHUTDOWN) && (runStateAtLeast(c, STOP) || firstTask != null || workQueue.isEmpty())) return false; for (;;) { if (workerCountOf(c) >= ((core ? corePoolSize : maximumPoolSize) & COUNT_MASK)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateAtLeast(c, SHUTDOWN)) continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { // 把任务交给worker，此时要执行的任务就已经传入给worker里面的thread了 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); // 检查线程池状态 if (isRunning(c) || (runStateLessThan(c, STOP) && firstTask == null)) { if (t.getState() != Thread.State.NEW) throw new IllegalThreadStateException(); workers.add(w); workerAdded = true; int s = workers.size(); if (s > largestPoolSize) largestPoolSize = s; } } finally { mainLock.unlock(); } if (workerAdded) { // 启动线程，执行worker t.start(); workerStarted = true; } } } finally { if (! workerStarted) addWorkerFailed(w); } return workerStarted; } final void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try { // 所以说在这里，在不断地取任务执行 // 如果要执行的task为空，则会去取一个task，取不到就阻塞 while (task != null || (task = getTask()) != null) { // 锁住worker，防止一个任务多个线程执行 w.lock(); // 线程池stop了，让线程中断 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() && runStateAtLeast(ctl.get(), STOP))) && !wt.isInterrupted()) wt.interrupt(); try { // 执行前钩子函数 beforeExecute(wt, task); try { // 执行真正的任务 // 而执行这个任务的线程就是worker里面的thread task.run(); // 执行后钩子函数 afterExecute(task, null); } catch (Throwable ex) { // 异常钩子函数 afterExecute(task, ex); throw ex; } } finally { task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { processWorkerExit(w, completedAbruptly); } } private Runnable getTask() { // 如果设置了线程超时时间，超过一定时间没有任务，超出coreSize部分的线程会被回收 boolean timedOut = false; // Did the last poll() time out? for (;;) { int c = ctl.get(); // 检查线程池状态 if (runStateAtLeast(c, SHUTDOWN) && (runStateAtLeast(c, STOP) || workQueue.isEmpty())) { decrementWorkerCount(); return null; } int wc = workerCountOf(c); boolean timed = allowCoreThreadTimeOut || wc > corePoolSize; // 如果线程数大于maxSize但是存活时间还没超过keepalive，则跳过后面取任务的部分 if ((wc > maximumPoolSize || (timed && timedOut)) && (wc > 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } try { // 超过keepAliveTime时间取不到数据就返回，此时线程不再运行，结束了，JVM会回收掉 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } } 应用场景 coreSize == maxSize 让线程一下子增加到 maxSize，并且不要回收线程，防止线程回收，避免不断增加回收的损耗 maxSize 无界 + SynchronousQueue 当任务被消费时，才会返回，这样请求就能够知道当前请求是已经在被消费了，如果是其他的队列的话，我们只知道任务已经被提交成功了，但无法知道当前任务是在被消费中，还是正在队列中堆积 比较消耗资源，大量请求到来时，我们会新建大量的线程来处理请求 maxSize 有界 + Queue 无界 对实时性要求不大，但流量忽高忽低的场景下，可以使用这种方式 当流量高峰时，大量的请求被阻塞在队列中，对于请求的实时性难以保证 maxSize 有界 + Queue 有界 把队列从无界修改成有界，只要排队的任务在要求的时间内，能够完成任务即可 keepAliveTime 设置无穷大 想要空闲的线程不被回收，我们可以设置 keepAliveTime 为无穷大值 线程池的公用和独立 查询和写入不公用线程池，如果公用的话，当查询量很大时，写入的请求可能会到队列中去排队，无法及时被处理 原则上来说，每个写入业务场景都独自使用自己的线程池，绝不共用，这样在业务治理、限流、熔断方面都比较容易 多个查询业务场景是可以公用线程池的 问题 对线程池的理解 线程池结合了锁、线程、队列等元素，在请求量较大的环境下，可以多线程的处理请求，充分的利用了系统的资源，提高了处理请求的速度 队列在线程池中起的作用 请求数大于 coreSize 时，可以让任务在队列中排队，让线程池中的线程慢慢的消费请求 当线程消费完所有的线程后，会阻塞的从队列中拿数据，通过队列阻塞的功能，使线程不消亡 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-27 08:33:45 "},"编程语言/JAVA/JAVA源码解析/编译原理.html":{"url":"编程语言/JAVA/JAVA源码解析/编译原理.html","title":"编译原理","keywords":"","body":"编译原理 词法解析 // JavaParser public JCTree.JCCompilationUnit parseCompilationUnit() { Token firstToken = token; JCModifiers mods = null; boolean consumedToplevelDoc = false; boolean seenImport = false; boolean seenPackage = false; ListBuffer defs = new ListBuffer<>(); if (token.kind == MONKEYS_AT) mods = modifiersOpt(); // 解析修饰符 if (token.kind == PACKAGE) { // 解析包声明 int packagePos = token.pos; List annotations = List.nil(); seenPackage = true; if (mods != null) { checkNoMods(mods.flags); annotations = mods.annotations; mods = null; } nextToken(); JCExpression pid = qualident(false); accept(SEMI); JCPackageDecl pd = toP(F.at(packagePos).PackageDecl(annotations, pid)); attach(pd, firstToken.comment(CommentStyle.JAVADOC)); consumedToplevelDoc = true; defs.append(pd); } boolean checkForImports = true; boolean firstTypeDecl = true; while (token.kind != EOF) { if (token.pos JavaParser 根据 Java 语言规范来解析.java文件进行词法解析 每调用一次nextToken 就会构造一个Token 语法分析 进行package词法分析的时候构建一个节点 JCExpression t = toP(F.at(token.pos).Ident(ident())); 进行import词法分析时构造的import语法树 protected JCTree importDeclaration() { int pos = token.pos; nextToken(); boolean importStatic = false; if (token.kind == STATIC) { importStatic = true; nextToken(); } JCExpression pid = toP(F.at(token.pos).Ident(ident())); do { int pos1 = token.pos; accept(DOT); if (token.kind == STAR) { pid = to(F.at(pos1).Select(pid, names.asterisk)); nextToken(); break; } else { pid = toP(F.at(pos1).Select(pid, ident())); } } while (token.kind == DOT); accept(SEMI); return toP(F.at(pos).Import(pid, importStatic)); } 类主体语法树构造 JCTree typeDeclaration(JCModifiers mods, Comment docComment) { int pos = token.pos; if (mods == null && token.kind == SEMI) { nextToken(); return toP(F.at(pos).Skip()); } else { return classOrRecordOrInterfaceOrEnumDeclaration(modifiersOpt(mods), docComment); } } 最后会生成一颗完整的语法树 语义分析 打磨语法树 Enter类 代码生成 Gen类 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-04 02:31:39 "},"编程语言/JAVA/JVM/JVM.html":{"url":"编程语言/JAVA/JVM/JVM.html","title":"JVM","keywords":"","body":"JVM 系统虚拟机 软件虚拟机 JVM是一种规范 JDK14:https://docs.oracle.com/javase/specs/jvms/se14/jvms14.pdf 常见JVM实现 Hotspot Jrockit J9 越过操作系统的虚拟机： LiquidVM azul zing 其他： Apache Harmony Android Dalvik Microsoft JVM 未来的趋势 GraalVM：将这些语言的源代码（例如JavaScript）或源代码编译后的中间格式（例如LLVM字节码）通过解释器转换为能被Graal VM接受的中间表示 Graal编译器：新一代即时编译器 Native化：提前编译 功能越来越多：监控 调试 语法特性持续增强 JDK JRE JVM JVM 体系结构 类加载器 内存区 执行引擎 基于栈的架构： 平台无关 不同的平台寄存器各不相同 基于栈的寄存器指令更加紧凑 执行引擎的架构： 执行引擎的执行过程： 方法调用： 执行方法调用指令时 会创建一个新栈帧 这个栈帧会存储传递过来的参数 编译JDK 安装依赖库 apt install libfreetype6-dev apt install libcups2-dev apt install libx11-dev libxext-dev libxrender-dev libxrandr-dev libxtst-dev libxt-dev apt install libasound2-dev apt install libffi-dev apt install autoconf 准备一个目标JDK-1的bootstrap jdk sudo apt-get install openjdk-11-jdk 编译前配置与检查 bash configure --enable-debug --with-jvm-variants=server 开始编译 make images MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-14 08:21:20 "},"编程语言/JAVA/JVM/自动内存管理/自动内存管理.html":{"url":"编程语言/JAVA/JVM/自动内存管理/自动内存管理.html","title":"自动内存管理","keywords":"","body":"自动内存管理 Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的高墙，墙外面的人想进去，墙里面的人却想出来 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-23 06:15:18 "},"编程语言/JAVA/JVM/自动内存管理/内存结构.html":{"url":"编程语言/JAVA/JVM/自动内存管理/内存结构.html","title":"内存结构","keywords":"","body":"内存结构 总体内存结构 概览 PC 程序计数器 用来存放执行指令的偏移量和行号指示器等 Java虚拟机的多线程是通过线程轮流切换、分配处理器执行时间的方式来实现的，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器 存放指令位置 虚拟机的运行，类似于这样的循环： while( not end ) { ​ 取PC中的位置，找到对应位置的指令； ​ 执行该指令； ​ PC ++; } JVM Stack 每个线程私有 Frame - 每个方法对应一个栈帧 Local Variable Table　局部变量表 存放方法参数和局部变量的区域 Operand Stack　操作栈 各种指令往栈中写入或者读取信息 对于long的处理（store and load），多数虚拟机的实现都是原子的 jls 17.7，没必要加volatile Dynamic Linking　动态连接 常量池中一个对当前方法的引用 https://blog.csdn.net/qq_41813060/article/details/88379473 jvms 2.6.3 return address　方法返回地址 a() -> b()，方法a调用了方法b, b方法的返回值放在什么地方 本地方法栈 为本地方法服务 堆 共享，内存大户，存储所有的对象和数组 是垃圾收集器管理的内存区域 所有线程共享的Java堆中可以划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB），以提升对象分配时的效率 -Xms(memory start) 初始堆值，-Xmx(memory max)最大堆值 方法区 各个线程共享的内存区域，它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据 1.8之前被HotSpot使用一个永久代实现 字符串常量位于永久代 FGC不会清理 这区域的内存回收目标主要是针对常量池的回收和对类型的卸载 但是类型卸载条件十分苛刻 大小启动的时候指定，不能变 Meta Space (>=1.8) 字符串常量位于堆 会触发FGC清理 不设定的话，最大就是物理内存 运行时常量池 是方法区的一部分 用于存放编译期生成的各种字面量与符号引用 Java语言并不要求常量一定只有编译期才能产生，运行期间也可以将新的常量放入池中，比如String.intern() 直接内存 JVM可以直接访问的内核空间的内存 (OS 管理的内存) NIO ， 提高效率，实现zero copy 一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据 本机直接内存的分配不会受到Java堆大小的限制 对象的创建 内存分配 把那个指针向空闲空间方向挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞” 如果没有一块完整的空闲内存 就无法使用这种方法了 线程安全的保证 分配时 多个线程并发执行 虚拟机是采用CAS配上失败重试的方式保证更新操作的原子性 另外一种方式是每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（TLAB） 只有这个缓冲区用完了 才会在堆中分配 对象内存布局 以下分析都是基于HotSpot虚拟机 对象头 对象本身运行时的数据 哈希吗 GC标记 锁信息等等 类元信息：指向Class的指针 实例数据：实例成员变量及所有可见的父类成员变量 对齐填充 锁升级：无锁状态 -> 偏向锁 -> 自旋锁 -> 重量级锁 32位虚拟机对象头： 64位虚拟机对象头： Hotspot开启内存压缩的规则 UseCompressedOopsClassPointers UseCompressedOops 4G以下，直接砍掉高32位 4G - 32G，默认开启内存压缩 ClassPointers Oops 32G，压缩无效，使用64位 对象定位 使用直接指针来访问最大的好处就是速度更快，它节省了一次指针定位的时间开销 对象实例化 字节码角度 Object ref = new Object() 得到字节码: stack=2, locals=2, args_size=1 0: new #2 // class java/lang/Object 3: dup 4: invokespecial #1 // Method java/lang/Object.\"\":()V 7: astore_1 8: return new: 如果类不存在　就先进行类加载 为所有属性值分配内存 对所有属性值进行０值初始化 最后将指向实例对象的引用变量压入虚拟机栈顶 dup: 在栈顶复制实例对象的引用变量 复制出来的这个变量用来作为句柄调用相关方法 早一点的那个变量则是用来赋值 invokespecial: 通过上面dup复制的变量调用对象的 方法 从执行步骤 确认类信息是否存在于metaspace 否则使用类加载器加载类　并生成相关Class对象 计算对象占用的内存空间(实例数据) 接下来在堆内存划分一块空间进行分配　为对象分配内存时　需要进行同步操作 设定成员变量的默认值 设置对象头　哈希吗　GC信息等等 执行init方法　初始化成员变量　执行初始化代码块等等 查看堆内存使用情况 使用jstat命令 jstat -class pid # 查看加载的类 jstat -gc pid # 查看垃圾回收情况 内存分析 jmap命令 jmap -histo pid # 查看所有对象 jmap -histo:live pid # 查看所有存活对象 jmap -dump:format=b,file=filename pid # 导出dump文件 jhat分析dump文件 JDK9以后不再提供，被Visual VM代替 jhat filename mat分析 内存溢出定位与分析 Java 堆溢出 添加运行参数 java -Xmx8m -Xms8m -XX:+HeapDumpOnOutOfMemoryError List list = new ArrayList<>(); while (true){ list.add(new Object()); } 分析dump文件 如果是内存泄漏 找到泄漏对象是通过怎样的引用路径、与哪些GC Roots相关联，才导致垃圾收集器无法回收它们 如果内存中的对象确实都是必须存活的，那就应当检查Java虚拟机 的堆参数（-Xmx与-Xms）设置 虚拟机栈和本地方法栈移除 -Xss256k 减少栈内存容量 异常出现时输出的堆栈深度相应缩小 public class JVMSOFWithMinStack { private int stackLength = 1; public void stackLeak() { stackLength++; stackLeak(); } public static void main(String[] args) throws Throwable { JVMSOFWithMinStack oom = new JVMSOFWithMinStack(); try { oom.stackLeak(); } catch (Throwable e) { System.out.println(\"stack length:\" + oom.stackLength); // 3183 throw e; } } } 定义了大量的本地变量 异常出现时输出的堆栈深度相应缩小 public class JVMSOFWithMuchParams { private static int stackLength = 0; public static void test() { long unused1, unused2, unused3, unused4, unused5, unused6, unused7, unused8, unused9, unused10, unused11, unused12, unused13, unused14, unused15, unused16, unused17, unused18, unused19, unused20, unused21, unused22, unused23, unused24, unused25, unused26, unused27, unused28, unused29, unused30, unused31, unused32, unused33, unused34, unused35, unused36, unused37, unused38, unused39, unused40, unused41, unused42, unused43, unused44, unused45, unused46, unused47, unused48, unused49, unused50, unused51, unused52, unused53, unused54, unused55, unused56, unused57, unused58, unused59, unused60, unused61, unused62, unused63, unused64, unused65, unused66, unused67, unused68, unused69, unused70, unused71, unused72, unused73, unused74, unused75, unused76, unused77, unused78, unused79, unused80, unused81, unused82, unused83, unused84, unused85, unused86, unused87, unused88, unused89, unused90, unused91, unused92, unused93, unused94, unused95, unused96, unused97, unused98, unused99, unused100; stackLength++; test(); unused1 = unused2 = unused3 = unused4 = unused5 = unused6 = unused7 = unused8 = unused9 = unused10 = unused11 = unused12 = unused13 = unused14 = unused15 = unused16 = unused17 = unused18 = unused19 = unused20 = unused21 = unused22 = unused23 = unused24 = unused25 = unused26 = unused27 = unused28 = unused29 = unused30 = unused31 = unused32 = unused33 = unused34 = unused35 = unused36 = unused37 = unused38 = unused39 = unused40 = unused41 = unused42 = unused43 = unused44 = unused45 = unused46 = unused47 = unused48 = unused49 = unused50 = unused51 = unused52 = unused53 = unused54 = unused55 = unused56 = unused57 = unused58 = unused59 = unused60 = unused61 = unused62 = unused63 = unused64 = unused65 = unused66 = unused67 = unused68 = unused69 = unused70 = unused71 = unused72 = unused73 = unused74 = unused75 = unused76 = unused77 = unused78 = unused79 = unused80 = unused81 = unused82 = unused83 = unused84 = unused85 = unused86 = unused87 = unused88 = unused89 = unused90 = unused91 = unused92 = unused93 = unused94 = unused95 = unused96 = unused97 = unused98 = unused99 = unused100 = 0; } public static void main(String[] args) { try { test(); } catch (Error e) { System.out.println(\"stack length:\" + stackLength); // 127 throw e; } } } 方法区和运行时常量池溢出 在JDK7和7之前如果大量创建String.intern或者动态类 由于类的回收条件苛刻 极有可能造成OOM 但在JDK8之后 这些问题就没有了 本机直接内存溢出 -Xmx20M -XX:MaxDirectMemorySize=10M public class DirectMemoryOOM { private static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception { Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while (true) { unsafe.allocateMemory(_1MB); } } } 直接内存导致的内存溢出，一个明显的特征是在Heap Dump文件中不会看见有什么明显的异常 分析线程执行情况 jstack pid 死锁 两个进程互相等待对方，一直阻塞下去 Found one Java-level deadlock: ============================= \"Thread-0\": waiting to lock monitor 0x000002292014eb00 (object 0x00000000ffea7640, a java.lang.Object), which is held by \"Thread-1\" \"Thread-1\": waiting to lock monitor 0x000002292014ea00 (object 0x00000000ffea7630, a java.lang.Object), which is held by \"Thread-0\" Java stack information for the threads listed above: =================================================== \"Thread-0\": at Main.lambda$main$0(Main.java:24) - waiting to lock (a java.lang.Object) - locked (a java.lang.Object) at Main$$Lambda$14/0x0000000800ba4840.run(Unknown Source) at java.lang.Thread.run(java.base@13/Thread.java:830) \"Thread-1\": at Main.lambda$main$1(Main.java:37) - waiting to lock (a java.lang.Object) - locked (a java.lang.Object) at Main$$Lambda$15/0x0000000800ba4c40.run(Unknown Source) at java.lang.Thread.run(java.base@13/Thread.java:830) Found 1 deadlock. JMX MX(Java Management Extensions)是一个为应用程序植入管理功能的框架。JMX是一套标准的代理和服务，实际上，用户可以在任何Java应用程序中使用这些代理和服务实现管理 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-23 06:15:18 "},"编程语言/JAVA/JVM/自动内存管理/垃圾回收.html":{"url":"编程语言/JAVA/JVM/自动内存管理/垃圾回收.html","title":"垃圾回收","keywords":"","body":"垃圾回收 一个跟踪过程，它传递性地跟踪指向当前使用的对象的所有指针，以便找到可以引用的所有对象，然后重新使用在此跟踪过程中未找到的任何堆内存。公共语言运行库垃圾回收器还压缩使用中的内存，以缩小堆所需要的工作空间 回收什么 何时回收 如何回收 JAVA对象生命周期 内存回收API Object的finalize方法，垃圾收集器在回收对象时调用，有且仅被调用一次 如果覆写了该方法的对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条由虚拟机自动建立的、低调度优先级的Finalizer线程去执行它们的finalize() 方法 System的gc方法。不靠谱 内存分配与回收 Minor GC 和 Full GC Minor GC（Young GC）:回收新生代，这种类型的GC执行很频繁，执行速度也很快 当 Eden 空间满时，就将触发一次 Minor GC Full GC（Major GC）：回收老年代和新生代，这种GC执行一般比较少，执行速度慢 System.gc()会建议虚拟机去触发Full GC,但只是建议 老年代空间不足的情况下，也会进行Full GC CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足，会触发 Full GC 内存分配策略 对象优先在Eden上分配 // -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 public class AllocationWithEden { private static final int _1MB = 1024 * 1024; public static void main(String[] args) { byte[] allocation1, allocation2, allocation3, allocation4; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; allocation4 = new byte[4 * _1MB]; // 出现一次Minor GC } } 为避免在 Eden 和 Survivor 之间的大量内存复制，大对象的内存直接在老年代 -XX:PretenureSizeThreshold /** * -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 */ public class LargeObjectWithOld { public static void main(String[] args) { byte[] allocation; allocation = new byte[8 * 1024*1024]; // //直接分配在老年代中 } } 长期存活的对象进入老年代 -XX:MaxTenuringThreshold 用来定义年龄的阈值 /** * -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1 */ public class OldObjectWithOld { private static int _1MB = 1024*1024; public static void main(String[] args) { byte[] allocation1, allocation2, allocation3; allocation1 = new byte[_1MB / 4]; // 什么时候进入老年代决定于XX:MaxTenuring-Threshold设置 allocation2 = new byte[4 * _1MB]; allocation3 = new byte[4 * _1MB]; allocation3 = null; allocation3 = new byte[4 * _1MB]; } } 动态对象年龄判定 如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄 /** * -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 -XX:+PrintTenuringDistribution */ public class OldObjectWithHalfSpace { private static int _1MB = 1024*1024; public static void main(String[] args) { byte[] allocation1, allocation2, allocation3, allocation4; allocation1 = new byte[_1MB / 4]; // allocation1+allocation2大于survivo空间一半 allocation2 = new byte[_1MB / 4]; allocation3 = new byte[4 * _1MB]; allocation4 = new byte[4 * _1MB]; allocation4 = null; allocation4 = new byte[4 * _1MB]; } } 空间分配担保 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的 否则虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许失败 就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC 否则进行Full GC JDK 6 Update 24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小，就会进行Minor GC，否则将进行Full GC 对象已死 引用计数算法 为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 在两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收 虽然占用了一些额外的内存空间来进行计数，它的原理简单，判定效率也很高。但这个看似简单的算法有很多例外情况要考虑，必须要配合大量额外处理才能保证正确地工作 可达性分析算法 基本思路就是通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，对象之间的联系称为引用链，如果某个对象无法从 GC Root到达，则证明此对象是不可能再被使用的 可以作为GCRoots的对象包括下面几种： 虚拟机栈（栈帧中的局部变量区，也叫做局部变量表）中引用的对象 方法区中的类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI(Native方法)引用的对象 Java虚拟机内部的引用，如基本数据类型对应的Class对象 被同步锁（synchronized关键字）持有的对象 反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等 除了这些固定的GC Roots集合以外，根据垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整GC Roots集合 引用 基于对象引用判定无用对象 对象引用链 强引用 Object obj = new Object(); Object obj2 = obj; 强引用还存在，对象就不会被回收，哪怕发生OOM异常 软引用 Object obj = new Object(); SoftReference sf = new SoftReference(obj); obj = null; // 使对象只被软引用关联 有用但并非必需的对象 在系统的内存不够时，会把这些对象列为可回收 应用场景：缓存 弱引用 Object obj = new Object(); WeakReference wf = new WeakReference(obj); obj = null; 比软引用强度更弱些 只能生存到下一次垃圾收集发生之前 作用在于当强引用丢失之后，这个对象就会被回收 虚引用 Object obj = new Object(); PhantomReference pf = new PhantomReference(obj, null); obj = null; 为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知，用于对象回收跟踪 应用场景：管理堆外内存 总结 引用类型 强引用 软引用 弱引用 虚引用 类型 正常赋值 SoftReference WeakReference PhantomReference 回收时间 不回收 内存紧张时回收 GC就回收 随时可能被回收 方法区的回收 方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，所以在方法区上进行回收性价比不高。 为了避免内存溢出，在大量使用反射和动态代理的场景都需要虚拟机具备类卸载功能。 常量回收：如果一个常量没有再被使用，那么就可以被回收 类的卸载，需要满足三个条件才有可能被回收： 该类所有的实例都已经被回收 加载该类的类加载器已经被回收 该类对应的java.lang.Class对象没有在任何地方被引用 可以控制Xnoclassgc参数让HotSpot进行回收类 垃圾回收算法 垃圾回收类型： 部分收集（Partial GC）：指目标不是完整收集整个Java堆的垃圾收集 新生代收集（Minor GC/Young GC）：指目标只是新生代的垃圾收集 老年代收集（Major GC/Old GC）：指目标只是老年代的垃圾收集 混合收集（Mixed GC）：指目标是收集整个新生代以及部分老年代的垃圾收集 只有G1收集器会有这种行为 整堆收集（Full GC）：收集整个Java堆和方法区的垃圾收集 分代收集理论 前商业虚拟机的垃圾收集器，大多数都遵循了“分代收集”（Generational Collection）的理论 建立在以下两个分代假说上： 弱分代假说：绝大多数对象都是朝生夕灭的 强分代假说：熬过越多次垃圾收集过程的对象就越难以消亡 根据上面两条假说得到 -> 跨代引用假说：跨代引用相对于同代引用来说仅占极少数 标记-清除算法 GC 标记-清除算法由标记阶段和清除阶段构成。在标记阶段会把所有的活动对象都做上标记，然后在清除阶段会把没有标记的对象，也就是非活动对象回收，该算法一般应用于老年代,因为老年代的对象生命周期比较长 后续的收集算法大多都是以标记-清除算法为基础，对其缺点进行改进而得到的 可以解决循环引用的问题 必要时才回收(内存不足时) 回收时，应用需要挂起，也就是stop the world。 标记和清除的效率不高 会造成内存碎片 标记-复制算法 把内存分为两个空间一个是From空间，一个是To空间，对象一开始只在From空间分配，To空间是空闲的。GC时把存活的对象从From空间复制粘贴到To空间，之后把To空间变成新的From空间，原来的From空间变成To空间，这也是JVM年轻代所使用的的回收算法 商业虚拟机都采用这种收集算法回收新生代，但是并不是划分为大小相等的两块，而是一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor。 当进行GC时，将Eden与使用过的Survivor中存活的对象移动到另外一个Survivor中，然后清除Eden与使用过的Survivor HotSpot 虚拟机的 Eden 和 Survivor 大小比例默认为 8:1，保证了内存的利用率达到 90% 在存活对象不多的情况下，性能高，能解决内存碎片和java垃圾回收算法之-标记清除 中导致的引用更新问题。 会造成一部分的内存浪费。不过可以根据实际情况，将内存块大小比例适当调整；如果存活对象的数量比较大，coping的性能会变得很差 标记-整理算法 其中标记阶段跟标记-复制算法中的标记阶段是一样的,而对于整理阶段，它的工作就是移动所有的可达对象到堆内存的同一个区域中，使他们紧凑的排列在一起，从而将所有非可达对象释放出来的空闲内存都集中在一起，通过这样的方式来达到减少内存碎片的目的 但这种方式需要移动大量对象，处理效率比较低，同时也会STW 是否移动对象都存在弊端，移动则内存回收时会更复杂，不移动则内存分配时会更复杂。从垃圾收集的停顿时间来看，不移动对象停顿时间会更短，甚至可以不需要停顿，但是从整个程序的吞吐量来看，移动对象会更划算 任意顺序 : 即不考虑原先对象的排列顺序，也不考虑对象之间的引用关系，随意移动对象； 线性顺序 : 考虑对象的引用关系，例如a对象引用了b对象，则尽可能将a和b移动到一块； 滑动顺序 : 按照对象原来在堆中的顺序滑动到堆的一端。 分代收集 除Epsilon ZGC Shenandoah之外的GC都是使用逻辑分代模型 G1是逻辑分代，物理不分代 除此之外不仅逻辑分代，而且物理分代 不同对象使用不同的回收算法 新生代 主要存放短暂生命周期的对象 新创建的对象都先放入新生代，大部分新建对象在第一次gc时被回收 新生代 GC（Minor GC/Young GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快 使用复制清除算法 老年代 一个对象经过几次gc仍存活，则放入老年代 具体是超过XX:MaxTenuringThreshold 这些对象可以活很长时间，或者伴随程序一生，需要常驻内存的，可以减少回收次数 老年代 GC（Major GC / Full GC）：指发生在老年代的 GC 使用标记清除 或者标记压缩算法 HotSport算法细节实现 根节点枚举 迄今为止，所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的，根节点枚举始终还是必须在一个能保障一致性的快照中才得以进行 在HotSpot的解决方案里，是使用一组称为OopMap的数据结构来保存着对象的引用 安全点 导致OopMap内容变化的指令非常多，如果为每一条指令都生成对应的OopMap，那将会需要大量的额外存储空间，HotSpot通过只记录位于安全点的指令的方式来让其他线程在这个点开始进行垃圾回收 线程会通过主动式中断，各个线程执行过程时会不停地主动去轮询这个标志，一旦发现中断标志为真时就自己在最近的安全点上主动中断挂起，这个时候线程就是暂停起来的 HotSpot将这个轮询操作精简到了一条汇编指令 安全区域 安全区域是指能够确保在某一段代码片段之中，引用关系不会发生变化，这个区域可以安全地进行垃圾回收 如果线程要离开安全区域，要检查虚拟机是否已经完成了根节点枚举，如果完成了枚举，就可以离开，否则就要一直等待 直到收到了可以离开的信号 记忆集与卡表 垃圾收集器在新生代中建立了名为记忆集（Remembered Set）的数据结构，用以避免把整个老年代加进GC Roots扫描范围 记忆集的实现精度有： 字长精度 精确到一个机器字长 对象精度 精确到一个对象 卡精度 精确到一块内存区域 通过卡表就可以使用比较少的内存来记录，一个卡页的内存中通常包含不止一个对象，只要卡页内有一个（或更多）对象的字段存在着跨代指针，那就将对应卡表的数组元素的值标识为1，脏卡页在垃圾回收时也会一起被扫描 写屏障 HotSpot通过写屏障（和并发操作的内存读写屏障非同一概念），这里的写屏障类似于虚拟机在解释字节码时的AOP环绕通知，通过这个写屏障来更新卡表 三色标记 把遍历对象图过程中遇到的对象，按照“是否访问过”这个条件标记成以下三种颜色： 白色：表示对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达 黑色：表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过 灰色：表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过 当以下两个条件同时满足，则会出现将原本应该是黑色的对象被误标为白色： 赋值器插入了一条或多条从黑色对象到白色对象的新引用 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用 增量更新破坏第一个条件：黑色对象一旦新插入了指向白色对象的引用之后，它就变回灰色对象了 原始快照破坏第二个条件：无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索 CMS是基于增量更新来做并发标记的，G1、Shenandoah则是用原始快照来实现 内存分配 内存配置常见参数 -XX:+PrintGC 每次触发GC的时候打印相关日志 -XX:+UseSerialGC 串行回收 -XX:+PrintGCDetails 更详细的GC日志 -Xms 堆初始值 -Xmx 堆最大可用值 -Xmn 新生代堆最大可用值 -XX:SurvivorRatio 用来设置新生代中eden空间和from/to空间的比例. -XX:NewRatio 配置新生代与老年代占比 1:2 含以-XX:SurvivorRatio=eden/from=den/to 总结:在实际工作中，我们可以直接将初始的堆大小与最大堆大小相等， 这样的好处是可以减少程序运行时垃圾回收次数，从而提高效率。 -XX:SurvivorRatio 用来设置新生代中eden空间和from/to空间的比例. OutOfMemoryError异常 Java堆溢出 java.lang.OutOfMemoryError: Java heap space 堆内存溢出 因为堆内存无法满足内存申请需要 设置堆内存大小解决-Xmx 虚拟机栈溢出 java.lang.StackOverflowError 栈内存溢出 由于方法调用栈过深 设置线程最大调用深度-Xss 内存溢出与内存泄漏 内存溢出就是申请的内存大小超出了系统所能提供的，系统不能满足需求，于是产生溢出 内存泄漏是使用过的内存空间没有被及时释放，长时间占用内存，最终导致内存空间不足，而出现内存溢出 垃圾收集器 衡量垃圾收集器的三项最重要的指标是： 内存占用（Footprint） 吞吐量（Throughput） 延迟（Latency） 截止到JDK14,当前JAVA已有的垃圾回收器 Serial 几十兆 PS 上百兆 - 几个G CMS - 20G G1 - 上百G ZGC - 4T - 16T（JDK13） 连线表示垃圾收集器可以配合使用 垃圾回收器的发展路线是随着内存越来越大演进以及从分代算法演化到不分代算法 除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行 串行垃圾收集器Serial 会导致STW（stop the world） Client 场景下的默认新生代收集器，因为在该场景下内存一般来说不会很大 而且没有线程切换的开销 FGC的时间较长 [120.792s][info ][gc ] GC(25) Pause Young (Allocation Failure) 10M->6M(15M) 0.936ms [120.792s][info ][gc,cpu ] GC(25) User=0.00s Sys=0.00s Real=**0.00s** 通过JVM参数-XX:+UseSerialGC可以使用串行垃圾回收器 ParNew 它是 Serial 收集器的多线程版本 [GC (Allocation Failure) [ParNew: 4928K->512K(4928K), 0.0024282 secs] 7129K->3525K(15872K), 0.0024673 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 参数控制：-XX:+UseParNewGC 指定使用ParNew收集器 -XX:ParallelGCThreads 限制线程数量 Parallel Scavenge 其它收集器目标是尽可能缩短垃圾收集时用户线程的停顿时间，而它的目标是达到一个可控制的吞吐量，因此它被称为“吞吐量优先”收集器 吞吐量指的是CPU用于运行用户程序的时间占总时间的比值 停顿时间短，回收效率高，对吞吐量要求高 -XX:-UseParallelGC(年轻代) 和 -XX:+UseParallelOldGC(老年代) Serial Old Serial 收集器的老年代版本，给 Client 场景下的虚拟机使用 如果用在Server端：是作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用 Parallel Old Parallel Scavenge 收集器的老年代版本 CMS垃圾收集器 （Concurrent Mark Sweep） CMS是老年代垃圾收集器，在收集过程中可以与用户线程并发操作。它可以与Serial收集器和Parallel New收集器搭配使用。CMS牺牲了系统的吞吐量来追求收集速度，适合追求垃圾收集速度的服务器上 响应时间优先，减少垃圾收集停顿时间 CMS默认启动的回收线程数是（处理器核心数量+3）/4 ，如果在CPU核数较低的情况下，对应用本身的性能还是有影响的 采用的标记清除算法 会产生大量空间碎片 通过JVM参数 -XX:+UseConcMarkSweepGC设置 G1垃圾收集器 一款面向服务端应用的垃圾收集器 目标是替代CMS JDK9默认开启 暂停时间更加可控 使用的标记复制算法 不会产生大量碎片 优先回收垃圾最多的区域 G1将堆空间划分成若干个相同大小的区域 不同的区域存放不同的对象 几个问题： Region里面存在的跨Region引用对象如何解决？通过记忆集解决 并发标记阶段如何保证收集线程与用户线程互不干扰地运行？通过快照的方式 怎样建立起可靠的停顿预测模型？通过收集信息来得到最近一段时间来得到统计状态以进行分析，根据回收价值排序来得到可预测的回收时间 过程: 初始标记 STW 标记GC根可达对象 根区域扫描 从上一阶段标记的存活区域扫描老年代对象 并发标记 对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象 最终标记 STW 完成最终的标记处理 用于处理并发阶段结束后仍遗留下来的最后那少量的SATB记录 清理 STW 统计所有存活对象 并将回收区域排序 优先回收垃圾最多的区域 G1使用建议： 避免设置年轻代大小 暂停时间不要太苛刻(默认为200ms) 通过JVM参数 -XX:+UseG1GC 使用G1垃圾回收器 从G1开始，最先进的垃圾收集器的设计导向都不约而同地变为追求能够应付应用的内存分配速率 G1比CMS的弱项： G1的卡表实现更为复杂，无论扮演的是新生代还是老年代角色，都必须有一份卡表 G1对写屏障的复杂操作要比CMS消耗更多的运算资源 Shenandoah收集器 目的是每次停顿都在10ms内 使用了连接矩阵来维护Regin 之间的引用关系： 过程： 初始标记 STW 标记与GC Roots直接关联的对象 停顿时间与GC Roots的数量相关 并发标记 遍历对象图，标记出全部可达的对象 最终标记 STW 处理并发标记时产生的新关系 并发回收 把回收集里面的存活对象先复制一份到其他未被使用的Region之中 使用的读屏障及转发指针实现 初始引用更新 STW 并发回收阶段复制对象结束后，还需要把堆中所有指 向旧对象的引用修正到复制后的新地址 并发引用更新 最终引用更新 STW 解决了堆中的引用更新后，还要修正存在于GC Roots 中的引用 并发清理 转发指针 有两点问题需要注意： 并发更新问题 通过CAS解决 增加了一层转发肯定会带来效率的损失 ZGC 一款基于Region内存布局的，（暂时）不设分代的，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-整理算法的，以低延迟为首要目标的一款垃圾收集器 目的也是在任意堆内存大小下都可以把垃圾收集的停顿时间限制在十毫秒以内的低延迟 会因为GC Root增大而增加STW时间 会将内存划分为区域大不同的区域 堆内存布局： 过程： 并发标记 遍历对象图做可达性分析的阶段 并发预备重分配 这个阶段需要根据特定的查询条件统计得出本次收集过程要清理哪些Region，将这些Region组成重分配集 并发重分配 把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个转发表（ForwardTable），记录从旧对象到新对象的转向关系 如果用户代码此时访问了位于重分配集中的对象 会进行一次引用修改 使其指向新对象 并发重映射 修正整个堆中指向重分配集中旧对象的所有引用 染色指针 它直接把标记信息记在引用对象的指针上 由于只有42位作为对象地址 所以ZGC最高能管理的内存只有4TB 并且不支持32位平台 也不支持压缩指针 但是染色指针可以使得一旦某个Region的存活对象被移走之后，这个Region立即就能够被释放和重用掉，而不必等待整个堆中所有指向该Region的引用都被修正后才能清理 染色指针的操作系统问题： 重新定义内存中某些指针的其中几位，操作系统是否支持？处理器是否支持？ Linux/x86-64平台上的ZGC使用了多重映射（Multi-Mapping）将多个不同的虚拟内存地址映射到同一个物理内存地址上 Epsilon收集器 所谓垃圾收集器 干的不仅仅是收集垃圾的活 它还要负责堆的管理与布局、对象的分配、与解释器的协作、与编译器的协作、与监控子系统协作等职责 这款垃圾收集器不干GC的活 对于微服务 低内存 运行时间短的应用及时不回收垃圾 也是可以接受的 GC日志分析 一些参数： 看GC基本信息，在JDK 9之前使用-XX：+PrintGC，JDK 9后使用-Xlog:gc 看GC详细信息，在JDK 9之前使用-XX：+PrintGCDetails，在JDK 9之后使用-X-log:gc* 查看GC前后的堆、方法区可用容量变化，在JDK 9之前使用-XX：+PrintHeapAtGC，JDK 9之后使用-Xlog:gc+heap=debug 查看GC过程中用户线程并发时间以及停顿的时间，在JDK 9之前使用-XX：+Print-GCApplicationConcurrentTime以及-XX+PrintGCApplicationStoppedTime，JDK 9之后使用-Xlog:safepoint 查看收集器Ergonomics机制（自动设置堆空间各分代区域大小、收集目标等内容，从Parallel收集器开始支持）自动调节的相关信息。在JDK 9之前使用-XX：+PrintAdaptive-SizePolicy，JDK 9之后使用-Xlog：gc+ergo*=trace 查看熬过收集后剩余对象的年龄分布信息，在JDK 9前使用-XX：+PrintTenuring-Distribution，JDK 9之后使用-Xlog：gc+age=trace 可视化GC日志分析工具 gceasy MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-23 06:15:18 "},"编程语言/JAVA/JVM/自动内存管理/工具.html":{"url":"编程语言/JAVA/JVM/自动内存管理/工具.html","title":"工具","keywords":"","body":"工具 商业授权工具 正式支持工具 实验性工具 故障处理 jps：输出正在运行的虚拟机进程 -q 只输出LVMID 省略主类的名称 -m 输出虚拟机进程启动时传递给主类main函数的参数 -l 输出主类的全名 如果执行的jar包 则输出jar路径 -v 输出虚拟机进程启动时的JVM参数 jstat：用于监视虚拟机各种运行状态信息的命令行工具 jstat -gcutil 39920 jinfo: 实时查看和调整虚拟机各项参数 jmap: 获取堆转储快照，它还可以查询finalize执行队列、Java堆和方法区的详细信息等 jmap -histo 39920 jhat: 分析jmap生成的堆转储快照 没有太大必要使用 jstack：用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件） 总结 名称 主要作用 appletviewer 在不使用Web浏览器的情况下运行和调试Applet，JDK11中被移除 extcheck 检查JAR冲突的工具，从JDK9中被移除 jar 创建和管理JAR文件 java Java运行工具，用于运行Class文件或JAR 文件 javac 用于Java编程语言的编译器 javadoc Java的API文档生成器 javah C语言头文件和 Stub函数生成器，用于编写JNI方法 javap Java字节码分析工具 jlink 将 Module和它的依赖打包成一个运行时镜像文件 jdb 基于JPDA协议的调试器，以类似于GDB的方式进行调试Java代码 jdeps Java类依赖性分析器 jdeprscan 用于搜索JAR包中使用了\"deprecated\"的类，从JDK 9开始提供 keytool 管理密钥库和证书。主要用于获取或缓存Kerberos 协议的票据授权票据。允许用户查看本地凭据缓存和密钥表中的条目（用于Kerberos协议） jarsigner 生成并验证JAR签名 policytool 管理策略文件的GUI工具，用于管理用户策略文件(java.policy)，在JDK10中被移除 国际化工具 - native2ascii 本地编码到ASCII编码的转换器(Native-to-ASCII Converter)，用于\"任意受支持的字符编码\"和与之对应的\"ASCII编码和 Unicode转义\"之间的相互转换 远程方法调用工具 - rmic Java RMI编译器，为使用JRMP或IIOP协议的远程对象生成Stub、Skeleton和Tie类，也用于生成OMG IDL rmiregistry 远程对象注册表服务，用于在当前主机的指定端口上创建并启动一个远程对象注册表 rmid 启动激活系统守护进程，允许在虚拟机中注册或激活对象 serialver 生成并返回指定类的序列化版本ID tnameserv 提供对命名服务的访问 idlj IDL转Java编译器（IDL-to-Java Compiler)，生成映射OMG IDL 接口的Java源文件，并启用以Java编程语言编写的使用CORBA功能的应用程序的Java源文件。IDL意即接口定义语言(Interface Definition Language) orbd 对象请求代理守护进程（Object Request Broker Daemon)，提供从客户端查找和调用CORBA环境服务端上的持久化对象的功能。使用ORBD代替瞬态命名服务tnameserv。ORBD包括瞬态命名服务和持久命名服务。ORBD工具集成了服务器管理器、互操作命名服务和引导名称服务器的功能。当客户端想进行服务器时定位、注册和激活功能时，可以与servertool一起使用 servertool 为应用程序注册、注销、启动和关闭服务器提供易用的接口 部署工具 - javapackager 打包、签名Java和JavaFX应用程序，在JDK11中被移除 pack200 使用Java GZIP压缩器将JAR文件转换为压缩的Pack200文件。压缩的压缩文件是高度压缩的JAR，可以直接部署，节省带宽并减少下载时间 unpack200 将Pack200生成的打包文件解压提取为JAR文件 Java Web Start - javaws 启动Java Web Start并设置各种选项的工具。在JDK11中被移除 性能监控和故障处理 - jps JVM Process Status Tool，显示指定系统内所有的HotSpot虚拟机进程 jstat JVM Statistics Monitoring Tool，用于收集Hotspot虚拟机各方面的运行数据 jstatd JVM Statistics Monitoring Tool Daemon，jstat的守护程序，启动一个RMI服务器应用程序，用于监视测试的HotSpot虚拟机的创建和终止，并提供一个界面，允许远程监控工具附加到在本地系统上运行的虚拟机。在JDK 9中集成到了JHSDB 中 jinfo Configuration Info for Java，显示虚拟机配置信息。在JDK9中集成到了JHSDB中 jmap Mcmory Map for Java，生成虚拟机的内存转储快照(heapdump文件)。在JDK9中集成到了JHSDB中 jhat JVM Heap Analysis Tool，用于分析堆转储快照，它会建立一个HTTP/Web服务器，让用户可以在浏览器上查看分析结果。在JDK9中被JHSDB代替 jstack Stack Trace for Java，显示虚拟机的线程快照。在JDK9中集成到了JHSDB中 jhsdb Java HotSpot Debugger，一个基于Serviceability Agent的HotSpot进程调试器，从JDK9开始提供 jsadebugd Java Serviceability Agent Debug Dacmon，适用于Java的可维护性代理调试守护程序，主要用于附加到指定的Java进程、核心文件，或充当一个调试服务器 jcmd JVM Command，虚拟机诊断命令工具，将诊断命令请求发送到正在运行的Java虚拟机。从JDK7开始提供 jconsole Java Console，用于监控Java虚拟机的使用JMX规范的图形工具。它可以监控本地和远程Java虚拟机，还可以监控和管理应用程序 jmc Java Mission Control，包含用于监控和管理Java应用程序的工具，而不会引入与这些工具相关联的性能开销。开发者可以使用jmc命令来创建JMC工具，从JDK 7 Update 40开始集成到OracleJDK 中 jvisualvm Java VisualVM，一种图形化工具，可在Java虚拟机中运行时提供有关基于Java技术的应用程序(Java应用程序）的详细信息。Java VisualVM提供内存和CPU分析、堆转储分析、内存泄漏检测、MBcan访问和垃圾收集。从JDK6 Update7开始提供;从JDK9开始不再打包入JDK中，但仍保持更新发展，可以独立下载 schemagen 用于 XML 绑定的Schema生成器，用于生成XML Schema文件 wsgen XML Web Service 2.0的Java API，生成用于JAX-WS Web Service的JAX-WS便携式产物 wsimport XML Web Service 2.0的Java API，主要用于根据服务端发布的WSDL文件生成客户端 xjc 主要用于根据XML Schema 文件生成对应的Java类 REPL和脚本工具 - jshell 基于Java的 Shell REPL (Read-Eval-Print Loop）交互工具 ijs 对Nashorn引擎的调用入口。Nashorn是基于Java实现的一个轻量级高性能JavaScript运行环境 jrunscript Java命令行脚本外壳工具（Command Line Script Shell)，主要用于解释执行JavaScript、Groovy,Ruby 等脚本语言 可视化工具 jhsdb jconsole VisualVM jmc MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-23 06:15:18 "},"编程语言/JAVA/JVM/自动内存管理/调优.html":{"url":"编程语言/JAVA/JVM/自动内存管理/调优.html","title":"调优","keywords":"","body":"调优 调优方向： 吞吐量 用户代码时间 /（用户代码执行时间 + 垃圾回收时间） 【PS+PO】 响应时间 STW越短，响应时间越好 【CMS G1 ZGC】 规划与预调优 调优，从业务场景开始，没有业务场景的调优都是耍流氓 无监控（压力测试，能看到结果），不调优 步骤： 熟悉业务场景（没有最好的垃圾回收器，只有最合适的垃圾回收器） 响应时间、停顿时间 [CMS G1 ZGC] （需要给用户作响应） 吞吐量 = 用户时间 /( 用户时间 + GC时间) [PS+PO] 选择回收器组合 计算内存需求（经验值 1.5G 16G） 选定CPU（越高越好） 设定年代大小、升级年龄 设定日志参数 -Xloggc:/opt/xxx/logs/xxx-xxx-gc-%t.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCCause 或者每天产生一个日志文件 观察日志情况 优化运行环境 系统CPU经常100%，如何调优？(面试高频) CPU100%那么一定有线程在占用系统资源， 找出哪个进程cpu高（top） 该进程中的哪个线程cpu高（top -Hp） 导出该线程的堆栈 (jstack) 查找哪个方法（栈帧）消耗时间 (jstack) 工作线程占比高 | 垃圾回收线程占比高 系统内存飙高，如何查找问题？（面试高频） 导出堆内存 (jmap) 分析 (jhat jvisualvm mat jprofiler ... ) 如何监控JVM jstat jvisualvm jprofiler arthas top... 案例分析 大内存硬件的部署策略 一个单独的JVM来管理大量的堆内存 对于用户交互性强、对停顿时间敏感、内存又较大的系统，可以考虑使用一些以延迟为目标的垃圾收集器（如ZGC）来解决问题 使用这种方式有如下缺点： 大内存必须是64位JVM 相同的程序64位JVM消耗的内存比32位的多 一旦发生OOM，大内存转储也很麻烦 建立若干个JVM 通过集群的方式来利用硬件资源 这种方式通过负载均衡的方式来达到内存资源的充分利用，避免了上面的一些问题的同时也带来了下面的问题： 32位的的内存限制 对于一些本地资源，如连接池或者缓存，这些资源可能会由于热点原因倾斜，造成资源分配不均 集群同步的内存溢出问题 对于一些集群，需要通过网络同步数据，如果同步的数据产生的速度大于网络速率，则大量数据在内存里堆积，就会发生溢出的问题 直接内存溢出 JVM对直接内存的回收不能像新生代、老年代那样，发现空间不足了就主动通知收集器进行垃圾回收，它只能等待老年代满后Full GC出现后，“顺便”帮它清理掉内存的废弃对象 此时如果程序用完了直接内存，只能眼睁睁看着堆中还有许多空闲内存，自己却不得不抛出内存溢出异常了 外部命令导致系统缓慢 一些系统调用对于JVM来说是十分重的，如果频繁调用，系统资源的消耗必定很大 不合适的数据结构 如果数据很大，不选择合适的数据结构，空间利用效率不高，就会让原本不富裕的内存更加雪上加霜 Windows虚拟内存导致的停顿 https://hllvm-group.iteye.com/group/topic/28745 该案例给出了一个由于程序最小化working set会被trim的情况，也就是内存被交换到了硬盘中，此时发生GC的时候需要花费很长时间将内存数据再交换到内存中，这就导致了明明堆内存很小，GC时间却非常长 安全点导致的长时间停顿 https://juejin.im/post/5d1b1fc46fb9a07ef7108d82 该案例给出了一个由于部分线程执行到安全点非常慢从而导致拖慢整个用户线程停顿时间 方法调用、循环跳转、异常跳转这些位置都可能会设置有安全点，但是HotSpot虚拟机为了避免安全点过多带来过重的负担，对循环还有一项优化措施，认为循环次数较少的话，执行时间应该也不会太长，所以使用int类型或范围更小的数据类型作为索引值的循环默认是不会被放置安全点的 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-23 06:15:18 "},"编程语言/JAVA/JVM/字节码.html":{"url":"编程语言/JAVA/JVM/字节码.html","title":"字节码","keywords":"","body":"字节码 虚拟机实现的方式主要有以下两种： 将输入的Java虚拟机代码在加载时或执行时翻译成另一种虚拟机的指令集； 将输入的Java虚拟机代码在加载时或执行时翻译成宿主机处理程序的本地指令集（即即时编译器代码生成技术）。 Class 文件 JVM所执行的二进制文件，跨平台的基础 满足这种规范的class文件都会被JVM加载运行 可以由其他语言编译生成 不同版本的JDK生成的类文件略有不同 构成 类型 名称 数量 u4 magic 1 u2 minor_version 1 u2 major_version 1 u2 constant_pool_count 1 cp_info constant_pool constant_pool_count-1 u2 access_flags 1 u2 this_class 1 u2 super_class 1 u2 interfaces_count 1 u2 interfaces interfaces_count u2 fields_count 1 field_info fields fields_count u2 methods_count 1 method_info methods methods_count u2 attributes_count 1 attribute_info attributes attributes_count Class 文件中的所有字节存储都是使用大端序 Class文件格式采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构中只有两种数据类型： 无符号数：以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节的无符号数 以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值 表：由多个无符号数或者其他表作为数据项构成的复合数据类型 反编译： javap -v classname 魔数与 Class 文件版本 前4个字节为魔数，十六进制表示为0xCAFEBABE，标识该文件为class文件 第5、6字节表示次版本号（小更新） 第7和第8个字节是主版本号（从45开始，一个大版本加1） 常量池 常量池的入口放置了一项u2类型的数据，代表常量池容量计数值（constant_pool_count），这个数是从1开始 字面量：接近于Java语言层面的常量概念，如文本字符串、被声明为final的常量值等 符号引用 被模块导出或者开放的包（Package） 类和接口的全限定名（Fully Qualified Name） 字段的名称和描述符（Descriptor） 方法的名称和描述符 方法句柄和方法类型（Method Handle、Method Type、Invoke Dynamic 动态调用点和动态常量（Dynamically-Computed Call Site、Dynamically-Computed Constant） 访问标志 常量池结束之后的两个字节，描述该Class是类还是接口，以及是否被public、abstract、final等修饰符修饰 标志名称 标志值 含义 ACC_PUBLIC 0x0001 是否为public类型 ACC_FINAL 0x0010 是否被声明为final，只有类可设置 AcC_SUPER 0x0020 是否允许使用invokespecial字节码指令的新语义，invokespecial指令的语义在JDK1.0.2发生过改变，为了区别这条指令使用哪种语义，JDK1.0.2之后编译出来的类的这个标志都必须为真 ACC_INTERFACE 0x0200 标识这是一个接口 AcC_ABSTRACT Ox0400 是否为abstract类型，对于接口或者抽象类来说，此标志值为真，其他类型值为假 AcC_SYNTHETIC Ox1000 标识这个类并非由用户代码产生的 Acc_ANNOTATION 0x2000 标识这是一个注解 ACC_ENUM 0x4000 标识这是一个枚举 AcC_MODULE 0x8000 标识这是一个模块 类索引、父类索引与接口索引集合 类索引与父类索引都是一个u2类型的数据 接口索引入口的第一项u2类型的数据为接口计数器 字段表集合 用于描述类和接口中声明的变量（包括类级以及实例级别） 第一部分为两个字节，描述字段个数；第二部分是每个字段的详细信息fields_info。 字段表结构： 类型 名称 数量 u2 access_flags 1 u2 name_index 1 u2 descriptor_index 1 u2 attributes_count 1 attribute_info attributes attributes_count 字段访问标志，存放在access_flags里面： 标志名称 标志值 含义 ACC_PUBLIC Ox0001 字段是否public ACC_PRIVATE Ox0002 字段是否 private ACC_PROTECTED ox0004 字段是否 protected ACC_STATIC Ox0008 字段是否static ACC FINAL 0x0010 字段是否final ACC_VOLATILE Ox0040 字段是否 volatile ACC_TRANSIENT ox0080 字段是否transient ACC_SYNTHETIC ox1000 字段是否由编译器自动产生 ACC_ENUM Ox4000 字段是否 enum name_index和descriptor_index分别代表着字段的简单名称以及字段和方法的描述符 简单名称则就是指没有类型和参数修饰的方法或者字段名称 描述符： 标志字符 含义 B 基本类型byte C 基本类型char D 基本类型double F 基本类型float I 基本类型int J 基本类型1ong S 基本类型short Z 基本类型boolean V 特殊类型void L 对象类型，如Ljava/lang/Object; 对于数组类型，每一维度将使用一个前置的[字符来描述，，如一个定义为“java.lang.String[][]”类型的二维数组将被记录成“[[Ljava/lang/String；” 用描述符来描述方法时，按照先参数列表、后返回值的顺序描述，参数列表按照参数的严格顺序放在一组小括号“()”之内 方法int indexOf(char[]source，int sourceOffset，int sourceCount，char[]target，int targetOffset，int targetCount，int fromIndex)的描述符为“([CII[CIII)I” 方法表集合 方法表的结构同字段表 方法访问标志： 标志名称 标志值 含义 ACC_PUBLIC Ox0001 方法是否为public ACC_PRIVATE Ox0002 方法是否为private ACC_PROTECTED Ox0004 方法是否为protected ACC_STATIC 0x0008 方法是否为static ACC_FINAL 0x0010 方法是否为final AcC_SYNCHRONIZED Ox0020 方法是否为synchronized ACC_BRIDGE Ox0040 方法是不是由编译器产生的桥接方法 AcC_VARARGS Ox0080 方法是否接受不定参数 ACC_NATIVE Ox0100 方法是否为native ACC_ABSTRACT 0x0400 方法是否为abstract AcC_STRICT Ox0800 方法是否为strictfp ACC_SYNTHETIC Ox1000 方法是否由编译器自动产生 方法里的Java代码，经过Javac编译器编译成字节码指令之后，存放在方法属性表集合中一个名为“Code”的属性里面 属性表集合 Class文件、字段表、方法表都可以携带自己的属性表集合，以描述某些场景专有的信息 属性名称 使用位置 含义 Code 方法表 Java代码编译成的字节码指令 ConstantValue 字段表 由final关键字定义的常量值 Deprecated 类、方法表、字段表 被声明为deprecated 的方法和字段 Exceptions 方法表 方法抛出的异常列表 EnclosingMethod 类文件 仅当一个类为局部类或者匿名类时才能拥有这个属性，这个属性用于标示这个类所在的外围方法类文件 InncrClasses Code属性 内部类列表 LineNumberTable Codc属性 Java 源码的行号与字节码指令的对应关系 LocalVariableTable Code属性 方法的局部变量描述 StackMapTable Code属性 JDK6中新增的属性，供新的类型检查验证器(Type Checker）检查和处理目标方法的局部变量和操作数栈所需要的类型是否匹配 Signature 类、方法表、字段表 JDK 5中新增的属性，用于支持范型情况下的方法签名。在Java语言中，任何类、接口、初始化方法或成员的泛型签名如果包含了类型变量（TypeVariables）或参数化类型（Parameterized Types)，则Signature属性会为它记录泛型签名信息。由于Java的范型采用擦除法实现，为了避免类型信息被擦除后导致签名混乱，需要这个属性记录范型中的相关信息 SourceFile 类文件 记录源文件名称 SourceDebugExtension 类文件 JDK 5中新增的属性，用于存储额外的调试信息。譬如在进行JSP文件调试时，无法通过Java堆栈来定位到JSP文件的行号JSR 45提案为这些非Java类文件语言编写，却需要编译成字节码并运行在Java虚拟机中的程序提供了一个进行调试的标准机制，使用该属性就可以用于存储这个标准所新加人的调试信息 Synthetic 类、方法表、字段表 标识方法或字段为编译器自动生成的 LocalVariablcTypeTable 类 JDK 5中新增的属性，它使用特征签名代替描述符，是为了引人泛型语法之后能描述泛型参数化类型而添加 RuntimeVisibleAnnotations 类、方法表、字段表 JDK 5中新增的属性，为动态注解提供支持。该属性用于指明哪些注解是运行时（实际上运行时就是进行反射调用）可见的 RuntimcInvisiblcAnnotations 类、方法表、字段表 JDK 5中新增的属性，与RuntimeVisibleAnnota-tions属性作用刚好相应，用于指明哪些注解是运行时不可见的 RuntimeVisibleParamcterAnnotations 方法表 JDK5中新增的属性，作用与RuntimeVisible-Annotations属性类似，只不过作用对象为方法参数 RuntimelnvisibleParameterAnnotations 方法表 JDK 5中新增的属性，作用与 RuntimelnvisiblcAnnotations属性类似，只不过作用对象为方法参数 AnnotationDefault 方法表 JDK 5中新增的属性，用于记录注解类元素的默认值 BootstrapMethods 类文件 JDK 7中新增的属性，用于保存invokedynamic指令引用的引导方法限定符 RuntimeVisibleTypeAnnotations 类、方法表、字段表，Code属性 JDK 8中新增的属性，为实现JSR 308中新增的类型注解提供的支持，用于指明哪些类注解是运行时(实际上运行时就是进行反射调用）可见的 RuntimelnvisibleTypeAnnotations 类、方法表、字段表,Code属性 JDK 8中新增的属性，为实现JSR 308中新增的类型注解提供的支持，与RuntimeVisibleTypeAnnotations属性作用刚好相反，用于指明哪些注解是运行时不可见的 MethodParameters 方法表 JDK 8中新增的属性，用于支持（编译时加上-parameters参数）将方法名称编译进 Class文件中，并可运行时获取。此前要获取方法名称（典型的如IDE的代码提示）只能通过JavaDoc中得到 Module 类 JDK 9中新增的属性，用于记录一个Module的名称以及相关信息（requires.exports.opens, uses .provides) ModulePackages 类 JDK9中新增的属性，用于记录一个模块中所有被exports或者opens 的包 ModuleMainClass 类 JDK9中新增的属性，用于指定一个模块的主类 NestHost 类 JDK 11中新增的属性，用于支持嵌套类（Java中类的内部类）的反射和访问控制的API，一个内部类通过该属性得知自己的宿主类 NestMembers 类 JDK 11中新增的属性，用于支持嵌套类（Java中的内部类）的反射和访问控制的API，一个宿主类通过该属性得知自已己有哪些内部类 属性表结构： 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u1 info attribute_length 1.Code属性 类型 名称 数量 说明 u2 attribute_name_index 1 attribute_name_index是一项指向CONSTANT_Utf8_info型常量的索引，此常量值固定为\"Code\"，它代表了该属性的属性名称 u4 attribute_length l 属性值的长度 u2 max_stack l 代表了操作数栈（Operand Stack）深度的最大值 u2 max_locals 1 代表了局部变量表所需的存储空间（32位以下（包含）的变量占用一个槽） u4 code_length 1 执行的字节码长度（《Java虚拟机规范》中明确限制了一个方法不允许超过65535条字节码指令） u1 code code_length 存放执行的字节码 u2 exception_table_length 1 exception_info exception_table exception_table_length u2 attributes_count 1 u2 attributes_count 1 attribute_info attributes attributes_count public int inc() {return m + 1;} 一个方法编译后： public int inc(); descriptor: ()I flags: (0x0001) ACC_PUBLIC Code: stack=2, locals=1, args_size=1 //这里的方法虽然没有参数，但是参数数量为1,1就是this 0: aload_0 1: getfield #2 // Field m:I 4: iconst_1 5: iadd 6: ireturn LineNumberTable: line 4: 0 异常表： 类型 名称 数量 说明 u2 start_pc 1 异常捕获起始行 u2 end_pc 1 异常捕获结束行（不包含本行） u2 handler_pc 1 发生异常后跳转的位置 u2 catch_type 1 异常的类型 2.Exceptions属性 列举出方法中可能抛出的受查异常（Checked Excepitons） 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 number_of_exceptions 1 u2 exception_index_table number_of_exceptions 3.LineNumberTable属性 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 line_number_table_length 1 line_number_info line_number_table line_number_table_length 4.LocalVariableTable及LocalVariableTypeTable属性 LocalVariableTable属性用于描述栈帧中局部变量表的变量与Java源码中定义的变量之间的关系 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 local_variable_table_length 1 local_variable_info local_variable_table local_variable_table_length local_variable_info项目代表了一个栈帧与源码中的局部变量的关联: 类型 名称 数量 说明 u2 start_pc 1 生命周期开始的字节码偏移量 u2 length 1 作用范围覆盖的长度 u2 name_index 1 局部变量的名称 u2 descriptor_index 1 局部变量的描述符 u2 index 1 局部变量在栈帧的局部变量表中变量槽的位置 LocalVariableTypeTable。这个新增的属性结构与LocalVariableTable非常相似，仅仅是把记录的字段描述符的descriptor_index替换成了字段的特征签名（Signature） 5.SourceFile及SourceDebugExtension属性 类型 名称 数量 说明 u2 attribute_name_index 1 u4 attribute_length 1 u2 sourcefile_index 1 指向常量池中CONSTANT_Utf8_info型常量的索引，常量值是源码文件的文件名 SourceDebugExtension属性用于存储额外的代码调试信息: 类型 名称 数量 说明 u2 attribute_name_index 1 u4 attribute_length 1 u1 debug_extension[attribute_length] 1 额外的debug信息 6.ConstantValue属性 通知虚拟机自动为静态变量赋值。 目前Oracle公司实现的Javac编译器的选择是，如果同时使用final和static来修饰一个变量（按照习惯，这里称“常量”更贴切），并且这个变量的数据类型是基本类型或者java.lang.String的话，就将会生成ConstantValue属性来进行初始化 类型 名称 数量 说明 u2 attribute_name_index 1 u4 attribute_length 1 u2 constantvalue_index 1 所以这里的常量最多只能为64bit 7.InnerClasses属性 用于记录内部类与宿主类之间的关联 类型 名称 数量 说明 u2 attribute_name_index 1 u4 attribute_length 1 u2 number_of_classes 1 表需要记录多少个内部类信息 inner_class_info inner_classes number_of_classes 记录的内部类信息 类型 名称 数量 说明 u2 inner_class_info_index 1 内部类的符号引用 u2 outer_class_info_index 1 宿主类的符号引用 u2 inner_name_index 1 代表这个内部类的名称，如果是匿名内部类，这项值为0 u2 inner_class_access flags 1 内部类的访问标志 8.Deprecated及Synthetic属性 Deprecated属性用于表示某个类、字段或者方法，已经被程序作者定为不再推荐使用，它可以通过代码中使用“@deprecated”注解进行设置 Synthetic属性代表此字段或者方法并不是由Java源码直接产生的 属性结构： 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 9.StackMapTable属性 在编译阶段将一系列的验证类型（Verification Type）直接记录在Class文件之中，通过检查这些验证类型代替了类型推导过程，从而大幅提升了字节码验证的性能 类型 名称 数量 说明 u2 attribute_name_index 1 u4 attribute_length 1 u2 number_of_entries 1 stack_map_frame stack_map_frame_entries number_of_entries 10.Signature属性 一个可选的定长属性，可以出现于类、字段表和方法表结构的属性表中,用来记录泛型信息 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 signature_index 1 11.BootstrapMethods属性 位于类文件的属性表中。这个属性用于保存invokedynamic指令引用的引导方法限定符 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 num_bootstrap_methods 1 bootstrap_method bootstrap_methods num_bootstrap_methods 12.MethodParameters属性 一个用在方法表中的变长属性。MethodParameters的作用是记录方法的各个形参名称和信息 13.模块化相关属性 14.运行时注解相关属性 内存结构 字节码指令 不考虑异常处理的字节码执行： do { 自动计算PC寄存器的值加1; 根据PC寄存器指示的位置，从字节码流中取出操作码; if (字节码存在操作数) 从字节码流中取出操作数; 执行操作码所定义的操作; } while (字节码流长度 > 0); 大部分与数据类型相关的字节码指令，它们的操作码助记符中都有特殊的字符来表明专门为哪种数据类型服务：i代表对int类型的数据操作，l代表long，s代表short，b代表byte，c代表char，f代表float，d代表double，a代表reference oracle 官方 pdf 基于寄存器的指令集 基于栈的指令集 Hotspot中的Local Variable Table = JVM中的寄存器 加载和存储指令 用于将数据在栈帧中的局部变量表和操作数栈之间来回传输 将一个局部变量加载到操作栈：iload、iload_、lload、lload_、fload、fload_、dload、dload_、aload、aload_ 将一个数值从操作数栈存储到局部变量表：istore、istore_、lstore、lstore_、fstore、fstore_、dstore、dstore_、astore、astore_ 将一个常量加载到操作数栈：bipush、sipush、ldc、ldc_w、ldc2_w、aconst_null、iconst_m1、iconst_、lconst_、fconst_、dconst_ iload_代表了iload_0、iload_1、iload_2和iload_3这几条指令 这些指令都是iload的特殊形式，这些特殊的指令省略掉了操作数，但是语义同iload一样 运算指令 用于对两个操作数栈上的值进行某种特定运算，并把结果重新存入到操作栈顶 加法指令：iadd、ladd、fadd、dadd 减法指令：isub、lsub、fsub、dsub 乘法指令：imul、lmul、fmul、dmul 除法指令：idiv、ldiv、fdiv、ddiv 求余指令：irem、lrem、frem、drem 取反指令：ineg、lneg、fneg、dneg 位移指令：ishl、ishr、iushr、lshl、lshr、lushr 按位或指令：ior、lor 按位与指令：iand、land 按位异或指令：ixor、lxor 局部变量自增指令：iinc 比较指令：dcmpg、dcmpl、fcmpg、fcmpl、lcmp 类型转换指令 Java虚拟机直接支持（即转换时无须显式的转换指令）的宽化类型转换 窄化转换：i2b、i2c、i2s、l2i、f2i、f2l、d2i、d2l和d2f 对象/数组创建与访问指令 创建类实例的指令：new 创建数组的指令：newarray、anewarray、multianewarray 访问类字段（static字段，或者称为类变量）和实例字段（非static字段，或者称为实例变量）的 指令：getfield、putfield、getstatic、putstatic 把一个数组元素加载到操作数栈的指令：baload、caload、saload、iaload、laload、faload、daload、aaload 将一个操作数栈的值储存到数组元素中的指令：bastore、castore、sastore、iastore、fastore、dastore、aastore 取数组长度的指令：arraylength 检查类实例类型的指令：instanceof、checkcast 操作数栈管理指令 直接操作操作数栈的指令 将操作数栈的栈顶一个或两个元素出栈：pop、pop2 复制栈顶一个或两个数值并将复制值或双份的复制值重新压入栈顶：dup、dup2、dup_x1、dup2_x1、dup_x2、dup2_x2 将栈最顶端的两个数值互换：swap 控制转移指令 有条件或无条件地从指定位置指令（而不是控制转移指令）的下一条指令继续执行程序，概念模型上理解，可以认为控制指令就是在有条件或无条件地修改PC寄存器的值 条件分支：ifeq、iflt、ifle、ifne、ifgt、ifge、ifnull、ifnonnull、if_icmpeq、if_icmpne、if_icmplt、if_icmpgt、if_icmple、if_icmpge、if_acmpeq和if_acmpne 复合条件分支：tableswitch、lookupswitch 无条件分支：goto、goto_w、jsr、jsr_w、ret 方法调用和返回指令 invokevirtual指令：用于调用对象的实例方法，根据对象的实际类型进行分派（虚方法分派），这也是Java语言中最常见的方法分派方式。 invokeinterface指令：用于调用接口方法，它会在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。 invokespecial指令：用于调用一些需要特殊处理的实例方法，包括实例初始化方法、私有方法和父类方法。 invokestatic指令：用于调用类静态方法（static方法）。 invokedynamic指令：用于在运行时动态解析出调用点限定符所引用的方法。并执行该方法。前面四条调用指令的分派逻辑都固化在Java虚拟机内部，用户无法改变，而invokedynamic指令的分派逻辑 是由用户所设定的引导方法决定的 方法返回指令是根据返回值的类型区分的，包括ireturn（当返回值是boolean、byte、char、short和int类型时使用）、lreturn、freturn、dreturn和areturn，另外还有一条return指令供声明为void的方法、实例初始化方法、类和接口的类初始化方法使用 异常处理指令 显式抛出异常的操作（throw语句）都由athrow指令来实现 异常捕获现在则是使用了异常表的来完成 同步控制指令 ACC_SYNCHRONIZED 标志同步方法 MONITORENTER MONITOREXIT 标记临界区 ASM ASM是一个通用的Java字节码操作和分析框架 Core API 不需要读取类的整个结构，使用流式的方法来处理字节码文件 编程难度较大 Tree API 消耗内存多，但是编程比较简单 通过各种Node类来映射字节码的各个区域 字节码增强 java agent premain：支持在main函数之前，对类的字节码进行修改/替换 agentmain：支持在程序运行过程中，对字节码进行替换 字节码混淆 使反编译的代码可读性变差 ProGuard javassist 生成类 ClassPool pool = ClassPool.getDefault(); // 创建类 CtClass userClass = pool.makeClass(\"wang.ismy.test.User\"); // 添加属性 userClass.addField(CtField.make(\"private String name;\",userClass)); userClass.addField(CtField.make(\"private Integer age;\",userClass)); // 添加方法 userClass.addMethod(CtMethod.make(\"public String getName(){return name;}\",userClass)); userClass.addConstructor(new CtConstructor(new CtClass[]{pool.get(\"java.lang.String\"),pool.get(\"java.lang.Integer\")},userClass)); userClass.writeFile(\"./User.class\"); 修改类 ClassPool pool = ClassPool.getDefault(); pool.appendClassPath(new ClassClassPath(Main.class)); CtClass userClass = pool.get(\"wang.ismy.assist.User\"); userClass.getDeclaredMethod(\"getName\").setBody(\"{return name + \\\"123\\\";}\"); Class aClass = userClass.toClass(); Object obj = aClass.newInstance(); System.out.println(aClass.getMethod(\"getName\").invoke(obj)); 字节码的执行 解释执行 编译执行 JIT编译与解释混合执行 这样就造成机器在热机所承载的负载可能会比冷机的高 -Xmixed 默认为混合模式 -Xint 解释模式 -Xcomp 纯编译模式 热点代码检测 多次被调用的方法 方法计数器 多次被被调用的循环 循环计数器 代码优化 使用局部变量 减少重复计算 懒加载 异常对性能不利 避免创建导入不使用的对象和类 反射对性能不利 连接池和线程池有利于提高性能 容器初始化指定长度 不同的数据结构在不同操作下的性能表现不同 使用键值对遍历Map 不应手动调用GC 正则表达式对性能有影响 日志输出注意级别 资源close可以分开 实例-动态代理字节码生成 public class DynamicProxyTest { public static void main(String[] args) { System.getProperties().put(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\"); Run origin = new Run(); Runnable hello = (Runnable)Proxy.newProxyInstance(Run.class.getClassLoader(), new Class[]{Runnable.class}, new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"hello\"); return method.invoke(origin); } }); hello.run(); } } class Run implements Runnable{ @Override public void run() { System.out.println(\"world\"); } } 这里newProxyInstance会生成这么样的一个代理类： public final class $Proxy0 extends Proxy implements Runnable { ... public final void run() throws { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } ... } 生成的代理类run方法会调用我们写的InvocationHandler 我们的InvocationHandler又会执行一些附带逻辑并最后执行真实对象的方法 实例-Backport：回到未来 把高版本JDK中编写的代码放到低版本JDK环境中去部署使用。为了解决这个问题，一种名为“Java逆向移植”的工具（Java Backporting Tools）应运而生，Retrotranslator和Retrolambda是这类工具中的杰出代表 这些工具可以很好地移植下面两种情况： 对Java类库API的代码增强 在前端编译器层面做的改进。这种改进被称作语法糖 对于第一种情况 一些诸如只有高版本才有的类库移植工具可以很方便移植 但对于第二种情况，移植工具就需要通过修改字节码的方式来实现 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-08 05:13:48 "},"编程语言/JAVA/JVM/字节码执行引擎.html":{"url":"编程语言/JAVA/JVM/字节码执行引擎.html","title":"字节码执行引擎","keywords":"","body":"字节码执行引擎 运行时栈帧结构 用于支持虚拟机进行方法调用和方法执行背后的数据结构 栈帧存储了方法的局部变量表、操作数栈、动态连接和方法返回地址等信息 每个栈帧的大小在编译期就已经确定（根据局部变量表 操作数栈等） 局部变量表 用于存放方法参数和方法内部定义的局部变量，方法的Code属性max_locals数据项确定了局部变量表的最大容量 规范说到每个变量槽都应该能存放一个boolean、byte、char、short、int、float、reference或returnAddress类型的数据 虚拟机实现至少都应当能通过reference做两件事： 根据引用直接或间接地查找到对象在Java堆中的数据存放的起始地址或索引 根据引用直接或间接地查找到对象所属数据类型在方法区中的存储的类型信息 对于64位的数据类型，Java虚拟机会以高位对齐的方式为其分配两个连续的变量槽空间 局部变量表中的变量槽是可以重用的，但是这种重用会影响到垃圾回收，如果垃圾收集器发现变量表还存在某个变量的引用 就不会轻易回收它： byte[] bytes = new byte[1024 * 1024 * 128]; bytes = null; // 不加上这行 bytes不会在gc被调用时被回收 System.gc(); 操作数栈 操作数栈的最大深度也在编译的时候被写入到Code属性的max_stacks数据项之中 用来支持各种指令操作 动态连接 每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用 方法返回地址 方法执行后 有两种方式退出方法： 执行引擎遇到任意一个方法返回的字节码指令，这时候可能会有返回值传递给上层的方法调用者 方法执行的过程中遇到了异常，并且这个异常没有在方法体内得到妥善处理 方法退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值（如果有的话）压入调用者栈帧的操作数栈中 附加信息 《Java虚拟机规范》允许虚拟机实现增加一些规范里没有描述的信息到栈帧之中，例如与调试、性能收集相关的信息 方法调用 方法调用是最普遍、最频繁的操作之一 方法调用的指令： invokestatic：用于调用静态方法。 invokespecial：用于调用实例构造器()方法、私有方法和父类中的方法 invokevirtual:用于调用所有的虚方法 invokeinterface:用于调用接口方法，会在运行时再确定一个实现该接口的对象 invokedynamic:先在运行时动态解析出调用点限定符所引用的方法，然后再执行该方法 只要能被invokestatic和invokespecial指令调用的方法，都可以在解析阶段中确定唯一的调用版本, 这些方法被称为非虚方法 public static void say(){ System.out.println(\"hello world\"); } public static void main(String[] args) { say(); } public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: (0x0009) ACC_PUBLIC, ACC_STATIC Code: stack=0, locals=1, args_size=1 0: invokestatic #21 // Method say:()V 3: return LineNumberTable: line 12: 0 line 13: 3 分派 静态类型：编译时能确定的类型 所有依赖静态类型来决定方法执行版本的分派动作，都称为静态分派。静态分派的最典型应用表现就是方法重载 static void f(Object obj){ System.out.println(\"obj\"); } static void f(CharSequence seq){ System.out.println(\"seq\"); } static void f(String str){ System.out.println(\"str\"); } public static void main(String[] args) { Object obj = \"str\"; CharSequence seq = \"str\"; String str = \"str\"; f(obj); // obj f(seq); // seq f(str); // str } 动态分派 方法覆写的话会在运行时动态决定应该调用哪个方法 invokevirtual指令执行的第一步就是在运行期确定接收者的实际类型，只有方法才会参与多态 字段没有invokevirtual相关指令 所以字段不会多态 单分派与多分派 静态多分派：根据参数来决定 动态单分派：根据被调用的对象决定 虚拟机动态分派的实现 为了性能 JVM不会频繁搜索类元数据 而是使用了一个虚方法表： 动态类型语言支持 invokedynamic指令 动态类型语言：类型检查的主体过程是在运行期而不是编译期进行的 java.lang.invoke 模拟invokedynamic: // 返回值类型 参数类型 MethodType methodType = MethodType.methodType(void.class, String.class); Object obj = System.out; MethodHandle methodHandle = MethodHandles.lookup() .findVirtual(obj.getClass(), \"println\", methodType).bindTo(obj); methodHandle.invoke(\"hello world\"); MethodHandle是在模拟字节码层次的方法调用 反射API只能为Java服务 使用invoke包可以用来开发动态语言 实战 自己控制方法调用 static class GrandFather { void thinking() { System.out.println(\"i am grandfather\"); } } static class Father extends GrandFather { void thinking() { System.out.println(\"i am father\"); } } static class Son extends Father { void thinking() { // 在这里填入适当的代码（不能修改其他地方的代码） // 实现调用祖父类的thinking()方法，打印\"i am grandfather\" try { MethodType mt = MethodType.methodType(void.class); Field lookupImpl = MethodHandles.Lookup.class.getDeclaredField(\"IMPL_LOOKUP\"); lookupImpl.setAccessible(true); MethodHandle mh = ((MethodHandles.Lookup) lookupImpl.get(null)).findSpecial(GrandFather.class, \"thinking\", mt, GrandFather.class); try { mh.invoke(this); } catch (Throwable throwable) { throwable.printStackTrace(); } } catch (Exception e) { e.printStackTrace(); } } } 执行引擎 解释执行 早期的JVM是通过解释字节码来执行的 但后面也出现了编译为本地机器码的编译器 所以现代的Java是拥有编译模式以及解释模式亦或者混合模式 基于栈 对于JVM来说 基于栈移植容易 实现容易 栈架构指令集的缺点在于速度稍慢 实战：分析一段简单的四则运算 public int calc(){ int a = 100; int b = 200; int c = 300; return (a + b) * c; } public int calc(); descriptor: ()I flags: (0x0001) ACC_PUBLIC Code: stack=2, locals=4, args_size=1 0: bipush 100 2: istore_1 3: sipush 200 6: istore_2 7: sipush 300 10: istore_3 11: iload_1 12: iload_2 13: iadd 14: iload_3 15: imul 16: ireturn LineNumberTable: line 9: 0 line 10: 3 line 11: 7 line 12: 11 javap提示这段代码需要深度为2的操作数栈和4个变量槽的局部变量空间 1.Bipush指令的作用是将单字节的整型常量值（-128～127）推入操作数栈顶 参数为100 2.istore_1指令的作用是将操作数栈顶的整型值出栈并存放到第1个局部变量槽中 后面的istore 以及xxpush都是一样 3.iload_1指令的作用是将局部变量表第1个变量槽中的整型值复制到操作数栈顶 4.load_2指令的执行过程与iload_1类似，把第2个变量槽的整型值入栈 5.iadd指令的作用是将操作数栈中头两个栈顶元素出栈，做整型加法，然后把结果重新入栈 6.iload_3指令把存放在第3个局部变量槽中的300入栈到操作数栈中 7.指令imul是将操作数栈中头两个栈顶元素出栈，做整型乘法，然后 把结果重新入栈，与iadd完全类似 8.ireturn指令是方法返回指令之一，它将结束方法执行并将操作数栈顶的整型值返回给该方法的调用者 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-02 08:15:39 "},"编程语言/JAVA/JVM/运行参数.html":{"url":"编程语言/JAVA/JVM/运行参数.html","title":"运行参数","keywords":"","body":"运行参数 参数类型 标准参数 -help -version -X参数（非标准参数） Xint Xcomp -XX参数 -XX:newSize -XX:+UseSerialGC -D参数 用来获取命令行传入的参数 System.out.println(System.getProperty(\"str\")); java -Dstr=123 Main.java # JDK13可以直接编译并运行 -X参数 JDK13中的-X参数 -Xbatch 禁用后台编译 -Xbootclasspath/a: 附加在引导类路径末尾 -Xcheck:jni 对 JNI 函数执行其他检查 -Xcomp 强制在首次调用时编译方法 -Xdebug 不执行任何操作。为实现向后兼容而提供。 -Xdiag 显示附加诊断消息 -Xfuture 启用最严格的检查，预期将来的默认值。 此选项已过时，可能会在 未来发行版中删除。 -Xint 仅解释模式执行 -Xinternalversion 显示比 -version 选项更详细的 JVM 版本信息 -Xlog: 配置或启用采用 Java 虚拟 机 (Java Virtual Machine, JVM) 统一记录框架进行事件记录。使用 -Xlog:help 可了解详细信息。 -Xloggc: 将 GC 状态记录在文件中（带时间戳）。 此选项已过时，可能会在 将来的发行版中删除。它将替换为 -Xlog:gc:。 -Xmixed 混合模式执行（默认值） -Xmn 为年轻代（新生代）设置初始和最大堆大小 （以字节为单位） -Xms 设置初始 Java 堆大小 -Xmx 设置最大 Java 堆大小 -Xnoclassgc 禁用类垃圾收集 -Xrs 减少 Java/VM 对操作系统信号的使用（请参见文档） -Xshare:auto 在可能的情况下使用共享类数据（默认值） -Xshare:off 不尝试使用共享类数据 -Xshare:on 要求使用共享类数据，否则将失败。 这是一个测试选项，可能导致间歇性 故障。不应在生产环境中使用它。 -XshowSettings 显示所有设置并继续 -XshowSettings:all 显示所有设置并继续 -XshowSettings:locale 显示所有与区域设置相关的设置并继续 -XshowSettings:properties 显示所有属性设置并继续 -XshowSettings:vm 显示所有与 vm 相关的设置并继续 -XshowSettings:system （仅 Linux）显示主机系统或容器 配置并继续 -Xss 设置 Java 线程堆栈大小 -Xverify 设置字节码验证器的模式 请注意，选项 -Xverify:none 已过时， 可能会在未来发行版中删除。 -XX参数 boolean类型 -XX:+name表示启用 -XX:-name表示不启用 非boolean类型 -XX:name=value -Xms与-Xmx -Xmx2048m 设置最大堆内存为2048M -Xms523m 设置初始堆内存为512M 查看JVM运行参数 -XX:+PrintCommandLineFlags 查看正在运行的JVM参数 jinfo -flags pid 可以通过jps命令列出JAVA进程 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-09 03:29:47 "},"编程语言/JAVA/JVM/类加载机制.html":{"url":"编程语言/JAVA/JVM/类加载机制.html","title":"类加载机制","keywords":"","body":"类加载机制 类加载过程 将.class字节流实例化成Class对象并进行相关初始化的过程 加载 通过类的完全限定名称获取该类的二进制字节流 可从zip包读取，如jar、war 可从网络获取 运行时动态生成 将字节流表示的静态存储结构转换为方法区的运行时存储结构 在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口 对于数组类的创建：数组类本身不通过类加载器创建，由Java虚拟机直接在 内存中动态构造出来的 验证 目的是确保Class文件的字节流中包含的信息符合《Java虚拟机规范》的全部约束要求，验证阶段的工作量在虚拟机的类加载过程中占了相当大的比重 文件格式验证 验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。 该验证阶段的主要目的是保证输入的字节流能正确地解析并存储于方法区之内 元数据验证 对字节码描述的信息进行语义分析，主要目的是对类的元数据信息进行语义校验，保证不存在与《Java语言规范》定义相悖的元数据信息 字节码验证 对类的方法体（Class文件中的Code属性）进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的行为 符号引用验证 这个阶段检查该类是否缺少或者被禁止访问它依赖的某些外部类、方法、字段等资源 准备 准备阶段为类变量分配内存并设置初始值，使用的是方法区的内存 基本数据类型的初始值： 数据类型 零值 int 0 long 0L short (short)0 char '\\u0000' byte (byte)0 boolean false float 0.0f double 0.0d reference null 解析 确保类与类之间的相互引用正确性 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标 直接引用（Direct References）：直接引用是可以直接指向目标的指针、相对偏移量或者是一个能间接定位到目标的句柄 解析阶段是将常量池的符号引用替换为直接引用的过程 类或接口的解析 在解析类的时候，如果当前处于类D，则加载其他类的职责会交给类D的类加载器，在加载类时，会检查类D是否有访问权限（修饰符以及模块访问权限） 字段解析 字段解析的过程中会按照继承链从下往上进行查找，当查找到引用时，也会进行检查权限 类方法解析 方法解析首先会判断是否为接口，如果是接口 直接抛出异常 否则跟字段解析一样递归从下往上查找，递归查找不到就会查找父接口等，再找不到就抛出异常，如果找到了同样也会进行权限检查 接口方法解析 如果发现不是接口 抛出异常 递归查找父接口 直到Object 否则就查找失败 同样如果查找到会进行权限检查 初始化 初始化阶段是虚拟机执行类构造器 () 方法的过程 () 是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序决定的 静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问 static { i=1; // 可以赋值 System.out.println(i); // 无法通过编译 } static int i =0; Java虚拟机会保证在子类的()方法执行前，父类的()方法已经执行完毕 static class Father { static int a= 1; static { a=2; } } static class Son extends Father{ static int b = a; } public static void main(String[] args) { System.out.println(Son.a); // 2 } ()方法对于类或接口来说并不是必需的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成()方法 执行接口的()方法不需要先执行父接口的()方法 JVM会保证只有一个线程能进入clinit方法 类加载时机 主动引用 遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化 new关键字实例化对象 读取或设置一个类型的静态字段 调用一个类型的静态方法 对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化 始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化 虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类 如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStatic、REF_invokeStaticREF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化 一个接口中定义了默认方法，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化 被动引用 除此主动引用外，所有引用类的方式都不会触发初始化，称为被动引用 通过子类引用父类的静态字段，不会导致子类初始化 static class Father { static { System.out.println(\"father init\"); } static int value = 123; } static class Son extends Father{ static { System.out.println(\"son init\"); } } public static void main(String[] args) { System.out.println(Son.value); // fatcher init ... } 定义一个该类的数组不会导致该类的初始化 static class Ref{ static { System.out.println(\"ref init\"); } } public static void main(String[] args) { //Ref[]这个类由虚拟机自动生成，包装了对真正数组的访问 Ref[] refs = new Ref[10]; // print nothing } 引用该类的常量不会导致该类初始化 static class Ref { static { System.out.println(\"ref init\"); } public static final int value = 123; } public static void main(String[] args) { // 编译期优化掉了，这个123存放在常量池里面 System.out.println(Ref.value); // only print 123 } 类加载器 两个类相等，需要类本身相等，并且使用同一个类加载器进行加载 ClassLoader myLoader = new ClassLoader() { @Override public Class loadClass(String name) throws ClassNotFoundException { try { String fileName = name.substring(name.lastIndexOf(\".\") + 1)+\".class\"; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) { return super.loadClass(name); } byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); } catch (IOException e) { throw new ClassNotFoundException(name); } } }; Object obj = myLoader.loadClass(\"wang.ismy.jvm.classload.ClassLoaderTest\").newInstance(); System.out.println(obj.getClass()); // obj是使用自定义加载器加载的 System.out.println(obj instanceof wang.ismy.jvm.classload.ClassLoaderTest); // false 分类 按虚拟机角度 启动类加载器(bootstrap classloader)，使用 C++ 实现，是虚拟机自身的一部分 用来加载核心类库 如rt.jar 其他类加载器，都是JAVA中继承自java.lang.ClassLoader的类加载器 按JAVA开发人员角度 启动类加载器 负责\\lib目录 扩展类加载器 负责\\lib\\ext 应用程序类加载器 程序自定义 负责加载用户类路径（ClassPath）上所有的类库 双亲委派模型 protected Class loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // 首先，检查请求的类是否已经被加载过了 Class c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { // 如果有父加载器就从从父加载器加载 c = parent.loadClass(name, false); } else { // 否则从启动类加载器加载 c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // 如果一个类找不到就抛出ClassNotFoundException // 说明父类和启动类加载器都无法满足需求 } if (c == null) { // 依旧找不到，就调用自身的findClass long t1 = System.nanoTime(); c = findClass(name); // 用来记录类加载时间等等信息的... sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } 首先判断是否已经加载 若无，找父加载器加载 若再无，由当前加载器加载 上级类加载器所加载的类，无法访问下级类加载器所加载的类 一个类加载器首先将类加载请求转发到父类加载器，只有当父类加载器无法完成时才尝试自己加载 这样就使得 Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一 所以系统中的String类加载优先级就会比在classpath或者用户自定义的String类优先级更高 自定义类加载路径 使用URLClassLoader URL url = new URL(\"file:~/mysql-connector-java-5.1.44-bin.jar\"); URLClassLoader loader = new URLClassLoader(new URL[]{url}); Class klass = loader.loadClass(\"com.mysql.jdbc.Driver\"); System.out.println(klass); 获取当前线程类加载器 ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader(); 热部署 自定义类加载器 模板方法模式 findInCache -> parent.loadClass -> findClass() class MyClassLoader extends ClassLoader { @Override protected Class findClass(String name) throws ClassNotFoundException { if (\"wang.ismy.Main\".equals(name)){ byte[] bytes = new byte[0]; try { bytes = new FileInputStream(\"path\").readAllBytes(); } catch (IOException e) { e.printStackTrace(); } return defineClass(name,bytes,0,bytes.length); }else { return super.findClass(name); } } } 自定义类加载器的场景： 隔离加载类 确保中间件应用的jar不会影响到中间件的jar 修改加载方式 从其他地方获取class字节流 字节码加解密 打破双亲委派模型 JDK1.2之前 自定义ClassLoader必须重写loadClass ThreadContextClassLoader可以实现基础类调用实现类代码，通过thread.setContextClassLoader指定 OSGi 的类查找模型也不遵守双亲委派 Tomcat的类加载也不遵守 实例 Tomcat 的正统类加载机制 放置在/common目录中。类库可被Tomcat和所有的Web应用程序共同使用。 放置在/server目录中。类库可被Tomcat使用，对所有的Web应用程序都不可见。 放置在/shared目录中。类库可被所有的Web应用程序共同使用，但对Tomcat自己不可见。 放置在/WebApp/WEB-INF目录中。类库仅仅可以被该Web应用程序使用 Tomcat6之后 用户可以通过修改配置文件指定server.loader和share.loader的方式重新启用原来完整的加载器架构 OSGi 灵活的类加载机制 OSGi（Open Service Gateway Initiative）是OSGi联盟（OSGi Alliance）制订的一个基于Java语言的动态模块化规范 在OSGi中，加载器之间的关系不再是双亲委派模型的树形结构，而是已 经进一步发展成一种更为复杂的、运行时才能确定的网状结构 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-08 04:33:43 "},"编程语言/JAVA/JVM/前端编译与优化.html":{"url":"编程语言/JAVA/JVM/前端编译与优化.html","title":"前端编译与优化","keywords":"","body":"前端编译与优化 将.java编译为.class 编译过程 initProcessAnnotations(processors, sourceFileObjects, classnames); // 插入注解处理器 ... processAnnotations( // 注解处理 enterTrees( stopIfError(CompileState.PARSE,initModules(stopIfError(CompileState.PARSE, parseFiles(sourceFileObjects)))) ), classnames ); ... case BY_TODO: // 分析及字节码生成 while (!todo.isEmpty()) generate(desugar(flow(attribute(todo.remove())))); break; 准备过程：初始化插入式注解处理器 解析与填充符号表 词法、语法分析 将源代码的字符流转变为标记集合，构造出抽象语法树 如int a = b 解析出int,a,=,b四个符号 经过词法和语法分析生成语法树以后，编译器就不会再对源码字符流进行操作了，后续的操作都建立在抽象语法树之上 填充符号表 产生符号地址和符号信息 符号表中所登记的信息在编译的不同阶段都要被用到 注解处理 插入式注解处理器的执行阶段 可以把插入式注解处理器看作是一组编译器的插件，当这些插件工作时，允许读取、修改、添加抽象语法树中的任意元素。如果这些插件在处理注解期间对语法树进行过修改，编译器将回到解析及填充符号表的过程重新处理，直到所有插入式注解处理器都没有再对语法树进行修改为止 分析与字节码生成 语义分析的主要任务则是对结构上正确的源程序进行上下文相关性质的检查，譬如进行类型检查、控制流检查、数据流检查 标注检查 标注检查步骤要检查的内容包括诸如变量使用前是否已被声明、变量与赋值之间的数据类型是否能够匹配等等 这个阶段会对源代码做一个常量折叠的代码优化 数据流及控制流分析 数据流分析和控制流分析是对程序上下文逻辑更进一步的验证，它可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否都有返回值、是否所有的受查异常都被正确处理了等问题 比如final局部变量的不可修改性就是在这个阶段进行保证 解语法糖 将简化代码编写的语法糖还原为原有的形式 字节码生成 将前面各个步骤所生成的信息转化成字节码 实例构造器()方法和类构造器()方法就是在这个阶段被添加到语法树之中的 Java 语法糖 泛型 Java 的泛型是在编译阶段解决的 也就说在运行阶段泛型的类型都被擦除了，所以以下几种用法都有问题 public class TypeErasureGenerics { public void doSomething(Object item) { if (item instanceof E) { // 不合法，无法对泛型进行实例判断 ... } E newItem = new E(); // 不合法，无法使用泛型创建对象 E[] itemArray = new E[10]; // 不合法，无法使用泛型创建数组 } } Java 之所以要在编译之后抹除泛型 很大的一个原因就是为了保证向后兼容 也就是高版本JVM可以运行低版本Class文件 由于Java 采用的是通过在某些地方插入类型转换字节码的方式来实现泛型，所以擦除泛型带来了一些问题： 无法支持原生类型 因为原生类型无法转换为Object 运行期无法获取到泛型类型，必须通过额外的手段（比如方法传入一个Class对象） 后来引入了诸如Signature、LocalVariableTypeTable等新的属性用于解决伴随泛型而来的参数类型的识别问题 自动装拆箱 遍历循环 public static void main(String[] args) { List list = Arrays.asList(1, 2, 3, 4); int sum = 0; for (int i : list) { sum += i; } System.out.println(sum); } 编译之后： public static void main(String[] args) { List list = Arrays.asList( new Integer[] { Integer.valueOf(1), Integer.valueOf(2), Integer.valueOf(3), Integer.valueOf(4) }); int sum = 0; for (Iterator localIterator = list.iterator(); localIterator.hasNext(); ) { int i = ((Integer)localIterator.next()).intValue(); sum += i; } System.out.println(sum); } 但还是需要注意自动装拆箱的陷阱 比如著名的Integer 1 = 1 问题 == 在不晕倒算术运算的情况下不会自动装拆箱 以及包装类的equals并不会处理转型问题 条件编译 使用常量作为条件 可以条件编译代码块 编译期编译期会把死代码消除掉 if (condition){ ... } 实战-自定义注解处理器 @SupportedAnnotationTypes(\"*\") @SupportedSourceVersion(SourceVersion.RELEASE_8) public class NameScanner extends AbstractProcessor { @Override public boolean process(Set annotations, RoundEnvironment roundEnv) { System.out.println(annotations); return false; } } 运行时指定处理器： javac -processor wang.ismy.jvm.annotation.NameScanner wang/ismy/jvm/Main.java MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-08 08:28:16 "},"编程语言/JAVA/JVM/后端编译与优化.html":{"url":"编程语言/JAVA/JVM/后端编译与优化.html","title":"后端编译与优化","keywords":"","body":"后端编译与优化 即时编译器 解释器与编译器 在整个Java虚拟机执行架构里，解释器与编译器经常是相辅相成地配合工作 HotSpot在JDK10之前存在两个编译器： C1:客户端编译器 通过 -client 参数指定使用这个编译器 C2:服务端编译器 通过 -server 参数指定使用这个编译器 在JDK10之后 出现了一个Graal编译器 目的是用地取代C2 无论采用的编译器是C1还是C2，解释器与编译器搭配使用的方式在虚拟机中被称为“混合模式” 可以使用参数“-Xint”强制虚拟机运行于“解释模式 使用参数“-Xcomp”强制虚拟机运行于“编译模式” 分层编译根据编译器编译、优化的规模与耗时，划分出不同的编译层次，虚拟机会根据实际情况在不同层级之间转换 编译对象与触发条件 多次调用的方法以及多次执行的循环体被称为热点代码 这些热点代码会被进行编译 这两种情况编译的目标都会是方法体 第二种情况的编译方式因为编译发生在方法执行的过程中，因此被很形象地称为“栈上替换” JVM 对于热点代码的判断称之为热点检测，目前有两种方法： 基于采样：采用这种方法的虚拟机会周期性地检查各个线程的调用栈顶，如果发现某个（或某些）方法经常出现在栈顶，那这个方法就是“热点方法” 基于计数器：采用这种方法的虚拟机会为每个方法（甚至是代码块）建立计数器，统计方法的执行次数，如果执行次数超过一定的阈值就认为它是“热点方法” HotSpot 采用的是计数器方式 可以通过虚拟机参数-XX：CompileThreshold来人为设定这个计数器的阈值 默认设置下 HotSpot的计数器并不是绝对技术 而是一段时间内的相对计数 当这段时间一过 该方法的调用计数器就会被减少一半 称之为半衰周期 可以使用虚拟机参数-XX：-UseCounterDecay来关闭热度衰减 与方法计数器不同，回边计数器没有计数热度衰减的过程，因此这个计数器统计的就是该方法循 环执行的绝对次数 编译过程 在第一个阶段，一个平台独立的前端将字节码构造成一种高级中间代码表示（High-Level Intermediate Representation，HIR，即与目标机器指令集无关的中间表示） 在第二个阶段，一个平台相关的后端从HIR中产生低级中间代码表示（Low-Level Intermediate Representation，LIR，即与目标机器指令集相关的中间表示） 最后的阶段是在平台相关的后端使用线性扫描算法（Linear Scan Register Allocation）在LIR上分配寄存器，并在LIR上做窥孔（Peephole）优化，然后产生机器代码 提前编译器 GCJ（GNU Compiler for Java）出现后提前编译基本没有什么太大进展，因为这与Java一次编译到处运行的理念相悖，直到Android 的ART的出现，也震撼到了 Java 世界 提前编译的得与失 传统提前编译打破的就是即时编译占用了原本给程序运行时的资源 提前编译的第二条路就是在给即时编译做加速 但即使编译又有以下优势： 性能分析制导优化（Profile-Guided Optimization，PGO），可以在运行阶段收集监控信息 从而更好地进行优化 激进预测性优化（Aggressive Speculative Optimization），即使编译激进优化可以做出一些假设 如果假设错了 大不了就回退到解释模式 但是提前编译不能做这些假设 它必须保证程序的外部影响优化前优化后都是一样的 链接时优化（Link-Time Optimization，LTO） jaotc 提前编译 javac Main.class jaotc --output Main.so Main.class # 将class编译为静态链接文件 java -XX:+UnlockExperimentalVMOptions -XX:AOTLibrary=./Main.so Main # 运行它 编译器优化技术 方法内联 被戏称为优化之母 除了消除方法调用的成本之外，它更重要的意义是为其他优化手段建立良好的基础 在 Java 中，基本所有对象的方法都是虚方法，也就是这些方法直到运行时才能确定被调用的是哪一个，这位方法内联带来了困难 为了解决虚方法的内联问题，Java虚拟机首先引入了一种名为类型继承关系分析（Class HierarchyAnalysis，CHA）的技术用于确定在目前已加载的类中，某个接口是否有多于一种的实现、某个类是否存在子类、某个子类是否覆盖了父类的某个虚方法等 如果CHA也判断方法有多个版本 那么会进入最后一次内联缓存优化尝试 总而言之，多数情况下Java虚拟机进行的方法内联都是一种激进优化 逃逸分析 是为其他优化措施提供依据的分析技术 分析对象动态作用域，当一个对象在方法里面被定义后，它可能被外部所引用 逃逸级别从低到高： 不逃逸 方法逃逸：通过方法返回值或者参数逃逸到其他方法 线程逃逸：被其他线程访问到 根据这些逃逸级别，可以采取不同的优化手段： 栈上分配 如果对象不会方法逃逸 那对象可在栈内存分配 随着方法栈弹出，内存也被回收 大大减少GC的压力 标量替换 如果对象不会方法逃逸，将对对象的访问转换为对int long的标量类型的访问 或者将对象创建打散为各种基本数据类型的创建 同步消除 如果能确定不会线程逃逸 那就可以去掉同步机制 提高性能 公共子表达式消除 如果一个表达式E之前已经被计算过了，并且从先前的计算到现在E中所有变量的值都没有发生变化，那么E的这次出现就称为公共子表达式。对于这种表达式，没有必要花时间再对它重新进行计算，只需要直接用前面计算过的表达式结果代替E 数组边界检查消除 使用隐式异常来优化如数组边界检查以及NPE判断等每次操作的成本，用Java伪代码代表如下： try { return a[i] } catch(Exception e){ // 使用进程级别的Segment Fault信号的异常处理器处理这个异常 } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-09 03:29:47 "},"编程语言/JAVA/JVM/JAVA内存模型.html":{"url":"编程语言/JAVA/JVM/JAVA内存模型.html","title":"Java 内存模型","keywords":"","body":"JAVA内存模型(JMM) Java 虚拟机规范通过来定义一个JMM来屏蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果 硬件层数据一致性 由于计算机的存储设备与处理器的运算速度有着几个数量级的差距，所以现代计算机系统都不得不加入一层或多层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲 这样加入一个中间缓冲区就会导致当有多个处理器时 每个处理器都有自己的高速缓存 但又共用一个缓存 会造成数据的不一致性 所以这就需要各个处理器在读写时遵守一些协议，如有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及Dragon Protocol等 现代CPU的数据一致性实现 = 缓存锁(MESI ...) + 总线锁 缓存行 使用缓存行的对齐能够提高效率（disruptor） 主内存与工作内存 Java内存模型规定了所有的变量都存储在主内存, 每条线程还有自己的工作内存（本地内存），线程的工作内存中保存了被该线程使用的变量的主内存副本，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的数据，各个线程间变量的传递也必须通过主内存 这里主内存/工作内存的划分不与堆栈等在同一层次 更多地 工作内存指的是底层CPU缓存或者寄存器 主内存指的是物理主内存 乱序问题 CPU为了提高指令执行效率，除了增加缓存之后，也会在一条指令执行过程中（比如去内存读数据（慢100倍）），去同时执行另一条指令，前提是，两条指令没有依赖关系 硬件级防乱序 X86 sfence: store| 在sfence指令前的写操作当必须在sfence指令后的写操作前完成。 lfence：load | 在lfence指令前的读操作当必须在lfence指令后的读操作前完成。 mfence：modify/mix | 在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成 原子指令，如x86上的”lock …” 指令是一个Full Barrier，执行时会锁住内存子系统来确保执行顺序，甚至跨多个CPU。Software Locks通常使用了内存屏障或原子指令来实现变量可见性和保持程序顺序 JVM级防乱序(JSR133) JVM内存屏障 屏障两边的指令不可以重排序 LoadLoad屏障: 对于这样的语句Load1; LoadLoad; Load2, 在Load2及后续读取操作要读取的数据被访问前，保证Loadi要读取的数据被读取完毕 StoreStore屏障: 对于这样的语句Store1; StoreStore; Store2, 在Store2及后续写入操作执行前，保证Store1的写 入操作对其它处理器可见。 LoadStore屏障: 对于这样的语句Load1; LoadStore; Store2, 在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad屏障:对于这样的语句Store1; StoreLoad; Load2, 在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。 再低一层，虚拟机的实现是可以依赖于 lock 指令 volatile的细节 当一个变量被定义成volatile之后，它将具备两项特性：第一项是保证此变量对所有线程的可见性，第二个特性是禁止指令重排序优化 volatile变量读操作的性能消耗与普通变量几乎没有什么差别，但是写操作则可能会慢上一些，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行 底层实现 字节码层面 ACC_VOLATILE 修饰符 JVM层面 volatile内存区的读写 都加屏障 StoreStoreBarrier volatile 写操作 StoreLoadBarrier LoadLoadBarrier volatile 读操作 LoadStoreBarrier 硬件/OS层面 内存屏障/Lock指令 synchronized实现细节 字节码层面 ACC_SYNCHRONIZED monitorenter monitorexit JVM层面 C C++ 调用了操作系统提供的同步机制 OS和硬件层面 X86 : lock cmpxchg / xxx 内存间的交互操作 lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。 在最新的JSR133中，将这8大操作简化为read、write、lock和unlock四种 三大特性 Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这三个特征来建立的 原子性 JAVA内存模型保证了8种内存操作具有原子性 但在模型中特别定义了一条宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行 但对于大多数情况，除非知道long 或者 double变量会有线程争用，否则没有必要使用volatile修饰它们 虚拟机提供了monitorenter monitorexit来提供更大范围原子性的保证 对应的语言层面就是synchronized关键字 可见性 可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改 变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性 实现可见性的方式： 被volatile修饰的变量，它会保证修改的值会立即被更新到主存 synchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存 final，被 final 关键字修饰的字段在构造器中一旦初始化完成，那么其它线程就能看见 final 字段的值 有序性 在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序 指令重排序：Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性 volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前 synchronized 也可以来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码 数据依赖性 如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性 as-if-serial语义 as-if-serial语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变 先行发生原则 Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器协助就已经存在 时间先后顺序与先行发生原则之间基本没有因果关系，所以我们衡量并发安全问题的时候不要受时间顺序的干扰，一切必须以先行发生原则为准 单一线程原则 一个线程内，在程序前面的操作先行发生于后面的操作 管程锁定规则 一个 unlock 操作先行发生于后面对同一个锁的 lock 操作 volatile 变量规则 一个 volatile 变量的写操作先行发生于后面对这个变量的读操作 线程启动规则 Thread 对象的 start() 方法调用先行发生于此线程的每一个动作 线程加入规则 Thread 对象的结束先行发生于 join() 方法返回 线程中断规则 对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生 对象终结规则 一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始 传递性 如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-10 02:43:09 "},"编程语言/JAVA/JakartaEE/nav.html":{"url":"编程语言/JAVA/JakartaEE/nav.html","title":"Jakara EE","keywords":"","body":"Jakarta EE Java EE，Java平台企业版（Java Platform Enterprise Edition），之前称为Java 2 Platform, Enterprise Edition (J2EE)，2018年3月更名为Jakarta EE。是Sun公司为企业级应用推出的标准平台 Java EE平台为每个层中不同的组件定义了API，同时还提供了一些额外的服务，比如命名（naming）、注入（injection）和跨平台的资源管理等 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-28 04:25:47 "},"编程语言/JAVA/JakartaEE/Servlet.html":{"url":"编程语言/JAVA/JakartaEE/Servlet.html","title":"Servlet","keywords":"","body":"Servlets server applet 运行在服务器端的小程序 WebServlet 使用 实现Servlet接口 public class MyServlet implements Servlet{ ... @Override public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException { servletResponse.getWriter().println(\"hello world\"); } ... } 在web.xml配置 MyServlet wang.ismy.web.MyServlet MyServlet /* 原理 当服务器接受到客户端浏览器的请求后，会解析请求URL路径，获取访问的Servlet的资源路径 查找web.xml文件，是否有对应的标签体内容。 如果有，则在找到对应的全类名 tomcat会将字节码文件加载进内存，并且创建其对象 调用其方法 生命周期方法 被创建：执行init方法，只执行一次 * Servlet什么时候被创建？ * 默认情况下，第一次被访问时，Servlet被创建 * 可以配置执行Servlet的创建时机。 * 在标签下配置 1\\. 第一次被访问时，创建 * 的值为负数 2\\. 在服务器启动时，创建 * 的值为0或正整数 * Servlet的init方法，只执行一次，说明一个Servlet在内存中只存在一个对象，Servlet是单例的 * 多个用户同时访问时，可能存在线程安全问题。 * 解决：尽量不要在Servlet中定义成员变量。即使定义了成员变量，也不要对修改值 提供服务：执行service方法，执行多次 * 每次访问Servlet时，Service方法都会被调用一次。 被销毁：执行destroy方法，只执行一次 * Servlet被销毁时执行。服务器关闭时，Servlet被销毁 * 只有服务器正常关闭时，才会执行destroy方法。 * destroy方法在Servlet被销毁之前执行，一般用于释放资源 Servlet3.0 加上注解后不用配置web.xml @WebServlet(\"/*\") 体系结构 配置 路径定义规则： /xxx：路径匹配 /xxx/xxx:多层路径，目录结构 *.do：扩展名匹配 Request 体系结构 request对象继承体系结构： ServletRequest -- 接口 | 继承 HttpServletRequest -- 接口 | 实现 org.apache.catalina.connector.RequestFacade 类(tomcat) 方法 获取请求行数据 String getMethod() String getContextPath() String getServletPath() String getQueryString() String getRequestURI() String getProtocol() String getRemoteAddr() 获取请求头数据 String getHeader(String name) Enumeration string getHeaderNames() 获取请求体数据 BufferedReader getReader() ServletInputStream getInputStream() 其他 String getParameter(String name) String[] getParameterValues(String name) Map getParameterMap() 请求转发 req.getRequestDispatcher(\"/404\") .forward(req,resp); 浏览器地址栏路径不发生变化 只能转发到当前服务器内部资源中。 转发是一次请求 共享数据 request域：代表一次请求的范围，一般用于请求转发的多个资源中共享数据 void setAttribute(String name,Object obj):存储数据 Object getAttitude(String name):通过键获取值 void removeAttribute(String name):通过键移除键值对 Response 方法 设置状态码：setStatus(int sc) 字符输出流：PrintWriter getWriter() 字节输出流：ServletOutputStream getOutputStream() * 重定向的特点:redirect 1\\. 地址栏发生变化 2\\. 重定向可以访问其他站点(服务器)的资源 3\\. 重定向是两次请求。不能使用request对象来共享数据 * 转发的特点：forward 1\\. 转发地址栏路径不变 2\\. 转发只能访问当前服务器下的资源 3\\. 转发是一次请求，可以使用request对象来共享数据 乱码问题 PrintWriter pw = response.getWriter();获取的流的默认编码是ISO-8859-1 //设置编码，是在获取流之前设置 response.setContentType(\"text/html;charset=utf-8\"); ServletContext 获取： 通过request对象获取 request.getServletContext(); 通过HttpServlet获取 this.getServletContext(); 获取MIME类型 System.out.println(getServletContext().getMimeType(\"a.jpg\")); 域对象：共享数据 setAttribute(String name,Object value) getAttribute(String name) removeAttribute(String name) 获取文件真实路径 String getRealPath(String path) Servlet 过滤器(Filter) 一般用于完成通用的操作。如：登录验证、统一编码处理、敏感字符过滤 @WebFilter public class LoggingFilter implements Filter { @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { //... } } 也可以不适用注解使用如下xml配置 demo1 wang.ismy.javaee.LoggingFilter demo1 /* 执行流程 执行过滤器 执行放行后的资源 回来执行过滤器放行代码下边的代码 生命周期方法 init:在服务器启动后，会创建Filter对象，然后调用init方法。只执行一次。用于加载资源 doFilter:每一次请求被拦截资源时，会执行。执行多次 destroy:在服务器关闭后，Filter对象被销毁。如果服务器是正常关闭，则会执行destroy方法。只执行一次。用于释放资源 拦截方式配置：资源被访问的方式 REQUEST：默认值。浏览器直接请求资源 FORWARD：转发访问资源 INCLUDE：包含访问资源 ERROR：错误跳转资源 ASYNC：异步访问资源 @WebFilter(value = \"/*\",dispatcherTypes = DispatcherType.ERROR) 过滤器链 注解配置 按照类名字符串排序 web.xml配置 按照filter-mapping排序 事件监听器(Listener) ServletContextListener HttpSessionListener ServletRequestListener 异步支持 @WebServlet(urlPatterns = \"/hello\",asyncSupported = true) public class MyServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { AsyncContext async = req.startAsync(); async.addListener(new AsyncListener() { @Override public void onComplete(AsyncEvent asyncEvent) throws IOException { asyncEvent.getSuppliedResponse().getWriter().write(\"jntm\"); } //... }); new Thread(()->{ try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } async.complete(); }).start(); } } 非阻塞IO AsyncContext async = req.startAsync(); ServletInputStream inputStream = req.getInputStream(); inputStream.setReadListener(new ReadListener() { @Override public void onDataAvailable() throws IOException { byte[] bytes = new byte[1024]; while (inputStream.isReady() && inputStream.read(bytes)!=-1){ System.out.println(new String(bytes)); } async.complete(); } @Override public void onAllDataRead() throws IOException { async.complete(); } @Override public void onError(Throwable throwable) { throwable.printStackTrace(); async.complete(); } }); WebFragment 可以对XML配置进行分区 安全 @ServletSecurity 错误映射 404 /404.html java.lang.RuntimeException /500.html 文件上传 @MultiPartConfig 工作原理 Servlet 体系结构： ServletContexnt：贯穿请求的上下文 ServletConfig：传递参数集合 创建 StandardWrapper.loadServlet() 方法创建Servlet实例 InstanceManager instanceManager = ((StandardContext)getParent()).getInstanceManager(); try { servlet = (Servlet) instanceManager.newInstance(servletClass; ... 初始化 StandardWrapper.initServlet() 调用Servlet.init() servlet.init(facade); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-06 03:06:46 "},"编程语言/JAVA/JakartaEE/JSP.html":{"url":"编程语言/JAVA/JakartaEE/JSP.html","title":"JSP","keywords":"","body":" Java Server Pages： java服务器端页面 JSP本质上就是一个Servlet 指令 page:配置JSP页面的 contentType：等同于response.setContentType() import：导包 errorPage：当前页面发生异常后，会自动跳转到指定的错误页面 isErrorPage：标识当前也是是否是错误页面。 include:页面包含的。导入页面的资源文件 taglib导入资源 注释 html注释： :只能注释html代码片段 jsp注释：推荐使用 ：可以注释所有 JSP脚本 ：定义的java代码，在service方法中。service方法中可以定义什么，该脚本中就可以定义什么 ：定义的java代码，在jsp转换后的java类的成员位置。 ：定义的java代码，会输出到页面上。输出语句中可以定义什么，该脚本中就可以定义什么。 内置对象 变量名 真实类型 作用 pageContext PageContext 当前页面共享数据,还可以获取其他八个内置对象 request HttpServletRequest 一次请求访问的多个资源(转发) session HttpSession 一次会话的多个请求间 application ServletContext 所有用户间共享数据 response HttpServletResponse 响应对象 page Object 当前页面(Servlet)的对象 this out JspWriter 输出对象，数据输出到页面上 config ServletConfig Servlet的配置对象 exception Throwable 异常对象 MVC 耦合性低，方便维护，可以利于分工协作 重用性高 使得项目架构变得复杂，对开发人员要求高 EL表达式 Expression Language 表达式语言 语法：${表达式} 忽略 设置jsp中page指令中：isELIgnored=\"true\" 忽略当前jsp页面中所有的el表达式 \\${表达式} ：忽略当前这个el表达式 运算符 算术运算符 比较运算符 逻辑运算符 空运算符 ${empty list} 获取值 ${域名称.键名} pageScope requestScope sessionScope applicationScope ${键名}：表示依次从最小的域中查找是否有该键对应的值，直到找到为止。 获取对象、List集合、Map集合的值 对象：${域名称.键名.属性名} List集合：${域名称.键名[索引]} Map集合： ${域名称.键名.key名称} ${域名称.键名[\"key名称\"]} 逻辑视图 隐式对象 JSTL JavaServer Pages Tag Library JSP标准标签库 if choose forEach MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/JakartaEE/Cookie&Session.html":{"url":"编程语言/JAVA/JakartaEE/Cookie&Session.html","title":"Cookie&Session","keywords":"","body":"Cookie与Session 两者都是为了保持访问用户与后端服务器的交互状态 Cookie 客户端会话技术，将数据保存到客户端 客户端第一次访问时服务器时 服务器会返回一个设置cookie的响应头 此后在cookie有效期内 并且在cookie所允许的域名下 浏览器发起请求时都会自动携带这个cookie请求头 Cookie[] cookies = req.getCookies(); for (Cookie cookie : cookies) { if (\"time\".equals(cookie.getName())){ resp.getWriter().println(cookie.getValue()); } } resp.addCookie(new Cookie(\"time\", LocalDateTime.now().toString())); 实现原理 基于响应头set-cookie和请求头cookie实现 细节 持久化存储： setMaxAge(int seconds) 共享 设置共享虚拟目录范围：setPath(String path) 设置共享域：setDomain(String path) 特点 cookie存储数据在客户端浏览器 浏览器对于单个cookie 的大小有限制(4kb) 以及 对同一个域名下的总cookie数量也有限制(20个) cookie 压缩 gzip只能对body进行压缩 cookie位于头上 需要手动编程对http header 进行处理 作用 cookie一般用于存出少量的不太敏感的数据 在不登录的情况下，完成服务器对客户端的身份识别 注意事项 Cookie的Name不能和属性值一样 比如Doamin MaxAge等待 Name和Value不能设置成非ASCII字符 不同的浏览器都会对Cookie的大小以及数量进行限制 需要注意 Session 服务器端会话技术，在一次会话的多次请求间共享数据，将数据保存在服务器端的对象中。HttpSession Session用来解决Cookie数量多传输浪费的问题 Session的本质就是将一个ID存储在Cookie里 当用户访问后端服务器 后端服务器根据这个ID查找其对应的数据 使用 获取HttpSession对象： HttpSession session = request.getSession(); 使用HttpSession对象： Object getAttribute(String name) void setAttribute(String name, Object value) void removeAttribute(String name) 原理 Session的实现是依赖于Cookie的。 如果基于Cookie的Session不可用 浏览器会自动将其重写到URL中 session如何工作： session持久化：SessionManager 其会复制持久化没有过期的session session的过期检查： Tomcat的一个后台线程会定期检查每个session是否失效 值得注意的是 request.getSession()也会检查是否过期 如果过期就会创建一个新的session出来 细节 持久化session Cookie c = new Cookie(\"JSESSIONID\",session.getId()); c.setMaxAge(60*60); response.addCookie(c); session序列化 tomcat自动完成 销毁时间 服务器关闭 session对象调用invalidate() session默认失效时间 30分钟 30 特点 session用于存储一次会话的多次请求的数据，存在服务器端 session可以存储任意类型，任意大小的数据 分布式session 单独使用session或者cookie是无法满足需求的 一些分布式session架构将独立的服务器用来存储session 就可以达到session共享的目的 多端session： 只需要统一注册登录接口即可 前后端分离的时代这点已是常态 多终端登录的话在此基础上进行开发 Session与Cookie区别 比较类别 Session Cookie 存储方式 服务端 客户端 大小限制 无 有 安全 较安全 较不安全 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-07 06:46:26 "},"编程语言/JAVA/JakartaEE/JNDI.html":{"url":"编程语言/JAVA/JakartaEE/JNDI.html","title":"JNDI","keywords":"","body":" MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/JakartaEE/JPA.html":{"url":"编程语言/JAVA/JakartaEE/JPA.html","title":"JPA","keywords":"","body":" JPA的全称是Java Persistence API， 即Java 持久化API，是SUN公司推出的一套基于ORM的规范，内部是由一系列的接口和抽象类构成 Persistence对象 Persistence对象主要作用是用于获取EntityManagerFactory对象的 EntityManagerFactory EntityManagerFactory 接口主要用来创建 EntityManager 实例 EntityManager 在 JPA 规范中, EntityManager是完成持久化操作的核心对象 getTransaction : 获取事务对象 persist ： 保存操作 merge ： 更新操作 remove ： 删除操作 find/getReference ： 根据id查询 EntityTransaction begin,commit,rollback 使用 创建classpath:META-INF/persistence.xml org.hibernate.jpa.HibernatePersistenceProvider 创建实体类 @Entity @Table(name = \"cst_customer\") @Data public class Customer { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \"cust_id\") /* * IDENTITY：底层数据库必须支持自动增长 * SEQUENCE: 底层数据库必须支持序列 * TABLE:jpa提供的机制 * AUTO:由程序自动选择策略 * */ private Long custId; @Column(name = \"cust_name\") private String custName; @Column(name = \"cust_source\") private String custSource; @Column(name = \"cust_level\") private String custLevel; @Column(name = \"cust_industry\") private String custIndustry; @Column(name = \"cust_phone\") private String custPhone; @Column(name = \"cust_address\") private String custAddress; } 操作 添加 EntityManager manager = Persistence .createEntityManagerFactory(\"jpa\").createEntityManager(); EntityTransaction tx = manager.getTransaction(); tx.begin(); Customer customer = new Customer(); customer.setCustName(\"老王\"); customer.setCustIndustry(\"隔壁\"); manager.persist(customer); tx.commit(); manager.close(); 根据ID查询 Customer customer = entityManager.find(Customer.class, 1L); // 立即加载 Customer customer = entityManager.getReference(Customer.class, 1L); // 延迟加载 删除 Customer customer = entityManager.find(Customer.class, 1L); entityManager.remove(customer); 更新 Customer customer = entityManager.find(Customer.class, 2L); customer.setCustName(\"老王八\"); entityManager.merge(customer); JPQL 基于首次在EJB2.0中引入的EJB查询语言(EJB QL),Java持久化查询语言(JPQL)是一种可移植的查询语言，旨在以面向对象表达式语言的表达式，将SQL语法和简单查询语义绑定在一起·使用这种语言编写的查询是可移植的，可以被编译成所有主流数据库服务器上的SQL 查询全部 String jpql = \"FROM Customer \"; List list = entityManager.createQuery(jpql).getResultList(); for (Object o : list) { System.out.println(o); } 倒序查询 FROM Customer ORDER BY custId DESC 统计查询 SELECT COUNT(custId) FROM Customer 分页查询 String jpql = \"FROM Customer\"; List list = entityManager.createQuery(jpql) .setFirstResult(0) .setMaxResults(2).getResultList(); 条件查询 String jpql = \"FROM Customer WHERE custName LIKE ?1\"; List list = entityManager.createQuery(jpql) .setParameter(1,\"%李%\") .getResultList(); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/JakartaEE/Freemarker.html":{"url":"编程语言/JAVA/JakartaEE/Freemarker.html","title":"Freemarker","keywords":"","body":"使用 org.springframework.boot spring-boot-starter-freemarker 配置 spring: freemarker: cache: false enabled: true suffix: .html content-type: text/html 指令 hello ${name} 类型 注释，即，介于其之间的内容会被freemarker忽略 插值（Interpolation）：即${..}部分,freemarker会用真实的值代替${..} FTL指令：和HTML标记类似，名字前加#予以区分，Freemarker会解析标签中的表达式或逻辑。 文本，仅文本信息，这些不是freemarker的注释、插值、FTL指令的内容会被freemarker忽略解析，直接输出内 容。 list指令 ${name} map操作 ${map['name']} ${map.name} 遍历map ${map[key]} 条件渲染 jntm 空值处理 存在 ${map.class!\"default\"} 内建函数 内建函数语法格式： 变量+?+函数名称 ${time?time} ${time?date} ${time?datetime} MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/mybatis/nav.html":{"url":"编程语言/JAVA/框架/mybatis/nav.html","title":"Mybatis","keywords":"","body":"NAV 框架 框架（Framework）是整个或部分系统的可重用设计，表现为一组抽象构件及构件实例间交互的方法;另一种 定义认为，框架是可被应用开发者定制的应用骨架。前者是从应用方面而后者是从目的方面给出的定义。 简而言之，框架其实就是某种应用的半成品，就是一组组件，供你选用完成你自己的系统。简单说就是使用别 人搭好的舞台，你来做表演。而且，框架一般是成熟的，不断升级的软件。 Mybatis 持久层框架 动态sql ORM 搭建 创建mapper接口 public interface UserDao { List findAll(); } 创建总配置文件 创建映射配置文件 SELECT * FROM user 使用 @Test public void findAll() throws IOException { SqlSessionFactory factory = new SqlSessionFactoryBuilder().build( Resources.getResourceAsStream(\"config.xml\")); SqlSession sqlSession = factory.openSession(); List list = sqlSession.getMapper(UserDao.class).findAll(); assertEquals(6,list.size()); } 注解 public interface UserDao { @Select(\"SELECT * FROM user\") List findAll(); } 分析 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/mybatis/CURD操作.html":{"url":"编程语言/JAVA/框架/mybatis/CURD操作.html","title":"CURD操作","keywords":"","body":"根据条件查询 SELECT * FROM user WHERE id = #{id} 细节 resultType 属性： 用于指定结果集的类型。 parameterType 属性： 用于指定传入参数的类型。 sql 语句中使用的#{}： 它代表占位符，相当于原来 jdbc 部分所学的?，都是用于执行语句时替换实际的数据 #{}中的内容：因为参数只有一个，所以此处可以随意写 更新 INSERT INTO user(username,address,sex,birthday) VALUES(#{username},#{address},#{sex},#{birthday}) int save(User user); 需要注意的是，mybatis的SqlSession关闭了事务的默认提交，当进行完更新操作后，需要手动调用sqlSession.commit(); 模糊查询字符串拼接问题 SELECT * FROM user WHERE username LIKE '%' #{name} '%' 插入数据后返回ID select last_insert_id(); INSERT INTO user(username,address,sex,birthday) VALUES(#{username},#{address},#{sex},#{birthday}) 使用resultMap select * from user Properties标签 typeAliases标签 mapper MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/mybatis/连接池与事务.html":{"url":"编程语言/JAVA/框架/mybatis/连接池与事务.html","title":"连接池与事务","keywords":"","body":"连接池 UNPOOLED:不使用连接池的数据源 POOLED:使用连接池的数据源 JNDI:使用 JNDI 实现的数据源 事务 /*提交事务*/ sqlSession.commit(); /*回滚事务*/ sqlSession.rollback(); 动态SQL if #{username} 'abc' where 标签 ... 这样就不用写where 1=1前缀 foreach标签 collection:代表要遍历的集合元素，注意编写时不要写#{} open:代表语句的开始部分 close:代表结束部分 item:代表遍历集合的每个元素，生成的变量名 sperator:代表分隔符 #{uid} SQL重用 SELECT * FROM user WHERE id = #{id} MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/mybatis/多表操作.html":{"url":"编程语言/JAVA/框架/mybatis/多表操作.html","title":"多表操作","keywords":"","body":"多表查询 一对一 定义结果映射 多表查询设置结果映射 SELECT account.ID AS account_id, account.UID, account.MONEY, user.* FROM account,user WHERE account.UID = user.id 实体类 @Data public class Account { private Integer id; private Integer uid; private Double money; private User user; } 一对多 SELECT user.*, account.ID as account_id, account.uid, account.money FROM user LEFT OUTER JOIN account ON user.id = account.UID @Data public class User { private Integer id; private String username; private LocalDate birthday; private String sex; private String address; private List account; } 左外连接的使用 多对多 多对多的映射关系，可以拆分成两个一对多的关系 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/mybatis/缓存.html":{"url":"编程语言/JAVA/框架/mybatis/缓存.html","title":"缓存","keywords":"","body":"mybatis 缓存 延迟加载 就是在需要用到数据时才进行加载，不需要用到数据时就不加载数据。延迟加载也称懒加载. 开启延迟加载 修改连接 使用的动态代理实现的延迟加载 缓存 一级缓存 一级缓存是 SqlSession 范围的缓存，当调用 SqlSession 的修改，添加，删除，commit()，close()等方法时，就会清空一级缓存。 命中原则： statementId相同 查询参数相同（hash的方式） 分页参数 sql语句 同一环境（environment属性） 生命周期： 缓存销毁： session close commit clearCache主动清除 设计理念： 不过期 不更新 不限制 二级缓存 二级缓存是 mapper 映射级别的缓存，多个 SqlSession 去操作同一个 Mapper 映射的 sql 语句，多个 SqlSession 可以共用二级缓存，二级缓存是跨 SqlSession 的。 二级缓存中存放的是数据而不是对象 开启 第一步：在 SqlMapConfig.xml 文件开启二级缓存 第二步：配置相关的 Mapper 映射文件 第三步：配置 statement 上面的 useCache 属性 SELECT * FROM user 命中原则 同一 session factory statement id 相同 参数相同 environment 环境相同 sql session close 或 commit 生命周期 创建: sql session close 或 commit 销毁： sql session update 缓存清除策略 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-05-18 03:18:33 "},"编程语言/JAVA/框架/mybatis/注解开发.html":{"url":"编程语言/JAVA/框架/mybatis/注解开发.html","title":"注解开发","keywords":"","body":" 注解 作用 @Insert 实现新增 @Update 实现更新 @Delete 实现删除 @Select 实现查询 @Result 实现结果集封装 @Results 可以与@Result 一起使用，封装多个结果集 @ResultMap 实现引用@Results 定义的封装 @One 实现一对一结果集封装 @Many 实现一对多结果集封装 @SelectProvider 实现动态 SQL 映射 @CacheNamespace 实现注解二级缓存的使用 Result注解使用 @Select(\"SELECT * FROM user\") @Results({ @Result(id=true,column = \"id\",property =\"id\"), @Result(column = \"username\",property =\"username\"), @Result(column = \"sex\",property =\"sex\"), @Result(column = \"address\",property =\"address\"), @Result(column = \"birthday\",property =\"birthday\") }) List find(); 一对一查询 @Select(\"SELECT * FROM account\") @Results({ @Result(id=true,column = \"id\",property = \"id\"), @Result(column = \"uid\",property = \"uid\"), @Result(column = \"money\",property = \"money\"), @Result(column = \"uid\",property = \"user\",one = @One(select = \"wang.ismy.mybatis.dao.UserDao.findById\",fetchType = FetchType.LAZY)) }) List findAll(); 一对多查询 @Select(\"SELECT * FROM user\") @Results({ @Result(id=true,column = \"id\",property =\"id\"), @Result(column = \"username\",property =\"username\"), @Result(column = \"sex\",property =\"sex\"), @Result(column = \"address\",property =\"address\"), @Result(column = \"birthday\",property =\"birthday\"), @Result(column = \"id\",property = \"account\", many = @Many(select = \"wang.ismy.mybatis.dao.AccountDao.findById\",fetchType = FetchType.LAZY)) }) List find(); 开启二级缓存 @CacheNamespace public interface UserDao {} MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/mybatis/分页插件.html":{"url":"编程语言/JAVA/框架/mybatis/分页插件.html","title":"分页插件","keywords":"","body":" 引入依赖 com.github.pagehelper pagehelper 5.1.10 配置 oracle true 使用 @Override public List findAll() { PageHelper.startPage(1,5); return orderDao.findAll(); } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/mybatis-plus.html":{"url":"编程语言/JAVA/框架/mybatis-plus.html","title":"Mybatis-Plus","keywords":"","body":"基本配置 spring boot 添加依赖 com.baomidou mybatis-plus-boot-starter 3.1.2 定义mapper接口 public interface UserMapper extends BaseMapper { } 使用 @Autowired UserMapper userMapper; @Test public void test(){ User user = new User(); user.setUsername(\"root\"); user.setPassword(\"123\"); user.setAge(15); user.setCreateTime(LocalDate.now()); assertEquals(1,userMapper.insert(user)); } 查询 普通查询 条件构造器查询 @Test public void test2(){ QueryWrapper queryWrapper = new QueryWrapper<>(); queryWrapper.like(\"username\",\"roo\") .lt(\"age\",50); var list = userMapper.selectList(queryWrapper); assertEquals(2,list.size()); assertEquals(\"root\",list.get(0).getUsername()); assertEquals(\"rood\",list.get(1).getUsername()); } 自定义SQL 注解 public interface UserMapper extends BaseMapper { @Select(\"SELECT * FROM user \") List selectAll(); } xml 同mybatis 分页查询 配置分页插件 @Bean public PaginationInterceptor paginationInterceptor(){ return new PaginationInterceptor(); } 查询 @Test public void test4(){ Page page = new Page<>(1,2); var list = userMapper.selectPage(page,null).getRecords(); assertEquals(2,list.size()); } 更新 @Test public void test5(){ UpdateWrapper wrapper = new UpdateWrapper().eq(\"username\",\"root\"); User user = new User(); user.setPassword(\"5678\"); userMapper.update(user, wrapper); } 删除 UpdateWrapper wrapper = new UpdateWrapper() .eq(\"username\",\"root\"); userMapper.delete(wrapper); AR模式 实体类继承Model @Data public class User extends Model { private String username; private String password; private Integer age; private LocalDate createTime; } @Test public void test6(){ User user = new User(); user.setUsername(\"20190716\"); user.setPassword(\"123\"); user.setCreateTime(LocalDate.now()); user.setAge(111); assertTrue(user.insert()); } 主键策略 设置策略 @TableId(type = IdType.UUID) private String username; User user = new User(); user.setPassword(\"1111\"); assertTrue(user.insert()); 通过Service MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Hibernate.html":{"url":"编程语言/JAVA/框架/Hibernate.html","title":"Hibernate","keywords":"","body":"Hibernate Hibernate 是由 Gavin King 于 2001 年创建的开放源代码的对象关系框架。它强大且高效的构建具有关系对象持久性和查询服务的 Java 应用程序。 Hibernate 将 Java 类映射到数据库表中，从 Java 数据类型中映射到 SQL 数据类型中 架构 配置 ORM元数据配置 --> 主配置 com.mysql.cj.jdbc.Driver jdbc:mysql:///hibernate?characterEncoding=utf8 root 123 org.hibernate.dialect.MySQLDialect true true update 使用 // 加载配置文件 Configuration cfg = new Configuration().configure(\"hibernate.cfg.xml\"); // 创建核心对象session的工厂 SessionFactory factory = cfg.buildSessionFactory(); // 获得session Session session = factory.openSession(); // 开启事务 Transaction tx = session.beginTransaction(); Book book = new Book(); book.setBname(\"JAVASCRIPT hight level program\"); book.setBauthor(\"nigolas\"); // 保存对象 session.save(book); // 提交事务 tx.commit(); // 关闭会话 session.close(); factory.close(); // 根据ID查询 session.get(Book.class, 6) // 根据ID修改 Book book = session.get(Book.class, 6); book.setBauthor(\"cxk\"); session.update(book); // 根据ID删除 Book book = session.get(Book.class, 6); session.delete(book); // 回滚事务 tx.rollback(); 实体 实体类注意事项 持久类提供无参数构造方法 成员变量私有,提供有get/set方法访问.需提供属性 持久化类中的属性,应尽量使用包装类型 持久化类需要提供id.与数据库中的主键列对应 不要用final修饰class 主键类型 自然主键 表的业务列中,有某业务列符合,必须有,并且不重复的特征时,该列可以作为主键使用. 代理主键 表的业务列中,没有某业务列符合,必须有,并且不重复的特征时,创建一个没有业务意义的列作为主键 主键生成策略 代理主键 identity : 主键自增.由数据库来维护主键值.录入时不需要指定主键. sequence: Oracle中的主键生成策略. increment(了解): 主键自增.由hibernate来维护.每次插入前会先查询表中id最大值.+1作为新主键值. hilo(了解): 高低位算法.主键自增.由hibernate来维护.开发时不使用. native:hilo+sequence+identity 自动三选一策略. uuid: 产生随机字符串作为主键. 主键类型必须为string 类型. 自然主键 assigned:自然主键生成策略. hibernate不会管理主键值.由开发人员自己录入. 对象状态 瞬时状态 没有ID，没有在session缓存中 持久化状态 有id,在session缓存中 持久化对象的变化会同步到数据库中 游离|托管状态 有id,没有在session缓存中 Book book = new Book(); // 瞬时状态 book.setBauthor(\"unknown\"); // 瞬时状态 session.save(book); // 持久化状态 tx.commit(); // 关闭会话 session.close(); // 游离|托管状态 一级缓存 Book book = session.get(Book.class, 1); Book book1 = session.get(Book.class, 1); System.out.println(book == book1); // true 快照 Book book = session.get(Book.class, 1); book.setBname(\"java learning\"); tx.commit(); // 与快照中对象进行对比，如果对象发生改变，则更新对象 事务 设置事务隔离级别 4 在项目中管理事务 获取线程绑定session thread // 获取线程绑定session // 注意，线程绑定的session事务提交后会自动关闭 Session session = factory.getCurrentSession(); 其他方式查询 HQL查询 String hql = \"FROM Book\"; Query query = session.createQuery(hql,Book.class); System.out.println(query.list()); -- 条件查询 FROM Book where bauthor='unknown' -- 排序 FROM Book ORDER BY bid DESC -- 投影 SELECT bname FROM Book -- 投影封装对象 SELECT new Book(bname) FROM Book -- 连接Book与Author FROM Book b INNER JOIN fetch b.authors // 聚合函数 String hql = \"SELECT max(bid) FROM Book\"; Query query = session.createQuery(hql); Number number = (Number) query.uniqueResult(); // 占位符 String hql = \"FROM Book where bauthor=:name\"; Query query = session.createQuery(hql,Book.class); query.setParameter(\"name\",\"unknown\"); // 分页 第一页，每页10条 query.setFirstResult(0); query.setMaxResults(10); Criteria查询(单表条件查询) Criteria criteria = session.createCriteria(Book.class); System.out.println(criteria.list()); // 根据ID查询 criteria.add(Restrictions.idEq(2)); // 条件查询 criteria.add(Restrictions.eq(\"bname\",\"clean code\")); // 排序 criteria.addOrder(Order.asc(\"bname\")); // 聚合函数 criteria.setProjection(Projections.max(\"bid\")); 离线查询 DetachedCriteria criteria = DetachedCriteria.forClass(Book.class); criteria.add(Restrictions.eq(\"bname\",\"clean code\")); List list = criteria.getExecutableCriteria(session).list(); 原生sql查询 String sql = \"SELECT * FROM tb_book WHERE bid = ?\"; NativeQuery query = session.createSQLQuery(sql).addEntity(Book.class); query.setParameter(1,1); 多表查询 一对多|多对一 操作 // 新增 Book book = new Book(); book.setBname(\"java\"); Author author1 = new Author(); author1.setName(\"author1\"); author1.setBook(book); Author author2 = new Author(); author2.setName(\"author2\"); author2.setBook(book); book.setAuthors(Set.of(author1,author2)); session.save(book); session.save(author1); session.save(author2); // 追加一个多 Book book = session.get(Book.class,1); Author author3 = new Author(); author3.setName(\"author3\"); author3.setBook(book); book.getAuthors().add(author3); session.save(author3); // 移除一个多 Book book = session.get(Book.class,1); book.getAuthors().removeIf(a-> \"author1\".equals(a.getName())); 级联操作 Book book = new Book(); book.setBname(\"python\"); Author author1 = new Author(); author1.setName(\"authorx\"); author1.setBook(book); book.setAuthors(Set.of(author1)); session.save(book); 多对多 操作 Book book1 = new Book(); book1.setBname(\"clean code\"); Book book2 = new Book(); book2.setBname(\"clean coder\"); Author author1 = new Author(); author1.setName(\"martin flower\"); Author author2 = new Author(); author2.setName(\"robert c\"); book1.setAuthors(Set.of(author1,author2)); book2.setAuthors(Set.of(author1,author2)); author1.setBook(Set.of(book1,book2)); author2.setBook(Set.of(book1,book2)); session.save(book1); session.save(book2); session.save(author1); session.save(author2); 加载策略 类级别 // 立即加载 Book book = session.get(Book.class, 1); // 延迟加载 使用时才去数据库查询（动态代理） // 使用懒加载时要确保,调用属性加载数据时,session还是打开的.不然会抛出异常 Book book = session.load(Book.class, 2); 关联级别 集合 关联属性 为了提高效率.fetch的选择上应选择select. lazy的取值应选择 true. 全部使用默认值. 批量抓取 batch-size MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-04 06:52:13 "},"编程语言/JAVA/框架/Dubbo.html":{"url":"编程语言/JAVA/框架/Dubbo.html","title":"Dubbo","keywords":"","body":"Dubbo 一款分布式服务框架 高性能和透明化的RPC远程服务调用方案 SOA服务治理方案 需求 当服务越来越多时，服务 URL 配置管理变得非常困难，F5 硬件负载均衡器的单点压力也越来越大 当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系 接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器 架构 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 容器. Dubbo技术的服务端(Provider), 在启动执行的时候, 必须依赖容器才能正常启动. 工作流程 start: 启动Spring容器时,自动启动Dubbo的Provider register: Dubbo的Provider在启动后自动会去注册中心注册内容.注册的内容包括: Provider的 IP Provider 的端口. Provider 对外提供的接口列表.哪些方法.哪些接口类 Dubbo 的版本. 访问Provider的协议. subscribe: 订阅.当Consumer启动时,自动去Registry获取到所已注册的服务的信息. notify: 通知.当Provider的信息发生变化时, 自动由Registry向Consumer推送通知. invoke: 调用. Consumer 调用Provider中方法 同步请求.消耗一定性能.但是必须是同步请求,因为需要接收调用方法后的结果. count:次数. 每隔2分钟,provoider和consumer自动向Monitor发送访问次数.Monitor进行统计. 注册中心 Dubbo支持Multicast，Zookeeper，Redis，Simple注册中心 ZooKeeper 服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址 服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址，当提供者发生变化时，zk会通知消费者 监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址 协议 Dubbo 默认协议采用单一长连接和 NIO 异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。 反之，Dubbo 默认协议不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低 缺省协议，使用基于 mina 1.1.7 和 hessian 3.2.1 的 tbremoting 交互。 连接个数：单连接 连接方式：长连接 传输协议：TCP 传输方式：NIO 异步传输 序列化：Hessian 二进制序列化 适用范围：传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满 提供者，尽量不要用 dubbo 协议传输大文件或超大字符串。 适用场景：常规远程服务方法调用 Protocol Buffer Protocol Buffer 其实是 Google 出品的一种轻量并且高效的结构化数据存储格式，性能比 JSON、XML 要高很多 序列化和反序列非常快 压缩后体积很小 负载均衡策略 random loadbalance 随机调用实现负载均衡，可以对 provider 不同实例设置不同的权重，会按照权重来负载均衡 roundrobin loadbalance 默认就是均匀地将流量打到各个机器上去，但是如果各个机器的性能不一样，容易导致性能差的机器负载过高。所以此时需要调整权重 leastactive loadbalance 给不活跃的性能差的机器更少的请求 consistanthash loadbalance 相同参数的请求一定分发到一个 provider 上去，provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量 建议在 Provider 端配置的 Consumer 端属性 timeout：方法调用的超时时间 retries：失败重试次数，缺省是 2 loadbalance：负载均衡算法，缺省是随机 random + 权重。还可以配置轮询 roundrobin、最不活跃优先 leastactive 和一致性哈希 consistenthash 等 actives：消费者端的最大并发调用限制，即当 Consumer 对一个服务的并发调用到上限后，新调用会阻塞直到超时，在方法上配置 dubbo:method 则针对该方法进行并发限制，在接口上配置 dubbo:service，则针对该服务进行并发限制 executes服务提供方可以使用的最大线程数 在 Provider 端配置合理的 Provider 端属性 建议在 Provider 端配置的 Provider 端属性有： threads：服务线程池大小 executes：一个服务提供者并行执行请求上限，即当 Provider 对一个服务的并发调用达到上限后，新调用会阻塞，此时 Consumer 可能会超时。在方法上配置 dubbo:method 则针对该方法进行并发限制，在接口上配置 dubbo:service，则针对该服务进行并发限制 集群容错策略 failover cluster 模式 失败自动切换，自动重试其他机器，默认就是这个 failfast cluster 模式 一次调用失败就立即失败 failsafe cluster 模式 出现异常时忽略掉 failback cluster 模式 失败了后台自动记录请求，然后定时重发 forking cluster 模式 并行调用多个 provider，只要一个成功就立即返回 broadcacst cluster 逐个调用所有的 provider。任何一个 provider 出错则报错 spi service provider interface 当某个接口有多个实现，需要根据指定的配置或者是默认的配置，选择相对应的实现 服务治理 调用链路自动生成 对各个服务之间的调用自动记录下来，然后自动将各个服务之间的依赖关系和调用链路生成出来，做成一张图 服务访问压力以及时长统计 每个服务的每个接口每天被调用多少次 从源头入口开始，一个完整的请求链路经过几十个服务之后，完成一次请求，每天全链路走多少次 设计一个rpc框架 注册中心 要能注册、拉取服务信息 网络请求的发送与接收 使用动态代理来封装 多个服务本地负载均衡 请求数据响应数据的序列化与反序列 SpringCloud与Dubbo SpringCloud 和Dubbo都可以实现RPC远程调用和服务治理 SpringCloud是一套目前比较完善的微服务框架，整合了分布式常用解决方案遇到了问题，Dubbo只是实现服务治理 整合spring boot provider compile group: 'org.apache.dubbo', name: 'dubbo-spring-boot-starter', version: '2.7.7' compile group: 'org.apache.curator', name: 'curator-recipes', version: '4.2.0' spring.application.name=dubbo-provider dubbo.scan.base-packages=wang.ismy.dubbo dubbo.protocol.name=dubbo dubbo.protocol.port=666 dubbo.protocol.host=192.168.1.109 dubbo.registry.address=zookeeper://local:2181 @DubboService(version = \"1.0.0\",timeout = 10000,interfaceClass = HelloService.class) @Service public class HelloServiceImpl implements HelloService{...} consumer 依赖配置同上 @DubboReference(version = \"1.0.0\") HelloService helloService; dubbo-admin 可视化管理服务 启动admin-server 配置admin-ui server ip npm run dev MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-16 06:23:22 "},"编程语言/JAVA/框架/Junit.html":{"url":"编程语言/JAVA/框架/Junit.html","title":"JUnit","keywords":"","body":"JUint 4 白盒测试 黑盒测试 @Test public void test(){ Assert.assertEquals(1,1); } @Before @After 5 组成： JUint Platform 用于在JVM上启动测试框架 JUint Jupiter 5版本的全新编程模型与扩展机制 JUint Vintage 兼容3和4 命名： shoud...when... 流式断言： AssertJ MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-26 03:15:52 "},"编程语言/JavaScript/JavaScript.html":{"url":"编程语言/JavaScript/JavaScript.html","title":"JavaScript","keywords":"","body":"与html结合方式 内部js 外部js 注释 数据类型 原始数据类型 number string null undefined 引用数据类型 变量 var a = 5; typeof 运算符 一元运算符 ++ -- + - 算术运算符 + - * / % ... 赋值运算符 = += -+.... 比较运算符 > = 逻辑运算符 && || ! 其他对象转boolean number：0或NaN为假，其他为真 string：除了空字符串(\"\")，其他都是true null&undefined:都是false 对象：所有对象都为true 三元运算符 JS特殊语法 流程控制语句 if..else... switch while do...while for 基本对象 Function function f(x){ ... } var f = function(){ ... } Array 创建 new Array(元素列表); new Array(长度); [1,2,3,4]; 特点 元素类型可变 长度可变 方法 join：拼接成字符串 push Date 常用方法 Math 常用方法 Gloal encodeURI decodeURI encodeURIComponent:编码范围更广 parseInt isNaN eval 立即执行函数 ( function(){ //... } )() window 方法 与弹出框有关的方法： alert() 显示带有一段消息和一个确认按钮的警告框。 confirm() 显示带有一段消息以及确认按钮和取消按钮的对话框。 如果用户点击确定按钮，则方法返回true 如果用户点击取消按钮，则方法返回false prompt() 显示可提示用户输入的对话框。 返回值：获取用户输入的值 与打开关闭有关的方法： close() 关闭浏览器窗口。 谁调用我 ，我关谁 open() 打开一个新的浏览器窗口 返回新的Window对象 动画函数封装 核心原理：通过定时器 setInterval() 不断移动盒子位置。 利用 JS 是一门动态语言，可以很方便的给当前对象添加属性来将定时器添加到对象中 缓动效果 核心算法： (目标值 - 现在的位置) / 10 做为每次移动的距离步长 动函数添加回调函数 回调函数原理：函数可以作为一个参数。将这个函数作为参数传到另一个函数里面，当那个函数执行完之后，再执行传进去的这个函数，这个过程就叫做回调 完整代码 function animate(obj,target,callback){ clearInterval(obj.timer); obj.timer = setInterval(() => { var step = Math.ceil((target - obj.offsetLeft)/10); if (obj.offsetLeft >= target){ clearInterval(obj.timer); callback(); } obj.style.left = obj.offsetLeft + step + 'px'; }, 15); } JSON 语法 数据在名称/值对中：json数据是由键值对构成的 数据由逗号分隔：多个键值对由逗号分隔 花括号保存对象：使用{}定义json 格式 方括号保存数组：[] 获取数据 json对象.键名 json对象[\"键名\"] 数组对象[索引] 转换 JSON.stringify({username:'name'}) // to text JSON.parse(str) // to obj 后端解析 常见的解析器：Jsonlib，Gson，fastjson，jackson 移动端常用插件 Swiper 插件：轮播图插件 lsuperslide：常用特效插件 l iscroll：平滑滚动 zy.media.js：移动端视频插件 移动端常用框架 bootstrap 本地存储 特性 1、数据存储在用户浏览器中 2、设置、读取方便、甚至页面刷新不丢失数据 3、容量较大，sessionStorage约5M、localStorage约20M 4、只能存储字符串，可以将对象JSON.stringify() 编码后 sessionStorage 1、生命周期为关闭浏览器窗口 2、在同一个窗口(页面)下数据可以共享 3、以键值对的形式存储使用 // 存储 sessionStorage.setItem(key, value); // 获取 sessionStorage.getItem(key); // 删除 sessionStorage.removeItem(key); // 清除所有 sessionStorage.clear(); localStorage 生命周期永久，除非手动删除 多窗口共享 使用方式同sessionStorage MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-29 04:22:36 "},"编程语言/JavaScript/DOM.html":{"url":"编程语言/JavaScript/DOM.html","title":"DOM","keywords":"","body":"DOM DOM是W3C组织制定的一套处理 html和xml文档的规范 DOM树 核心DOM Document：文档对象 Element：元素对象 Attribute：属性对象 Text：文本对象 Comment:注释对象 Node：节点对象，其他5个的父对象 XML DOM HTML DOM 获取元素 根据ID获取 语法：document.getElementById(id) 作用：根据ID获取元素对象 参数：id值，区分大小写的字符串 返回值：元素对象 或 null 根据标签名获取元素 语法：document.getElementsByTagName('标签名') 或者 element.getElementsByTagName('标签名') 作用：根据标签名获取元素对象 参数：标签名 返回值：元素对象集合（伪数组，数组元素是元素对象） 根据name属性获取 document.getElementsByName('name'); H5新增获取元素方式 document.getElementsByClassName('className'); document.querySelector('selector'); // 根据指定选择器返回第一个元素 document.querySelectorAll('selector'); // 根据指定选择器返回全部 获取特殊元素 document.body; // 返回body对象 document.documentElement; // 返回html对象 操作元素 获取/改变元素内容 element.innerText; // 不包括html标签与空格和换行 element.innerHTML; // 包括html标签与空格换行 表单元素的属性操作 type/value/checked/selected/disabled 样式属性操作 element.style.backgroundColor; // 直接修改样式 element.className; // 修改类属性 自定义属性操作 element.getAttribute('name'); // 获取自定义属性 element.removeAttribute('name'); // 移除自定义属性 element.setAttribute('name','value'); // 设置自定义属性 HTML5自定义属性 获取方法 // 可以使用获取自定义属性的方式获取 console.log(div.getAttribute('data-index')); console.log(div.getAttribute('data-list-name')); // 也可以使用专用API console.log(div.dataset.index); console.log(div.dataset['index']); // 需要使用驼峰命名 console.log(div.dataset.listName); console.log(div.dataset['listName']); classList 属性 element.classList.add('current'); element.classList.remove('current'); element.classList.toggle('current'); 节点操作 网页中的所有内容都是节点（标签、属性、文本、注释等），在DOM 中，节点使用 node 来表示 HTML DOM 树中的所有节点均可通过 JavaScript 进行访问，所有 HTML 元素（节点）均可被修改，也可以创建或删除 节点至少拥有nodeType（节点类型）、nodeName（节点名称）和nodeValue（节点值）这三个基本属性 元素节点 nodeType=1 属性节点 nodeType=2 文本节点 nodeType=3（包括文字 空格 换行） 父节点 // 获取该节点最近的父节点 node.parentNode; 子节点 // 获取所有子节点，包含 元素节点 文本节点等等 node.childNodes; // 只返回元素节点 node.children; // 返回子节点，包含 元素节点 文本节点等等 node.firstChild; node.lastChild; // 返回元素子节点 node.firstElementChild; node.lastElementChild; 兄弟节点 // 下一个 node.nextSibling; // 前一个 node.previousSibling; node.nextElementSibling; node.previousElementSibling; 创建元素 document.write(); // 创建元素 如果页面文档流加载完毕，再调用这句话会导致页面重绘 node.innerHTML(); // 直接写HTML来创建元素 document.createElement('tagName');// 创建成功将返回一个节点 节点新增 node.appendChild() node.insertBefore(child,指定元素) document.replaceChild() 节点删除 // 从 node节点中删除一个子节点，返回删除的节点 node.removeChild(childNode) 节点复制 // 参数true深拷贝，false浅拷贝 node.cloneNode(); 元素偏移量 offset 系列 offset offset 可以得到任意样式表中的样式值 offset 系列获得的数值是没有单位的 offsetWidth 包含padding+border+width offsetWidth 等属性是只读属性，只能获取不能赋值 style style 只能得到行内样式表中的样式值 style.width 获得的是带有单位的字符串 style.width 获得不包含padding和border 的值 style.width 是可读写属性，可以获取也可以赋值 元素可视区 client 系列 元素滚动 scroll 系列 使用 scroll 系列的相关属性可以动态的得到该元素的大小、滚动距离等 如果浏览器的高（或宽）度不足以显示整个页面时，会自动出现滚动条。当滚动条向下滚动时，页面上面被隐藏掉的高度，我们就称为页面被卷去的头部。滚动条在滚动时会触发 onscroll事件 三大系列总结 offset系列 经常用于获得元素位置 offsetLeft offsetTop client经常用于获取元素大小 clientWidth clientHeight scroll 经常用于获取滚动距离 scrollTop scrollLeft 注意页面滚动的距离通过 window.pageXOffset 获得 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"编程语言/JavaScript/事件.html":{"url":"编程语言/JavaScript/事件.html","title":"事件","keywords":"","body":"事件 事件三要素 事件源（谁）：触发事件的元素 事件类型（什么事件）： 例如 click 点击事件 事件处理程序（做什么）：事件触发后要执行的代码(函数形式)，事件处理函数 执行事件的步骤 获取事件源 注册事件 添加事件处理程序 注册事件 传统注册方式 button.onclick = function(){} 同一个元素同一个事件只能设置一个处理函数，后注册的会覆盖先注册的 监听注册方式 button.addEventListener('click',function(e){}) 同一个元素可以注册多个处理函数，按注册顺序依次执行 删除事件 // 传统方式 button.onclick = null; button.removeEventListener('click',fn); DOM事件流 事件冒泡：事件开始时有最具体的元素接收，然后逐级向上传播到DOM最顶层节点的过程 事件捕获：由DOM最顶层节点开始，然后主机向下传播到最具体的元素接收的过程 DOM 事件流会经历3个阶段： 捕获阶段 当前目标阶段 冒泡阶段 addEventListener的第三个参数如果是true表示在事件捕获阶段调用事件处理函数，反之则是在事件冒泡阶段调用 事件对象 事件发生后，跟事件相关的一系列信息数据的集合都放到这个对象里面，这个对象就是事件对象 在 IE6~8 中，浏览器不会给方法传递参数，如果需要的话，需要到 window.event 中获取查找 常见属性和方法 常情况下terget 和 this是一致的， 但有一种情况不同，那就是在事件冒泡时（父子元素有相同事件，单击子元素，父元素的事件处理函数也会被触发执行）， 这时候this指向的是父元素，因为它是绑定事件的元素对象， 而target指向的是子元素，因为他是触发事件的那个具体元素对象。 阻止默认行为 a.onclick = function(e) { // 普通浏览器 e.preventDefault(); 方法 e.preventDefault(); // 低版本浏览器 ie678 returnValue 属性 e.returnValue = false; // 我们可以利用return false 也能阻止默认行为 没有兼容性问题 return false; } 阻止冒泡 // 阻止事件继续向上传递给父组件 son.addEventListener('click', function(e) { alert('son'); e.stopPropagation(); // stop 停止 Propagation 传播 window.event.cancelBubble = true; // 非标准 cancel 取消 bubble 泡泡 }, false); 事件委托 给父元素注册事件，利用事件冒泡，当子元素的事件触发，会冒泡到父元素，然后去控制相应的子元素 我们只操作了一次 DOM ，提高了程序的性能。 动态新创建的子元素，也拥有事件。 常见事件 鼠标事件 鼠标事件对象 键盘事件 键盘事件 触发条件 onkeyup 某个键盘按键被松开时触发 onkeydown 某个键盘按键被按下时触发 onkeypress 某个键盘按键被按下时触发，但是不识别功能键 键盘事件对象 keyCode：返回该键的ASCII值 mouseenter 和mouseover的区别 当鼠标移动到元素上时就会触发mouseenter 事件，- mouseover 鼠标经过自身盒子会触发，经过子盒子还会触发。mouseenter 只会经过自身盒子触发，之所以这样，就是因为mouseenter不会冒泡，跟mouseenter搭配鼠标离开 mouseleave 同样不会冒泡 触屏事件 移动端浏览器兼容性较好，我们不需要考虑以前 JS 的兼容性问题，可以放心的使用原生 JS 书写效果，但是移动端也有自己独特的地方。比如触屏事件 touch（也称触摸事件），Android和 IOS 都有 常见的触屏事件 触屏事件 说明 touchstart 手指触摸到一个DOM元素时触发 touchmove 手指在一个DOM元素上滑动时触发 touchend 手指从一个DOM元素上移开时触发 触摸事件对象（TouchEvent） 触摸列表 说明 touches 正在触发屏幕的所有手指的一个列表 targetTouches 正在触发当前DOM元素上的手指的一个列表 changedTouches 手指状态发生了改变的列表，从无到有，从有到无的变化 click 延时解决方案 移动端 click 事件会有 300ms 的延时，原因是移动端屏幕双击会缩放(double tap to zoom) 页面 禁用缩放 利用touch事件封装事件解决300ms 延迟 当我们手指触摸屏幕，记录当前触摸时间 当我们手指离开屏幕， 用离开的时间减去触摸的时间 如果时间小于150ms，并且没有滑动过屏幕， 那么我们就定义为点击 fastclick 插件 if ('addEventListener' in document) { document.addEventListener('DOMContentLoaded', function() { FastClick.attach(document.body); }, false); } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"编程语言/JavaScript/BOM.html":{"url":"编程语言/JavaScript/BOM.html","title":"BOM","keywords":"","body":"BOM BOM（Browser Object Model）即浏览器对象模型，它提供了独立于内容而与浏览器窗口进行交互的对象，其核心对象是 window 组成 window document location navigator screen history window 事件 window.onload 是窗口 (页面）加载事件，当文档内容完全加载完成会触发该事件(包括图像、脚本文件、CSS 文件等), 就调用的处理函数 window.onresize 是调整窗口大小加载事件, 当触发时就调用的处理函数.经常利用这个事件完成响应式布局。 window.innerWidth 当前屏幕的宽度 定时器 setTimeout() 在指定的毫秒数后调用函数或计算表达式。 clearTimeout() 取消由 setTimeout() 方法设置的 timeout。 setInterval() 按照指定的周期（以毫秒计）来调用函数或计算表达式。 clearInterval() 取消由 setInterval() 设置的 timeout。 this指向问题 全局作用域或者普通函数中this指向全局对象window（注意定时器里面的this指向window） 方法调用中谁调用this指向谁 构造函数中this指向构造函数的实例 location 属性 属性 描述 hash 设置或返回从井号 (#) 开始的 URL（锚）。 host 设置或返回主机名和当前 URL 的端口号。 hostname 设置或返回当前 URL 的主机名。 href 设置或返回完整的 URL。 pathname 设置或返回当前 URL 的路径部分。 port 设置或返回当前 URL 的端口号。 protocol 设置或返回当前 URL 的协议。 search 设置或返回从问号 (?) 开始的 URL（查询部分）。 方法 属性 描述 assign() 加载新的文档。 reload() 重新加载当前文档。 replace() 用新的文档替换当前文档（不在历史记录中，无法后退）。 navigator 属性 属性 描述 appCodeName 返回浏览器的代码名。 appMinorVersion 返回浏览器的次级版本。 appName 返回浏览器的名称。 appVersion 返回浏览器的平台和版本信息。 browserLanguage 返回当前浏览器的语言。 cookieEnabled 返回指明浏览器中是否启用 cookie 的布尔值。 cpuClass 返回浏览器系统的 CPU 等级。 onLine 返回指明系统是否处于脱机模式的布尔值。 platform 返回运行浏览器的操作系统平台。 systemLanguage 返回 OS 使用的默认语言。 userAgent 返回由客户机发送服务器的 user-agent 头部的值。 userLanguage 返回 OS 的自然语言设置。 history 属性 描述 length 返回浏览器历史列表中的 URL 数量。 方法 描述 back() 加载 history 列表中的前一个 URL。 forward() 加载 history 列表中的下一个 URL。 go() 加载 history 列表中的某个具体页面。 screen 属性 描述 availHeight 返回显示屏幕的高度 (除 Windows 任务栏之外)。 availWidth 返回显示屏幕的宽度 (除 Windows 任务栏之外)。 bufferDepth 设置或返回调色板的比特深度。 colorDepth 返回目标设备或缓冲器上的调色板的比特深度。 deviceXDPI 返回显示屏幕的每英寸水平点数。 deviceYDPI 返回显示屏幕的每英寸垂直点数。 fontSmoothingEnabled 返回用户是否在显示控制面板中启用了字体平滑。 height 返回显示屏幕的高度。 logicalXDPI 返回显示屏幕每英寸的水平方向的常规点数。 logicalYDPI 返回显示屏幕每英寸的垂直方向的常规点数。 pixelDepth 返回显示屏幕的颜色分辨率（比特每像素）。 updateInterval 设置或返回屏幕的刷新率。 width 返回显示器屏幕的宽度。 JS执行机制 JS是单线程 单线程导致的问题就是后面的任务等待前面任务完成，如果前面任务很耗时，后面任务不得不一直等待，为了解决这个问题，利用多核 CPU 的计算能力，HTML5 提出 Web Worker 标准，允许 JavaScript 脚本创建多个线程，但是子线程完全受主线程控制。于是，JS 中出现了同步任务和异步任务 JS执行机制（事件循环） 由于主线程不断的重复获得任务、执行任务、再获取任务、再执行，所以这种机制被称为事件循环(event loop) MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"编程语言/JavaScript/面向对象.html":{"url":"编程语言/JavaScript/面向对象.html","title":"面向对象","keywords":"","body":"面向对象 对象 属性 方法 创建对象 // 字面量创建对象 var man = { name: 'cxk', play:function(){ console.log('jntm') } } // 实例化对象 var man = new Man() man.play() 构造函数 // 构造函数创建对象 function Man(){ this.name = 'cxk'; this.play=function(){ console.log('jntm') } } // 实例化对象 var man = new Man() man.play() 成员 实例成员 // 在函数内容通过this访问的是实例成员 this.name = 'cxk'; 静态成员 // 静态成员只能通过构造函数访问 Man.people='70亿' console.log(Man.people) 构造函数的问题 构造函数原型prototype 每一个构造函数都有一个prototype 属性，指向另一个对象。注意这个prototype就是一个对象，这个对象的所有属性和方法，都会被构造函数所拥有 我们可以把那些不变的方法，直接定义在 prototype 对象上，这样所有对象的实例就可以共享这些方法 Man.prototype.people='70亿' var man = new Man() console.log(man.people) 对象原型 对象都会有一个属性 __proto__ 指向构造函数的 prototype 原型对象，之所以我们对象可以使用构造函数 prototype 原型对象的属性和方法，就是因为对象有 __proto__ 原型的存在 man.__proto__ == Man.prototype // true constructor构造函数 一般情况下，对象的方法都在构造函数的原型对象中设置。如果有多个对象的方法，我们可以给原型对象采取对象形式赋值，但是这样就会覆盖构造函数原型对象原来的内容，这样修改后的原型对象 constructor 就不再指向当前构造函数了。此时，我们可以在修改后的原型对象中，添加一个 constructor 指向原来的构造函数 Man.prototype = { constructor:Man, play:function(){ console.log('真香') } } 原型链 当访问一个对象的属性（包括方法）时，首先查找这个对象自身有没有该属性 如果没有就查找它的原型（也就是 proto指向的 prototype 原型对象） 如果还没有就查找原型对象的原型（Object的原型对象），依此类推一直找到 Object 为止（null）。 this指向 构造函数中的this和原型对象的this,都指向我们new出来的实例对象 继承 构造函数继承 function Animal(){ this.run = function(){ console.log('animal run') } } function Dog(){ // 让父构造函数的this指向当前的this Animal.call(this) this.bark = function(){ console.log('wolf wolf') } } var dog = new Dog(); dog.run() dog.bark() 原型继承 function Animal() { } Animal.prototype.run = function () { console.log('animal run') } function Dog() { } Dog.prototype = new Animal() Dog.prototype.constructor = Dog; Dog.prototype.bark = function () { console.log('wolf wolf') } var dog = new Dog() dog.run() dog.bark() 类 在 ES6 中新增加了类的概念，可以使用 class 关键字声明一个类，之后以这个类来实例化对象 创建类 // 创建一个Man类 class Man{ // 构造器 constructor(){ this.name = 'cxk' } // 实例方法 play(){ console.log('jntm') } } // 实例化 var man = new Man() man.play() 类继承 class Animal { constructor(){ console.log('animal create') } run(){ console.log('animal run') } } class Dog extends Animal { // 创建子类前会调用父类的构造器 constructor(){ // 必须在第一行手动调用 super() console.log('dog create') } // 覆写父类的方法 run(){ // 调用父类的run方法 super.run() console.log('dog run') } // 定义新方法 bark(){ console.log('wolf wolf') } } var dog = new Dog() dog.run() dog.bark() 注意事项 ES6 中类没有变量提升，所以必须先定义类，才能通过类实例化对象 注意this的指向问题,类里面的共有的属性和方法一定要加this使用 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-28 06:31:46 "},"编程语言/JavaScript/函数.html":{"url":"编程语言/JavaScript/函数.html","title":"函数","keywords":"","body":"函数 定义 // 命名函数 function fn(){} // 匿名函数 var fn = function(){} // 函数对象 里面参数都必须是字符串格式 var fn = new Function('参数1','参数2'..., '函数体') 调用 // 普通调用 fn() // 对象的方法 obj.fn() // 构造方法 new Object() // 事件绑定 btn.onclick = function(){} // 定时器函数 setInterval(function(){}, 1000); // 立即执行函数 (function(){})(); this 改变this指向 call() function fn(arg1){ console.log(this) // string cxk } // 修改fn函数里面的this指向'cxk' fn.call('cxk','arg1') apply() function fn(a, b) { console.log(a, b) console.log(this) // obj } var obj = { name: 'cxk' } // 参数使用数组传递 fn.apply(obj, [1, 2]) call 和 apply 传递的参数不一样,call传递参数使用逗号隔开,apply使用数组传递 bind() // 返回一个包装函数 var f = fn.bind(obj, 1, 2) f()// 调用这个函数，this指向obj 严格模式 JavaScript 除了提供正常模式外，还提供了严格模式（strict mode）。ES5 的严格模式是采用具有限制性 JavaScript变体的一种方式，即在严格的条件下运行 JS 代码 消除了 Javascript 语法的一些不合理、不严谨之处，减少了一些怪异行为 消除代码运行的一些不安全之处，保证代码运行的安全 提高编译器效率，增加运行速度 禁用了在 ECMAScript 的未来版本中可能会定义的一些语法 开启严格模式 // 为整个脚本开启严格模式 \"use strict\"; ... // 在函数中开启严格模式 function fn(){ \"use strict\"; } 严格模式中的变化 // 变量未声明不能使用 num = 10 // 变量不能删除 delete num // 严格模式下全局作用域中函数中的 this 是 undefined function fn() { console.log(this); } // 严格模式下,如果 构造函数不加new调用, this 指向的是undefined 如果给他赋值则 会报错 Object(); //严格模式下，定时器 this 还是指向 window setTimeout(function() { console.log(this); }, 2000); // 严格模式下不能有重名的函数 function a(){} function a(){} // 不允许在非函数的代码块内声明函数 if (condition){ function(){} } 更多变化参考:https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Strict_mode 高阶函数 当参数的类型或者返回值类型是一个函数，则称之为高阶函数 闭包 闭包（closure）指有权访问另一个函数作用域中变量的函数 作用：延伸变量的作用范围 function fn(){ var num=1; return function(){ console.log(num); } } fn()() 拷贝 浅拷贝 var obj = {name:'cxk'} var o ={} Object.assign(o,obj) 深拷贝 function deepCopy(newObj,oldObj){ for (var k in oldObj){ if (oldObj[k] instanceof Array){ newObj[k]=[] deepCopy(newObj[k],oldObj[k]) }else if(oldObj[k] instanceof Object){ newObj[k]={} deepCopy(newObj[k],oldObj[k]) }else{ newObj[k]=oldObj[k] } } } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-28 06:31:46 "},"编程语言/JavaScript/正则表达式.html":{"url":"编程语言/JavaScript/正则表达式.html","title":"正则表达式","keywords":"","body":"正则表达式 正则表通常被用来检索、替换那些符合某个模式（规则）的文本 参考资料 使用 创建 // 对象创建 var reg = new RegExp(\"正则表达式\"); // 字面量创建 var reg = /正则表达式/; 使用 reg.test('some text'); 组成 边界符 边界符 说明 ^ 表示匹配行首的文本（以谁开始） $ 表示匹配行尾的文本（以谁结束） /^abc/.test('abcdefg') // true /abc$/.test('xxabc') // true 字符类 []方括号 一系列字符可供选择，只要匹配其中一个就可以了 /[abc]/.test('a') // true // 匹配a-z之间的任意字母 /[a-z]/.test('h') // true // a-z不区分大小写 /[a-zA-Z]/.test('H') // true // a-c之外的 /[^a-c]/.test('c') // false 量词符 量词 说明 * 重复0次或更多次 + 重复1次或更多次 ? 重复0次或1次 {n} 重复n次 {n,} 重复n次或更多次 {n,m} 重复n到m次 /[a-zA-Z]*/.test('HHHH') // true /[a-zA-Z]+/.test('') // false /[a-zA-Z]{2}/.test('xx') // true /[a-zA-Z]{2,}/.test('xxxx') // true /^a${2,6}/.test('aaaaaaa') // false 预定义类 /^\\d{3,4}-\\d{7,8}$/.test('0596-3766183') // true 正则替换 '我的电话:0596-3766183'.replace(/\\d{3,4}-\\d{7,8}/,'****') // 我的电话:**** 正则表达式参数 /reg/[g] // 全局匹配 /reg/[i] // 忽略大小写 /reg/[gi] // 全局匹配+忽略大小写 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-29 04:22:36 "},"编程语言/JavaScript/AJAX.html":{"url":"编程语言/JavaScript/AJAX.html","title":"AJAX","keywords":"","body":"AJAX 传统网站的弊端 应用场景 动态数据加载 表单验证 实现 原生方式 let xhr = new XMLHttpRequest(); // 发送get请求 通过url传递参数 xhr.open('get',\"/home\"); xhr.send(); xhr.onload = function(){ console.log(xhr.responseText); } post xhr.open('post',\"/home\"); xhr.setRequestHeader('Content-Type',\"application/json\"); xhr.send('{\"name\":\"jntm\"}'); ajax状态码 0：请求未初始化(还没有调用open()) 1：请求已经建立，但是还没有发送(还没有调用send()) 2：请求已经发送 3：请求正在处理中，通常响应中已经有部分数据可以用了 4：响应已经完成，可以获取并使用服务器的响应了 xhr.onreadystatechange = function(){ console.log(xhr.readyState); } 区别描述 onload事件 onreadystatechange事件 是否兼容IE低版本 不兼容 兼容 是否需要判断Ajax状态码 不需要 需要 被调用次数 一次 多次 错误处理 后端能调通，但是返回错误 xhr.status 网络中断，后端无法调通 会触发xhr对象下面的onerror事件，在onerror事件处理函数中对错误进行处理 低版本ie存在ajax缓存问题 ajax封装 function ajax(req) { let xhr = new XMLHttpRequest(); let params = \"\"; for (let attr in req.data) { params += attr + \"=\" + req.data[attr] + \"&\"; } params = params.substr(0, params.length - 1); xhr.open(req.type, req.type != 'get' ? req.url:req.url + \"?\" + params); for(let attr in req.headers){ xhr.setRequestHeader(attr,req.headers[attr]); } if (req.type == 'get'){ xhr.send(); }else{ if (req.headers['Content-Type']=='application/json'){ xhr.send(JSON.stringify(req.data)); }else{ xhr.send(params); } } xhr.onload = function () { let contentType = xhr.getResponseHeader(\"Content-Type\"); let responseText = xhr.responseText; if (contentType.includes(\"application/json\")){ responseText = JSON.parse(responseText); } if (xhr.status === 200) { req.success && req.success(responseText); } else { req.error && req.error(responseText); } }; } ajax({ url: '/home', type: 'get', data: {name: \"cxk\", age: 18}, headers:{ \"Content-Type\":\"application/json\" }, success: function (res) { console.log('normal res', res); }, error: function (res) { console.error('error res', res); } }) JQuery实现方式 ajax $.ajax({ url:\"./\" , // 请求路径 type:\"POST\" , //请求方式 //data: \"username=jack&age=23\",//请求参数 data:{\"username\":\"jack\",\"age\":23}, success:function (data) { alert(data); },//响应成功后的回调函数 error:function () { alert(\"出错啦...\") },//表示如果请求响应出现错误，会执行的回调函数 }); 发送jsonp请求 $.ajax({ url: 'http://www.example.com', // 指定当前发送jsonp请求 dataType: 'jsonp', // 修改callback参数名称 jsonp: 'cb', // 指定函数名称 jsonCallback: 'fnName', success: function (response) {} }) $.get $.post serialize $(\"#form\").serialize(); // 将表单输入的内容转换成如k=v&a=b这种形式 全局事件 .ajaxStart() // 当请求开始发送时触发 .ajaxComplete() // 当请求完成时触发 配合nprogress来实现页面加载进度条 FormData 表单上传 二进制文件上传 简单使用 let form = document.querySelector(\"#form\"); let formData = new FormData(form); let xhr = new XMLHttpRequest(); xhr.open('post','/formData'); xhr.send(formData); 实例方法 // 获取表单对象属性 formData.get('username'); // 设置表单对象属性 formData.set(\"username\",\"cxk\"); // 删除表单对象属性 formData.delete(\"username\"); // 追加表单对象属性,属性名已存在的情况下,set会覆盖,append会保留 formData.append(\"username\",\"cxk\"); 文件上传进度展示 xhr.upload.onprogress = function (ev) { console.log(ev.loaded / ev.total) } 图片上传实时预览 var file = document.querySelector('#file'); file.onchange = function(){ var reader = new FileReader(); reader.readAsDataURL(this.files[0]); reader.onload = function(){ document.querySelector('.img-thumbnail').src = reader.result; } } 使用Promise发送ajax function query() { return new Promise((resolve, reject) => { let xhr = new XMLHttpRequest(); xhr.onreadystatechange = () => { if (xhr.readyState != 4) { return; } if (xhr.readyState == 4 && xhr.status == 200) { resolve(xhr.responseText); } else { reject(xhr.status); } }; xhr.open('get', '/home'); xhr.send(); }); } query().then(r => console.log(r)).catch(r => console.error(r)) fetch Fetch API是新的ajax解决方案 fetch不是ajax的进一步封装，而是原生js，没有使用XMLHttpRequest对象 fetch('/home').then(data=>{ return data.text(); }) .then(data=>{ console.log(data); }); data是一个response对象，其中包括返回的一堆原始字节，这些字节需要在收到后，需要我们通过调用方法将其转换为相应格式的数据，比如JSON，BLOB或者TEXT等等 传递参数 let formData = new FormData(); formData.append('username','cxk'); formData.append('password','jntm'); fetch('/formData',{ method:'post', body:formData }) axios axios.get('/home') .then(res=>{ console.log(res); }) let formData = new FormData(); formData.append('username','cxk'); formData.append('password','jntm'); // 默认传递的是json axios.post('/formData',formData) .then(res=>{ console.log(res); }) 同步调用 async function f(){ let res = await axios.post('/formData',formData); console.log(res); } 全局参数 // 配置公共的请求头 axios.defaults.baseURL = 'https://api.example.com'; // 配置 超时时间 axios.defaults.timeout = 2500; // 配置公共的请求头 axios.defaults.headers.common['Authorization'] = AUTH_TOKEN; // 配置公共的 post 的 Content-Type axios.defaults.headers.post['Content-Type'] = 'application/x-www-form-urlencoded'; 拦截器 // 请求拦截器 axios.interceptors.request.use(function(config) { console.log(config.url) // 这里一定要return 否则配置不成功 return config; }, function(err){ // 对请求错误做点什么 console.log(err) }) // 响应拦截器 axios.interceptors.response.use(function(res) { console.log(res.data); return res.data; }, function(err){ console.log(err) }); 同源策略 ajax受同源策略限制 JSONP 原理： 客户端定义一个函数： function fn (data) { // 接收到服务器data后的一些处理 } 服务端返回一个函数调用： const data = 'fn({name: \"张三\", age: \"20\"})'; 客户端使用script可以跨域加载数据 这样客户端就可以获取服务端的数据 function fn(data){ console.log('server res',data); } let script = document.createElement('script'); script.src = '/jsonp?v=1'; document.body.appendChild(script); @GetMapping(\"/jsonp\") public String jsonp(){ return \"fn({name:'cxk',age:18})\"; } 优化 回调函数名称参数化 回调函数参数化 注意回调函数覆盖问题 url参数化 接收到回调后删除script标签 CORS 全称为 Cross-origin resource sharing，即跨域资源共享，它允许浏览器向跨域服务器发送 Ajax 请求，克服了 Ajax 只能同源使用的限制 通过设置Access-Control-Allow-Origin和Access-Control-Allow-Methods响应头来允许哪些源可以使用哪些方法访问 @RestController @CrossOrigin(\"*\") public class Controller {...} withCredentials：指定在涉及到跨域请求时，是否携带cookie信息，默认值为false 使用后端服务器辅助访问 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-21 01:00:46 "},"编程语言/JavaScript/ES5.html":{"url":"编程语言/JavaScript/ES5.html","title":"ES5","keywords":"","body":"ES5 数组方法 // 遍历数组 [1, 2, 3, 4, 5].forEach(function (v, i, a) { console.log(\"index:\" + i + \",value:\" + v) }) // 对数组中的每个元素进行操作，然后返回 var a = [1, 2, 3, 4, 5].map(function (v, i, a) { return v = v*v; }) // filter过滤数组 var a = [1, 2, 3, 4, 5].filter(function (v, i, a) { return i % 2 == 0; }) // 是否有满足条件的元素(any) var flag = [1, 2, 3, 4, 5].some(function (v, i, a) { // 当找到第一个满足条件的元素后，就停止循环了 return v 0; }) 字符串方法 // 去除前后空格 \" das \".trim() 对象方法 // 获取对象属性名列表 Object.keys({name:'cxk',age:'18'}) Object.defineProperty Object.defineProperty(对象，修改或新增的属性名，{ value:修改或新增的属性的值, writable:true/false,//如果值为false 不允许修改这个属性值 enumerable: false,//enumerable 如果值为false 则不允许遍历 configurable: false //configurable 如果为false 则不允许删除这个属性 属性是否可以被删除或是否可以再次修改特性 }) var obj = { name:'cxk' } Object.defineProperty(obj,'name',{ writable:false, enumerable:true, configurable:false }) obj.name= 'jntm'; //无效 for (let i in obj){ // 无法枚举到name console.log(i) } // 无法再重新修改特性 Object.defineProperty(obj,'name',{ configurable:true }) MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-27 06:32:32 "},"编程语言/JavaScript/ES6.html":{"url":"编程语言/JavaScript/ES6.html","title":"ES6","keywords":"","body":"ES6 let 所声明的变量，只在let命令所在的代码块内有效 { let a = 10; // 暂时性死区 var b = 1; } b = 1 // 1 a = 1 // ReferenceError: a is not defined. 不存在变量提升 console.log(a); // Cannot access 'a' before initialization let a = 20; const 声明一个只读的常量。一旦声明，常量的值就不能改变。 具有块级作用域 { const PI = 3; } console.log(PI); // PI is not defined 声明时必须赋值 const PI; // Missing initializer in const declaration 不能重新赋值 const PI = 3.1415; PI = 3; // TypeError: Assignment to constant variable. var、let、const var let const 函数级作用域 块级作用域 块级作用域 变量提升 不存在变量提升 不存在变量提升 值可更改 值可更改 值不可更改 模板字符串 let name = \"cxk\" // 模板字符串中可以解析变量 console.log(`your name is ${name}`) const fn = ()=>'fn function '; // 模板字符串可以调用函数 let text = `fn call: ${fn()}`; // 模板字符串可以换行 let info =`123 456 789` 解构赋值 解构赋值就是把数据结构分解，然后给变量进行赋值 如果解构不成功，变量跟数值个数不匹配的时候，变量的值为undefined 数组 let [a, b, c] = [1, 2, 3]; // a=1 b=2 c=3 const color = [1,2] const color2=[...color,3,4] // color2 = [1,2,3,4],同样能用于对象 对象 let {name,age} = {name:\"123\",age:15} // name = \"123\" age = 15 let {name:myName,age:myAge} = {name:\"123\",age:15} // myName = \"123\" myAge = 15 函数默认值 function a(a = 2){ console.log(a); } 剩余参数 function f(...args){ console.log(args); // [1,2,3,4] } f(1,2,3,4); 箭头函数 // 函数体中只有一句代码，且代码的执行结果就是返回值，可以省略大括号 let sum = (a,b) => a+b; // 如果形参只有一个，可以省略小括号 let f = res => res.data; // 箭头函数不绑定this关键字，箭头函数中的this，指向的是函数定义位置的上下文this var obj = { f: () => { console.log(this); // Window } } obj.f(); Array新增方法 Arrat.from //定义一个集合 let arrayLike = { '0': 'a', '1': 'b', '2': 'c', length: 3 }; //转成数组 let arr2 = Array.from(arrayLike); // ['a', 'b', 'c'] let arrayLike = { \"0\": 1, \"1\": 2, \"length\": 2 } let newAry = Array.from(arrayLike, item => item *2)//[2,4] Array实例方法:find [1,2,3].find(i=>i/2==1) // 2 Array实例方法:findIndex [1,2,3].findIndex(i=>i/2==1) // 1 Array实例方法:includes [1,2,3].includes(4) // false String新增方法 实例方法:startsWith,endsWith 'javascript'.startsWith('java') // true 'javascript'.endsWith('script') // true 实例方法:repeat 'x'.repeat(3) // xxx 数据结构Set ES6 提供了新的数据结构 Set。它类似于数组，但是成员的值都是唯一的，没有重复的值 const set = new Set([1,2,3,4,4]) // set = {1,2,3,4} 一些方法 set.add(1); // 添加元素 set.delete(1) // 删除元素 set.has(1) // 判断是否有这个元素 set.clear() // 清空集合 set.forEach(v => console.log(v)) MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-22 03:39:28 "},"编程语言/JavaScript/Node/NodeJs.html":{"url":"编程语言/JavaScript/Node/NodeJs.html","title":"NodeJS","keywords":"","body":"node 组成 ECMAScript Node模块API 运行js文件 node xxx 模块化开发 Node.js规定一个JavaScript文件就是一个模块，模块内部定义的变量和函数默认情况下在外部无法得到 模块内部可以使用exports对象进行成员导出， 使用require方法导入其他模块 js开发弊端 文件依赖 命名冲突 模块导出 // module.js exports.add= (a,b) => a+b // 另外一种导出方式 module.exports.add = (a,b) => a+b; // exports是module.exports的别名(地址引用关系)，当它们指向的部署同一个对象时，导出对象最终以module.exports为准 模块导入 // other.js let demo = require('./module'); demo.add(1,2); 系统模块 fs const fs = require('fs') // 读取文件 fs.readFile('./index.html',(err,doc)=>{ if (!err){ console.log(doc.toString()) } }) // 文件写入 fs.writeFile('test.txt','run it',error => { console.log(error); }) path const path = require('path') // 拼接路径 console.log(path.join(__dirname,'TMP','MY')) // windows: C:\\Users\\MY\\TMP\\web\\TMP\\MY // 大多数情况下使用绝对路径，因为相对路径有时候相对的是命令行工具的当前工作目录 第三方模块 http://npmjs.com npm install xx # 安装模块（本地安装） npm uninstall xx # 卸载模块 npm install xx -g # 全局安装 nodemon 能监控文件的变化，变化时自动运行它 npm install nodemon -g # 安装 nodemon test # 使用nodemon代替node执行js文件，当js文件发生变更后，会自动重新运行js文件 nrm npm下载地址切换工具 nrm ls # 列出可用源 nrm use xx # 使用某个源 gulp npm install gulp npm install gulp-cli -g // 执行 gulp first const gulp = require('gulp'); gulp.task('first', () => { return gulp.src('./src/index.html') .pipe(gulp.dest('./dist')) }) 插件 使用 // 压缩html const htmlmin = require('gulp-htmlmin') gulp.task('htmlmin', () => { return gulp.src('./src/*.html') .pipe(htmlmin({collapseWhitespace:true})) .pipe(gulp.dest('./dist')) }) 全局对象 global package.json 项目描述文件,记录了当前项目信息，例如项目名称、版本、作者、github地址、 当前项目依赖了哪些第三方模块等。 使用npm init -y命令生成。 dependencies devDependencies package-lock.json 锁定包的版本 记录了包以及依赖的下载地址 script \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\", \"build\":\"nodemon a.js\" } npm run build 模块加载机制 // 如果模块后缀省略,先找同名JS文件再找同名JS文件夹 // 如果找到了同名文件夹，找文件夹中的index.js // 如果文件夹中没有index.js就会去当前文件夹中的package.js文件中查找main选项中的入口文件 // 如果再找不到就抛出异常 require('./xx') // Node.js会假设它是 系统模块 // Node.js会去node_ modules文件夹中 // 首先看是否有该名字的JS文件 // 再看是否有该名字的文件夹 // 如果是文件夹看里面是否有index.js // 如果没有index.js查看 该文件夹中的package.json中的main选项确定模块入口文件 // 否则找不到报错 require('xx') 异步编程 同步api 会阻塞 从返回值拿执行结果 异步api 不会阻塞 从回调函数拿执行结果 代码执行顺序 console.log('代码开始执行'); setTimeout(() => { console.log('2秒后执行的代码'); }, 2000); setTimeout(() => { console.log('\"0秒\"后执行的代码'); }, 0); console.log('代码结束执行'); Promise 解决异步编程问题 Promise 是一个对象，它代表了一个异步操作的最终完成或者失败 var promise = new Promise((resolve, reject) => { setTimeout(function () { let condition = true; if (condition) { resolve('foo'); // 回调then里的函数 } else { reject('error'); // 回调catch里的函数 } }, 300); }); promise .then(value => { console.log(value); }) .catch(error => { console.log(error) }) 解决回调地狱 promise .then(v=>{ // 如果返回Promise，则这个promise是调用下一个then的promise // 如果不是promise，则就是下一个then的回调函数参数v return new Promise() }) .then(v=>{ return new Promise() }) all与race // 所有任务都完成才返回结果 Promise.all([query(),query(),query()]).then(()=>console.log('all mission complete')); // 任一任务都完成就返回结果 Promise.race([query(),query(),query()]).then(()=>console.log('mission complete')); 异步函数 // 使用async修饰，这个函数会返回一个Promise const fn = async () => {}; async function fn () {} async function f() { return 11; } f() .then(v=>console.log(v)) await await关键字只能出现在异步函数中 await promise await后面只能写promise对象 写其他类型的API是不不可以的 await关键字可是暂停异步函数向下执行 直到promise返回结果 async function f1() { return 11; } async function f2(){ return 22; } async function f(){ // 可以通过await关键字将异步函数转同步执行 let i1 = await f1(); let i2 = await f2(); console.log(i1,i2) } f() web服务器 创建 var http = require('http') http.createServer((request,response)=>{ const body = \"hello world\"; response.writeHead(200,{ 'Content-Length':Buffer.byteLength(body), 'Content-Type':'text/plain' }); response.end(body); }).listen(8888); 请求报文 const body = `request method:${request.method} request url:${request.url} request headers ua:${request.headers[\"user-agent\"]} ` 响应报文 response.writeHead(200,{ 'Content-Type':'application/json' }) response.end('{\"result\":\"25\"}') 请求参数 get const url = require('url') let { query } = url.parse(request.url, true) // 输出name参数与age参数 response.end(query.name + \",\" + query.age) post let postData = '' request.on('data',params=>{ postData += params }) request.on('end',()=>{ let i = querystring.parse(postData) response.end(`name: ${i.name} address: ${i.address}`) }) 路由 let { pathname } = url.parse(req.url); if (pathname == '/' || pathname == '/index') { response.end('欢迎来到首页'); } else if (pathname == '/list') { response.end('欢迎来到列表页页'); } else { response.end('抱歉, 您访问的页面出游了'); } 静态资源 fs.readFile(__dirname+'/static'+pathname,(error,data)=>{ if (!error){ let type = pathname.substring(pathname.lastIndexOf('.')+1) response.writeHead(200,{ \"Content-Type\":mime.getType(pathname) }) response.end(data) }else{ response.writeHead(404,{ \"Content-Type\":\"text/html;charset=utf8\" }) response.end('404 NOT FOUND') } }) MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-20 12:15:33 "},"编程语言/JavaScript/Node/art-template.html":{"url":"编程语言/JavaScript/Node/art-template.html","title":"art-template","keywords":"","body":"art-template 使用 const template = require('art-template') const view = path.join(__dirname,'views','index.art') let ret = template(view,{ name:'cxk', age:18 }) 姓名:{{name}} 年龄:{{age}} 模板语法 标准语法： 原始语法： 输出 {{value}} {{a ? b : c}} {{a + b}} 原文输出 {{@ value }} 条件 {{if age==18}} 沉鱼落雁 {{else if age == 20}} 闭月羞花 {{/if}} 沉鱼落雁 闭月羞花 循环 let ret = template(view,{ name:'cxk', age:20, skills:['唱','跳','rap','篮球'] }) {{each skills}} 技能{{$index}}:{{$value}} {{/each}} 技能: 子模板 {{include './header.art'}} 模板继承 HTML骨架模板 {{block 'head'}}{{/block}} {{block 'content'}}{{/block}} 其他模板可以继承这个模板，填充占位符里的内容 {{extend './layout.art'}} {{block 'head'}} {{/block}} {{block 'content'}} test {{/block}} 渲染结果 HTML骨架模板 test 模板配置 导入变量 template.defaults.imports.random = ()=>{ return Math.random() } {{random()}} 设置模板根目录 template.defaults.root = 模板目录 设置模板默认后缀 template.defaults.extname = '.art' MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-07 06:38:35 "},"编程语言/JavaScript/Node/Express.html":{"url":"编程语言/JavaScript/Node/Express.html","title":"Express","keywords":"","body":"Express Express是一个基于Node平台的web应用开发框架，它提供了一系列的强大特性，帮助你创建各种Web应用 特性 提供了方便简洁的路由定义方式 对获取HTTP请求参数进行了简化处理 对模板引擎支持程度高，方便渲染动态HTML页面 提供了中间件机制有效控制HTTP请求 拥有大量第三方中间件对功能进行扩展 开始 const express = require('express') const app = express() app.listen(80) app.get('/',(req,res)=>{ // 自动设置响应内容类型 res.send({name:'cxk',age:18}) }) 中间件 next 使用next继续传递请求 app.get('/',(req,res,next)=>{ req.name = 'cxk' next() }) app.get('/',(req,res)=>{ res.send({name:req.name,age:18}) }) use 使用use接收任何类型方法的请求 app.use('/any',(req,res,next)=>{ res.end('ok') }) 可以用作过滤器 404处理: app.use((req,res,next)=>{ res.status(404).send('not found') }) 错误处理： app.use('/any',(req,res,next)=>{ throw Error('RuntimeException') }) app.use((error,req,res,next)=>{ res.status(500).send(\"SERVER INTERNAL ERROR:\"+error) }) 当发生错误的中间件是异步函数是，需要手动捕捉错误，调用next app.use('/any',async (req,res,next)=>{ try{ throw Error('RuntimeException') }catch(e){ next(e) } }) 模块化路由 const home = express.Router() const admin = express.Router() app.use('/home',home) app.use('/admin',admin) home.get('/index',(req,res)=>{ res.send('前台首页') }) admin.get('/index',(req,res)=>{ res.send('后台首页') }) 参数获取 get请求 req.query post请求 const bodyParser = require('body-parser') app.use(bodyParser.urlencoded({extended:false})) app.post('/',(req,res)=>{ res.send(req.body) }) 路由参数 请求:http://localhost/1 app.get('/:id',(req,res)=>{ res.send(req.params) // {id:1} }) 静态资源处理 app.use(express.static('static')) 整合art-template // app.use(express.static('static')) // 当渲染后缀为art的模板时，使用express-art-template app.engine('art',require('express-art-template')) // 设置模板目录 app.set('views',path.join(__dirname,'views')) // 设置模板后缀 app.set('view engine','art') app.get('/',(req,res)=>{ // 渲染模板 res.render('index',{ content:'jntm' }) }) 模板公共数据 app.locals.common = { name: 'site' } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-08 05:49:13 "},"编程语言/JavaScript/模块化.html":{"url":"编程语言/JavaScript/模块化.html","title":"模块化","keywords":"","body":"模块化 规范 浏览器模块化 AMD CMD 服务端模块化 NODEjs ES6模块化 ES6模块化 安装babel npm install --save-dev @babel/core @babel/cli @babel/preset-env @babel/node npm install --save @babel/polyfill 导出 // export default 只能用一次 export { firstName, lastName, year }; export function multiply(x, y) { return x * y; }; 导入 import { stat, exists, readFile } from 'fs'; // 一些混用 import m1, {a as x,c} from './m1.js'; // 直接指向导入模块的代码 import './m2.js' MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-22 03:39:28 "},"编程语言/JavaScript/Jquery.html":{"url":"编程语言/JavaScript/Jquery.html","title":"jQuery","keywords":"","body":"jQuery j就是 JavaScript；Query 查询； 意思就是查询js，把js中的DOM操作做了封装 版本介绍 1x ：兼容 IE 678 等低版本浏览器， 官网不再更新 2x ：不兼容 IE 678 等低版本浏览器， 官网不再更新 3x ：不兼容 IE 678 等低版本浏览器， 是官方主要更新维护的版本 基本操作 入口函数 $(function () { .... }); 不同于原生 js 中的 load 事件是等页面文档、外部的 js 文件、css文件、图片加载完毕才执行内部代码 window.onload 和 $(function) 区别 window.onload 只能定义一次,如果定义多次，后边的会将前边的覆盖掉 $(function)可以定义多次的。 jQuery中的顶级对象$ $是 jQuery 的别称，在代码中可以使用 jQuery 代替 $是jQuery的顶级对象，相当于原生JavaScript中的 window 用原生 JS 获取来的对象就是 DOM 对象 jQuery 方法获取的元素就是 jQuery 对象。 jQuery 对象本质是： 利用$对DOM 对象包装后产生的对象（伪数组形式存储） jq对象 -- > dom对象 : jq对象[索引] 或者 jq对象.get(索引) var domObject1 = $('div')[0] var domObject2 = $('div').get(0) dom对象 -- > jq对象 : $(js对象) var jQueryObject = $(box); 事件绑定 $(\"div\").click(function () { alert(\"click\"); }); 选择器 类型 语法 作用 - 基础选择器 - 标签选择器（元素选择器） $(\"html标签名\") 获得所有匹配标签名称的元素 ID选择器 $(\"#id的属性值\") 获得与指定id属性值匹配的元素 类选择器 $(\".class的属性值\") 获得与指定的class属性值匹配的元素 并集选择器 $(\"选择器1,选择器2....\") 获取多个选择器选中的所有元素 交集选择器 $(\"li.current\") 交集元素 - 层级选择器 - 后代选择器 $(\"A B \") 选择A元素内部的所有B元素 子选择器 $(\"A > B\") 选择A元素内部的所有B子元素 - 属性选择器 - 属性名称选择器 $(\"A[属性名]\") 包含指定属性的选择器 属性选择器 $(\"A[属性名='值']\") 包含指定属性等于指定值的选择器 符合属性选择器 $(\"A[属性名='值'][]...\") 包含多个属性条件的选择器 - 筛选选择器 - 过滤选择器 :first 获得选择的元素中的第一个元素 尾选择器 :last 获得选择的元素中的最后一个元素 非元素选择器 :not(selector) 不包括指定内容的元素 偶数选择器 :even 偶数，从 0 开始计数 奇数选择器 :odd 奇数，从 0 开始计数 等于索引选择器 :eq(index) 指定索引元素 大于索引选择器 :gt(index) 大于指定索引元素 小于索引选择器 :lt(index) 小于指定索引元素 标题选择器 :header 获得标题（h1~h6）元素，固定写法 可用元素选择器 :enabled 获得可用元素 不可用元素选择器 :disabled 获得不可用元素 选中选择器 :checked 获得单选/复选框选中的元素 选中选择器 :selected 获得下拉框选中的元素 一些节点选择的辅助方法： 隐式迭代 $('div').hide(); // 页面中所有的div全部隐藏，不用循环操作 样式控制 修改简单元素样式 // 1.参数只写属性名，则是返回属性值 var strColor = $(this).css('color'); // 2. 参数是属性名，属性值，逗号分隔，是设置一组样式，属性必须加引号，值如果是数字可以不用跟单位和引号 $(this).css(\"color\", \"red\"); // 3. 参数可以是对象形式，方便设置多组样式。属性名和属性值用冒号隔开， 属性可以不用加引号 $(this).css({ \"color\":\"white\",\"font-size\":\"20px\"}); 设置类样式 原生 JS 中 className 会覆盖元素原先里面的类名，jQuery 里面类操作只是对指定类进行操作，不影响原先的类名 // 1.添加类 $(\"div\").addClass(\"current\"); // 2.删除类 $(\"div\").removeClass(\"current\"); // 3.切换类 $(\"div\").toggleClass(\"current\"); DOM操作 内容操作 html(): 获取/设置元素的标签体内容 内容 $(\"a\").html(); // 内容 text(): 获取/设置元素的标签体纯文本内容 内容 $(\"a\").text(); // 内容 val()： 获取/设置元素的value属性值 属性操作 attr(): 获取/设置元素的属性(只能操作自定义属性) var link = $(\"div\").prop('index'); // 获取自定义属性 $(\"div\").prop('index','xx'); // 设置自定义属性 removeAttr():删除属性，如果操作的是元素自定义的属性，则建议使用attr prop():获取/设置元素的属性（只能操作固有属性） var link = $(\"div\").prop('href'); // 获取属性 $(\"div\").prop('href','xx'); // 设置属性 removeProp():删除自定义属性 数据缓存 data()，可以在指定的元素上存取数据，并不会修改 DOM 元素结构 $(\"div\").data(\"key\",\"value\") //向元素添加数据 $(\"div\").data(\"key\") //获取添加的数据 节点操作 append():父元素将子元素追加到末尾 对象1.append(对象2): 将对象2添加到对象1元素内部，并且在末尾 prepend():父元素将子元素追加到开头 对象1.prepend(对象2):将对象2添加到对象1元素内部，并且在开头 after():添加在目标元素后面 before():添加在目标元素前面 appendTo(): 对象1.appendTo(对象2):将对象1添加到对象2内部，并且在末尾 prependTo(): 对象1.prependTo(对象2):将对象1添加到对象2内部，并且在开头 after():添加元素到元素后边 对象1.after(对象2)： 将对象2添加到对象1后边。对象1和对象2是兄弟关系 before():添加元素到元素前边 对象1.before(对象2)： 将对象2添加到对象1前边。对象1和对象2是兄弟关系 insertAfter() 对象1.insertAfter(对象2)：将对象2添加到对象1后边。对象1和对象2是兄弟关系 insertBefore() 对象1.insertBefore(对象2)： 将对象2添加到对象1前边。对象1和对象2是兄弟关系 remove():移除元素（自身） empty():清空元素的所有后代元素 动画 参数： speed：动画的速度。三个预定义的值(\"slow\",\"normal\", \"fast\")或表示动画时长的毫秒数值(如：1000) easing：用来指定切换效果，默认是\"swing\"，可用参数\"linear\" swing：动画执行时效果是 先慢，中间快，最后又慢 linear：动画执行时速度是匀速的 fn：在动画完成时执行的函数，每个元素执行一次。 显示隐藏 show([speed,[easing],[fn]]) 显示 hide([speed,[easing],[fn]]) 引擎 toggle([speed],[easing],[fn]) 切换 滑入滑出 slideDown([speed],[easing],[fn]) 下拉 slideUp([speed,[easing],[fn]]) 上拉 slideToggle([speed],[easing],[fn]) 切换 淡入淡出 fadeIn([speed],[easing],[fn]) fadeOut([speed],[easing],[fn]) fadeToggle([speed,[easing],[fn]]) fadeTo([speed],opacity,[easing],[fn]) 自定义动画 animate(params,[speed],[easing],[fn]) params代表要变化的css样式 $(\"div\").animate({height:200}) 动画排队 动画或者效果一旦触发就会执行，如果多次触发，就造成多个动画或者效果排队执行 stop() 写到动画或者效果的前面， 相当于停止结束上一次的动画 元素操作 遍历 jq对象.each(callback) $(\"div\").each(function (index,element) { console.table(index,element); }); 回调方法传入的element是dom元素 如果当前function返回为false，则结束循环(break)。 如果当前function返回为true，则结束本次循环，继续下次循环(continue) $.each(object, [callback]) $.each($(\"div\"),function (i, e) { console.table(i,e); }) for..of ES6语法 for (let i of $(\"div\")){ console.log(i); } 事件 事件绑定 标准绑定 jq对象.事件方法(回调函数)，如果调用事件方法，不传递回调函数，则会触发浏览器默认行为。 on绑定 jq对象.on(\"事件名称\",回调函数) 或者 jq对象.on({ 事件1:处理函数, 事件2:处理函数 }) // 事件触发一次后失效 jq对象.one('click',fn) 事件委托 $(\"div\").on(\"click\",\"p\",function(){ // 将子元素发生的事件委托给父元素，这样就可以实现给动态创建的元素创建点击事件 alert('p元素触发'); }) 事件解绑 // 解绑某个事件 jq对象.off(\"事件名称\") // 解绑所有事件 jq对象.off() // 解绑事件委托 jq对象.off('click','a') 事件触发 jq对象.trigger(\"click\") // 不会触发元素的默认行为（比如input focus之后会光标闪烁，使用这个方法光标就不会闪烁） jq对象.triggerHandler(\"click\") 事件对象 与DOM中的event基本一致 对象拷贝 $.extend([deep],target,sourceObject,[sourceObjectN]) 多库共存 // 让jquery 释放对$ 控制权 让用自己决定 var $x = jQuery.noConflict(); 尺寸和位置操作 尺寸 // width height 获取或者设置 $(\"div\").width(); // innerWidth innerHeight 包含padding $(\"div\").outerWidth(); // outerWidth outerHeight 包含padding、border,加上参数true就包含margin $(\"div\").outerWidth(); 位置 // 绝对定位的偏移 $(\"div\").offset() // 设置 $(\"div\").offset({ top:0, left:0 }) // 获取相对于父级定位盒子的偏移,只能获取不能设置 $(\"div\").position() // 设置或者获取被卷去的头部 $(\"div\").scrollTop() // 设置或者获取被卷去的左部 $(\"div\").scrollLeft() MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-25 05:52:00 "},"编程语言/JavaScript/Vue/nav.html":{"url":"编程语言/JavaScript/Vue/nav.html","title":"Vue","keywords":"","body":"VUE 两种视图模式 MVP 与MVC不同的是，MVP中的M与V没有直接交互 MVVM vue实例 每个 Vue 应用都是通过用 Vue 函数创建一个新的 Vue 实例开始的 var vm = new Vue({ // 选项 }) 根实例 └─ TodoList ├─ TodoItem │ ├─ DeleteTodoButton │ └─ EditTodoButton └─ TodoListFooter ├─ ClearTodosButton └─ TodoListStatistics 实例生命周期 vue-cli Vue脚手架可以快速生成Vue项目基础的架构 安装 npm install -g @vue/cli 创建项目 vue create project-name 工程结构 配置 // vue.config.js module.exports = { devServer:{ port:9001 } } 集成vue 单页面、多页面 vue.js 复杂单页面 vue-cli MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-22 08:15:09 "},"编程语言/JavaScript/Vue/数据渲染.html":{"url":"编程语言/JavaScript/Vue/数据渲染.html","title":"数据渲染","keywords":"","body":"数据渲染 插值表达式 {{ number + 1 }} {{ ok ? 'YES' : 'NO' }} ... ... 表单绑定 请选择职业... 教师 软件工程师 律师 修饰符 列表渲染 渲染list {{value}} and {{index}} 渲染对象 {{key}} : {{ value }} 条件渲染 v-if --> content v-else 0.5\"> Now you see me Now you don't v-else-if A B C Not A/B/C v-show --> content 样式绑定 绑定class home home 数组语法 data: { activeClass: 'active', errorClass: 'text-danger' } 渲染为 绑定style 拼接字符串 data: { activeColor: 'red', fontSize: 30 } 样式对象 data: { styleObject: { color: 'red', fontSize: '13px' } } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-19 01:38:36 "},"编程语言/JavaScript/Vue/属性操作.html":{"url":"编程语言/JavaScript/Vue/属性操作.html","title":"属性操作","keywords":"","body":"属性 计算属性 new Vue({ el:\"#app\", data:{ msg:\"123\", birthday:158536 } , computed:{ birth(){ return new Date(this.birthday); } } }); 与方法的区别 不同的是计算属性是基于它们的响应式依赖进行缓存的。只在相关响应式依赖发生改变时它们才会重新求值 getter与setter // ... computed: { fullName: { // getter get: function () { return this.firstName + ' ' + this.lastName }, // setter set: function (newValue) { var names = newValue.split(' ') this.firstName = names[0] this.lastName = names[names.length - 1] } } } // ... 侦听属性 var vm = new Vue({ el: '#demo', data: { firstName: 'Foo', lastName: 'Bar', fullName: 'Foo Bar' }, watch: { // 当firstName属性发生改变，该方法会被调用 firstName: function (val) { this.fullName = val + ' ' + this.lastName }, lastName: function (val) { this.fullName = this.firstName + ' ' + val } } }) 过滤器 定义过滤器 // 全局过滤器 Vue.filter('upper',function(v){ return v.toUpperCase(); }); 使用 {{msg | upper}} 传递参数 {{msg | f('a')}} Vue.filter('f',function(v,a){ return v + a; }); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-19 03:13:55 "},"编程语言/JavaScript/Vue/系统指令.html":{"url":"编程语言/JavaScript/Vue/系统指令.html","title":"系统指令","keywords":"","body":"指令 v-on事件绑定 v-on:click vue的onclick new Vue({ el:\"#app\", data:{ message:\"hello world\"//model }, methods:{ fun:function(msg){ //alert(msg); this.message = msg; } } }); v-on:keydown v-on:mouseover 这是一个文件域 @mouseover == v-on:mouseover 事件修饰符 ... ... 按键修饰符 .enter .tab .delete ( \"删除\" 和 \"退格\" ) .esc .space .up .down .left .right .ctrl .alt .shift .meta 自定义指令 // 定义一个全局指令 Vue.directive('focus',{ inserted:function(el){ el.focus(); } }) // 携带参数 Vue.directive('color',{ inserted:function(el,bingding){ // 这里的value是data里面的，而不是双引号里面的 el.style.backgroundColor = bingding.value; } }) 局部指令 var vm = new Vue({ el: '#app', //局部指令，需要定义在 directives 的选项 directives: { focus: { inserted: function(el) { el.focus(); } } } }); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-19 03:13:55 "},"编程语言/JavaScript/Vue/组件.html":{"url":"编程语言/JavaScript/Vue/组件.html","title":"组件","keywords":"","body":"组件 组件化 利用组件化开发，拆分功能，封装组件，单独维护 组件注册 // 定义一个名为 button-counter 的全局组件 Vue.component('button-counter', { data: function () { // data必须是一个函数，如果data是一个对象的话，那么所有button-counter都会共享同一份数据 return { count: 0 } }, template: 'You clicked me {{ count }} times.' }); new Vue({ el: '#app' }); 局部注册 new Vue({ el: '#app' , components:{ 'compomenta':{ template:` componenta ` } } }); 组件通信 父子组件通信 const introduce = { template:'{{msg}}', methods: { fun() { // 触发上一层事件,第一个参数是事件名称,第二个参数是传递给父组件的参数 this.$emit('delete',\"delete it\"); } }, props:['msg'] // 子组件需要声明要接收的参数 } new Vue({ el: '#app', data:{ msg:'大家好，我是渣渣辉' }, methods: { handleDelete(args) { console.log(args); } }, components:{ introduce } }); 兄弟组件通信 使用一个事件中心，这个事件中心可以监听事件、触发事件 var hub = new Vue(); // 注册事件 hub.$on('event', (val) => { this.num += val; }); // 触发事件 hub.$emit('event', 2); // 销毁事件 hub.$off('event'); 组件参数校验 //... props: { // 要求传递过来的msg必须是String类型 msg: String, id: [Number,String], // 可以是数字或者字符串类型 content: { type: String, required: false, // 非必传 defaultValue: 'cxk', // required必须为false这个值才会生效 validator: function(val) { // 自定义校验器 retrun val.length === 3; } } } 非props特性 父组件向子组件传递参数，但是子组件没在props声明接收，所以子组件就无法使用 非props特性的属性声明会在dom中显示 插槽 header footer no name 'child':{ template: ` default value ` } 动态组件 添加v-once来提高性能 组件事件 当定义子组件时，默认的原生事件监听@xxx不会生效，可以加上.native修饰符 组件使用中的细节 使用is='componentName'来解决html结构问题 子组件的data应该是一个函数，如果是对象的话，则所有的子组件的data都是共享的 可以通过ref来获取到子组件的引用 组件化带来的问题 组件状态管理(vuex) 多组件混合使用(vue-router) 组件间的合作(props,emit/on,bus) vue-router 引入vue组件 import Info from '../views/Info.vue'; 在router中添加 const routes = [ //... { path: '/info', name: 'info', component: Info, }, ]; 单文件组件 // js代码区域 export default { ... } /* 样式代码区域 */ 安装 npm install vue-loader vue-template-compiler vue -D 配置 const VueLoaderPlugin = require(\"vue-loader/lib/plugin\"); const vuePlugin = new VueLoaderPlugin(); module.exports = { .... plugins:[ ... new vueLoader() ], module : { rules:[ ... { test:/\\.vue$/, loader:\"vue-loader\" } ] } } 使用 import Vue from 'vue'; import App from './App.vue'; const vm = new Vue({ el:'#app', render:h=>h(App) }) MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-31 09:02:52 "},"编程语言/JavaScript/Vue/动画.html":{"url":"编程语言/JavaScript/Vue/动画.html","title":"动画","keywords":"","body":"动画 CSS动画过渡 hello .fade-enter { opacity: 0; } .fade-enter-active { transition: opacity 3s; } .fade-leave-to { opacity: 0; } .fade-leave-active { transition: opacity 3s; } 使用animate.css main.js引入 import animated from 'animate.css' // npm install animate.css --save安装，在引入 Vue.use(animated) transition使用 hello 动画钩子 当只用 JavaScript 过渡的时候，在 enter 和 leave 中必须使用 done 进行回调。否则，它们将被同步调用，过渡会立即完成 多个组件过渡 使用动态组件 列表过渡 {{ item }} 封装动画 Vue.component('my-special-transition', { template: '\\ \\ \\ \\ ', methods: { beforeEnter: function (el) { // ... }, afterEnter: function (el) { // ... } } }) MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"编程语言/JavaScript/Vue/前端路由.html":{"url":"编程语言/JavaScript/Vue/前端路由.html","title":"前端路由","keywords":"","body":"前端路由 根据不同的事件来显示不同的页面内容，即事件与事件处理函数之间的对应关系 前端路由是基于hash值的变化进行实现的 vue router 简单使用 user register // 两个组件 let user = { template: 'user' }; let register = { template: 'register' }; // 定义路由组件映射规则 let router = new VueRouter({ routes: [ { path: '/user', component: user }, { path: '/register', component: register } ] }) let vm = new Vue({ el: '#app', // 将路由挂载到vue实例 router }) 路由重定向 { path:\"/\",redirect:\"/user\"} 嵌套路由 let User = { template: ` user user add user delete ` }; let UserAdd = { template: `this is user add page` }; let UserDelete = { template: `this is user delete page` }; { path: '/user', component: User, children: [ { path: '/user/add', component: UserAdd }, { path: '/user/delete', component: UserDelete }, ] } 动态路由 register1 register2 { path: '/register/:id', component: register } 获取路径传递的参数 register id:{{$route.params.id}} 使用props获取路径参数 let register = { props:['id'], template: 'register id:{{id}}' }; // 如果props设置为true，route.params将会被设置为组件属性 { path: '/register/:id', component: register,props:true } // 可以将props设置为对象，那么就直接将对象的数据传递给组件进行使用 { path: '/register/:id', component: register,props:{name:'cxk',age:18} } // props设置为函数形式,该函数能访问router.params { path: \"/user/:id\", component: User,props:(route)=>{ return {username:\"jack\",pwd:123,id:route.params.id} } 命名路由 user { name:'user', path: '/user', ... } 编程式导航 声明式导航：通过点击链接的方式实现的导航 编程式导航：使用js控制导航跳转 this.$router.push('/register/1'); this.$router.go(-1); // 后退 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-21 10:50:23 "},"编程语言/JavaScript/Vue/Vuex.html":{"url":"编程语言/JavaScript/Vue/Vuex.html","title":"Vuex","keywords":"","body":"Vuex Vuex是实现组件全局状态（数据）管理的一种机制，可以方便的实现组件之间的数据共享 使用vuex来管理全局状态 访问共享数据 this.$store.state.count import { mapState } from 'vuex' export default { data () { return {} }, computed: { ...mapState(['count']) } } 更新共享数据 向store触发一个事件 import store from '@/store'; export default { name: 'info', store, methods: { add() { console.log('add'); store.commit('add'); }, }, }; vuex更新状态 //... export default new Vuex.Store({ state: { count: 0 }, mutations: { add() { this.state.count++; }, } // ... }); 传递参数 this.$store.commit('add', 1) mutations: { add (state, step) { state.count += step } } import { mapMutations } from 'vuex' export default { ... methods: { ...mapMutations(['sub']), handleClick () { this.sub() } } } 使用action异步更新数据 actions: { addAsync (context) { setTimeout(() => { // action不能直接修改共享数据 context.commit('add', 1) }, 1000) } } // 触发action this.$store.dispatch('addAsync') // action同Mutation一样，也可以通过map引入vue实例 about组件通过vuex来获取状态 import store from '@/store'; export default { name: 'about', store, data() { return { count: store.state.count }; }, }; getter getters: { showNum (state) { return 'current val:' + state.count } } {{$store.getters.showNum}} MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-31 09:02:52 "},"编程语言/JavaScript/ReactJS.html":{"url":"编程语言/JavaScript/ReactJS.html","title":"ReactJS","keywords":"","body":"前端开发的演变 静态页面-AJAX-前端MVC-SPA ReactJS ReactJS把复杂的页面，拆分成一个个的组件，将这些组件一个个的拼装起来，就会呈现多样的页面。ReactJS可以用于 MVC 架构，也可以用于 MVVM 架构，或者别的架构 JSX语法 JSX语法就是，可以在js文件中插入html片段，是React自创的一种语法 在JSX语法中，只能有一个根标签，不能有多个 const div1 = right; const div2 = errorerror; 函数调用 {f()} // f是函数名 组件 组件定义 import React from 'react'; class HelloWorld extends React.Component{ render() { // 重写渲染方法 return cxk：jntm } } export default HelloWorld; // 导出该类 使用自定义组件 import React from 'react'; import HelloWorld from \"./HelloWorld\"; class Show extends React.Component{ render() { return } } export default Show; 组件参数传递 // 属性传递 标签包裹传递 蔡徐坤 // 接收 {this.props.name}：{this.props.children} 组件状态 每一个组件都有一个状态，其保存在this.state中，当状态值发生变化时，React框架会自动调用render()方法，重新渲染页面 this.state值的设置要在构造参数中完成 要修改this.state的值，需要调用this.setState()完成，不能直接对其进行修改 class HelloWorld extends React.Component{ constructor(props, context) { super(props, context); this.state = { dataList : [1,2,3] }; } render() { // 重写渲染方法 return { this.state.dataList.map((value,index)=>{ return {value} }) } { let list = this.state.dataList; list.push(Math.random()); this.setState({dataList:list}) }}>click } } 生命周期 添加钩子方法 class HelloWorld extends React.Component{ // 组件挂载后调用 componentDidMount() { console.log(\"组件挂载后...\"); } // 省略其他 } 前端代码分层 Page 负责与用户直接打交道：渲染页面、接受用户的操作输入，侧重于展示型交互 性逻辑 Model 负责处理业务逻辑，为 Page 做数据、状态的读写、变换、暂存等 Service 负责与 HTTP 接口对接，进行纯粹的数据读写 使用DVA进行数据分层管理 添加models export default { namespace : 'list', state:{ data:[1,2,3] } } 使用数据 import React from 'react' import {connect} from 'dva' const namespace = 'list' const map = (state)=>{ const list = state[namespace].data; return { list } }; @connect(map) class List extends React.Component{ render() { return { this.props.list.map((v,i)=>{ return {v} }) } } } export default List; 修改数据 export default { namespace: 'list', state: { data: [1, 2, 3] } , reducers: { addNewData(state){ let list = [...state.data,Math.random()]; console.log(list); return { data:list } } } } // 省略导入 // 省略map1 const map1 = (dispatch)=>{ return { addNewData:()=>{ dispatch( { type:namespace+\"/addNewData\" } ) } } } @connect(map,map1) class List extends React.Component{ render() { return { this.props.list.map((v,i)=>{ return {v} }) } { this.props.addNewData() }}> 点击 } } export default List; MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"编程语言/python.html":{"url":"编程语言/python.html","title":"python","keywords":"","body":"Python 数据类型 整数型 浮点型 字符串 布尔型 None 数据结构 列表 # 列表中的元素可以是任意类型的 list = [1,'2',3.0] # 通过下标来获取/修改元素 list[0]='a' print(list[0]) # 通过len函数来获取列表长度 print(len(list)) # 通过list的append函数来添加元素 list.append('xx') # 查看元素在列表中的下标 print(list.index(3.0)) # 查看元素是否在列表中 print('2' in list) # 统计列表中某元素的数量 print(list.count(1)) # 向某位置插入元素,如果提供的下标超出列表的大小，会插在最后 list.insert(0,'x') # 添加一个列表 list.extend([5,5,5]) # 根据下标删除元素并返回 x = list.pop(0) # 直接删除指定下标位置的元素 del list[0] # 删除并返回最后一个元素 x = list.pop() # 直接删除元素 list.remove('2') # 反转列表 list.reverse() # 排序 list.sort() # 清空列表 list.clear() 元组 元组创建完成后，便不能向其中添加元素，也不能修改和删除其中的任何一个元素 # 空元祖 items = () # 一个元素的元组，需要在最后加一个(,)，如果括号中只有一个元素，那么 Python 会将这个括号当作优先级符号进行处理 items=(1,) # 多个元素的元组 items=(1,2,3) # 获取元素 print(items[2]) # 获取下标 print(items.index(2)) # 是否存在 print(2 in items) # 统计元素个数 print(items.count(1)) 字符串 字符串是字符的有序序列，所以也具有索引。也可以根据索引取出其中某一个字符 print('cxk'[2]) # 字符串是不可变的，所以不能通过下标修改 # 'cxk'[2]='b' # 同样可以用len获取长度 print(len('cxk')) str = 'java language' # 查找子串 print(str.find('ang')) # 判断子串 print('ava' in str) # 统计子串数 print(str.count('a')) # 是否以某子串开头 print(str.startswith('ja')) # 是否以某子串结尾 print(str.endswith('ge')) # 字符串替换 print(str.replace('java','python')) # 去除字符串前后空白字符 print(str.strip()) # 分割字符串，返回list print(str.split(' ')) # 拼接字符串 print(str.join(['so','good'])) # 转成大写形式 print(str.upper()) # 转成小写形式 print(str.lower()) 字符转义 常用的转义字符 含义 \\' 单引号 \\\" 双引号 \\\\ 反斜杠 \\n 换行符 \\t 制表符（Tab） \\r 回车 原始字符串 # 原始字符串，有啥就是啥 print(r'java \\t no.1') 多行字符串 # 多行字符串，输出的字符串不换行 print('java no.1\\ yes!\\ ') # 输出的字符串换行 print(\"\"\" java no.1 \"\"\") 列表、元组、字符串的通用操作 # 长度 print(len(str)) # 获取子序列 print(str[1:10]) # 拼接子序列 print(str + '?') # 重复序列中的元素 print(str*3) 字典 也就是map,显著优势是可以通过键快速地查询数据 # 创建空字典 map = {} # 创建有内容的字典 map = {'key1': 1, 'key2': 2} # 增加键值对/修改键所对应的值 map['key3'] = 3 # 通过键获取值,若键不存在则将抛出 KeyError 异常 print(map['key2']) # 通过方法来获取，不存在返回None print(map.get('key1')) # 不存在返回默认值0 print(map.get('keyx', 0)) # 是否包含某个键 print('x' in map) # 获取所有键，返回迭代器 print(map.keys()) # 获取所有值，返回迭代器 print(map.values()) # 获取键值对迭代器，每一对都是元组 print(map.items()) # 根据键删除,返回值，如果键不存在，则会抛出 KeyError 异常 map.pop('key1') # 键不存在返回默认值，不会抛异常 map.pop('key1', 'x') # 键不存在会抛异常 del map['key2'] # 随机弹出一个键值对 print(map.popitem()) # 用字典更新字典 map = {'key1': 'x'} map.update({'key1': 1}) 集合 其中的元素没有顺序关系。集合中的元素没有重复，重复的元素将被自动剔除最终只留下一个，集合也是用花括号（{}）来表示，不同于字典的是，花括号中放的是一个个数据，而不是键值对 # 创建空集合 s = set() # 创建集合 s = {1, 2, 3, 4, 5} # 添加元素 s.add(0) # 并集 s.update({7, 8, 9}) # 查看元素是否在集合中 print(0 in s) # 弹出一个元素 print(s.pop()) # 删除指定元素,如果要删除的元素不存在，则抛出 KeyError 异常 s.remove(1) # 删除，但不抛出异常 s.discard(1) # 求交集 print({1, 2, 3}.intersection({3, 4, 5})) print({1, 2, 3} & {3, 4, 5}) # 求并集 print({1, 2, 3}.union({3, 4, 5})) print({1, 2, 3} | {3, 4, 5}) # 求差集 print({1, 2, 3}.difference({3, 4, 5})) print({1, 2, 3} - {3, 4, 5}) # 是否为子集 print({1, 2}.issubset({1, 2, 3})) # 是否为超集 print({1, 2, 3}.issuperset({1, 2})) # 清空集合 s.clear() 数值运算 # 加法 print(33+725) # 减法 print(33-11) # 乘法 print(33*25) # 除法 print(33/22) # 取余 print(33 % 11) # 次方 print(33**2) # 整除 print(33//22) 比较运算 print(2>3) print(2==3) print(2 变量与赋值 a=5 函数 抽象 代码复用 函数定义 def sum(a,b): return a+b 副作用 函数包含一些会引起程序或系统状态变化的操作，如修改全局变量、命令行输入输出、读写文件等，这样的变化叫做函数的副作用 几个内置函数 # 获取终端的一个输入 str = input('input str') # 将str转为int类型 a = int(str) # 输出 print(a) python内置函数 数据类型相关 内置函数 功能 示例 示例结果 dict() 将参数转换为字典类型 dict(a=1, b=2, c=3) {'a': 1, 'b': 2, 'c': 3} float() 将字符串或数字转换为浮点型 float('0.22') 0.22 int() 将字符串或数字转换为整数型 int(1.23) 1 list() 将元组、字符串等可迭代对象转换为列表 list('abc') ['a', 'b', 'c'] tuple() 将列表、字符串等可迭代对象转换为元组 tuple([1, 2, 3]) (1, 2, 3) set() 1.创建空集合；2.将可迭代对象转换为列表集合 set('abc') {'b', 'a', 'c'} str() 将参数转换为字符串 str(3.14) '3.14' bytes() 将参数转换为字节序列 bytes(4) b'\\x00\\x00\\x00\\x00 数值计算相关 内置函数 功能 示例 示例结果 max() 求最大值 max([13, 2, 0.6, -51, 7]) 13 min() 求最小值 min([13, 2, 0.6, -51, 7]) -51 sum() 求和 sum([13, 2, 0.6, -51, 7]) -28.4 abs() 求绝对值 abs(-51) 51 pow() 求次方 pow(2, 10) 1024 bin() 转换为二进制 bin(77) '0b1001101' （注意结果为字符串） hex() 转换为十六进制 hex(77) '0x4d' （注意结果为字符串） round() 浮点数四舍五入 round(4.5678, 2) （第二个参数为小数精度） 4.57 bool 值判断相关 内置函数 功能 bool() 判断参数是否为真，为真则返回 True，否则返回 False。「为真」指的是，表达式的结果为布尔值 True，或非零数字，或非空字符串，或非空列表 all() 如果可迭代对象中的所有值，在逐一应用 bool(值) 后结果都为 True，则返回 True，否则返回 False any() 如果可迭代对象中的任意一个或多个值，在应用 bool(值) 后结果为 True，则返回 True，否则返回 False IO 相关 内置函数 功能 input() 从标准输入中读取字符串 print() 将内容写入标准输出中 open() 打开一个文件。之后便可以对文件做读写操作 元数据相关 内置函数 功能 type() 获取对象的类型 isinstance() 判断对象是否是某个类（或其子类）的对象 dir() 获取类或对象中的所有方法和属性；无参数时获取当前作用域下的所有名字 id() 返回一个对象的唯一标识。在我们所使用的 CPython 中这个唯一标识实际为该对象在内存中的地址 help # 得到有关int函数的相关信息 help(int) sorted # 排序 print(sorted([3,5,7,1])) range # 获取一个整数序列 print(range(100)) 函数进阶 参数默认值 # 如果省略a，则a的默认值为10 def f(a=10): print(a) 关键字参数 def f(x,y): print(x) print(y) # 这里通过指定参数名，可以颠倒参数的顺序 f(y=1,x=2) # 使用这种方式，kw能把接收到参数组合成一个map def f(**kw): print(kw) f(x=1,y=2,z=3) 任意参数列表 # 类似于java的可变参数 def f(*kw): print(kw) f(1,2,3) 多返回值 def f(): x=1 y=2 return x,y a,b=f() 逻辑关键字 and or not 分支语句 需要注意的是，python使用的缩进来代表c/java中的花括号 if a=18 and a 循环语句 while循环 while a>=0: print(a) a = a-1 for循环 list = [1,2,3] for i in list: print(i) 错误处理与异常机制 异常捕获 # 捕获所有异常 try: b=a/0 except: print('catch exception') # 捕获某个异常 try: b=a/0 except ZeroDivisionError as e: print('catch exception:',e) # 捕获多个异常 try: b=a/0 except (ZeroDivisionError,IndexError) as e: print('catch exception:',e) # 增加finally语句，finally语句无论是否发生异常都会执行 try: b=a/0 except: print('catch exception') finally: print(\"finally\") python常见的内置异常 异常名 含义 Exception 大多数异常的基类 SyntaxError 无效语法 NameError 名字（变量、函数、类等）不存在 ValueError 不合适的值 IndexError 索引超过范围 ImportError 模块不存在 IOError I/O 相关错误 TypeError 不合适的类型 AttributeError 属性不存在 KeyError 字典的键值不存在 ZeroDivisionError 除法中被除数为 0 抛出异常 try: raise ValueError(\"参数错误\") except ValueError as e: print('catch exception:',e) 面向对象 查看数据类型 print(type('')) 类的定义 class Person: pass # pass是占位符 实例化 p = Person() 属性 class Person: # 增加构造器参数,self，定义时必须有这个参数，但是调用时不必传递，等同于this def __init__(self,firstName,lastName): self.firstName = firstName self.lastName = lastName # 创建对象时传入参数 p = Person('c','xk') # 访问属性 print(p.firstName) 方法 class Person: # 省略... def say(self): print(self.firstName+self.lastName) # 调用方法 p.say() 进阶 类属性与类方法 class Person: # 定义一个类变量 people = '70亿' # 定义一个类方法 @classmethod def go(klass): print(str(klass)+'go') # 使用 print(Person.people) Person.go() 静态方法 class Person: ... # 定义一个静态方法，区别在于不用传入klass @staticmethod def go0(): print('static go') 私有属性 class Person: # 定义一个类私有属性 __people = '70' @classmethod def f(klass): print(Person.__people) def f1(self): # 私有成员变量 self.__age=15 return self.__age Person.f() p = Person() print(p.f1()) # 会抛异常 p.__age # 会抛出异常 print(Person._people) 特殊方法 头尾有双下划线的方法都是特殊方法 __init__()用于对象的初始化。在实例化类的过程中，被自动调用,就是构造器 __next__() 对迭代器调用 next() 函数，便能生成下一个值。这个过程的背后，next() 调用了迭代器的 __next__() 方法 __len__() 实现了 __len__() 方法，调用 len() 函数时将自动调用容器的__len__()方法 __str__() 在使用 print() 函数时将自动调用类的 __str__() 方法,toString() __getitem__() 'abc'[2] 即等同于 'abc'.__getitem__(2) 类继承 class Animal: def run(self): print('animal run') class Dog(Animal): def __init__(self): # 调用父类的构造器 super().__init__() # 覆写父类的方法 def run(self): print('dog run') def bark(self): print('wolf wolf') dog = Dog() dog.run() dog.bark() 多继承 class MachineDog: def kill(self): print('machine dog kill you') class Dog(Animal): ... class KillingMachineDog(Dog,MachineDog): pass superDog = KillingMachineDog() superDog.bark() superDog.kill() 模块和包 模块的导入 # 导入模块 import random # 使用模块 print(random.randint(1,9)) 包 包/ ├── __init__.py ├── 模块1.py ├── 模块2.py ├── 子包1/ ├── __init__.py ├── 模块3.py └── 模块4.py └── 子包2/ ├── __init__.py ├── 模块5.py └── 孙子包1/ ├── __init__.py └── 模块6.py 包的导入 import package.subpackage.module 迭代器 迭代指的是通过重复执行某个操作，不断获取被迭代对象中的数据。这样的每一次操作就是就是一次 迭代 迭代器可以提供迭代功能，当我们需要逐一获取数据集合中的数据时，使用迭代器可以达成这个目的 迭代器可以不保存数据，它的数据可以在需要时被计算出来（这一特性也叫做惰性计算） # 将容器包装成一个迭代器 iterator = iter([1,2,3,4]) # 不断迭代，直至迭代完抛出异常 while True: print(next(iterator)) python的for循环迭代就是通过使用迭代器完成的 对一个容器调用 iter() 函数，获取到该容器的迭代器 每次循环时对迭代器调用 next() 函数，以获取一个值 若捕获到 StopIteration 异常则结束循环 可迭代 定义了 __iter__() 方法的类对象就是可迭代的。当这个类对象被 iter() 函数使用时，将返回一个迭代器对象 自定义迭代器 class MyIterator: # 定义了这个方法就代表是可迭代的 def __iter__(self): self.count=0 return self # 实现可迭代对象的接口 def __next__(self): self.count = self.count+1 return self.count # 使用 i = MyIterator() for i in i: print(i) 生成器 yield 语句的作用和 return 语句有几分相似，都可以将结果返回。不同在于，生成器函数执行至 yield 语句，返回结果的同时记录下函数内的状态，下次执行这个生成器函数，将从上次退出的位置（yield 的下一句代码）继续执行 # 另外一种定义迭代器的方式 def f(): for i in range(10): yield i # 使用 i = f() for j in i: print(j) 生成器表达式 生成器 = (针对项的操作 for 项 in 可迭代对象) # 输出0-9每个数的平方 for i in (j**2 for j in range(10)): print(i) 也可以加上if语句 # 输出0-100中偶数的平方 for i in (j**2 for j in range(100) if j%2==0): print(i) 字典生成式 {键: 值 for 项 in 可迭代对象} # 生成0-10的键为i，值为i的平方的map map = {i:i**2 for i in range(10)} 集合生成式 # 生成0-10的集合 set = {i for i in range(10)} 函数式编程 def say(): print('say') # 函数可赋值给变量并调用 f = say f() 函数作为参数 def f(callback): callback('date') def f1(x): print(x) f(f1) lambda表达式 # 上面的函数调用也可以缩写成 f(lambda x: print(x)) 函数作为返回值 def f(): return lambda x,y: x+y print(f()(1,2)) map与filter # filter函数可对一个可迭代对象做过滤，符合过滤lambda的元素会被返回 l = filter(lambda x: x%2==0,[1,2,3,4,5]) print(list(l)) l = [1,2,3,4,5] # map函数则是对可迭代对象中的每个元素做处理，然后返回 ret = map(lambda x: x**2,l) print(list(ret)) 装饰器 自定义装饰器 def aop(fun): # 对fun进行包装，在其外层拦截参数 def wrapper(*args,**kw): print(\"aop拦截参数:\",args,kw) fun(*args,**kw) return wrapper class A: # 加上这一行等于 m = aop(m) @aop def m(self): print('method invoke') a = A() a.m() 一些语言特性 切片 l = [1,2,3,4,5] # 负数代表倒数第几个 print(l[-2]) # 起始索引跟结束索引默认不写就代表是第一个/最后一个 print(l[:]) # 代表从0到最后一个，步长为2取一个元素 print(l[0:-1:2]) 赋值 # 连续赋值 a = b = c = 1 # 拆包 x, y = 1, 2 # 拆包一次接收多个元素 x, *y = 1, 2, 3, 4 # 交换两个元素 x, y = y, x # or的使用 print('' or '1') # 结果为'1' 类似于js 控制语句 # 三元表达式 # 如果1=1,ret=1 否则ret=2 ret = 1 if 1==1 else 2 # for...else # 如果可迭代对象全部都被迭代了，就会执行else语句，否则不执行else语句，while...else同理 for i in range(5): print(i) else: print('all used') # try except else,没有发生异常时，else语句会被调用 try: pass except: print('发生异常') else: print('没有发生异常') 类 # 自定义异常 class BussinessException(Exception): pass 函数 # 参数类型标注 返回值类型标注 def f(name:str) -> str: return 'hello' IO 打开文件 f = open('test.py','r') # 指定编码 f = open('test.py','r',encoding='gbk') 读写模式 'r'：只读，若文件不存在则抛出 FileNotFoundError 异常 'rb': 以二进制的形式 'w'：只写，将覆盖所有原有内容，若文件不存在则创建文件 'a'：只写，以追加的形式写入内容，若文件不存在则创建文件 'r+'：可读可写，若文件不存在则抛出 FileNotFoundError 异常 'w+'：可读可写，若文件不存在则创建文件 'a+'：可读可写，写入时使用追加模式，若文件不存在则创建文件 文件写入 f = open('a.txt','w') f.write('a dog') 文件读取 f = open('test.py','r',encoding='utf8') # 读出全部内容 print(f.read()) # 读出文件行的列表 print(f.readlines()) 文件关闭 f.close() 文件系统操作 import os # 创建目录 os.mkdir('./test') # 枚举目录下的文件 for i in os.listdir('./'): print(i) # 删除目录 os.rmdir('./test') # 删除文件 os.remove('a.txt') # 重命名文件 os.rename('test.py','test1.py') 序列化 pickle(python独有) import pickle # 序列化成二进制 ret = pickle.dumps([1,2,3]) print(ret) # 反序列化 print(pickle.loads(ret)) json import json # 序列化成json str = json.dumps({'a':1,'b':2}) print(str) # 反序列化 print(json.loads(str)) 进程与线程 进程 import multiprocessing import os def f(): print('子进程') print('pid',os.getpid()) print('ppid',os.getppid()) # 只有主进程才创建子进程 if __name__ == '__main__': # 创建一个子进程 p = multiprocessing.Process(target=f) p.start() # 等待子线程运行完毕才会继续往下走 p.join() 线程 import threading def f(): print('sub thread') # 创建线程并启动 t = threading.Thread(target=f) t.start() # 等待子线程执行完毕才继续往下执行 t.join() print('main thread') 锁 import threading count = 0 # 创建一个锁 lock = threading.Lock() def add(): for i in range(2000000): global count # 获取锁 lock.acquire() count = count+1 # 释放锁 lock.release() print('执行完成：当前结果:',count) for i in range(10): threading.Thread(target=add).start() 安装第三方包 pip install requests --user python编码风格 变量和函数 「全小写+下划线」 max_capacity = 10 类名 「驼峰写法」 class CodeGenerator: pass 异常名 「驼峰写法」 ValueError 常量 「全大写+下划线」 MAX_VALUE=100 模块名和包名 模块可使用「小写 + 下划线」 open_api 包名仅使用小写字母命名 requests 缩进 每级缩进应使用 4 个空格 换行 每行代码的最大字符数为 79。若某一行代码过长，可以将其换行书写 定义函数和类时，多个函数或类之间使用两个空行进行分隔 导入 import 按下列类型和顺序使用： 标准库导入 第三方库导入 本地库导入 注释 注释以 # 及一个空格开始 行内注释和代码间至少要有两个空格分隔 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-29 04:47:26 "},"编程语言/go.html":{"url":"编程语言/go.html","title":"go","keywords":"","body":"go 静态类型、编译型 支持两种范式 特点 原生并发支持 概念 package 基本的分发单位、依赖关系的体现 每个源码文件都必须声明package 要生成可执行程序，必须要有main的package，并且还需要有main函数 同一个路径下只能存在一个package 源码文件 命令源码文件、库源码文件 测试源码文件 命令行工具 go build 编译 go run 编译并运行 go get获取远程代码包 语法 注释 // single row /* multi row */ 基础结构 package main // 程序所属包 import \"fmt\" // 导入依赖包 const NAME = \"cxk\" // 常量定义 type myInt int // 一般类型声明 // 结构体声明 type user struct { } // 接口声明 type UserService interface { } // 入口函数 func main(){ var a = \"cxk\" fmt.Println(a+NAME) } import 不能导入源码中没有使用的package // 另外一种语法 import ( \"fmt\" \"time\" ) 原理 如果一个main导入其他包,包将被顺序导入; 如果导入的包中依赖其它包(包B) ,会首先导入B包,然后初始化B包中常量和变量,最后如果B包中有init ,会自动执行init() ; 所有包导入完成后才会对main中常量和变量进行初始化,然后执行main中的init函数(如果存在) , 最后执行main函数; 如果一个包被导入多次则该包只会被导入一次; 别名 别名操作的含义是:将导入的包命名为另- -个容易记忆的别名; import pk \"awesomeProject/pkg1\" pk.F() 点(.)操作的含义是:点(.)标识的包导入后,调用该包中函数时可以省略前缀包名; import . \"awesomeProject/pkg1\" F() 下划线( )操作的含义是:导入该包,但不导入整个包,而是执行该包中的init函数,因此无法通过包名来调用包中的其他函数。使用下划线( ) 操作往往是为了注册包里的引擎,让外部可以方便地使用; import _ \"awesomeProject/pkg1\" 数据类型 数值类型,字符串类型和布尔型; 派生类型; var i uint32 = 2 fmt.Println(unsafe.Sizeof(i)) // 4 var i1 int = 2 fmt.Println(unsafe.Sizeof(i1)) // 8 var i2 float32 = 1.0 fmt.Println(unsafe.Sizeof(i2)) // 4 var i3 bool = true fmt.Println(unsafe.Sizeof(i3)) // 1 var i4 byte = 1 fmt.Println(unsafe.Sizeof(i4)) // 1 变量 变量的声明格式: var [变量类型] 变量的赋值格式: = 声明和赋值同时进行: var [变量类型]= 分组声明格式: var( i int j float32 name string ) 同一行声明多个变量和赋值 var a, b, c int = 1,2,3 // 或者 var a,b,c = 1,2,3 // 省略var a,b,c := 1,2,3 全局变量的声明必须使用var关键词，局部变量则可以省略 var a=1 func main(){ b:=2 fmt.Println(a,b) } 特殊变量下划线 ”_” var _ = 2 // 无法使用_ Go中不存在隐式转换,类型转换必须是显式的; var a =1 var b = float32(a) 类型转换只能发生在两种兼容类型之间; 大写字母开头的变量是可导出的,也就是其它包可以读取的,是公用变量; 小写字母开头的就是不可导出的,是私有变量。 // pkg1 func F1(){} func f1(){} // main func main(){ pkg1.F1() //pkg1.f1() 无法访问 } 常量 显式: const identifier [type] = value 隐式: const identifier = value ( 通常叫无类型常量) const name = \"cxk\" const age int = 18 const ( habbit1 = \"sing\" habbit2 = \"rap\" ) 常量可以使用内置表达式定义,例如: len()，unsafe.Sizeof()等 ; 常量范围目前只支持布尔型、数字型(整数型、浮点型和复数)和字符串型; 特殊常量iota iota在const关键字出现时将被重置为0 const中每新增一行常量 声明将使iota计数自增1次 const a = iota const b = iota const ( c = iota d = iota ) func main(){ fmt.Println(a,b) // 0 0 fmt.Println(c,d) // 0 1 } iota常见使用法: 1)跳值使用法; const ( c = iota _ = iota d = iota ) func main(){ fmt.Println(c,d) // 0 2 } 2)插队使用法; const ( c = iota d = 3 e = iota ) func main(){ fmt.Println(c,d,e) // 0 3 2 } 3 )表达式隐式使用法; const ( c = iota *2 d // 没有指定值，默认会继承之前的表达式 e ) func main(){ fmt.Println(c,d,e) // 0 2 4 } 4)单行使用法; const ( a ,b = iota,iota+3 c,d ) func main(){ fmt.Println(a,b,c,d) // 0 3 1 4 } 运算符 a := 1 b := 2 a++ // ++运算符只能这样用 println(a) b-- // --运算符只能这样用 println(b) 控制语句 条件控制 a := 0 if a>=1 { println(\"true\") }else if a 选择语句 a := 10 switch a { case 1: { println(\"1\") } case 2: { println(\"2\") } default: { println(\"default\") } } 循环语句 // 死循环 for { println(\"run\") time.Sleep(1*time.Second) } // 经典for循环 for i:=1;i goto if true { goto label2 }else { goto label1 } label1: println(\"label1\") label2: println(\"label2\") break a := []string{\"cxk\", \"jntm\"} for key, value := range a { println(key, value) if key == 0 { break } } 内建方法 make // slice类似于数组 slice := make([]string,3) slice[0] = \"cxk\" slice[1] = \"cxk2\" slice[2] = \"cxk3\" for k,v := range slice { println(k,v) } println(\"---\") // map aMap := make(map[string]string,3) aMap[\"a\"]=\"1\" aMap[\"b\"]=\"2\" for k,v := range aMap { println(k,v) } println(\"---\") // channel 类似缓冲区 aChan := make(chan int,3) close(aChan) new // 返回一个指针 aMap := new(map[string]string) fmt.Println(reflect.TypeOf(aMap)) // *map[string]string append & copy & delete slice :=make ([]string,2) slice[0]=\"1\" slice[1]=\"2\" slice = append(slice,\"3\") fmt.Println(slice) // 1 2 3 slice1 :=make ([]string,2) slice1[0]=\"1\" slice1[1]=\"2\" slice2 :=make([]string,2) copy(slice2,slice1) fmt.Println(slice2) // 1 2 aMap := make(map[string]string) aMap[\"1\"]=\"a\" aMap[\"2\"]=\"b\" delete(aMap,\"1\") fmt.Println(aMap) // 2:b 异常 func main() { defer func() { // 异常处理 msg := recover() fmt.Println(\"msg:\",msg) }() // 抛出异常 panic(\"异常\") } len && cap && close slice := make([]int,3,5) println(len(slice)) // 3 println(cap(slice)) // 5 aChan := make(chan int,1) aChan 结构体 // 定义结构体 type Person struct { Name string Age int } func main(){ var p Person // 声明结构体变量 p.Age = 18 // 结构体成员赋值 p1 := Person{Name: \"cxk\"} // 另外一种方式 p2 := new(Person) // 返回一个Person指针 p.Name = \"cxk\" fmt.Println(p) } 属性及函数 两种作用域，大写开头为公开，小写开头为私有 // 定义Person的一个公开成员方法 func (p *Person)Say(){ fmt.Println(\"person say\") } 组合 type Animal struct { Type string } type Dog struct { Animal // 组合animal，Dog继承Animal的属性 Name string } 接口 // 定义接口 type Service interface { GetUser() string } // 实现类 type UserService struct {} // 隐式实现接口方法 func (us *UserService)GetUser() string{ return \"user\" } func main(){ // 多态 var service Service = new(UserService) fmt.Println(service.GetUser()) } 并发 协程 func main(){ go run() go run() time.Sleep(time.Second*5) } func run(){ for i:=1;i 协程通讯 var chanInt = make(chan int,10) func main(){ go send() go receive() time.Sleep(5*time.Second) } func send(){ chanInt 使用select var chanInt = make(chan int,10) var chan1 = make(chan int,10) func send(){ for i:=0;i select可以随机在多个channel中取数据 同步 func main(){ makeFood(10) go eatFood(10) waitGroup.Wait() } var waitGroup sync.WaitGroup func makeFood(i int){ for j:=0;j 指针 i:=20 var pi *int=&i // pi指向i fmt.Println(*pi) // 读取pi所指向的内容 fmt.Println(pi == nil) // 判断是否为空 a,b :=1,2 pa := [...]*int{&a,&b} // 指针数组(元素为指针的数组) fmt.Println(pa) arr := [...]int{1,2,3} ap := &arr // 数组指针（指向一个数组的指针） fmt.Println(ap) json 序列化 setting := Setting{Menu:\"menu\",Count: 15} byte,err:=json.Marshal(setting) if err!=nil { fmt.Println(err) }else { fmt.Println(string(byte)) } tag type Setting struct { Menu string `json:\"menu\"` // 指定序列后的字段名字 Count int } 反序列化 str := \"{\\\"menu\\\":\\\"menu\\\",\\\"Count\\\":15}\\n\" var setting Setting err := json.Unmarshal([]byte(str),&setting) if err != nil { fmt.Println(err) }else { fmt.Println(setting) } module 初始化项目 go mod init 输出项目依赖 go mod graph MY all right reserved，powered by Gitbook该页面最后修改于： 2020-04-27 05:25:34 "},"编程语言/typescript.html":{"url":"编程语言/typescript.html","title":"typescript","keywords":"","body":"typescript ES新规范支持 IDE支持 类型 var myname: string = \"cxk\"; // 字符串 var alias: any = 1 // 可以是任何类型 var age: number = 13 // 数字类型 var gender: boolean = true // 布尔 function test(name: string): void { } // 函数参数以及函数返回值 // 自定义类型 class Person { name: string age: number } // 创建对象 var cxk = new Person() cxk.name = \"cxk\" cxk.age = 18 参数 默认值 function test(a: string = \"default\") { } 可选参数 // 调用函数test时，可不传递b function test(a: string,b?: string) { } 不定项参数 function test(...args) { } 函数 generator function* test() { console.log(\"start\"); yield; console.log(\"finish\"); } var f1 = test(); f1.next();//输出start f1.next(); // 输出 finish 解构 function test() { return { pname: 'cxk', age: 18 } } const {pname,age} = test() 箭头函数 for for of for (let n of arr) { // 可以用在数组、字符串、对象 } 面向对象 class Person { name; run() { } } const p1 = new Person() p1.name = \"cxk1\" const p2 = new Person() p2.name=\"cxk2\" 权限控制 private run() { } 泛型 const list: Array = [] list[0]=\"1\" // 只能存放string 接口 interface Runnable { run(); } class Thread implements Runnable { run () {} } 模块 暴露 export var prop1; export function data () { console.log('data') } export class Thread{ run():void{ console.log('run') } } 引入使用 import {data} from './module1' data() MY all right reserved，powered by Gitbook该页面最后修改于： 2020-04-28 05:48:42 "},"编程语言/HasKell.html":{"url":"编程语言/HasKell.html","title":"HasKell","keywords":"","body":"HashKell 编程环境 ghc是生成快速本底代码的优化编译器。 ghci是一个交互解析器和调试器。 runghc是一个以脚本形式(并不要首先编译)运行Haskell代码的程序 基本操作 登入解释器 ghci 算术运算 Prelude> 2+2 逻辑运算 Prelude> True && False 不等于 Prelude> 1/=2 True 变量定义 Prelude> let name = \"cxk\" Prelude> name \"cxk\" 列表 Prelude> [\"1\",\"2\"] [\"1\",\"2\"] 列表中的项必须是相同类型 列举 Prelude> [1..10] [1,2,3,4,5,6,7,8,9,10] 列表相加 Prelude> [1..5] ++ [6..10] [1,2,3,4,5,6,7,8,9,10] 增加元素到列表头 Prelude> 1 : [2..5] [1,2,3,4,5] 判断类型 Prelude> :type 'a' 'a' :: Char 第一个Haskell程序 main = putStrLn \"hello world\" runghc Helloworld.hs 类型系统 强类型 不会进行自动转换 静态 可以在编译期（而不是执行期）知道每个值和表达式的类型 自动推导 Haskell 编译器可以自动推断出程序中几乎所有表达式的类型 函数与类型不可分离 一些常用类型 Char 单个 Unicode 字符。 Bool 表示一个布尔逻辑值 Int 在 32 位机器里， Int 为 32 位宽，在 64 位机器里， Int 为 64 位宽 Integer 不限长度的带符号整数，在编写RSA加密，大数运算时很重要 Double 用于表示浮点数。长度由机器决定 元组 (1,\"cxk\") :type (18, \"cxk\") 定义类型 data Person = Person String Int -- 定义一个新类型，= 后面的Person是构造函数 let man = Person \"cxk\" 1 类型别名 type Age = Int 代数类型 data Name = String String | String let name = Name \"c\" \"xk\" let name1 = Name \"cxk\" 枚举 data Color = Red | Blue | Yellow :type Red -- Red :: Color 参数化类型 -- 定义一个带有泛型a参数的类型 data Optional a = Just a | Nothing 函数 使用函数 -- 调用compare函数 参数分别为1，2 compare 1 2 -- 嵌套调用 sqrt (sqrt 81) 函数类型 :type sqrt -- sqrt :: Floating a => a -> a 纯度 我们将带副作用的函数称为“不纯（impure）函数”，而将不带副作用的函数称为“纯（pure）函数”。 函数定义 add :: (Int, Int) -> Int add (x,y) = x+y 非柯里化函数：当函数有多个参数，必须通过元组一次性传入，染回返回结果 当函数有多个参数时，参数可以一个一个地依次输入，如果参数不足，将返回一个函数作为结果，这样的函数就是柯里化的函数。 分支 if age 惰性求值 isOdd (1+2) -- 1+2只有在真正需要时，才会被计算 多态 :type last -- last :: [a] -> a -- 输入一个列表，这个列表的元素类型为a，返回一个类型为a的元素 软件的大部分风险，都来自于与外部世界进行交互 模式匹配 -- Haskell 允许将函数定义为一系列等式 -- 执行函数时，会逐个进行匹配 myNot True = False myNot False = True MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-10 08:12:40 "},"编程语言/Ruby.html":{"url":"编程语言/Ruby.html","title":"Ruby","keywords":"","body":"Ruby 起步 使用irb进入交互式命令行 puts 'hello world' name = 'world' puts \"hello #{name}\" 编程模型 Ruby 是一门纯面向对象语言 puts 4.class # Integer puts 4.methods 判断 x = 6 if x > 5 # singleif puts 'great than 5' end unless x 除了nil和false之外 其他值都代表true puts 'hello' && true # true ruby的逻辑运算可以为and or 或者 && || puts true && false # false puts true and false # true 类型 Ruby是强类型语言 会对某些操作进行类型检查 Ruby是在运行时才检查 puts 4 + 'hello' 函数 def say_sth puts 'bark' end say_sth 数组 list = [1,2,3,4] puts list[0] puts list[-1] # desc order first puts list[0..-1] # 0-end list.push(5) puts list.pop list[10] = [1,2,3] 散列表 map = {1 => 'cxk', 2 => 'k'} puts map[1] map = {:string => 'string', :array => 'array'} # symbol 表示一种特殊对象 puts map[:string] puts map[:array] 代码块与yield 代码块就是一个匿名函数 3.times {puts 'hello world'} # 传给times一个代码块 3.times {|i| puts i} # 传给代码块一个参数i 使用yield实现： def f i = 0 while i 5 # 条件执行 end end condition_yeild {puts 'ddd'} 类 class Animal attr_accessor :name def initialize(name) @name = name end end dog = Animal.new('dog') puts dog.name method_mission方法 当调用的方法找不到 该方法会被调用 class Man def self.method_missing name, *args puts \"oh, no such method:${name}\" end end puts Man.go Mixin 通过混入模块的方式隐式实现一些功能 module Human def go puts 'gogogo' end end class Person include Human end p = Person.new p.go 集合的可枚举 可比较 list = [1,2,3,4,5] puts list.sort puts list.any? {|i| i> 6} puts list.all? {|i| i> 6} puts list.collect {|i| i * 2} # 对每一元素进行此操作 puts list.select {|i| i > 2} # 收集符合这个条件的元素 puts list.member?(2) # 存在一个2 puts list.inject {|sum,i| sum * i} # 求乘积 应用场景 脚本 web开发 不足 性能 并发与OOP 类型安全 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-28 12:11:52 "},"编程语言/Io.html":{"url":"编程语言/Io.html","title":"Io","keywords":"","body":"Io 优势：大量可定制语法和函数 强大的并发模型 起步 \"hello world\" print # 打印 Vehicle := Object clone # 复制现有对象创建新对象 Vehicle print Vehicle desc := \"a vehicle\" # 给一个槽赋值 Vehicle desc print # 输出槽 Vehicle slotNames print # 获取所有槽 原型与对象 Vehicle := Object clone car := Vehicle clone # Vehicle的实例 Bike := Vehicle clone # 创建一个继承于Vehicle的Bike car name := \"terrbyte\" car name print 方法 obj := Object clone obj say := method(\"go out\" println) # 定义一个方法 obj say obj proto print # 打印原型 list 和 map list := list(1,2,3) list average println list sum println list at(1) println list append(1) list pop println list isEmpty println map := Map clone map atPut(\"name\",\"cxk\") map at(\"name\") println true false true and false println false or true println 注意：0代表true 单例 true clone println // itself Vehicle := Object clone Vehicle clone := Vehicle # 创建自己的单例 (Vehicle clone == Vehicle clone) println 循环与条件 #loop(\"cxk\" println) # 死循环 i := 1; while(i 运算符 OperatorTable addOperator(\"xor\", 11) true xor := method(bool, if(bool, true, false)) # 定义xor结果为true的运算函数 false xor := method(bool, if(bool, false, true)) # 定义xor结果为false的运算函数 true xor false println 消息 反射 DSL 通过IO的运算符定义 可以实现DSL forward 类似于ruby中的method_missiing object := Object clone object forward := method(call message name println) object unknow 并发 协程 thread1 := Object clone thread2 := Object clone thread1 run := method( for(i,1,10, i println;yield) ) thread2 run := method( for(i,11,20, i println;yield) ) thread1 @@run; thread2 @@run Coroutine currentCoroutine pause actor future 核心优势 占用空间小 用在嵌入式领域 语法简单 十分灵活 可以通过改变各种槽来修改语言 并发 不足 语法简单导致的表达能力弱 社区不活跃 性能 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-08 11:49:45 "},"编程语言/Prolog.html":{"url":"编程语言/Prolog.html","title":"Prolog","keywords":"","body":"Prolog 事实 规则 查询 起步 likes(wallace, cheese). likes(grommit, cheese). likes(wendolene, sheep). friend(X,Y) : - \\+(X = Y), likes(X, Z), likes(Y, Z). 前面三行定义事实 最后一行定义规则 pl会通过根据规则并且扫描知识的方式得出yes或no的回答 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-10 09:02:54 "},"编程语言/Scala.html":{"url":"编程语言/Scala.html","title":"Scala","keywords":"","body":"Scala 类型 object Hello extends App { println(\"hello world\") println(1 + 1) println(5 + 3*4) println((5). + (3).*(4)) println(\"abc\".size) println(\"abc\" + 4) } 强类型语言 表达式与条件 object ExpressionAndCondition extends App { println(1 while 循环 var i = 1 while (i for 循环 for(i println(str)) // 函数式 范围 val r1 = 1 to 10 by 2 // 步长为2 val r2 = 1 to 10 // 步长为1 val r3 = 1 until 10 by 2 // 步长为2 不包括10 元组 val name = (\"c\", \"xk\") println(name._1 + name._2) val (x, y) = (1, 2) println(x+y) 类 class User(username: String, password: String) // pojo类 class UserService { val user = new User(\"cxk\", \"123\") def printUser(){ println(user) } } new UserService().printUser 构造器 class User(username: String){ def this(username: String, password: String){ this(username) println(password) } } 扩展类 单例 object singleton { // 单例对象 def print = println(\"he\") // 类方法 } singleton.print 继承 class Father(val name: String){ def say = println(\"i am f\") } class Son(override val name: String, val age: Int) extends Father(name){ override def say: Unit = { super.say println(\"i am s\") } } new Son(\"cx\",1).say trait trait Part { def say = println(\"i am say\") } class Person extends Object with Part{} new Person().say MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-11 09:50:10 "},"编程语言/JAVA/框架/Spring/spring概览.html":{"url":"编程语言/JAVA/框架/Spring/spring概览.html","title":"Spring","keywords":"","body":"Spring 概览 关键策略 基于POJO和最小侵入性编程 通过依赖和面向接口实现松耦合 基于切面和惯例进行声明式编程 通过切面和模板减少样板代码 简化JAVA开发 依赖注入 应用切面 各种模板 容纳你的Bean 常用上下文： AnnotationConfigApplicationContext AnnotationConfigWebApplicationContext ClassPathXmlApplicationContext FileSystemXmlApplicationContext XmlWebApplicationContext ApplicationContext立即加载 BeanFactory延迟加载 bean的生命周期 Spring 模块 Spring框架的核心 DI 和 AOP 解耦 反射 工厂模式解耦 控制反转-Inversion Of Control MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-11 00:55:56 "},"编程语言/JAVA/框架/Spring/装配Bean.html":{"url":"编程语言/JAVA/框架/Spring/装配Bean.html","title":"装配Bean","keywords":"","body":"Spring的配置方案 XML JAVA 自动装配 自动化装配 组件扫描 自动装配 @Component // 将当前类对象存入容器 public class Bean {...} 延伸 @Controller @Service @Repository 创建一个组件扫描配置： @ComponentScan(basePackages = \"wang.ismy.spring\") public class Config {} 获取context使用bean： AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(Config.class); context.getBean(Bean.class).say(); 自动注入 @Component public class Bean { private Bean1 bean1; @Autowired public Bean(Bean1 bean1) { this.bean1 = bean1; } public void say(){ System.out.println(\"hi\"); bean1.run(); } } JAVA代码装配 由于某些类来源于外部，我们无法修改其源码 所以可以使用java代码的方式创建后注入 @Configuration public class Config { @Bean // 默认值是方法名称 public wang.ismy.spring.Bean bean(Bean1 bean1){return new wang.ismy.spring.Bean(bean1);} @Bean public Bean1 bean1(){return new Bean1();} } 使用XML配置 由于spring早期大量使用xml来配置，所以这节的内容还是需要了解一下的。 不过对于新项目，还是推荐使用注解或者java配置 创建一个xml 创建一个bean 生命周期方法回调 属性注入 public class Bean1 { private String name; public void setName(String name){ this.name = name;} } 构造器注入 constructor-arg标签 index:指定参数在构造函数参数列表的索引位置 type:指定参数在构造函数中的数据类型 name:指定参数在构造函数中的名称 value:它能赋的值是基本数据类型和String类型 ref:它能赋的值是其他bean类型，也就是说，必须得是在配置文件中配置过的bean 集合注入 AAA BBB CCC AAA BBB CCC AAA BBB CCC a b 使用xml配置运行： ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:spring.xml\"); context.getBean(Bean1.class).run(); 导入配置 @ImportResource(\"classpath:spring.xml\") // 导入xml配置 @Import(Config.class) // 导入java代码配置 public class Config {} MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Spring/高级装配.html":{"url":"编程语言/JAVA/框架/Spring/高级装配.html","title":"高级装配","keywords":"","body":"高级装配 环境与profile 设置profile 在java代码中设置： @Configuration @Profile(\"pro\") public class Config1 { @Bean public Bean1 bean1(){ Bean1 bean1 = new Bean1(); bean1.setName(\"pro\"); return bean1; } } @Configuration @Profile(\"dev\") public class Config { @Bean public Bean1 bean1(){ Bean1 bean1 = new Bean1(); bean1.setName(\"dev\"); return bean1; } } 激活profile： System.setProperty(\"spring.profiles.active\",\"pro\"); AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(MasterConfig.class); context.getBean(Bean1.class).run(); 条件化装配 @Conditional注解 @Bean @Conditional(MyConditional.class) public Bean1 bean1(){ Bean1 bean1 = new Bean1(); bean1.setName(\"pro\"); return bean1; } 只要自定实现Condition接口，就可以控制bean的装配： public class MyConditional implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { return true; } } 处理自动装配歧义性 @Resource注解 使用该注解可以直接指定bean name，该注解非spring提供 标示首选bean @Primary注解 @Bean @Primary public Bean1 bean1(){ Bean1 bean1 = new Bean1(); bean1.setName(\"pro\"); return bean1; } 当有多个可选项时，将优先使用这个bean 限定自动装配的bean @Autowired @Qualifier(\"bean1f\") // 当有多个可选项时，将使用名为bean1f的bean public void setBean1(Bean1 bean1){} @Qualifier也可以用在方法参数上 bean的作用域 singleton：单例 prototype：每次获取都会创建实例 session：每个会话一个bean request：每个请求一个bean global session：应用在Portlet环境.如果没有Portlet环境那么globalSession相当于session 使用 @Component @Scope(\"prototype\") public class Bean { } 运行时值注入 @Configuration @ComponentScan(basePackages = \"wang.ismy.spring\") @PropertySource(\"classpath:config.properties\") public class Config { } config.properties name=my @Component public class Bean { @Value(\"${name}\") String name; } Spring EL表达式 使用 @Component public class Bean { @Value(\"#{T(System).currentTimeMillis()}\") long time; public void run(){ System.out.println(time); } } 生命周期方法 @Component public class Bean { //创建后执行 @PostConstruct public void init(){ System.out.println(\"init\"); } //销毁前执行 @PreDestroy public void destroy(){ System.out.println(\"destroy\"); } } 与junt整合 引入依赖 org.springframework spring-test 5.1.9.RELEASE test 创建测试 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = Config.class) public class BeanTest { @Autowired Bean bean; @org.junit.Test public void run() { bean.run(); } } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Spring/AOP.html":{"url":"编程语言/JAVA/框架/Spring/AOP.html","title":"AOP","keywords":"","body":"动态代理 基于接口 基于子类 public class Main { public static void main(String[] args) { Bean bean = (Bean) Enhancer.create(Bean.class, new MethodInterceptor() { private Bean bean = new Bean(); @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(method); return method.invoke(bean,objects); } }); bean.run(); } } class Bean{ public void run(){ System.out.println(\"bean run\"); } } AOP AOP简介 AOP术语 通知(Advice):所谓通知是指拦截到Joinpoint之后所要做的事情就是通知 前置通知（before）:执行前执行 后置通知（after）：执行后执行 返回通知（after returning） 异常通知（after throwing） 环绕通知（around） 使用xml时，后置通知与返回通知以及异常通知的执行顺序取决于配置顺序 连接点(Joinpoint):所谓连接点是指那些被拦截到的点。在spring中,这些点指的是方法,因为spring只支持方法类型的连接点。 切点(Pointcut):所谓切入点是指我们要对哪些Joinpoint进行拦截的定义。 切面(Aspect):是切入点和通知（引介）的结合。 引入(Introduction):引介是一种特殊的通知在不修改类代码的前提下, Introduction可以在运行期为类动态地添加一些方法或Field。 织入(Weaving):是指把增强应用到目标对象来创建新的代理对象的过程。 编写切点 AspectJ指示器 一个简单的切点实例 execution(* wang.ismy.spring.service.Service.doSth(..)) execution 创建切面 @Aspect @Component @Slf4j public class ErrorPageAspect { @Pointcut(\"@annotation(wang.ismy.zbq.annotations.ErrorPage)\") public void pointCut(){} @Around(\"pointCut()\") public Object around(ProceedingJoinPoint joinPoint){ try { return joinPoint.proceed(); } catch (Throwable throwable) { ModelAndView modelAndView = new ModelAndView(); modelAndView.setViewName(\"error\"); modelAndView.addObject(\"error\",throwable.getMessage()); return modelAndView; } } } 使用xml MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Spring/事务.html":{"url":"编程语言/JAVA/框架/Spring/事务.html","title":"事务","keywords":"","body":"事务 属性 read-only：是否是只读事务。默认false，不只读。 isolation：指定事务的隔离级别。默认值是使用数据库的默认隔离级别。 propagation：指定事务的传播行为。 timeout：指定超时时间。默认值为：-1。永不超时。 rollback-for：用于指定一个异常，当执行产生该异常时，事务回滚。产生其他异常，事务不回滚。没有默认值，任何异常都回滚。 no-rollback-for：用于指定一个异常，当产生该异常时，事务不回滚，产生其他异常时，事务回滚。没有默认值，任何异常都回滚。 传播行为 使用xml进行配置 声明式事务 声明式事务都是基于编程事务 public class Dao { private JdbcTemplate jdbcTemplate; public Dao(JdbcTemplate jdbcTemplate) { this.jdbcTemplate = jdbcTemplate; } public void transfer(){ String sql = \"UPDATE account SET money = money -200 WHERE uid = 41\"; String sql1 = \"UPDATE account SET money = money +200 WHERE uid = 45\"; jdbcTemplate.update(sql); jdbcTemplate.update(sql1); } } 注解配置 @Configuration @EnableTransactionManagement public class Config { @Bean public DataSource dataSource(){ DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setUsername(\"root\"); dataSource.setPassword(\"123\"); dataSource.setDriverClassName(\"com.mysql.cj.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql:///mybatis\"); return dataSource; } @Bean public JdbcTemplate jdbcTemplate(DataSource dataSource){ return new JdbcTemplate(dataSource); } @Bean public PlatformTransactionManager transactionManager(DataSource dataSource){ return new DataSourceTransactionManager(dataSource); } } @Service public class Dao { private JdbcTemplate jdbcTemplate; public Dao(JdbcTemplate jdbcTemplate) { this.jdbcTemplate = jdbcTemplate; } @Transactional(rollbackFor = Exception.class) public void transfer(){ String sql = \"UPDATE account SET money = money -200 WHERE uid = 41\"; String sql1 = \"UPDATE account SET money = money +200 WHERE uid = 45\"; jdbcTemplate.update(sql); jdbcTemplate.update(sql1); } } 编程式事务 @Bean public TransactionTemplate transactionTemplate(PlatformTransactionManager manager){ return new TransactionTemplate(manager); } @Service public class Dao { private JdbcTemplate jdbcTemplate; private TransactionTemplate transactionTemplate; public Dao(JdbcTemplate jdbcTemplate) { this.jdbcTemplate = jdbcTemplate; } public void transfer(){ transactionTemplate.execute((TransactionCallback) status -> { String sql = \"UPDATE account SET money = money -200 WHERE uid = 41\"; String sql1 = \"UPDATE account SET money = money +200 WHERE uid = 45\"; jdbcTemplate.update(sql); jdbcTemplate.update(sql1); return null; }); } @Autowired public void setTransactionTemplate(TransactionTemplate transactionTemplate) { this.transactionTemplate = transactionTemplate; } } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-11 01:13:57 "},"编程语言/JAVA/框架/Spring/源码解析.html":{"url":"编程语言/JAVA/框架/Spring/源码解析.html","title":"源码解析","keywords":"","body":"源码解析 整体架构 源码 BeanFactory：顶层接口 父子容器的关系 FactoryBean xxxPostProcessor 取地址符 获取bean工厂 Environment 存放环境配置或者配置文件配置 PropertySourcesPlaceholderConfigurer 用来进行xml配置信息注入 BeanFactoryPostProcessor 这个接口的实现类会被application context 探测到 ApplicationContext 核心接口 AbstractApplicationContext AutowireCapableBeanFactory ResourceLoader Lifecycle AbstractApplicationContext refresh AbstractRefreshableApplicationContext BeanDefinitionReader AbstractXmlApplicationContext DefaultSingletonBeanRegistry MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-17 11:33:14 "},"编程语言/JAVA/框架/Spring/SpringMVC/SpringMVC起步.html":{"url":"编程语言/JAVA/框架/Spring/SpringMVC/SpringMVC起步.html","title":"SpringMVC","keywords":"","body":"Spring MVC 请求处理流程 Step 1: 请求会被 DispatcherServlet 接收. Step 2: DispatcherServlet 根据 HandlerMapping 查找 Controller 类名与 相对应请求路径的映射. Step 3: 请求被转发到 Controller, controller会处理请求执行相对应的方法并返回ModelAndView object (包含 Model data 和视图名称)返回 DispatcherServlet. Step 4: DispatcherServlet发送model object给 ViewResolver 获取实际的页面. Step 5: 最终 DispatcherServlet 通过 Model object 渲染页面展示结果. DispatcherServlet：前端控制器 用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性。 HandlerMapping：处理器映射器 HandlerMapping负责根据用户请求找到Handler即处理器，SpringMVC提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 Handler：处理器 它就是我们开发中要编写的具体业务控制器。由DispatcherServlet把用户请求转发到Handler。由Handler对具体的用户请求进行处理。 View Resolver：视图解析器 View Resolver负责将处理结果生成View视图，View Resolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 View：视图 SpringMVC框架提供了很多的View视图类型的支持，包括：jstlView、freemarkerView、pdfView等。我们最常用的视图就是jsp。 一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。 配置SpringMVC 配置DispatcherServlet public class Initalizer extends AbstractAnnotationConfigDispatcherServletInitializer { @Override protected Class[] getRootConfigClasses() { return new Class[0]; } @Override protected Class[] getServletConfigClasses() { return new Class[]{MVCConfig.class}; } @Override protected String[] getServletMappings() { return new String[]{\"/\"}; } } // 启用web mvc 以及配置视图解析器 @Configuration @EnableWebMvc @ComponentScan(\"wang.ismy.spring\") public class MVCConfig extends WebMvcConfigurationSupport { @Bean public ViewResolver viewResolver() { InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(\"/WEB-INF/classes/views/\"); viewResolver.setSuffix(\".jsp\"); viewResolver.setViewClass(JstlView.class); return viewResolver; } @Override protected void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) { configurer.enable(); } } 使用以上代码可以使用java代码配置dispatcherServlet 原因：servlet3.0中，容器会在类路径查找实现了ServletContainerInitializer的类 Spring提供了该实现，叫做SpringServletContainerInitializer 此类会反过来查找WebApplicationInitializer的实现,而AbstractAnnotationConfigDispatcherServletInitializer就是它的一个实现 控制器编写 @org.springframework.stereotype.Controller public class Controller { @RequestMapping(\"/home\") public String hello(){ return \"home\"; } } @RequestMapping 可用在类上以及方法上 最终映射路径=类上的路径+方法上的路径 public @interface RequestMapping { // 控制器名称，一般不用 String name() default \"\"; // 同path @AliasFor(\"path\") String[] value() default {}; // 映射路径 @AliasFor(\"value\") String[] path() default {}; // 请求方法 RequestMethod[] method() default {}; // 限定请求参数条件 String[] params() default {}; // 限定请求头 String[] headers() default {}; String[] consumes() default {}; String[] produces() default {}; } 向视图传递数据 @RequestMapping(\"/home\") public String hello(ModelAndView modelAndView){ modelAndView.addObject(\"time\", LocalDate.now()); return \"home\"; } 接收请求的输入 @RequestParam @PathVariable 表单处理 接收数据 @PostMapping(\"/form\") public String form(Person person){ System.out.println(person); return \"home\"; } 绑定集合 ### 自定义类型转换器 ```java public class LocalDateConvert implements Converter { @Override public LocalDate convert(String source) { return LocalDate.parse(source); } } 表单校验 public class Person { @NotBlank private String username; @NotBlank private String password; } @PostMapping(\"/form\") public String form(@Valid Person person, Errors errors){ if (errors.hasErrors()){ throw new RuntimeException(errors.getAllErrors().get(0).getDefaultMessage()); } System.out.println(person); return \"home\"; } ` valid api: 获取servlet api @RequestMapping(\"/hello\") public String hello(HttpServletRequest request, HttpServletResponse response){ System.out.println(request+\"\"+response); return \"hello\"; } 注解 @RequestParam @RequestBody @PathVaribale @RequestHeader @CookieValue @ModelAttribute @SessionAttribute XML配置 配置前端控制器 dispatcher org.springframework.web.servlet.DispatcherServlet contextConfigLocation classpath:spring-mvc.xml dispatcher / spring配置文件 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-11 05:21:04 "},"编程语言/JAVA/框架/Spring/SpringMVC/渲染WEB视图.html":{"url":"编程语言/JAVA/框架/Spring/SpringMVC/渲染WEB视图.html","title":"渲染WEB视图","keywords":"","body":"视图解析 ViewResolver接口 public interface ViewResolver { View resolveViewName(String viewName, Locale locale) throws Exception; } View接口 public interface View { @Nullable default String getContentType() { return null; } void render(@Nullable Map model, HttpServletRequest request, HttpServletResponse response) throws Exception; } 视图解析器的工作原理很简单，外部会传给视图解析器一个视图名和地区对象， 解析根据两个参数返回一个视图。 视图做的工作就是根据外部传入的模型，来渲染出html页面。 Spring提供的视图解析器 创建JSP视图 配置视图解析器 @Bean public ViewResolver viewResolver() { InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(\"/WEB-INF/views/\"); viewResolver.setSuffix(\".jsp\"); viewResolver.setViewClass(JstlView.class); return viewResolver; } 访问home就相当于访问/WEB-INF/views/home.jsp 使用 Thymeleaf 三个与spring集成的bean 配置 thymeleaf @Bean public ViewResolver viewResolver() { ThymeleafViewResolver resolver = new ThymeleafViewResolver(); resolver.setTemplateEngine((ISpringTemplateEngine) templateEngine()); resolver.setCharacterEncoding(\"UTF-8\"); return resolver; } @Bean public TemplateEngine templateEngine() { SpringTemplateEngine engine = new SpringTemplateEngine(); engine.setEnableSpringELCompiler(true); engine.setTemplateResolver(templateResolver()); return engine; } private ITemplateResolver templateResolver() { SpringResourceTemplateResolver resolver = new SpringResourceTemplateResolver(); resolver.setApplicationContext(applicationContext); resolver.setPrefix(\"/WEB-INF/views/\"); resolver.setTemplateMode(TemplateMode.HTML); return resolver; } 使用thymeleaf 响应 返回String类型 返回字符串可以指定逻辑视图名，通过视图解析器解析为物理视图地址 return \"redirect:http://baidu.com\"; // 重定向(浏览器地址栏发生变化) return \"forward:/index.jsp\"; // 转发(地址栏不变化) 返回void类型 操作servlet api 返回ModelAndView类型 静态资源配置 响应json @ResponseBody MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Spring/SpringMVC/SpringMVC高级特性.html":{"url":"编程语言/JAVA/框架/Spring/SpringMVC/SpringMVC高级特性.html","title":"SpringMVC高级特性","keywords":"","body":"更多的配置 配置DispatcherServlet @Override protected void customizeRegistration(ServletRegistration.Dynamic registration) { registration.setMultipartConfig( new MultipartConfigElement(\"./\") ); } 配置Servlet与Filter @Override public void onStartup(ServletContext servletContext) throws ServletException { super.onStartup(servletContext); var a=servletContext.addServlet(\"my-servlet\",MyServlet.class); a.addMapping(\"/my\"); var b= servletContext.addFilter(\"my-fliter\",MyFliter.class); b.addMappingForUrlPatterns(null,false,\"/*\"); } 处理multipart 数据 必要前提 form表单的enctype取值必须是：multipart/form-data method属性取值必须是Post 提供一个文件选择域 使用 配置multipart解析器 StandardServletMultipartResolver CommonsMultipartResolver @Bean public MultipartResolver multipartResolver(){ return new StandardServletMultipartResolver(); } 处理multipart 请求 @RequestMapping(\"/upload\") @ResponseBody public String upload(@RequestPart(\"file\")MultipartFile file) throws IOException { FileUtils.writeByteArrayToFile(new File(\"d:/\"+file.getOriginalFilename()),file.getBytes()); return \"上传完成\"; } 处理异常 自定义异常 @ResponseStatus(value = HttpStatus.NOT_FOUND,reason = \"未找到\") public class MyException extends RuntimeException{ } @RequestMapping(\"/home\") public String hello(Model model){ model.addAttribute(\"time\", LocalDate.now()); if (true) throw new MyException(); return \"home.html\"; } 定义异常处理 public class MyExceptionHandler implements HandlerExceptionResolver { @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { try { response.getWriter().println(ex.getMessage()); } catch (IOException e) { e.printStackTrace(); } return null; } } 异常处理器@ExceptionHandler(Exception.class) @ResponseBody public Object handler(Exception e){ return e.getMessage(); } 控制器通知 本质：对Controller进行AOP // 所有的controller发生异常都会通过这个类进行处理 @ControllerAdvice public class MyControllerAdvice { @ExceptionHandler(Exception.class) @ResponseBody public Object handler(Exception e){ return e.getMessage(); } } 请求重定向转发数据 forward(服务器转发)与redirect(客户端重定向) 重定向传递数据的方法 url传递 flash属性传递 拦截器 public class MyInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { System.out.println(\"进入controller前执行\"); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { System.out.println(\"完成controller方法后执行\"); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { System.out.println(\"请求完成执行\"); } } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Spring/SpringData/概览.html":{"url":"编程语言/JAVA/框架/Spring/SpringData/概览.html","title":"SpringData","keywords":"","body":"Spring Data Spring的数据访问哲学 Spring的数据访问异常体系 SQLException 提供了挺多的异常 数据访问模板化 配置数据源 使用JNDI 使用数据源连接池 @Bean public DataSource dataSource(){ DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(\"com.mysql.cj.jdbc.Driver\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"Root@@715711877\"); dataSource.setUrl(\"jdbc:mysql:///manage\"); return dataSource; } 使用嵌入式数据源 使用profile选择数 @Profile(\"product\") @Bean public DataSource dataSource(){ DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(\"jdbc:h2:~/test\"); return dataSource; } @Profile(\"dev\") @Bean public DataSource dataSourceDev(){ DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(\"com.mysql.cj.jdbc.Driver\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"Root@@715711877\"); dataSource.setUrl(\"jdbc:mysql:///manage\"); return dataSource; } 在Spring 当中使用JDBC JDBC模板 JdbcDaoSupport update():执行DML语句。增、删、改语句 queryForMap():查询结果将结果集封装为map集合，将列名作为key，将值作为value 将这条记录封装为一个map集合 注意：这个方法查询的结果集长度只能是1 queryForList():查询结果将结果集封装为list集合 注意：将每一条记录封装为一个Map集合，再将Map集合装载到List集合中 query():查询结果，将结果封装为JavaBean对象 query的参数：RowMapper 一般我们使用BeanPropertyRowMapper实现类。可以完成数据到JavaBean的自动封装 new BeanPropertyRowMapper(类型.class) queryForObject：查询结果，将结果封装为对象 一般用于聚合函数的查询 配置模板 @Bean public JdbcTemplate jdbcTemplate(){ JdbcTemplate jdbcTemplate = new JdbcTemplate(); jdbcTemplate.setDataSource(dataSourceDev()); return jdbcTemplate; } 执行操作 @org.springframework.stereotype.Service public class Service { @Autowired private JdbcTemplate jdbcTemplate; public void insert(Admin admin){ jdbcTemplate.update(\"INSERT INTO admin(username,password) VALUES(?,?)\", admin.getUsername(), admin.getPassword()); } } 使用Lambda表达式 jdbcTemplate.query(\"select * from admin\",r->{ do{ System.out.println( r.getString(\"username\")+\"||\"+r.getString(\"password\") ); }while (r.next()); }); 使用命名参数 public void insert(Admin admin){ jdbcTemplate.update(\"INSERT INTO admin(username,password) VALUES(:username,:password)\", Map.of(\"username\",admin.getUsername(), \"password\",admin.getPassword())); } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-11 01:20:46 "},"编程语言/JAVA/框架/Spring/SpringData/ORM.html":{"url":"编程语言/JAVA/框架/Spring/SpringData/ORM.html","title":"ORM","keywords":"","body":" ORM（Object-Relational Mapping） 表示对象关系映射。在面向对象的软件开发中，通过ORM，就可以把对象映射到关系型数据库中。只要有一套程序能够做到建立对象与数据库的关联，操作对象就可以直接操作数据库数据，就可以说这套程序实现了ORM对象关系映射 JPA 需要的一些复杂特性 延迟加载 预先抓取 级联 集成 Hibernate Spring与JAVA持久化API 配置实体管理器工厂 @Configuration @ComponentScan(\"wang.ismy.spring\") @EnableJpaRepositories(basePackages = \"wang.ismy.spring\",entityManagerFactoryRef = \"entityManagerFactoryBean\") public class Config { @Bean public DataSource dataSourceDev(){ DruidDataSource dataSource = new DruidDataSource(); dataSource.setDriverClassName(\"com.mysql.cj.jdbc.Driver\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"Root@@715711877\"); dataSource.setUrl(\"jdbc:mysql:///manage\"); return dataSource; } @Bean public LocalContainerEntityManagerFactoryBean entityManagerFactoryBean(DataSource dataSource, JpaVendorAdapter adapter){ LocalContainerEntityManagerFactoryBean bean = new LocalContainerEntityManagerFactoryBean(); bean.setDataSource(dataSource); bean.setJpaVendorAdapter(adapter); bean.setPackagesToScan(\"wang.ismy.spring\"); return bean; } @Bean public JpaVendorAdapter jpaVendorAdapter(){ HibernateJpaVendorAdapter adapter = new HibernateJpaVendorAdapter(); adapter.setDatabase(Database.MYSQL); adapter.setGenerateDdl(false); adapter.setDatabasePlatform(\"org.hibernate.dialect.MySQL5InnoDBDialect\"); return adapter; } @Bean(name = \"transactionManager\") public PlatformTransactionManager transactionManager(EntityManagerFactory bean, DataSource dataSource) { JpaTransactionManager tm = new JpaTransactionManager(); tm.setEntityManagerFactory(bean); tm.setDataSource(dataSource); return tm; } } 从JNDI中获取实体管理器工厂 编写基于JPA的Repository 实体类 @Data @Entity @Table(name = \"admin\") public class Admin { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; private String username; private String password; } Repository类 public interface AdminRepository extends JpaRepository { } 使用 adminRepository.findAll(); 自定义查询方法 public interface AdminRepository extends JpaRepository { Admin findbyUsername(String username); } 一些关键词 Keyword Sample JPQL And findByLastnameAndFirstname ... where x.lastname = ?1 and x.firstname = ?2 Or findByLastnameOrFirstname ... where x.lastname = ?1 or x.firstname = ?2 Is,Equals findByFirstnameIs,findByFirstnameEquals ... where x.firstname = ?1 Between findByStartDateBetween ... where x.startDate between ?1 and ?2 LessThan findByAgeLessThan ... where x.age LessThanEqual findByAgeLessThanEqual ... where x.age ⇐ ?1 GreaterThan findByAgeGreaterThan ... where x.age > ?1 GreaterThanEqual findByAgeGreaterThanEqual ... where x.age >= ?1 After findByStartDateAfter ... where x.startDate > ?1 Before findByStartDateBefore ... where x.startDate IsNull findByAgeIsNull ... where x.age is null IsNotNull,NotNull findByAge(Is)NotNull ... where x.age not null Like findByFirstnameLike ... where x.firstname like ?1 NotLike findByFirstnameNotLike ... where x.firstname not like ?1 StartingWith findByFirstnameStartingWith ... where x.firstname like ?1 (parameter bound with appended %) EndingWith findByFirstnameEndingWith ... where x.firstname like ?1 (parameter bound with prepended %) Containing findByFirstnameContaining ... where x.firstname like ?1 (parameter bound wrapped in %) OrderBy findByAgeOrderByLastnameDesc ... where x.age = ?1 order by x.lastname desc Not findByLastnameNot ... where x.lastname <> ?1 In findByAgeIn(Collection ages) ... where x.age in ?1 NotIn findByAgeNotIn(Collection age) ... where x.age not in ?1 TRUE findByActiveTrue() ... where x.active = true FALSE findByActiveFalse() ... where x.active = false IgnoreCase findByFirstnameIgnoreCase ... where UPPER(x.firstame) = UPPER(?1) 使用SQL @Query(value = \"SELECT * FROM admin WHERE username = 'admin'\",nativeQuery = true) Admin selfCondition(); 使用JPQL @Query(\"FROM Customer WHERE custName = ?1\") List findByJPQL(String name); // 更新操作 @Query(\"UPDATE Customer SET custName = ?2 WHERE custId = ?1\") @Modifying int update(Long id,String name); 动态查询 JpaSpecificationExecutor Specification 示例 Specification spec = (Specification) (root/*比较的属性*/, query, cb/*查询方式*/) -> { Path custName = root.get(\"custName\"); return cb.equal(custName,\"老王八\"); }; Optional one = repository.findOne(spec); System.out.println(one.get()); 条件拼接 Specification spec = (Specification) (root/*比较的属性*/, query, cb/*查询方式*/) -> { Path custName = root.get(\"custName\"); Path custIndustry = root.get(\"custIndustry\"); var p1 = cb.equal(custName,\"老王八\"); var p2 = cb.equal(custIndustry,\"隔壁\"); return cb.and(p1,p2); }; 模糊查询 Specification spec = (Specification) (root/*比较的属性*/, query, cb/*查询方式*/) -> { Path custName = root.get(\"custName\"); return cb.like(custName.as(String.class),\"%老%\"); }; repository.findAll(spec).forEach(System.out::println); 排序 repository.findAll(spec, new Sort(Sort.Direction.DESC,\"custId\")).forEach(System.out::println); 分页 repository.findAll(PageRequest.of(0,3)).forEach(System.out::println); Page接口 public interface Page extends Slice { static Page empty() { return empty(Pageable.unpaged()); } static Page empty(Pageable pageable) { return new PageImpl<>(Collections.emptyList(), pageable, 0); } int getTotalPages(); long getTotalElements(); Page map(Function converter); } 多表操作 一对多 主表 @OneToMany(targetEntity = LinkMan.class) @JoinColumn(name = \"lkm_cust_id\",referencedColumnName = \"cust_id\") private Set linkMan = new HashSet<>(0); 从表 @ManyToOne(targetEntity = Customer.class) @JoinColumn(name = \"lkm_cust_id\",referencedColumnName = \"cust_id\") private Customer customer; 操作 Customer customer = new Customer(); customer.setCustName(\"20190908\"); LinkMan man = new LinkMan(); man.setLkmName(\"小婊砸\"); man.setCustomer(customer); customerRepository.save(customer); linkManRepository.save(man); 放弃外键维护 @OneToMany(mappedBy = \"customer\") 级联添加 @OneToMany(mappedBy = \"customer\",cascade = CascadeType.ALL) Customer customer = new Customer(); customer.setCustName(\"20190908\"); LinkMan man = new LinkMan(); man.setLkmName(\"小婊砸\"); man.setCustomer(customer); customer.getLinkMans().add(man); customerRepository.save(customer); 级联删除 Optional cus = customerRepository.findById(1L); customerRepository.delete(cus.get()); 多对多 @ManyToMany(targetEntity = Role.class) @JoinTable(name = \"user_role\",joinColumns = {@JoinColumn(name = \"user_id\",referencedColumnName = \"user_id\")}, inverseJoinColumns = {@JoinColumn(name = \"role_id\",referencedColumnName = \"role_id\")}) private Set roleSet = new HashSet<>(); @ManyToMany(targetEntity = User.class) @JoinTable(name = \"user_role\",joinColumns ={@JoinColumn(name = \"role_id\",referencedColumnName = \"role_id\")}, inverseJoinColumns = {@JoinColumn(name = \"user_id\",referencedColumnName = \"user_id\")}) private Set userSet = new HashSet<>(); User user = new User(); user.setUsername(\"老王\"); Role role = new Role(); role.setRoleName(\"隔壁\"); user.getRoleSet().add(role); userDao.save(user); roleDao.save(role); 级联 对象导航 public enum FetchType { LAZY,EAGER } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Spring/SpringData/缓存数据.html":{"url":"编程语言/JAVA/框架/Spring/SpringData/缓存数据.html","title":"缓存数据","keywords":"","body":"启用缓存支持 @Configuration @ComponentScan(\"wang.ismy.spring\") @EnableCaching public class Config { @Bean public CacheManager cacheManager(){ return new ConcurrentMapCacheManager(); } } Spring 提供的几个缓存管理器 让方法支持缓存 @Cacheable(value = \"find\",key = \"#id\") public String find(Integer id){ System.out.println(\"real find\"); return \"hello world\"+id; } 将值放到缓存当中 /** * 该方法肯定会被执行，但是返回结果会放到缓存当中 */ @CachePut(value = \"find\",key = \"#id\") public String put(Integer id){ return \"new\"+id; } 条件化缓存 unless : 阻止将对象放入缓存，但是还会进行缓存查找 condition : 不会进行缓存查找，也不会将结果放入缓存 在id等于10时不会进行缓存 @Cacheable(value = \"find\",key = \"#id\",condition = \"#id != 10\") public String find(Integer id){ System.out.println(\"real find\"); return \"hello world\"+id; } 移除缓存 @CacheEvict(value = \"find\",key = \"#id\") public void remove(Integer id){ } 使用xml添加缓存 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Spring/SpringData/elasticsearch.html":{"url":"编程语言/JAVA/框架/Spring/SpringData/elasticsearch.html","title":"Elasticsearch","keywords":"","body":"配置 @Document(indexName = \"index1\",type = \"article\") @Data public class Article { @Id @Field(type = FieldType.Long,store = true) private long id; @Field(type = FieldType.Text,store = true) private String title; @Field(type = FieldType.Text,store = true) private String content; } @Repository public interface ArticleDao extends ElasticsearchRepository { } 创建索引 ElasticsearchTemplate template = context.getBean(ElasticsearchTemplate.class); template.createIndex(Article.class); 添加文档 Article article = new Article(); article.setId(1L); article.setTitle(\"【中国稳健前行】“中国之治”的政治保证\"); article.setContent(\"新中国成立70年来，在中国共产党的坚强领导下，...\"); articleDao.save(article); 删除文档 articleDao.deleteById(1L); articleDao.deleteAll(); // 全部删除 修改文档 同添加文档 查询 查询全部 articleDao.findAll().forEach(System.out::println); 根据ID System.out.println(articleDao.findById(2L).get()); 自定义查询 @Repository public interface ArticleDao extends ElasticsearchRepository { List findAllByTitle(String title); } 分页查询 List findAllByTitle(String title, Pageable pageable); articleDao.findAllByTitle(\"中\", PageRequest.of(0,5)).forEach(System.out::println); 原生查询 NativeSearchQuery query = new NativeSearchQueryBuilder() .withQuery(QueryBuilders.queryStringQuery(\"中国\").defaultField(\"title\")) .withPageable(PageRequest.of(0,5)) .build(); template.queryForList(query,Article.class).forEach(System.out::println); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Spring/SpringSecurity/springSecurity.html":{"url":"编程语言/JAVA/框架/Spring/SpringSecurity/springSecurity.html","title":"SpringSecurity","keywords":"","body":"SpringSecurity Spring Security是一个能够为基于Spring的企业应用系统提供声明式的安全访问控制解决方案的安全框架 组成模块 配置 添加spring security 拦截链 @Override public void onStartup(ServletContext servletContext) throws ServletException { var a= servletContext.addFilter(\"springSecurityFilterChain\", DelegatingFilterProxy.class); a.addMappingForUrlPatterns(null,false,\"/*\"); } 创建相关安全性配置 @Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .anyRequest().authenticated() .and() .formLogin().and().httpBasic(); } } 添加用户 基于内存 @Override @Bean public UserDetailsService userDetailsService() { User.UserBuilder users = User.builder(); InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); manager.createUser(users.username(\"user\") .password(new BCryptPasswordEncoder().encode(\"123\")).roles(\"USER\") .authorities(\"play\") .build() ); manager.createUser(users.username(\"admin\").password(new BCryptPasswordEncoder().encode(\"123\")).roles(\"USER\", \"ADMIN\").build()); return manager; } 基于数据库 基于LDAP 限制访问 @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(\"/\").hasAnyAuthority(\"play\") .and() .httpBasic(); } 自定义错误页面 @Configuration public class WebServerAutoConfiguration { @Bean public ConfigurableServletWebServerFactory configurableServletWebServerFactory(){ TomcatServletWebServerFactory factory = new TomcatServletWebServerFactory(); factory.addErrorPages(new ErrorPage(HttpStatus.FORBIDDEN,\"/error/403\")); return factory; } } 自定义登录页面 .formLogin().loginPage(\"/login\").and().csrf().disable(); 自定义认证成功失败处理 AuthenticationFailureHandler 认证失败接口 AuthenticationSuccessHandler 认证成功接口 添加自定义用户服务 实现该接口 public interface UserDetailsService { UserDetails loadUserByUsername(String username) throws UsernameNotFoundException; } UserDetails需要实现的内容 public interface UserDetails extends Serializable { Collection getAuthorities(); String getPassword(); String getUsername(); boolean isAccountNonExpired(); boolean isAccountNonLocked(); boolean isCredentialsNonExpired(); boolean isEnabled(); } 自定义拦截请求 @Override protected void configure(HttpSecurity http) throws Exception { System.out.println(\"auth pro run\"); http .authorizeRequests() .antMatchers(\"/home\").hasRole(\"ADMIN\").and().formLogin().and() .authorizeRequests() .anyRequest().permitAll(); } 使用Spring表达式 @Override protected void configure(HttpSecurity http) throws Exception { System.out.println(\"auth pro run\"); http .authorizeRequests() .antMatchers(\"/home\").access(\"hasRole('ADMIN') and hasIpAddress('::1')\").and().formLogin().and() .authorizeRequests() .anyRequest().permitAll(); } 强制使用Https @Override protected void configure(HttpSecurity http) throws Exception { System.out.println(\"auth pro run\"); http .authorizeRequests() .antMatchers(\"/home\").access(\"hasRole('ADMIN') and hasIpAddress('::1')\").and().formLogin().and() .authorizeRequests() .anyRequest().permitAll().and().requiresChannel().anyRequest().requiresSecure(); } CSRF防御 使用HTTP Basic认证 http .authorizeRequests() .antMatchers(\"/home\").access(\"hasRole('ADMIN') and hasIpAddress('::1')\").and().httpBasic().and() .authorizeRequests() .anyRequest().permitAll(); 启用记住我功能 .and().httpBasic().and().rememberMe() 保护视图 Spring Security的jsp标签库 使用thymeleaf的spring security 方言 保护方法调用 使用注解保护方法 配置 @Configuration @EnableGlobalMethodSecurity(securedEnabled = true) class Config1 extends GlobalMethodSecurityConfiguration{ } @Secured @Secured(\"ROLE_ADMIN\") @RequestMapping(\"/home\") @ResponseBody public String home(){ return \"home\"; } 使用表达式保护方法 启用相关配置支持 @EnableGlobalMethodSecurity(prePostEnabled = true) 相关注解 @PreAuthorize :在方法调用前进行验证 @PostAuthorize：在方法调用后进行验证 @PreFilter :调用前对参数进行过滤 @PostFilter ：调用后对返回结果进行过滤 @PreAuthorize(\"#id == 10\") public void invoke(Integer id){ } 定义许可计算器 实现该接口 public interface PermissionEvaluator extends AopInfrastructureBean { boolean hasPermission(Authentication authentication, Object targetDomainObject, Object permission); boolean hasPermission(Authentication authentication, Serializable targetId, String targetType, Object permission); } 注册到Spring Security 中 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-18 00:37:15 "},"编程语言/JAVA/框架/Spring/SpringSecurity/用户认证.html":{"url":"编程语言/JAVA/框架/Spring/SpringSecurity/用户认证.html","title":"用户认证","keywords":"","body":" 认证与授权 单点登录 单点登录（Single Sign On），简称为 SSO，是目前比较流行的企业业务整合的解决方案之一。SSO的定义是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统 Oauth2 OAUTH协议为用户资源的授权提供了一个安全的、开放而又简易的标准。同时，任何第三方都可以使用OAUTH认 证服务，任何服务提供商都可以实现自身的OAUTH认证服务。 授权模式 授权码模式 密码模式 JWT JSON Web Token（JWT）是一个开放的行业标准（RFC 7519），它定义了一种简介的、自包含的协议格式，用于 在通信双方传递json对象，传递的信息经过数字签名可以被验证和信任。JWT可以使用HMAC算法或使用RSA的公 钥/私钥对来签名，防止被篡改 缺点：令牌长度较长 组成 头部 {\"typ\":\"JWT\",\"alg\":\"HS256\"} // 经过base64加密后：eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 载荷 标准中注册的声明 公共的声明 私有的声明 {\"sub\":\"1234567890\",\"name\":\"John Doe\",\"admin\":true} // eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9 签证 header (base64后的) payload (base64后的) secret secret是保存在服务器端的，jwt的签发生成也是在服务器端的，secret就是用 来进行jwt的签发和jwt的验证，所以，它就是你服务端的私钥，在任何场景都不应该流 露出去 JJWT 依赖 io.jsonwebtoken jjwt 0.9.1 构建 JwtBuilder jwtBuilder = Jwts.builder() .setId(\"jntm\") .setSubject(\"cxk\") .setIssuedAt(new Date()) .signWith(SignatureAlgorithm.HS256,\"1234\") .claim(\"role\",\"admin\") .setExpiration(new Date(System.currentTimeMillis()+300)); System.out.println(jwtBuilder.compact()); 解析 Claims body = Jwts.parser().setSigningKey(\"1234\") .parseClaimsJws(\"jwt\") .getBody(); System.out.println(body.getId()+\"|\"+body.getSubject()+\"|\"+body.getIssuedAt()); Bcrypt bcrypt是一个由Niels Provos以及David Mazières根据Blowfish加密算法所设计的密码散列函数，于1999年在USENIX中展示。实现中bcrypt会使用一个加盐的流程以防御彩虹表攻击，同时bcrypt还是适应性函数，它可以借由增加迭代之次数来抵御日益增进的电脑运算能力透过暴力法破解。 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Spring/SpringSecurity/RBAC.html":{"url":"编程语言/JAVA/框架/Spring/SpringSecurity/RBAC.html","title":"RBAC","keywords":"","body":"RBAC MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-18 02:18:05 "},"编程语言/JAVA/框架/Spring/Spring集成/nav.html":{"url":"编程语言/JAVA/框架/Spring/Spring集成/nav.html","title":"Spring集成","keywords":"","body":"NAV MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/Spring/Spring集成/远程服务.html":{"url":"编程语言/JAVA/框架/Spring/Spring集成/远程服务.html","title":"使用远程服务","keywords":"","body":"远程调用的一些技术 RMI Hessian 和 Burlap HTTP JAX-WS 和 Web Service Spring 的远程调用 RMI 导出服务 @Bean public RmiServiceExporter rmiServiceExporter(Service service){ RmiServiceExporter exporter = new RmiServiceExporter(); exporter.setService(service); exporter.setServiceName(\"service\"); exporter.setServiceInterface(Service.class); exporter.setRegistryHost(\"ismy.wang\"); exporter.setRegistryPort(1999); return exporter; } 装配服务 Hessian 和 Burlap HttpInvoker 使用web服务 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"编程语言/JAVA/框架/SpringBoot/nav.html":{"url":"编程语言/JAVA/框架/SpringBoot/nav.html","title":"SpringBoot","keywords":"","body":"Spring Boot 内嵌式容器简化Web项目 没有冗余代码生成和XML配置的要求 与和SpringCloud SpringCloud依赖于SpringBoot组件，使用SpringMVC编写HTTP接口，同时SpringCloud是一套完整的微服务解决框架 环境搭建 org.springframework.boot spring-boot-starter-parent 2.1.8.RELEASE org.springframework.boot spring-boot-starter-web @SpringBootApplication public class Application{ public static void main(String[] args) { SpringApplication.run(Application.class); } } 热部署 org.springframework.boot spring-boot-devtools true IDEA需要开启自动编译 配置 YML语法 # 普通数据配置 name: hello # 对象配置 person: name: kb age: 3 # 配置数组、集合(字符串) city: - beijing - tianjing - chongqing # 配置数组、集合(对象) student: - name: tom age: 3 - name: ll age: 2 属性注入 @Value @Value(\"${name}\") private String name; @ConfigurationProperties @RestController @ConfigurationProperties(prefix = \"person\") public class Controller { private String name; private Integer age; @RequestMapping(\"/hi\") public String hello(){ return name+age; } // 省略setter } 全局异常捕获 @ControllerAdvice public class ErrorHandler { @ResponseBody @ExceptionHandler(Throwable.class) public String error(Exception e){ return e.getMessage(); } } 异步调用 添加@EnableAsync 在需要异步调用的方法上面添加@Async 多环境配置 spring.profiles.active=dev 添加开发环境配置文件application-dev.properties 事务管理 依赖 javax.transaction javax.transaction-api 1.3 添加@Transactional 多数据源 配置多个DataSource，一个DataSource配置一个事务管理器，声明事务时指定事务管理器， 不同的ORM框架有不同的指定数据源的方式 jta-atomikos 通过把多个DataSource交给jta事务管理器管理，使用jta事务管理器来解决分布式事务问题 打包 jar 添加插件 org.springframework.boot spring-boot-maven-plugin 执行mvn package war 添加打包插件 设置打包方式 war 执行打包命令 性能 组件自动扫描带来的问题 使用 @SpringBootApplication 注解后，会触发自动配置（ auto-configuration ）和 组件扫描 （ component scanning ） JVM参数调整 将tomcat改为undertow org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-tomcat org.springframework.boot spring-boot-starter-undertow 监控中心 Actuator是spring boot的一个附加功能,可在应用程序生产环境时监视和管理应用程序 添加依赖 org.springframework.boot spring-boot-starter-actuator 添加配置 # 暴露出所有监控接口 management: endpoints: web: exposure: include: \"*\" 路径 作用 /actuator/beans 显示应用程序中所有Spring bean的完整列表。 /actuator/configprops 显示所有配置信息。 /actuator/env 陈列所有的环境变量。 /actuator/mappings 显示所有@RequestMapping的url整理列表。 /actuator/health 显示应用程序运行状况信息 up表示成功 down失败 /actuator/info 返回配置中前缀为info的配置项 集成其他框架 集成freemarker 引入依赖 org.springframework.boot spring-boot-starter-freemarker 配置 spring.freemarker.allow-request-override=false spring.freemarker.cache=true spring.freemarker.check-template-location=true spring.freemarker.charset=UTF-8 spring.freemarker.content-type=text/html spring.freemarker.expose-request-attributes=false spring.freemarker.expose-session-attributes=false spring.freemarker.expose-spring-macro-helpers=false spring.freemarker.suffix=.ftl spring.freemarker.template-loader-path=classpath:/templates/ 创建Controller @Controller public class HelloController { @RequestMapping(\"hello\") public String index(ModelMap map){ map.put(\"hello\",\"java\"); return \"index\"; } } 在template目录下创建index.ftl ${hello} 集成Mybatis 引入依赖 org.mybatis.spring.boot mybatis-spring-boot-starter 2.1.0 配置数据库信息和mybatis配置 # 数据库连接信息 spring.datasource.username=root spring.datasource.password=123 spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql:///ssm # mybatis相关配置 mybatis.mapper-locations=mappers/*.xml mybatis.configuration.map-underscore-to-camel-case=true 配置mybatis包扫描路径 @MapperScan(basePackages = \"wang.ismy.springmybatis.mapper\") public class SpringMybatisApplication { public static void main(String[] args) { SpringApplication.run(SpringMybatisApplication.class, args); } } 整合PageHelper 引入依赖 com.github.pagehelper pagehelper-spring-boot-starter 1.2.13 配置 pagehelper.helperDialect=mysql pagehelper.reasonable=true pagehelper.supportMethodsArguments=true pagehelper.params=count=countSql pagehelper.page-size-zero=true 集成Junit 导入依赖 org.springframework.boot spring-boot-starter-test test 建立测试 @SpringBootTest @RunWith(SpringRunner.class) public class ControllerTest{ @Autowired UserMapper mapper; @Test public void test(){ assertNotNull(mapper); } } 集成Spring data jpa 依赖 org.springframework.boot spring-boot-starter-data-jpa 配置 # 数据库连接信息 spring.datasource.username=root spring.datasource.password=123 spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql:///ssm # spring data jpa相关配置 spring.jpa.database=mysql spring.jpa.show-sql=true spring.jpa.generate-ddl=true spring.jpa.hibernate.ddl-auto=update 使用通用Mapper 依赖 tk.mybatis mapper-spring-boot-starter 2.1.5 继承 public interface UserMapper extends BaseMapper { } @MapperScan注解需要使用tk.mybatis包 集成Redis 依赖 org.springframework.boot spring-boot-starter-data-redis 配置 # redis相关配置 spring.redis.host=127.0.0.1 spring.redis.port=6379 使用 @RunWith(SpringRunner.class) @SpringBootTest public class RedisTest { @Autowired RedisTemplate redisTemplate; @Test public void test(){ String name = redisTemplate.boundValueOps(\"name\").get(); Assert.assertEquals(\"my\",name); } } 集成swagger 依赖 com.spring4all swagger-spring-boot-starter 1.9.1.RELEASE 配置 swagger.base-package=wang.ismy.consume @EnableSwagger2Doc zuul整合各个微服务文档 依赖 com.spring4all swagger-spring-boot-starter 1.9.1.RELEASE 配置 @Component @Primary @EnableSwagger2Doc class DocumentationConfig implements SwaggerResourcesProvider { @Override public List get() { List resources = new ArrayList<>(); resources.add(swaggerResource(\"consumer\", \"/api-consumer/v2/api-docs\", \"2.0\")); return resources; } private SwaggerResource swaggerResource(String name, String location, String version) { SwaggerResource swaggerResource = new SwaggerResource(); swaggerResource.setName(name); swaggerResource.setLocation(location); swaggerResource.setSwaggerVersion(version); return swaggerResource; } } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-07 12:37:18 "},"编程语言/JAVA/框架/SpringWebFlux.html":{"url":"编程语言/JAVA/框架/SpringWebFlux.html","title":"SpringWebFlux","keywords":"","body":"WebFlux 非阻塞，更高的性能 函数式编程 响应式：区别于传统编程模型，是异步的 围绕响应变化而构建的编程模型-网络组件响应I / O事件 概念 响应式api 接收Publisher作为输入 Flux或者Mono作为输出 编程模型 web flux提供了两种编程模型： 带注释的controller：和经典的web mvc一样 功能端点：从到到尾由应用程序自己路由、处理请求。和nodejs一样 web mvc or web flux？ 服务器 在 web flux中，可以跨tomcat、jetty等容器使用 性能 非阻塞方式进行操作需要更多的工作，这可能会稍微增加所需的处理时间 使用响应式的好处在于能够以较少的固定数量线程以及更少的内存资源进行更好的扩展 并发模型 调用阻塞api：虽然一些方法可以在响应式编程中使用，但会引入一些额外的问题 可变状态：通过运算符，形成一个响应式管道，在不同的阶段处理数据 线程模型 原始线程模型 事件循环 调度程序 配置 不同的服务器的配置需要使用各自服务器的api 响应式核心 HttpHandler 一个可以处理请求并且响应的单一方法 不同的服务器具有不同的api WebHandler spring web基于httphandler封装了WebHandler Filters 可以使用 WebFilter 处理请求 Exceptions 可以使用ExceptionHandler来处理请求与响应中的异常 Codecs web flux 提供了一些封装来负责数据的序列化与反序列化 DispatcherHandler 类似于mvc中的DispatcherServlet 负责对请求的统一控制与转发 使用 传统方式 跟MVC一样 可以使用controller等相关注解进行使用 函数式端点 概览 class Handler { public Mono listPeople(ServerRequest request) { // ... } public Mono createPerson(ServerRequest request) { // ... } public Mono getPerson(ServerRequest request) { // ... } } Handler handler = new Handler(); // 定义路由映射 RouterFunction route = route() .GET(\"/person/{id}\", accept(APPLICATION_JSON), handler::getPerson) .GET(\"/person\", accept(APPLICATION_JSON), handler::listPeople) .POST(\"/person\", handler::createPerson) .build(); ServerRequest 提供了一个访问请求数据的东西 Mono string = request.bodyToMono(String.class); ServerResponse 这玩意是不可变的，所以需要手动来创建 public Mono listPeople(ServerRequest request) { return ok().body(Mono.just(\"people list\"), String.class); } 路由判断 // 只有person/1才会被处理 route() .GET(\"/person/{id}\", accept(APPLICATION_JSON).and(request-> \"1\".equals(request.pathVariable(\"id\"))), handler::getPerson) 路由优先级 RouterFunction route = route() .GET(\"/person/{id}\", accept(APPLICATION_JSON), handler::getPerson) //1 .GET(\"/person\", accept(APPLICATION_JSON), handler::listPeople) // 2 .POST(\"/person\", handler::createPerson) // 3 .add(otherRoute) // 添加其他路由 .build(); 嵌套路由 RouterFunction route = route() .path(\"/person\", builder -> builder .GET(\"/{id}\", accept(APPLICATION_JSON), handler::getPerson) .GET(\"\", accept(APPLICATION_JSON), handler::listPeople) .POST(\"/person\", handler::createPerson)) .build(); 运行 spring boot @EnableWebFlux @Bean RouterFunction routerFunction(){ ... } 过滤器 route() .before(req->{ System.out.println(req.path()+\"before\"); return req; }) .GET(\"/person/{id}\", accept(APPLICATION_JSON).and(request-> \"1\".equals(request.pathVariable(\"id\"))), handler::getPerson) .GET(\"/person\", accept(APPLICATION_JSON), handler::listPeople) .POST(\"/person\", handler::createPerson) .after((req,res)->{ System.out.println(req.path()+\"after\"); return res; }) .build(); 或者另外一种方式： route() .GET(\"/person/{id}\", accept(APPLICATION_JSON).and(request-> \"1\".equals(request.pathVariable(\"id\"))), handler::getPerson) .GET(\"/person\", accept(APPLICATION_JSON), handler::listPeople) .POST(\"/person\", handler::createPerson) .filter((req,res)->{ System.out.println(req.path()+\"before\"); return res.handle(req); }) .build(); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-04-21 08:05:19 "},"DSL/nav.html":{"url":"DSL/nav.html","title":"DSL","keywords":"","body":"DSL MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 12:40:15 "},"DSL/HTML.html":{"url":"DSL/HTML.html","title":"HTML","keywords":"","body":" 静态资源 动态资源 超文本 标记语言 标签 围堵标签 自闭标签 基本标签 文件标签 html head title body 文本标签 h1 ~ h6 p br hr b i font 图片标签 src alt 列表标签 ul：无序 ol：有序 链接标签 块标签 div span 语义化标签 header footer nav 表格标签 编号 姓名 1 lisi 表单标签 input select option textarea label HTML5 HTML5 拓展了哪些内容 语义化标签 本地存储 兼容特性 2D、3D 动画、过渡 CSS3 特性 性能与集成 语义化标签 header --- 头部标签 nav --- 导航标签 article --- 内容标签 section --- 块级标签 aside --- 侧边栏标签 footer --- 尾部标签 语义化标签主要针对搜索引擎 新标签可以使用一次或者多次 在 IE9 浏览器中，需要把语义化标签都转换为块级元素 语义化标签，在移动端支持比较友好 多媒体标签 音频 -- audio 视频 -- video audio 音频格式 Chrome Firefox IE9 Opera Safari OGG 支持 支持 支持 支持 不支持 MP3 支持 不支持 支持 不支持 支持 WAV 不支持 支持 不支持 支持 不支持 属性 属性值 注释 src url 播放的音乐的url地址 preload preload 预加载（在页面被加载时进行加载或者说缓冲音频），如果使用了autoplay的话那么该属性失效。 loop loop 循环播放 controls controls 是否显示默认控制条（控制按钮） autoplay autoplay 自动播放 video 浏览器 MP4 WebM Ogg Internet Explorer YES NO NO Chrome YES YES YES Firefox YES YES YES Safari YES NO NO Opera YES (从 Opera 25 起) YES YES 音频标签与视频标签使用基本一致 多媒体标签在不同浏览器下情况不同，存在兼容性问题 谷歌浏览器把音频和视频标签的自动播放都禁止了 谷歌浏览器中视频添加 muted 标签可以自己播放 新增 input 标签 新增表单属性 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"DSL/CSS/nav.html":{"url":"DSL/CSS/nav.html","title":"CSS","keywords":"","body":"CSS 层叠样式表（英语：Cascading Style Sheets，缩写：CSS；又称串样式列表、级联样式表、串接样式表、阶层式样式表）是一种用来为结构化文档（如HTML文档或XML应用）添加样式（字体、间距和颜色等）的计算机语言，由W3C定义和维护。当前最新版本是CSS2.1，为W3C的推荐标准。CSS3现在已被大部分现代浏览器支持，而下一版的CSS4仍在开发中。 书写规范 空格规范 /* 选择器 与 { 之间必须包含空格。 */ .selector { /* 属性名 与之后的 : 之间不允许包含空格， : 与 属性值 之间必须包含空格 */ font-size: 12px; } 选择器规范 /* 并集选择器，每个选择器声明必须独占一行 */ .post, .page, .comment { line-height: 1.5; } 一般情况情况下，选择器的嵌套层级应不大于 3 级，位置靠后的限定条件应尽可能精确 属性规范 /* 属性定义必须另起一行。 */ .selector { margin: 0; padding: 0; /* 属性定义后必须以分号结尾。 */ } 使用方式 内联 内容 内嵌 选择器（选择的标签） { 属性1: 属性值1; 属性2: 属性值2; 属性3: 属性值3; } 外联 属性 作用 rel 定义当前文档与被链接文档之间的关系，在这里需要指定为\"stylesheet\"，表示被链接的文档是一个样式表文件。 type 定义所链接文档的类型，在这里需要指定为\"text/CSS\"，表示链接的外部文件为CSS样式表。我们都可以省略 href 定义所链接外部样式表文件的URL，可以是相对路径，也可以是绝对路径。 比较 样式表 优点 缺点 使用情况 控制范围 行内样式表 书写方便，权重高 没有实现样式和结构相分离 较少 控制一个标签（少） 内部样式表 部分结构和样式相分离 没有彻底分离 较多 控制一个页面（中） 外部样式表 完全实现结构和样式相分离 需要引入 最多，强烈推荐 控制整个站点（多） 三大特性 层叠性 所谓层叠性是指多种CSS样式的叠加。 样式冲突，遵循的原则是就近原则。 那个样式离着结构近，就执行那个样式。 继承性 子元素可以继承父元素的样式（text-，font-，line-这些元素开头的可以继承，以及color属性） 优先级 标签选择器 计算权重公式 继承或者 * 0,0,0,0 每个元素（标签选择器） 0,0,0,1 每个类，伪类 0,0,1,0 每个ID 0,1,0,0 每个行内样式 style=\"\" 1,0,0,0 每个!important 重要的 ∞ 无穷大 权重叠加 div ul li ------> 0,0,0,3 .nav ul li ------> 0,0,1,2 a:hover -----—> 0,0,1,1 .nav a ------> 0,0,1,1 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/选择器.html":{"url":"DSL/CSS/选择器.html","title":"选择器","keywords":"","body":"CSS选择器 选择器的作用 找到特定的HTML页面元素 基础选择器 标签选择器 标签名{属性1:属性值1; 属性2:属性值2; 属性3:属性值3; } p { font-size:14px; } 类选择器 .类名 { 属性1:属性值1; 属性2:属性值2; 属性3:属性值3; } 多类名 ID选择器 #id名 {属性1:属性值1; 属性2:属性值2; 属性3:属性值3; } ID选择器与类选择器 类选择器我们在修改样式中，用的最多。 id选择器一般用于页面唯一性的元素身上，经常和我们后面学习的javascript 搭配使用。 通配符选择器 * { 属性1:属性值1; 属性2:属性值2; 属性3:属性值3; } * { margin: 0; /* 定义外边距*/ padding: 0; /* 定义内边距*/ } 基础选择器总结 选择器 作用 缺点 使用情况 用法 标签选择器 可以选出所有相同的标签，比如p 不能差异化选择 较多 p { color：red;} 类选择器 可以选出1个或者多个标签 可以根据需求选择 非常多 .nav { color: red; } id选择器 一次只能选择器1个标签 只能使用一次 不推荐使用 #nav {color: red;} 通配符选择器 选择所有的标签 选择的太多，有部分不需要 不推荐使用 * {color: red;} MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/字体样式.html":{"url":"DSL/CSS/字体样式.html","title":"字体样式","keywords":"","body":"字体样式 单位 字体样式 font-size:大小 p { font-size:20px; } font-family:字体 p{ font-family:\"微软雅黑\";} /* 可以同时指定多个字体，按从左到右选择 */ p{font-family: Arial,\"Microsoft Yahei\", \"微软雅黑\";} CSS Unicode字体 /* 表示设置字体为“微软雅黑”。 */ font-family: \"\\5FAE\\8F6F\\96C5\\9ED1\"; font-weight:字体粗细 属性值 描述 normal 默认值（不加粗的） bold 定义粗体（加粗的） 100~900 400 等同于 normal，而 700 等同于 bold 我们重点记住这句话 font-style:字体风格 属性 作用 normal 默认值，浏览器会显示标准的字体样式 font-style: normal; italic 浏览器会显示斜体的字体样式。 font:综合设置字体样式 font: 加粗 字号/行高/ 字体 font: 400 14px/24px \"宋体\"; 字体总结 属性 表示 注意点 font-size 字号 我们通常用的单位是px 像素，一定要跟上单位 font-family 字体 实际工作中按照团队约定来写字体 font-weight 字体粗细 记住加粗是 700 或者 bold 不加粗 是 normal 或者 400 记住数字不要跟单位 font-style 字体样式 记住倾斜是 italic 不倾斜 是 normal 工作中我们最常用 normal font 字体连写 1. 字体连写是有顺序的 不能随意换位置 2. 其中字号 和 字体 必须同时出现 字体外观 颜色 表示表示 属性值 预定义的颜色值 red，green，blue，还有我们的御用色 pink 十六进制 #FF0000，#FF6600，#29D794 RGB代码 rgb(255,0,0)或rgb(100%,0%,0%) color:文本颜色 text-align:文本水平对齐方式 属性 解释 left 左对齐（默认值） right 右对齐 center 居中对齐 line-height:行间距 /* 一般情况下，行距比字号大7.8像素左右就可以了。 */ line-height: 24px; text-indent:首行缩进 /*首行缩进2个字 em 1个em 就是1个字的大小*/ text-indent: 2em; text-decoration 文本的装饰 值 描述 none 默认。定义标准的文本。 取消下划线（最常用） underline 定义文本下的一条线。下划线 也是我们链接自带的（常用） overline 定义文本上的一条线。（不用） line-through 定义穿过文本下的一条线。（不常用） MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/复合选择器.html":{"url":"DSL/CSS/复合选择器.html","title":"复合选择器","keywords":"","body":"复合选择器 后代选择器 后代选择器又称为包含选择器 父级 子级{属性:属性值;属性:属性值;} .class h3{color:red;font-size:16px;} 子元素选择器 子元素选择器只能选择作为某元素子元素(直接子元素)的元素 .class>h3{color:red;font-size:14px;} 交集选择器 /* 选择标签是p且类名是one的元素 */ p.one{color:red} 并集选择器 /* .one 和 p 和 #test 这三个选择器都会执行颜色为红色。 */ .one, p , #test {color: #F00;} 链接伪类选择器 a:link /* 未访问的链接 */ a:visited /* 已访问的链接 */ a:hover /* 鼠标移动到链接上 */ a:active /* 选定的链接 */ 写的时候，他们的顺序尽量不要颠倒 按照 lvha 的顺序。否则可能引起错误 总结 选择器 作用 特征 使用情况 隔开符号及用法 后代选择器 用来选择元素后代 是选择所有的子孙后代 较多 符号是空格 .nav a 子代选择器 选择 最近一级元素 只选亲儿子 较少 符号是 > .nav>p 交集选择器 选择两个标签交集的部分 既是 又是 较少 没有符号 p.one 并集选择器 选择某些相同样式的选择器 可以用于集体声明 较多 符号是逗号 .nav, .header 链接伪类选择器 给链接更改状态 较多 重点记住 a{} 和 a:hover 实际开发的写法 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/标签显式模式.html":{"url":"DSL/CSS/标签显式模式.html","title":"标签显式模式","keywords":"","body":"标签显式模式 标签以什么方式进行显示，比如div 自己占一行， 比如span 一行可以放很多个 块级元素(block-level) 常见的块元素有~、、、、、等，其中标签是最典型的块元素。 （1）比较霸道，自己独占一行 （2）高度，宽度、外边距以及内边距都可以控制。 （3）宽度默认是容器（父级宽度）的100% （4）是一个容器及盒子，里面可以放行内或者块级元素。 文字类块标签里面不能放其他块元素 行内元素(inline-level) 常见的行内元素有、、、、、、、、、等，其中标签最典型的行内元素。有的地方也成内联元素 （1）相邻行内元素在一行上，一行可以显示多个。 （2）高、宽直接设置是无效的。 （3）默认宽度就是它本身内容的宽度。 （4）行内元素只能容纳文本或则其他行内元素。 行内块元素（inline-block） 在行内元素中有几个特殊的标签——、、，可以对它们设置宽高和对齐属性，有些资料可能会称它们为行内块元素。 （1）和相邻行内元素（行内块）在一行上,但是之间会有空白缝隙。一行可以显示多个 （2）默认宽度就是它本身内容的宽度。 （3）高度，行高、外边距以及内边距都可以控制。 标签显示模式转换 display 块转行内：display:inline; 行内转块：display:block; 块、行内元素转换为行内块： display: inline-block; 总结 元素模式 元素排列 设置样式 默认宽度 包含 块级元素 一行只能放一个块级元素 可以设置宽度高度 容器的100% 容器级可以包含任何标签 行内元素 一行可以放多个行内元素 不可以直接设置宽度高度 它本身内容的宽度 容纳文本或则其他行内元素 行内块元素 一行放多个行内块元素 可以设置宽度和高度 它本身内容的宽度 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/行高.html":{"url":"DSL/CSS/行高.html","title":"行高","keywords":"","body":"行高 行高的测量 实现文本垂直居中 如果 行高 等 高度 文字会 垂直居中 如果行高 大于 高度 文字会 偏下 如果行高小于高度 文字会 偏上 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/背景.html":{"url":"DSL/CSS/背景.html","title":"背景","keywords":"","body":"背景 背景颜色 /* 默认的值是 transparent 透明的 */ background-color:颜色值; 背景图片(image) 参数 作用 none 无背景图（默认的） url 使用绝对或相对地址指定背景图像 background-image : url(images/demo.png); 背景平铺（repeat） 参数 作用 repeat 背景图像在纵向和横向上平铺（默认的） no-repeat 背景图像不平铺 repeat-x 背景图像在横向上平铺 repeat-y 背景图像在纵向平铺 背景位置(position)-重点 background-position : length || length background-position : position || position 参数 值 length 百分数 \\ 由浮点数字和单位标识符组成的长度值 position top \\ center \\ bottom \\ left \\ center \\ right 方位名词 必须先指定background-image属性 position 后面是x坐标和y坐标。 可以使用方位名词或者 精确单位。 如果指定两个值，两个值都是方位名字，则两个值前后顺序无关，比如left top和top left效果一致 如果只指定了一个方位名词，另一个值默认居中对齐。 如果position 后面是精确坐标， 那么第一个，肯定是 x 第二的一定是y 如果只指定一个数值,那该数值一定是x坐标，另一个默认垂直居中 如果指定的两个值是 精确单位和方位名字混合使用，则第一个值是x坐标，第二个值是y坐标 背景附着 background-attachment : scroll | fixed 参数 作用 scroll 背景图像是随对象内容滚动 fixed 背景图像固定 背景简写 background: 背景颜色 背景图片地址 背景平铺 背景滚动 背景位置; 背景透明(CSS3) background: rgba(0, 0, 0, 0.3); 总结 属性 作用 值 background-color 背景颜色 预定义的颜色值/十六进制/RGB代码 background-image 背景图片 url(图片路径) background-repeat 是否平铺 repeat/no-repeat/repeat-x/repeat-y background-position 背景位置 length/position 分别是x 和 y坐标， 切记 如果有 精确数值单位，则必须按照先X 后Y 的写法 background-attachment 背景固定还是滚动 scroll/fixed 背景简写 更简单 背景颜色 背景图片地址 背景平铺 背景滚动 背景位置; 他们没有顺序 背景透明 让盒子半透明 background: rgba(0,0,0,0.3); 后面必须是 4个值 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/盒子模型.html":{"url":"DSL/CSS/盒子模型.html","title":"盒子模型","keywords":"","body":"盒子模型 盒子边框（border） border : border-width || border-style || border-color 属性 作用 border-width 定义边框粗细，单位是px border-style 边框的样式 border-color 边框颜色 边框写法总结 上边框 下边框 左边框 右边框 border-top-style:样式; border-bottom-style:样式; border-left-style:样式; border-right-style:样式; border-top-width:宽度; border- bottom-width:宽度; border-left-width:宽度; border-right-width:宽度; border-top-color:颜色; border- bottom-color:颜色; border-left-color:颜色; border-right-color:颜色; border-top:宽度 样式 颜色; border-bottom:宽度 样式 颜色; border-left:宽度 样式 颜色; border-right:宽度 样式 颜色; 边框合并 border-collapse:collapse; 内边距（padding） padding属性用于设置内边距。 是指 边框与内容之间的距离。 属性 作用 padding-left 左内边距 padding-right 右内边距 padding-top 上内边距 padding-bottom 下内边距 盒子会变大 简写 值的个数 表达意思 1个值 padding：上下左右内边距; 2个值 padding: 上下内边距 左右内边距 ； 3个值 padding：上内边距 左右内边距 下内边距； 4个值 padding: 上内边距 右内边距 下内边距 左内边距 ； 内盒尺寸计算（元素实际大小） 盒子的实际的大小 = 内容的宽度和高度 + 内边距 + 边框 Element Width = content width + padding + border Element Height = content height + padding + border 内边距产生的问题 会撑大原来的盒子 通过给设置了宽高的盒子，减去相应的内边距的值，维持盒子原有的大小 如果没有给一个盒子指定宽度， 此时，如果给这个盒子指定padding， 则不会撑开盒子。 外边距（margin） margin属性用于设置外边距。 margin就是控制盒子和盒子之间的距离 属性 作用 margin-left 左外边距 margin-right 右外边距 margin-top 上外边距 margin-bottom 下外边距 margin值的简写 （复合写法）代表意思 跟 padding 完全相同。 块级盒子水平居中 盒子必须指定了宽度（width） 然后就给左右的外边距都设置为auto div { width:600px; height: 500px; background-color: skyblue; margin: 0 auto; } 文字居中和盒子居中区别 text-align: center; /* 文字 行内元素 行内块元素水平居中 */ margin: 10px auto; /* 块级盒子水平居中 左右margin 改为 auto 就可以了 上下margin都可以 */ 插入图片和背景图片区别 插入图片 我们用的最多 比如产品展示类 移动位置只能靠盒模型 padding margin 背景图片我们一般用于小图标背景 或者 超大背景图片 背景图片 只能通过 background-position 清除元素的默认内外边距 * { padding:0; /* 清除内边距 */ margin:0; /* 清除外边距 */ } 外边距合并 使用margin定义块元素的垂直外边距时，可能会出现外边距的合并。 嵌套块元素垂直外边距的合并（塌陷） 可以为父元素定义上边框。 可以为父元素定义上内边距 可以为父元素添加overflow:hidden。 盒子模型布局稳定性 使用优先级 width > padding > margin 圆角边框(CSS3) border-radius:length; 盒子阴影(CSS3) box-shadow:水平阴影 垂直阴影 模糊距离（虚实） 阴影尺寸（影子大小） 阴影颜色 内/外阴影； MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/浮动.html":{"url":"DSL/CSS/浮动.html","title":"浮动","keywords":"","body":"浮动 元素的浮动是指设置了浮动属性的元素会 脱离标准普通流的控制 移动到指定位置 作用 让多个盒子(div)水平排列成一行，使得浮动成为布局的重要手段。 可以实现盒子的左右对齐等等.. 浮动最早是用来控制图片，实现文字环绕图片的效果。 语法 选择器 { float: 属性值; } 属性值 描述 none 元素不浮动（默认值） left 元素向左浮动 right 元素向右浮动 特性 float 属性会让盒子漂浮在标准流的上面,并且不占有原来位置 任何元素都可以浮动。浮动元素会生成一个块级框，生成的块级框和我们前面的行内块极其相似 使用浮动的核心目的----让多个块级盒子在同一行显示 特点 说明 浮 加了浮动的盒子是浮起来的，漂浮在其他标准流盒子的上面。 漏 加了浮动的盒子是不占位置的，它原来的位置漏给了标准流的盒子。 特 特别注意：浮动元素会改变display属性， 类似转换为了行内块，但是元素之间没有空白缝隙 扩展 子盒子的浮动参照父盒子对齐 不会与父盒子的边框重叠，也不会超过父盒子的内边距 浮动只会影响当前的或者是后面的标准流盒子，不会影响前面的标准流 清除浮动 父级盒子很多情况下，不方便给高度，但是子盒子浮动就不占有位置，最后父级盒子高度为0，导致排版出现问题 清除浮动主要为了解决父级元素因为子级浮动引起内部高度为0 的问题。清除浮动之后， 父级就会根据浮动的子盒子自动检测高度。父级有了高度，就不会影响下面的标准流了 选择器{clear:属性值;} 属性值 描述 left 不允许左侧有浮动元素（清除左侧浮动的影响） right 不允许右侧有浮动元素（清除右侧浮动的影响） both 同时清除左右两侧浮动的影响 额外标签法 父级添加overflow after伪元素 .clearfix:after { content: \"\"; display: block; height: 0; clear: both; visibility: hidden; } .clearfix {*zoom: 1;} /* IE6、7 专有 */ 双伪元素 .clearfix:before,.clearfix:after { content:\"\"; display:table; } .clearfix:after { clear:both; } .clearfix { *zoom:1; } 清除浮动的方式 优点 缺点 额外标签法（隔墙法） 通俗易懂，书写方便 添加许多无意义的标签，结构化较差。 父级overflow:hidden; 书写简单 溢出隐藏 父级after伪元素 结构语义化正确 由于IE6-7不支持:after，兼容性问题 父级双伪元素 结构语义化正确 由于IE6-7不支持:after，兼容性问题 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/定位.html":{"url":"DSL/CSS/定位.html","title":"定位","keywords":"","body":"定位 将盒子定在某一个位置 自由的漂浮在其他盒子(包括标准流和浮动)的上面 定位 = 定位模式 + 边偏移 边偏移 边偏移属性 示例 描述 top top: 80px 顶端偏移量，定义元素相对于其父元素上边线的距离。 bottom bottom: 80px 底部偏移量，定义元素相对于其父元素下边线的距离。 left left: 80px 左侧偏移量，定义元素相对于其父元素左边线的距离。 right right: 80px 右侧偏移量，定义元素相对于其父元素右边线的距离 定位模式 选择器 { position: 属性值; } 值 语义 static 静态定位 relative 相对定位 absolute 绝对定位 fixed 固定定位 静态定位(static) 静态定位是元素的默认定位方式 相对定位(relative) 相对定位是元素相对于它原来在标准流中的位置来说的 原来在标准流的区域继续占有，后面的盒子仍然以标准流的方式对待它 绝对定位(absolute) 绝对定位是元素以带有定位的父级元素来移动位置 完全脱标 ---- 完全不占位置 父元素没有定位，则元素依据最近的已经定位（绝对、固定或相对定位）的父元素（祖先）进行定位 子绝父相 ---- 子级是绝对定位，父级要用相对定位。 固定定位(fixed) 完全脱标 ---- 完全不占位置 只认浏览器的可视窗口 ---- 浏览器可视窗口 + 边偏移属性 来设置元素的位置 不随滚动条滚动 扩展 居中 绝对定位/固定定位的盒子不能通过设置 margin: auto 设置水平居中。 left: 50%;：让盒子的左侧移动到父级元素的水平中心位置； margin-left: -100px;：让盒子向左移动自身宽度的一半。 堆叠顺序（z-index） 加了定位的盒子，默认后来者居上， 后面的盒子会压住前面的盒子 selector { z-index: value; } 属性值：正整数、负整数或 0，默认值是 0，数值越大，盒子越靠上 z-index 只能应用于相对定位、绝对定位和固定定位的元素，其他标准流、浮动和静态定位无效 定位改变display属性 一个行内的盒子，如果加了浮动、固定定位和绝对定位，不用转换，就可以给这个盒子直接设置宽度和高度等 给盒子改为了浮动或者定位，就不会有垂直外边距合并的问题了 总结 定位模式 是否脱标占有位置 移动位置基准 模式转换（行内块） 使用情况 静态static 不脱标，正常模式 正常模式 不能 几乎不用 相对定位relative 不脱标，占有位置 相对自身位置移动 不能 基本单独使用 绝对定位absolute 完全脱标，不占有位置 相对于定位父级移动位置 能 要和定位父级元素搭配使用 固定定位fixed 完全脱标，不占有位置 相对于浏览器移动位置 能 单独使用，不需要父级 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/高级技巧.html":{"url":"DSL/CSS/高级技巧.html","title":"高级技巧","keywords":"","body":"高级技巧 元素的显示与隐藏 display 显示 /* 隐藏对象 */ display: none 特点： 隐藏之后，不再保留位置。 配合后面js做特效，比如下拉菜单，原先没有，鼠标经过，显示下拉菜单， 应用极为广泛 visibility 可见性 /* 对象可视 */ visibility：visible ; 　 /* 对象隐藏 */ visibility：hidden; 特点： 隐藏之后，继续保留原有位置。 overflow 溢出 检索或设置当对象的内容超过其指定高度及宽度时如何管理内容 属性值 描述 visible 不剪切内容也不添加滚动条 hidden 不显示超过对象尺寸的内容，超出的部分隐藏掉 scroll 不管超出内容否，总是显示滚动条 auto 超出自动显示滚动条，不超出不显示滚动条 应用： 清除浮动 隐藏超出内容，隐藏掉, 不允许内容超过父盒子。 总结 属性 区别 用途 display 隐藏对象，不保留位置 配合后面js做特效，比如下拉菜单，原先没有，鼠标经过，显示下拉菜单， 应用极为广泛 visibility 隐藏对象，保留位置 使用较少 overflow 只是隐藏超出大小的部分 1. 可以清除浮动 2. 保证盒子里面的内容不会超出该盒子范围 CSS用户界面样式 鼠标样式cursor 设置或检索在对象上移动的鼠标指针采用何种系统预定义的光标形状 a:hover { cursor: value; } 属性值 描述 default 小白 默认 pointer 小手 move 移动 text 文本 not-allowed 禁止 轮廓线 outline outline : outline-color ||outline-style || outline-width outline : outline-color ||outline-style || outline-width 一般都直接去掉: outline: 0; outline: none; 防止拖拽文本域resize vertical-align 垂直对齐 vertical-align : baseline |top |middle |bottom vertical-align 不影响块级元素中的内容对齐，它只针对于行内元素或者行内块元素 行内块元素， 通常用来控制图片/表单与文字的对齐 图片、表单和文字对齐 去除图片底侧空白缝隙 图片或者表单等行内块元素，他的底线会和父级盒子的基线对齐 给img vertical-align:middle | top| bottom等等。 让图片不要和基线对齐 给img 添加 display：block; 转换为块级元素就不会存在问题了 溢出的文字省略号显示 /*1. 先强制一行内显示文本*/ white-space: nowrap; /*2. 超出的部分隐藏*/ overflow: hidden; /*3. 文字用省略号替代超出的部分*/ text-overflow: ellipsis; CSS精灵技术（sprite) CSS 精灵其实是将网页中的一些背景图像整合到一张大图中（精灵图） 滑动门 扩展 margin负值 负边距+定位：水平垂直居中 压住盒子相邻边框 需要添加浮动 CSS三角 将盒子宽高设置为0，然后设置四个边框 div { width: 0; height: 0; border-style: solid; border-width: 20px; border-color: pink skyblue deepskyblue darkcyan; } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/CSS3.html":{"url":"DSL/CSS/CSS3.html","title":"CSS3","keywords":"","body":"CSS3 选择器 属性选择器 input[type=search] { color: skyblue; } 结构伪类选择器 nth-child 详解 n 可以是数字、关键字、公式 n 如果是数字，就是选中第几个 常见的关键字有 even 偶数、odd 奇数 常见的公式如下(如果 n 是公式，则从 0 开始计算) 但如果是第 0 个元素或者超出了元素的个数会被忽略 nth-child 和 nt-of-type 的区别 nth-child 选择父元素里面的第几个子元素，不管是第几个类型 nt-of-type 选择指定类型的元素 伪元素选择器 ::before 在元素内部的前面插入内容 ::after 在元素内部的后面插入内容 注意事项 before 和 after 必须有 content 属性 before 在内容前面，after 在内容后面 before 和 after 创建的是一个元素，但是属于行内元素 创建出来的元素在 Dom 中查找不到，所以称为伪元素 伪元素和标签选择器一样，权重为 1 2D转换 2D转换translate x 就是 x 轴上水平移动 y 就是 y 轴上水平移动 transform: translate(x, y) transform: translateX(n) transfrom: translateY(n) 2D 的移动主要是指 水平、垂直方向上的移动 translate 最大的优点就是不影响其他元素的位置 translate 中的100%单位，是相对于本身的宽度和高度来进行计算的 行内标签没有效果 2D旋转rotate 2D 旋转指的是让元素在二维平面内顺时针或者逆时针旋转 transform: rotate(度数) rotate里面跟度数，单位是deg` 角度为正时，顺时针，角度为负时，逆时针 默认旋转的中心点是元素的中心点 设置元素旋转中心点(transform-origin) transform-origin: x y; 注意后面的参数 x 和 y 用空格隔开 x y 默认旋转的中心点是元素的中心 (50% 50%)，等价于 center center 还可以给 x y 设置像素或者方位名词(top、bottom、left、right、center) 2D 转换之 scale 用来控制元素的放大与缩小 transform: scale(x, y) 注意，x 与 y 之间使用逗号进行分隔 transform: scale(1, 1): 宽高都放大一倍，相当于没有放大 transform: scale(2, 2): 宽和高都放大了二倍 transform: scale(2): 如果只写了一个参数，第二个参数就和第一个参数一致 transform:scale(0.5, 0.5): 缩小 scale 最大的优势：可以设置转换中心点缩放，默认以中心点缩放，而且不影响其他盒子 综合写法 同时使用多个转换，其格式为 transform: translate() rotate() scale() 顺序会影响到转换的效果(先旋转会改变坐标轴方向) 但我们同时有位置或者其他属性的时候，要将位移放到最前面 动画 动画是 CSS3 中最具颠覆性的特征之一，可通过设置多个节点来精确的控制一个或者一组动画，从而实现复杂的动画效果 定义动画 @keyframes motion { 0% { transform: translateX(0); } 100% { transform: translateX(1000px); } } 使用动画 div { width: 200px; height: 200px; background-color: skyblue; animation: motion 5s; } 0% 是动画的开始，100 % 是动画的完成，这样的规则就是动画序列 在 @keyframs 中规定某项 CSS 样式，就由创建当前样式逐渐改为新样式的动画效果 动画是使元素从一个样式逐渐变化为另一个样式的效果，可以改变任意多的样式任意多的次数 用百分比来规定变化发生的时间，或用 from 和 to，等同于 0% 和 100% 场景属性 div { width: 100px; height: 100px; background-color: aquamarine; /* 动画名称 */ animation-name: move; /* 动画花费时长 */ animation-duration: 2s; /* 动画速度曲线 */ animation-timing-function: ease-in-out; /* 动画等待多长时间执行 */ animation-delay: 2s; /* 规定动画播放次数 infinite: 无限循环 */ animation-iteration-count: infinite; /* 是否逆行播放 */ animation-direction: alternate; /* 动画结束之后的状态 */ animation-fill-mode: forwards; } 简写 animation: name duration timing-function delay iteration-count direction fill-mode 简写属性里面不包含 animation-paly-state 暂停动画 animation-paly-state: paused; 经常和鼠标经过等其他配合使用 要想动画走回来，而不是直接调回来：animation-direction: alternate 盒子动画结束后，停在结束位置：animation-fill-mode: forwards 3D转换 三维坐标系 3D 移动 translate3d /* 注意：x, y, z 对应的值不能省略，不需要填写用 0 进行填充 */ transform: translate3d(x, y, z) 透视 perspective 透视需要写在被视察元素的父盒子上面 body { perspective: 1000px; } 3D 旋转rotate 3D 旋转指可以让元素在三维平面内沿着 x 轴、y 轴、z 轴 或者自定义轴进行旋转 transform: rotate3d(x, y, z, deg) rotateY rotateX rotateZ /* 沿着对角线旋转 */ transform: rotate3d(1, 1, 0, 180deg) 3D 呈现 transform-style 控制子元素是否开启三维立体环境 transform-style: flat 代表子元素不开启 3D 立体空间，默认的 transform-style: preserve-3d 子元素开启立体空间 浏览器私有前缀 火狐-moz- ie-ms- -webkit- -o- MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"DSL/CSS/less.html":{"url":"DSL/CSS/less.html","title":"Less","keywords":"","body":"Less Less 是一门 CSS 预处理语言，它扩展了 CSS 语言，增加了变量、Mixin、函数等特性，使 CSS 更易维护和扩展 CSS弊端 冗余度高 没有计算能力 不方便维护扩展，不利于复用 安装 npm install -g less 使用 变量定义与使用 // 必须有@为前缀 // 不能包含特殊字符 // 不能以数字开头 // 大小写敏感 @color: pink; div { background-color: @color; } 样式嵌套 .header { width: 200px; a { color: white; } } // 如果遇见 （交集|伪类|伪元素选择器） ，利用&进行连接 .header { width: 200px; &:hover { color: white; } } 运算 任何数字、颜色或者变量都可以参与运算。就是Less提供了加（+）、减（-）、乘（*）、除（/）算术运算 @width: 10px + 5; // 对颜色进行运算 div { border: @width solid red+2; } // 对宽度运算 div { width: (@width + 5) * 2; } 对于两个不同的单位的值之间的运算，运算结果的值取第一个值的单位 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 09:12:04 "},"DSL/CSS/Bootstrap.html":{"url":"DSL/CSS/Bootstrap.html","title":"Bootstrap","keywords":"","body":"响应式布局 响应式需要一个父级做为布局容器，来配合子级元素来实现变化效果。 原理就是在不同屏幕下，通过媒体查询来改变这个布局容器的大小，再改变里面子元素的排列方式和大小，从而实现不同屏幕下，看到不同的页面布局和样式变化 Bootstrap 布局容器 container：两边留白 响应式布局的容器 固定宽度 大屏 ( >=1200px) 宽度定为 1170px 中屏 ( >=992px) 宽度定为 970px 小屏 ( >=768px) 宽度定为 750px 超小屏 (100%) container-fluid 百分百宽度 占据全部视口（viewport）的容器 栅格系统 按照不同屏幕划分为1~12 等份 行（row） 可以去除父容器作用15px的边距 xs-extra small：超小； sm-small：小； md-medium：中等； lg-large：大； 列（column）大于 12，多余的\"列（column）\"所在的元素将被作为一个整体另起一行排列 每一列默认有左右15像素的 padding 可以同时为一列指定多个设备的类名，以便划分不同份数 例如 class=\"col-md-4 col-sm-6\" 栅格嵌套 小列 小列 列偏移 1 2 列排序 左侧 右侧 响应式工具 使用这些工具类可以方便的针对不同设备展示或隐藏页面内容 visible-* 可达到相反的效果 文档 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"DSL/xml.html":{"url":"DSL/xml.html","title":"xml","keywords":"","body":"xml 与 html xml标签都是自定义的，html标签是预定义。 xml的语法严格，html语法松散 xml是存储数据的，html是展示数据 基本语法 xml文档的后缀名 .xml xml第一行必须定义为文档声明 xml文档中有且仅有一个根标签 属性值必须使用引号(单双都可)引起来 标签必须正确关闭 xml标签名称区分大小写 组成部分 文档声明 格式： 属性列表： version：版本号，必须的属性 encoding：编码方式。告知解析引擎当前文档使用的字符集，默认值：ISO-8859-1 standalone：是否独立 取值： yes：不依赖其他文件 no：依赖其他文件 标签 规则： 名称可以包含字母、数字以及其他的字符 名称不能以数字或者标点符号开始 名称不能以字母 xml（或者 XML、Xml 等等）开始 名称不能包含空格 属性属性 id属性值唯一 文本： CDATA区：在该区域中的数据会被原样展示 格式： 约束 DTD 内部dtd：将约束规则定义在xml文档中 外部dtd：将约束的规则定义在外部的dtd文件中 本地： 网络： Schema 解析 DOM：将标记语言文档一次性加载进内存，在内存中形成一颗dom树 优点：操作方便，可以对文档进行CRUD的所有操作 缺点：占内存 SAX：逐行读取，基于事件驱动的。 优点：不占内存。 缺点：只能读取，不能增删改 jsuop Jsoup：工具类，可以解析html或xml文档，返回Document parse Document：文档对象。代表内存中的dom树 getElementByXX Element：元素对象 getElementByXX Node：节点对象 快捷查询 selector XPath MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"DSL/GraphQL.html":{"url":"DSL/GraphQL.html","title":"GraphQL","keywords":"","body":" GraphQL 是由 Facebook 创造的用于描述复杂数据模型的一种查询语言。这里查询语言所指的并不是常规意义上的类似 sql 语句的查询语言，而是一种用于前后端数据查询方式的规范 Restful的不足 扩展性，单个RESTful接口返回数据越来越臃肿 某个前端展现，实际需要调用多个独立的RESTful API才能获取到足够的数据 GraphQL的优势 按需索取数据 一次查询多个数据 API演进无需划分版本 查询规范 字段 在GraphQL的查询中，请求结构中包含了所预期结果的结构，这个就是字段。并且响应的结构和请求结构基本一致 { hero { name } } { \"data\": { \"hero\": { \"name\": \"R2-D2\" } } } 参数 语法：(参数名:参数值) { human(id: \"1000\") { name height } } { \"data\": { \"human\": { \"name\": \"Luke Skywalker\", \"height\": 1.72 } } } 别名 如果一次查询多个相同对象，但是值不同，这个时候就需要起别名了，否则json的语法就不能通过了 { empireHero: hero(episode: EMPIRE) { name } jediHero: hero(episode: JEDI) { name } } { \"data\": { \"empireHero\": { \"name\": \"Luke Skywalker\" }, \"jediHero\": { \"name\": \"R2-D2\" } } } 片段 查询对的属相如果相同，可以采用片段的方式进行简化定义 { leftComparison: hero(episode: EMPIRE) { ...comparisonFields } rightComparison: hero(episode: JEDI) { ...comparisonFields } } fragment comparisonFields on Character { name appearsIn friends { name } } { \"data\": { \"leftComparison\": { \"name\": \"Luke Skywalker\", \"appearsIn\": [ \"NEWHOPE\", \"EMPIRE\", \"JEDI\" ], \"friends\": [ { \"name\": \"Han Solo\" }, { \"name\": \"Leia Organa\" }, { \"name\": \"C-3PO\" }, { \"name\": \"R2-D2\" } ] }, \"rightComparison\": { \"name\": \"R2-D2\", \"appearsIn\": [ \"NEWHOPE\", \"EMPIRE\", \"JEDI\" ], \"friends\": [ { \"name\": \"Luke Skywalker\" }, { \"name\": \"Han Solo\" }, { \"name\": \"Leia Organa\" } ] } } } Schema Schema 是用于定义数据结构的，比如说，User对象中有哪些属性，对象与对象之间是什么关系等 schema { #定义查询 query: UserQuery } type UserQuery { #定义查询的类型 user(id:ID) : User #指定对象以及参数类型 } type User {#定义对象 id:ID! # !表示该属性是非空项 name:String age:Int } 类型规范 标量类型 Int ：有符号 32 位整数。 Float ：有符号双精度浮点值。 String ：UTF‐8 字符序列。 Boolean ： true 或者 false 。 ID ： ID 标量类型表示一个唯一标识符，通常用以重新获取对象或者作为缓存中的键。 枚举类型 枚举类型是一种特殊的标量，它限制在一个特殊的可选值集合内 enum Episode { # 定义枚举 NEWHOPE EMPIRE JEDI } type Character { # 使用枚举 name: String! appearsIn: [Episode]! } 接口 跟许多类型系统一样，GraphQL 支持接口。一个接口是一个抽象类型，它包含某些字段，而对象类型必须包含这些字段，才能算实现了这个接口 interface Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! } type Human implements Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! starships: [Starship] totalCredits: Int } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"DSL/SQL.html":{"url":"DSL/SQL.html","title":"SQL","keywords":"","body":"SQL SQL查询语言概览 数据定义语言（DDL） 数据操纵语言（DML） 完整性 视图定义 事务控制 嵌入式SQL和动态SQL 授权 SQL数据定义 基本类型 char(n):固定长度的字符串（会追加空格） varchar(n):可变长度的字符串 int：整数类型 smallint：小整数类型（和机器相关） numeric(p,d):定点数，p位数，d位小数 real，double，precision：浮点数与双精度浮点数，精度与机器相关 float(n)：精度至少为n位的浮点数 基本模式定义 create table 命令的通用形式 CREATE TABLE r ( A1 D1, A2 D2, AN DN, , ); 示例： CREATE TABLE department( dept_name VARCHAR(20), building VARCHAR(15), budget NUMERIC(12,2), PRIMARY KEY(dept_name) ); 完整性约束 PRIMARY KEY：取值唯一 FOREIGN KEY:外键约束 NOT NULL :非空约束 SQL查询的基本结构 单关系查询 示例： SELECT name FROM instructor distnct 去除重复元组 SELECT子句还可进行加减乘除运算 WHERE子句选出满足条件的元组 多关系查询 示例： SELECT name,instructor.dept_name,building FROM instructor , department WHERE instructor.dept_name = department.dept_name 典型的SQL查询语句形式： SELECT A1,A2,A3,...,AN FROM R1,R2,...,RN WHERE P 笛卡尔积： 表1： name age 小明 15 小红 16 表2： grade school 5 中心小学 6 中心小学 两张表的笛卡尔积是： name age grade school 小明 15 5 中心小学 小红 16 6 中心小学 小明 15 6 中心小学 小红 16 5 中心小学 自然连接 SELECT name,instructor.dept_name,building FROM instructor , department WHERE instructor.dept_name = department.dept_name 上面那条SQL可以简化成下列形式： SELECT name,instructor.dept_name,building FROM instructor NATURAL JOIN department 附加的基本运算 更名运算 AS 关键字：可以修改列名 字符串运算 upper() lower() trim() LIKE 关键字： %表示匹配任何字符（包括什么都没有） _表示匹配一个字符 示例： SELECT name FROM user WHERE name LIKE 'user%' # 查找用户名以user开头的用户 escape :用来标志逃逸字符 LIKE 'ab\\\\cd%' escape '\\' #匹配所有以ab\\cd开头的字符串 SQL1999 中提供了similar to操作，语法类似于正则表达式 SELECT子句中的属性说明 可以用*代表所有列 排列元组的显示次序 ORDER BY 子句 DESC 降序 ASC 升序 SELECT name,age FROM student ORDER BY age DESC # 根据学生的年龄进行降序排序 WHERE 子句谓词 BETWEEN ... AND ... money BETWEEN 9000 AND 10000 等价于 money >= 9000 AND money NOT BETWEEN ... AND ... 上面的取反 集合运算 并运算 UNION关键字 SELECT name FROM student WHERE age = 15 UNION SELECT name FROM student WHERE age = 16 交运算 INTERSECT关键字 用法同上 差运算 EXCEPT 关键字 同上 空值 IS NULL 判断是空值 IS NOT NULL 判断非空 聚集函数 AVG:求平均值 MIN:求最小值 MAX:求最大值 SUM:求和 COUNT:计数 分组聚集 GROUP BY 子句： 根据后面的列进行分组 select TO_DAYS(create_time),COUNT(1) FROM web_log GROUP BY TO_DAYS(create_time) # 查询每天的访问次数 HAVING子句 满足HAVING后的条件才会被选择 select TO_DAYS(create_time),COUNT(1) FROM web_log GROUP BY TO_DAYS(create_time) HAVING COUNT(1)>1000 # 查询访问次数1000的那些天 嵌套子查询 SELECT username FROM user WHERE user_id IN (SELECT user FROM state); # 查询发表过动态的用户 集合比较 some:某一些满足即可 all：全部满足 SELECT username FROM user WHERE age > all (SELECT age FROM user WHERE sex = '女') # 查询出年龄大于全部女性年龄的用户 空关系测试 EXIST 关键字： 当改关键字后面的关系非空时返回true，反之返回false 相关子查询： SELECT user_id FROM user WHERE EXISTS (SELECT * FROM state WHERE user = user_id); # 查询发表过动态的用户ID 重复元组存在性测试 UNIQUE 关键字： 查询是否存在重复的元组 FROM子句中的子查询 SELECT * FROM (SELECT username FROM user) AS T; # 使用FROM子句子查询，有些数据库要求FROM后面的子查询需要指定一个别名 WITH子句 提供定义临时关系的方法 标量子查询 如果一个子查询的结果只有一个元组，那么可以放在单个值能出现的任何地方： SELECT username,(SELECT COUNT(1) FROM state WHERE state.user = user.user_id) FROM user; # 查询每个用户的用户名及其发表的动态条数 数据库的修改 删除 DELETE FROM r WHERE p 示例: DELETE FROM user WHERE username = 'root' # 删除用户名为root的用户 插入 INSERT INTO user VALUES(1,'username',15); # 这种方式需要指定全部列 INSERT INTO user(username,age) VALUES('username',15); # 这种方式不需要指定全部列 INSERT INTO user SELECT * FROM user; # 插入查询出来的元组 更新 UPDATE r SET k1=v1,k2=v2,...,kn=vn WHERE p UPDATE user SET username = 'abc' WHERE username = 'root' 连接表达式 连接条件 JOIN...ON... SELECT * FROM user JOIN user_info ON user.user_info = user_info.user_info_id; # 连接两个表，查询出用户所有信息 上面的查询等价于: SELECT * FROM user,user_info WHERE user.user_info = user_info.user_info_id 外连接 左外连接：只保留出现在左外连接左边的关系中的元组（如果没有符合连接条件的元组，左表的元组还是会被展示出来） 右外连接：只保留出现在右外连接运算右边关系中的元组 全外连接：保留出现在两个关系中的元组 左外连接： select * from user left outer join state on user.user_id = state.user; # 把user和state进行连接，如果用户没有发表state，则仍保留用户，只是state相关列为NULL 右外连接如上取反 全外连接：原理同上，不详细解释（mysql不支持） 连接类型和条件 natural join等价于natural inner join 视图 定义：不是逻辑模型的一部分，但是作为虚关系对用户可见 视图定义 CREATE VIEW v AS 创建一个部分用户视图： CREATE VIEW user_part AS SELECT * FROM user LIMIT 10 SQL查询中使用视图 再查询中，视图能出现在关系名可以出现的任何地方 SELECT * FROM user_part 物化视图 如果用于定义视图的实际关系改变，视图也跟着修改。这样的视图称为物化视图 视图更新 一般来说，满足下列所有条件，则视图是可更新的 FROM子句中只有一个数据库关系 SELECT子句只包含关系的属性名，不包含任何表达式聚集或DISTINCT声明 没有出现在SELECT子句中的属性可以去空值，也不是主码的一部分 查询中没有GROUP BY 和HAVING子句 事务 定义：事务内的所有语句要么全部执行，要么全部不执行 Commit work:提交当前事务 Rollback work：回滚当前事务 完整性约束 完整性约束防止的是对数据的意外破坏。 单个关系上的约束 NOT NULL约束 CREATE TABLE `user` ( `user_id` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(20) NOT NULL, `password` varchar(32) NOT NULL, `user_info` int(11) NOT NULL, `permission` int(11) NOT NULL, `create_time` datetime NOT NULL, `update_time` datetime NOT NULL, `last_login` datetime DEFAULT NULL, PRIMARY KEY (`user_id`), UNIQUE KEY `username` (`username`) ) ENGINE=InnoDB AUTO_INCREMENT=293 DEFAULT CHARSET=utf8 表示禁止在该属性上插入NULL值 UNIQUE 约束 被该约束修饰的属性在单个关系上是唯一的，由于NULL != NULL ，所以一个关系上允许存在多个NULL值 CHECK 子句 check(p) 指定一个谓词P，只有当该谓词满足时，数据库才允许插入 参照完整性 一个关系中给定属性集上的取值在另一关系的特定属性集的取值中出现，这种情况称为参照完整性 CREATE TABLE test( user_id INT, FOREIGN KEY (user_id) REFERENCES user(user_id) ); test表中的user_id参照user表的user_id 事务中对完整性约束的违反 如果事务中的某条SQL语句违反了完整性约束，则会马上进行检查。有些DBS支持将initially deferred加入到约束中，这样完整性约束检查就会在事务结束的时候进行。 复杂CHECK条件与断言 比如CHECK后面的谓词可以使用子查询： CREATE TABLE test( user_id INT CHECK(user_id IN( SELECT user.user_id FROM user)) ) 这样在插入test表时，只有在user表中出现的user_id才被允许插入，但是大多数数据库还不支持 断言： CREATE ASSERTION CHECK 任何在断言中涉及到的关系发生变动，都会触发断言。 SQL中的数据类型与模式 SQL中的日期和时间类型 DATE:日历日期，包括年月日 TIME :一天中的时间 TIMESTAMP ：DATE+TIME 与时间相关的函数： CURRENT_DATE：返回当前日期 CURRENT_TIME：返回当前时间 默认值 如 CREATE TABLE test( user_id INT DEFAULT 0 ); 当user_id未指定时，默认为0 创建索引 CREATE INDEX index_1 ON test(id) 大对象类型 BLOB CLOB 用户定义的类型 CREATE TABLE 的扩展 创建两个模式相同的表： CREATE TABLE test1 LIKE test 从查询中创建表： CREATE TABLE test2 AS ( SELECT * FROM test ) WITH DATA; # mysql不支持 模式、目录与环境 当代数据库提供了三层结构的关系命名机制，最顶层由目录构成，每个目录当中可以包含模式，目录 == 数据库。 默认目录和模式是为每个连接建立的SQL环境的一部分。 授权 授权读取 授权插入 授权更新 授权删除 权限的授予与收回 GRANT ON TO GRANT SELECT ON department TO user1 # 授予user1查询department表的权限 public:代表当前系统的所有用户以及未来用户 REVOKE ON FROM REVOKE SELECT ON department FROM user1 # 收回user1的查询权限 角色 创建角色： CREATE ROLE GRANT admin to user1; # 将admin角色授予user1 视图的授权 同上 模式的授权 GRANT REFERENCES (dept_name) ON department TO user1 # 允许user1创建这样的关系：它能参照department的dept_name 权限的转移 在授权语句最后加上 WITH GRANT OPTION 即允许用户可将权限授予给其他用户 权限的收回 默认情况下，多数DBS都会级联收回用户的权限 如果在收回语句最后加上 RESTRICT关键字，可以防止级联收回 存储过程 存储过程可以看成是对一系列 SQL 操作的批处理 代码复用 比较安全 性能较高 使用程序设计语言访问数据库 动态SQL:运行时构建SQL语句字符串与数据库进行交互 嵌入式SQL:SQL语句必须在编译时全部确定，由预处理器来连接宿主语言与数据库 JDBC 一段经典的JDBC代码： // 加载驱动 Class.forName(\"com.mysql.jdbc.Driver\"); // 获取连接 Connection connection = DriverManager.getConnection(\"jdbc:mysql:///test\",\"root\",\"Root@@715711877\"); // 执行SQL ResultSet resultSet = connection.prepareStatement(\"SELECT * FROM test\").executeQuery(); //取回结果集 while (resultSet.next()){ System.out.println(resultSet.getInt(\"id\")+\"|\" +resultSet.getString(\"name\")); } connection.close(); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-24 07:38:37 "},"中间件/nav.html":{"url":"中间件/nav.html","title":"中间件","keywords":"","body":"中间件 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 12:40:15 "},"中间件/数据库/数据库.html":{"url":"中间件/数据库/数据库.html","title":"数据库","keywords":"","body":"数据库 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-29 08:41:48 "},"中间件/数据库/mysql/mysql.html":{"url":"中间件/数据库/mysql/mysql.html","title":"MySQL","keywords":"","body":"MYSQL 架构 并发控制 读写锁 共享锁与独占锁 锁粒度 锁机制 MyISAM采用表级锁(table-level locking)。 InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁 对比 表级锁： MySQL中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。 行级锁： MySQL中锁定 粒度最小的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。 InnoDB存储引擎的锁的算法 Record lock：单个行记录上的锁 Gap lock：间隙锁，锁定一个范围，不包括记录本身 Next-key lock：record+gap 锁定一个范围，包含记录本身 多版本并发控制(MVCC) 行级锁的变种 避免了加锁操作 用户及权限管理 创建一个能在主机登录的用户 create user 'user2'@'%' identified by '123'; 授予权限 grant all on *.* to 'user2'@'%'; 复制 主从复制 binlog线程：将master服务器上的数据写入binlog io线程：读取master的binlog到replica的relay log（中继日志） sql线程：读取中继日志，将数据写入到replica 半同步复制与并行复制 主库上并行的操作，在从库上会串行执行，所以从库会有一定的数据延迟 半同步复制是主库接收到一个写命令会将这个写命令同步给从库，只有当收到至少一个从库的ack确认，才会认为写操作完成 并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志 由于这个特性，所以做主从分离写代码可能需要注意插入的数据，可能不一定能马上查到 搭建 master配置 server_id=177 ###服务器id log-bin=mysql-bin ###开启日志文件 show master status; # 查看master日志与当前日志位置 slave配置 server_id=178 ###从服务器server_id log-bin=mysql-bin ###日志文件同步方式 binlog_do_db=test ###同步数据库 show slave status; 从服务器执行 change master to master_host='192.168.182.131',master_user='root',master_password='123', master_log_file='mysql-bin.000002',master_log_pos=0; start slave 读写分离 主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作 读写分离提高性能的原因： 缓解了锁的争用 从服务器只做读，资源利用率更高 增加冗余数据，提高可用性 实现 常用代理方式实现，代理服务器根据传进来的请求，决定将请求转发到哪台服务器 设计规范 命名规范 数据库 [a-z ][0-9] _ 不超过30字符 备份数据库可以加自然数 表 [a-z ][0-9] _ 相同关系的表可以加相同的前缀 字段 [a-z ][0-9] _ 多个单词使用下划线分割 每个表必须有自增主键（默认系统时间） 关联字段名尽可能相同 字段类型规范 使用较少的空间来存储 ip最好使用int 固定长度的类型使用char 最好给默认值 索引规范 加一个index后缀 为每个表创建主键索引 符合索引慎重 范式规范 必须满足第二范式 尽量满足第三范式 MYSQL设计原则 核心原则 不在数据库做运算 控制列数量（20以内） 平衡范式与冗余 禁止大SQL 禁止大事务 禁止大批量 字段原则 用好数据类型节约空间 字符转为数字 避免使用NULL 少用text 索引原则 不在索引列做运算 innodb主键使用自增 不用外键 SQL原则 尽可能简单 简单事务 避免使用触发器，函数 不使用select * OR改写成IN或UNION 避免前% 慎用count（*） limit高效分页 少用连接join group by 使用同类型比较 打散批量更新 参数设置 general datadir=/var/lib/mysql 数据文件存放的目录 socket=/var/lib/mysql/mysql.sock mysql.socket表示server和client在同一台服务器，并且使用localhost进行连接，就会使用socket进行连接 pid_file=/var/lib/mysql/mysql.pid 存储mysql的pid port=3306 mysql服务的端口号 default_storage_engine=InnoDB mysql存储引擎 skip-grant-tables 当忘记mysql的用户名密码的时候，可以在mysql配置文件中配置该参数，跳过权限表验证，不需要密码即可登录mysql character character_set_client 客户端数据的字符集 character_set_connection mysql处理客户端发来的信息时，会把这些数据转换成连接的字符集格式 character_set_results mysql发送给客户端的结果集所用的字符集 character_set_database 数据库默认的字符集 character_set_server mysql server的默认字符集 connection max_connections mysql的最大连接数，如果数据库的并发连接请求比较大，应该调高该值 max_user_connections 限制每个用户的连接个数 back_log mysql能够暂存的连接数量，当mysql的线程在一个很短时间内得到非常多的连接请求时，就会起作用，如果mysql的连接数量达到max_connections时，新的请求会被存储在堆栈中，以等待某一个连接释放资源，如果等待连接的数量超过back_log,则不再接受连接资源 wait_timeout mysql在关闭一个非交互的连接之前需要等待的时长 interactive_timeout 关闭一个交互连接之前需要等待的秒数 log log_error 指定错误日志文件名称，用于记录当mysqld启动和停止时，以及服务器在运行中发生任何严重错误时的相关信息 log_bin 指定二进制日志文件名称，用于记录对数据造成更改的所有查询语句 binlog_do_db 指定将更新记录到二进制日志的数据库，其他所有没有显式指定的数据库更新将忽略，不记录在日志中 binlog_ignore_db 指定不将更新记录到二进制日志的数据库 sync_binlog 指定多少次写日志后同步磁盘 general_log 是否开启查询日志记录 general_log_file 指定查询日志文件名，用于记录所有的查询语句 slow_query_log 是否开启慢查询日志记录 slow_query_log_file 指定慢查询日志文件名称，用于记录耗时比较长的查询语句 long_query_time 设置慢查询的时间，超过这个时间的查询语句才会记录日志 log_slow_admin_statements 是否将管理语句写入慢查询日志 cache key_buffer_size 索引缓存区的大小（只对myisam表起作用） query cache query_cache_size 查询缓存的大小，未来版本被删除 show status like '%Qcache%';查看缓存的相关属性 Qcache_free_blocks：缓存中相邻内存块的个数，如果值比较大，那么查询缓存中碎片比较多 Qcache_free_memory：查询缓存中剩余的内存大小 Qcache_hits：表示有多少此命中缓存 Qcache_inserts：表示多少次未命中而插入 Qcache_lowmen_prunes：多少条query因为内存不足而被移除cache Qcache_queries_in_cache：当前cache中缓存的query数量 Qcache_total_blocks：当前cache中block的数量 query_cache_limit 超出此大小的查询将不被缓存 query_cache_min_res_unit 缓存块最小大小 query_cache_type 缓存类型，决定缓存什么样的查询 0表示禁用 1表示将缓存所有结果，除非sql语句中使用sql_no_cache禁用查询缓存 2表示只缓存select语句中通过sql_cache指定需要缓存的查询 sort_buffer_size 每个需要排序的线程分派该大小的缓冲区 max_allowed_packet=32M 限制server接受的数据包大小 join_buffer_size=2M 表示关联缓存的大小 thread_cache_size Threads_cached：代表当前此时此刻线程缓存中有多少空闲线程 Threads_connected：代表当前已建立连接的数量 Threads_created：代表最近一次服务启动，已创建现成的数量，如果该值比较大，那么服务器会一直再创建线程 Threads_running：代表当前激活的线程数 innodb innodb_buffer_pool_size= 该参数指定大小的内存来缓冲数据和索引，最大可以设置为物理内存的80% innodb_flush_log_at_trx_commit 主要控制innodb将log buffer中的数据写入日志文件并flush磁盘的时间点，值分别为0，1，2 innodb_thread_concurrency 设置innodb线程的并发数，默认为0表示不受限制，如果要设置建议跟服务器的cpu核心数一致或者是cpu核心数的两倍 innodb_log_buffer_size 此参数确定日志文件所用的内存大小，以M为单位 innodb_log_file_size 此参数确定数据日志文件的大小，以M为单位 innodb_log_files_in_group 以循环方式将日志文件写到多个文件中 read_buffer_size mysql读入缓冲区大小，对表进行顺序扫描的请求将分配到一个读入缓冲区 read_rnd_buffer_size mysql随机读的缓冲区大小 innodb_file_per_table 此参数确定为每张表分配一个新的文件 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-25 05:38:03 "},"中间件/数据库/mysql/基本使用.html":{"url":"中间件/数据库/mysql/基本使用.html","title":"基本使用","keywords":"","body":"基本使用 SQL 模式 STRICT_ALL_TABLES 和 STRICT_TRANS_TABLES： TRADITIONAL ANSI_QUOTES 告诉服务器把双引号是识别为标识符引用字符 PIPES_AS_CONCAT 将 || 当做连接运算符 ANSI 启动多种组合模式 设置模式： mysql ... --sql-model=\"xxx\" SET sql_mode='xx' SET GLOBAL sql_mode='xx' -- 全局模式 标识符与命名 不加双引号的标识符： 大小写字母 数字 美元符号 下划线组成 可以以数字开头 没有引号的命名不能全由数字构成 如果启用了 IGNORE_SPACE 模式 函数名会变成保留字 标识符的最大长度为64个字符 别名最大长度256字符 完全限定表名与完全限定列名：db.table.column 大小写规则 SQL 关键字与和函数名，存储过程的名字不区分大小写 数据库名 表名 视图名区分大小写取决于操作系统 列名、索引名不区分 别名区分 字符串区分大小写取决于是否是二进制串 为避免出现问题，统一采用小写 字符集与校对规则 字符集指的是一种从二进制编码到某类字符符号的映射。校对规则则是指某种字符集下的排序规则。MySQL中每一种字符集都会对应一系列的校对规则 MySQL采用的是类似继承的方式指定字符集的默认值，每个数据库以及每张数据表都有自己的默认值，他们逐层继承。比如：某个库中所有表的默认字符集将是该数据库所指定的字符集（这些表在没有指定字符集的情况下，才会采用默认字符集） SHOW CHARSET -- 列出可用字符集 unicode支持：utf8 utf8mb4 数据库操作 USE db; -- 切换数据库 CREATE DATABASE [IF NOT EXISTS] db [CHARSET xx] [COLLATE xxx]; -- 创建数据库 DROP DATABASE db; -- 删除数据库 ALTER DATABASE db [CHARSET xx] [COLLATE xxx]; -- 更改字符集与排序规则 表操作 CREATE TABLE [IF NOT EXISTS] (..) ENGINE = xxx DEFAULT CHARSET = xxx; -- 创建 ALTER TABLE (..) ENGINE = xxx DEFAULT CHARSET = xxx; -- 修改 CREATE TEMPORARY TABLE table (...); -- 临时表 会话关闭丢失 CREATE TABLE table LIKE xxx -- 复制其他表的结构 CREATE TABLE table SELECT ... -- 复制查询的数据 一些列的属性不会被复制 CREATE TABLE tr (id INT, name VARCHAR(50), purchased DATE) PARTITION BY RANGE( YEAR(purchased) ) ( PARTITION p0 VALUES LESS THAN (1990), PARTITION p1 VALUES LESS THAN (1995), PARTITION p2 VALUES LESS THAN (2000) ); -- 分区表 DROP TABLE [IF EXISTS] tb; -- 删除表 ALTER TABLE tb CHANGE cname cname INT; -- 改变列名并修改列类型 ALTER TABLE tb ENGINE = xxx; -- 更改存储引擎 ALTER TABLE tb RENAME TO tb1; -- 表重命名 索引 除了 PRIMARY KEY ,绝大部分索引可以使用CREATE IDNEX创建 CREATE UNIQUE INDEX name ON table (...); -- 唯一索引 单列中不允许有重复值出现 CREATE FULLTEXT INDEX name ON table (...); -- 全文索引 CREATE SPATIAL INDEX name ON table (...); -- myisam 空间索引 CREATE TABLE ( ... INDEX (name(10)) -- 对字符串前10个字符简历索引 ) DROP INDEX name ON tb; --删除索引 获取数据库元数据 show语句： 可以使用 LIKE 'xx' 限制输出范围 SHOW DATABASES; SHOW CREATE DATABASE db; -- 显示创建数据库时的语句 SHOW CREATE TABLE tb; SHOW TABLES; SHOW TABLE STATUS; SHOW COLUMNS FROM tb; SHOW INDEX FROM tb; INFORMATION_SCHEMA 库 事务处理 默认是开启执行SQL自动提交的 SET AUTOCOMMIT = 0; -- 关闭自动提交 START TRANSACTION; -- 开启事务 INSERT INTO person SET name = 'cxk'; -- 执行事务操作 COMMIT; -- 提交事务 -- ROLLBACK; 回滚事务 事务保存点 START TRANSACTION; insert into person SET name = 'cxkk'; SAVEPOINT myp; -- 保存一个事务点 insert into person SET name = 'cxkd'; ROLLBACK TO SAVEPOINT myp; -- 回滚到事务保存点 COMMIT; 事务隔离 设置隔离级别：SET [GLOBAL, SESSION] TRANSACTION ISOLATION LEVEL 在同一个事务中混合使用不同的存储引擎是不可靠的，有的存储引擎不支持事务 外键 CREATE TABLE tb( .. FOREIGN KEY (id) REFERENCES parent (id) ON DELETE CASCADE -- 删除父表相关行 子表也会被删除 ON UPDATE CASCADE -- 更新相关 -- ON DELETE SET NULL 删除时将相关列设置NULL ) 全文搜索 自然语言搜索 搜索字符串会被解析成单词进行搜索 布尔模式搜索 搜索出现某些单词的行 查询扩展搜索 先进行自然语言搜索 第二阶段将搜索字符串与第一阶段的结果进行拼接后搜索 特点： 需要建立全文索引 会忽略常见词 至少在一半的行都出现过的词 忽略内置常用词 after the 忽略过短的单词 使用： CREATE FULLTEXT INDEX index_actor_info ON actor_test(film_info); -- 创建相关全文索引 select * from actor_test where match(film_info) against('LUKE'); -- 自然语言搜索 select * from actor_test where match(film_info) against('LUKE CHISUM' IN BOOLEAN MODE); -- 布尔模式 select * from actor_test where match(film_info) against('LUKE CHISUM' WITH QUERY EXPANSION); -- 查询扩展 配置： ft_min_word_len=3 # 最小单词长度 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-25 05:38:03 "},"中间件/数据库/mysql/数据类型.html":{"url":"中间件/数据库/mysql/数据类型.html","title":"数据类型","keywords":"","body":"数据类型 数据值类别 数值： 精确值：整数 带小数点的数 位域值： b'1000' 代表8 字符串值： 'cxk' -- 推荐使用单引号 二进制串比较是逐字节比较 非二进制串根据排序规则比较 日期时间值: '2020-08-25' '11:47:00' '2020-08-25 11:47:00' SELECT '2020-08-25 11:47:00' + INTERVAL 2 DAY; 空间值：(10 20) 布尔值：0会被当成假 非0非NULL会被当成真 NULL值：\\N 会被当成NULL 整型 TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间，一般情况下越小的列越好 浮点数 FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型，DECIMAL 的计算比浮点类型需要更高的代价 字符串 一种是定长的(char)，一种是变长的(varchar)。 变长类型能够节省空间，因为只需要存储必要的内容，但当变长类型发生UPDATE操作后，需要执行额外的操作 存储和检索时，VARCHAR 末尾的空格会保留下来，而会 CHAR 末尾的空格会被删除 时间和日期 DATE TIME YEAR DATETIME 能够保存从 1000 年到 9999 年的日期和时间，精度为秒 时区无关 TIMESTAMP 和 UNIX 时间戳相同 应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高 序列 使用 AUTO_INCREMENT 来生成序列 通用 每个表只能有一个列具有 AUTO_INCREMENT 列必须建立索引 列为 NOT NULL 使用LAST_INSERT_ID()获取最后一个序号 插入0或NULL都会生成自增ID 某些存储引擎可以复用被删除的序列 存储引擎特有 MyISAM: 不会复用被删除的序列 默认从1开始 使用ALTER TABLE tb AUTO_INCREMENT = 10 语句更改当前序列的值\\ InnoDB: CREATE TABLE 时可以指定起始值 事务被回滚 序列不会混滚 需要考虑的问题 AUTO_INCREMENT 只能生成正整数序列 使用 UNSINGED 可以获得双倍的空间 TRUNCATE TABLE 会重置序列 不使用 AUTO_INCREMENT 生成序列 UPDATE seq SET n = LAST_INSERT_ID(n+1); -- 调用有参方法 下次无参调用就会返回n+1 INSERT INTO tb(..) VALUES(LAST_INSERT_ID()...) START TRANSACTION; UPDATE seq SET n = n+1; COMMIT; 表达式 SELECT (SELECT ...),.. FROM ...; -- 标量子查询提供单个值必须使用括号 运算符 算术： + - * / % DIV a DIV b 整除 逻辑： AND OR XOR NOT 位运算： & | ^ > 比较运算符： 类型转换 MySQL 会尽量将值转换成表达式所需要的类型 选择 具体对应的数据类型 考虑值是否在数据类型所对应的区间 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-26 03:27:57 "},"中间件/数据库/mysql/视图和存储程序.html":{"url":"中间件/数据库/mysql/视图和存储程序.html","title":"视图和存储程序","keywords":"","body":"视图和存储程序 视图 虚拟表 使用： CREATE VIEW v AS SELECT ...; CREATE VIEW v(c1,c2) AS SELECT ...; -- 对SELECT结果的列重命名 CREATE VIEW v AS SELECT id FROM tb WHERE i>1; UPDATE v SET i = i+1; -- 对于单张表的简单视图 是可以进行更新的 存储程序 存储过程 不能用在 sql 表达式中 可以返回多个结果集 CREATE PROCEDURE show_tables () SELECT * FROM information_schema.tables; CALL show_tables(); -- 调用存储过程 CREATE PROCEDURE print_2 () -- 复合语句 BEGIN SELECT * FROM staff; SELECT * FROM actor; END; -- 存储过程参数 CREATE PROCEDURE count_people_1(OUT ret INT) BEGIN SET ret = (SELECT COUNT(*) FROM staff); END; CALL count_people_1(@ret); SELECT @ret; 存储函数 可以有参数 有返回值 存储函数不能对调用它的那条语句正操作的表进行修改 CREATE FUNCTION count_people() RETURNS INT BEGIN RETURN (SELECT COUNT(*) FROM staff); END; SELECT count_people(); 触发器 -- 插入前检验 CREATE TRIGGER tri_person BEFORE INSERT ON person FOR EACH ROW BEGIN IF NEW.name != 'cxk' THEN SET NEW.name = 'cxk'; END IF; END; 事件 开启事件调度：SET GLOBAL event_scheduler = ON; -- 每秒插入一条记录 CREATE EVENT insert_people ON SCHEDULE EVERY 1 SECOND DO INSERT INTO person VALUES('cxk'); 安全性 对于视图或者存储程序 默认调用者的身份都是创建者 可以在CREATE 语句后面加上DEGINER = xxx 来指定定义者 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-26 03:27:57 "},"中间件/数据库/mysql/存储引擎.html":{"url":"中间件/数据库/mysql/存储引擎.html","title":"存储引擎","keywords":"","body":"存储引擎 大多数时候我们使用的都是 InnoDB 存储引擎，但是在某些情况下使用 MyISAM 也是合适的比如读密集的情况下 除非万不得已 否则不要混用引擎 查看可用引擎： show engines; MyISAM存储引擎 1、大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持。 2、当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成。 3、每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16 4、NULL被允许在索引的列中，这个值占每个键的0~1个字节 5、可以把数据文件和索引文件放在不同目录（InnoDB是放在一个目录里面的） InnoDB存储引擎 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎 1、InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事物安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合 2、InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎锁不能匹敌的 3、InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上 4、InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键 MEMORY存储引擎 1、MEMORY表的每个表可以有多达32个索引，每个索引16列，以及500字节的最大键长度 2、MEMORY存储引擎执行HASH和BTREE缩影 3、可以在一个MEMORY表中有非唯一键值 4、MEMORY表使用一个固定的记录长度格式 5、MEMORY不支持BLOB或TEXT列 6、MEMORY支持AUTO_INCREMENT列和对可包含NULL值的列的索引 7、MEMORY表在所由客户端之间共享（就像其他任何非TEMPORARY表） 8、MEMORY表内存被存储在内存中，内存是MEMORY表和服务器在查询处理时的空闲中，创建的内部表共享 9、当不再需要MEMORY表的内容时，要释放被MEMORY表使用的内存，应该执行DELETE FROM或TRUNCATE TABLE，或者删除整个表（使用DROP TABLE） 对比 功能 MYISAM Memory InnoDB Archive 存储限制 256TB RAM 64TB None 支持事务 No No Yes No 支持全文索引 Yes No Yes(5.6之后) No 支持数索引 Yes Yes Yes No 支持哈希索引 No Yes No No 支持数据缓存 No N/A Yes No 支持外键 No No Yes No 引擎转换 ALTER TABLE mysqldump导出数据 INSERT ... SELECT 语法 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-24 07:34:56 "},"中间件/数据库/mysql/索引.html":{"url":"中间件/数据库/mysql/索引.html","title":"索引","keywords":"","body":"索引 为什么使用索引 大大减少了服务器需要扫描的数据量 帮助服务器避免排序和临时表 将随机io变成顺序io 索引用处 快速查找匹配WHERE子句的行 从consideration中消除行,如果可以在多个索引之间进行选择，mysql通常会使用找到最少行的索引 如果表具有多列索引，则优化器可以使用索引的任何最左前缀来查找行 当有表连接的时候，从其他表检索行数据 查找特定索引列的min或max值 如果排序或分组时在可用索引的最左前缀上完成的，则对表进行排序和分组 在某些情况下，可以优化查询以检索值而无需查询数据行 索引使用条件 小表全表扫描效率优于索引 索引适合中大型表 特大型表，建立和维护索引的代价将会随之增长 一些索引数据结构 hash 可以直接根据key访问 但是无法进行范围查询 avl 平衡二叉树，左子树和右子树都是平衡二叉树，且左子树和右子树的深度之差的绝对值（平衡因子 ） 不超过1 支持范围查询 插入操作可能需要旋转，效率低 b+树 B+ Tree原理 B-tree减少了定位记录时所经历的中间过程，从而加快存取速度。普遍运用在数据库和文件系统 B+树中叶子节点中包含了key和value，非叶子节点中只是包含了key，不包含value 所有叶子节点位于同一层 操作 查找 首先在根节点进行二分查找，找到一个key的指针，接下来递归地不断向其非叶子节点查找，到了叶子节点，再进行二分查找，找出key所对应的data 修改操作会破坏平衡性，所以修改之后会进行分裂、合并、旋转 vs红黑树 红黑树的出度为2，B树的出度要大很多，所以B树的查找次数更少 B+ Tree能更好地利用磁盘的预读特性 MYSQL索引 技术名词 回表 最左匹配 索引下推 分类 主键索引 唯一索引 普通索引 全文索引 组合索引 B+ Tree索引 是大多数 MySQL 存储引擎的默认索引类型 除了用于查找，还可以用于排序和分组 适用于全键值、键值范围和键前缀查找 存储引擎的实现 MyISAM: B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引” InnoDB: 其数据文件本身就是索引文件。相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂 哈希索引 无法用于排序与分组 只支持精确查找，无法用于部分查找和范围查找 全文索引 MyISAM 存储引擎支持（innodb 5.6后支持） 用于查找文本中的关键词 查找条件使用 MATCH AGAINST 使用倒排索引 空间数据索引 间数据索引（R-Tree），可以用于地理数据存储 索引匹配方式 全值匹配 全值匹配指的是和索引中的所有列进行匹配 explain select * from staffs where name = 'July' and age = '23' and pos = 'dev' 匹配最左前缀 只匹配前面的几列 explain select * from staffs where name = 'July' and age = '23'; explain select * from staffs where name = 'July'; 匹配列前缀 可以匹配某一列的值的开头部分 explain select * from staffs where name like 'J%'; -- 可以用索引 explain select * from staffs where name like '%y'; -- 用不到索引 匹配范围值 可以查找某一个范围的数据 explain select * from staffs where name > 'Mary'; 精确匹配某一列并范围匹配另外一列 可以查询第一列的全部和第二列的部分 explain select * from staffs where name = 'July' and age > 25; 只访问索引的查询 查询的时候只需要访问索引，不需要访问数据行，本质上就是覆盖索引 explain select name,age,pos from staffs where name = 'July' and age = 25 and pos = 'dev'; 组合索引 当包含多个列作为索引，需要注意的是正确的顺序依赖于该索引的查询，同时需要考虑如何更好的满足排序和分组的需要 聚簇索引与非聚簇索引 聚簇索引：不是单独的索引类型，而是一种数据存储方式，指的是数据行跟相邻的键值紧凑的存储在一起 非聚簇索引：数据文件跟索引文件分开存放 覆盖索引 如果一个索引包含所有需要查询的字段的值，称之为覆盖索引 MyISAM和InnoDB对B+Tree的使用 MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录 myisam innodb 索引优化 如果表很大，性能下降？ 如果有索引，增删改都会变慢 少量查询仍然很快 但是并发大的时候会收到硬盘带宽影响 独立的列 进行查询时，索引列不能是表达式的一部分，也不能是函数的参数 SELECT a FROM B WHERE a+3 = 6; -- a不能作为索引 主键索引 尽量使用主键查询，而不是其他索引，因此主键查询不会触发回表查询 多列索引 多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好 组合索引 当一个索引不止一个列时，只有当最左索引（索引的第一个列）出现时，才会走索引查询 索引列的顺序 让选择性最强的索引列放在前面 一个列比另外一个列更越能确定一条数据，则前者选择性更强 前缀索引 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符 覆盖索引 索引包含所有需要查询的字段的值 只读取索引能大大减少数据访问量 一些存储引擎只缓存索引 索引扫描 使用索引扫描来排序 只有当索引的列顺序和order by子句的顺序完全一致，并且所有列的排序方式都一样时，mysql才能够使用索引来对结果进行排序 细节 union all,in,or都能够使用索引，但是推荐使用in 范围列可以用到索引 范围条件是：、>=、between 范围列可以用到索引，但是范围列后面的列无法用到索引，索引最多用于一个范围列 强制类型转换会全表扫描 更新十分频繁，数据区分度不高的字段上不宜建立索引 更新会变更B+树，更新频繁的字段建议索引会大大降低数据库性能 区分不大的属性，建立索引是没有意义的，不能有效的过滤数据 创建索引的列，不允许为null，可能会得到不符合预期的结果 当需要进行表连接的时候，最好不要超过三张表，因为需要join的字段，数据类型必须一致 三种join实现方式 能使用limit的时候尽量使用limit 单表索引建议控制在5个以内 单索引字段数不允许超过5个（组合索引） 一些错误概念： 索引越多越好 过早优化 索引监控 show status like 'Handler_read%'; Handler_read_first：读取索引第一个条目的次数 Handler_read_key：通过index获取数据的次数 Handler_read_last：读取索引最后一个条目的次数 Handler_read_next：通过索引读取下一条数据的次数 Handler_read_prev：通过索引读取上一条数据的次数 Handler_read_rnd：从固定位置读取数据的次数 Handler_read_rnd_next：从数据节点读取下一条数据的次数 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-20 01:20:48 "},"中间件/数据库/mysql/管理.html":{"url":"中间件/数据库/mysql/管理.html","title":"管理","keywords":"","body":"管理 MySQL 组件 服务器 mysqld 服务器主程序 mysql_safe 启动和监控 mysql_multi 同一主机管理多台MySQL 客户端和util mysql 客户端交互式程序 mysqladmin 管理数据库 mysqldump 备份或复制 mysqlcheck 检查分析优化或者修复表 myisamchk只适用于myisam 数据目录 位置：指定datadir配置项 结构 数据库的表示：文件目录 数据表的表示： InnoDB 系统表空间：只有一个.frm文件 独立表空间: .frm文件与索引文件.ibd MyISAM .frm 表结构描述 .MYD 数据文件 .MYI 索引文件 Memory 只有.frm存储表结构 将lower_case_table_name环境变量设置为1 MySQL 在操作表时 会将表名自动转换为小写字母 影响表最大长度的因素：操作系统文件大小 存储引擎内部限制 视图与触发器： 视图 .frm 触发器 .TRG 与 .TRN 状态与日志文件： 进程PID文件：写入进程PID 其他应用可以读取mysql的进程ID 从而进行一些操作 迁移数据目录 迁移之前需要停止服务器 常规管理 用户系统 SELECT Host, User,authentication_string,plugin FROM mysql.user; -- 查看用户信息 SET PASSWORD FOR root = 'root'; -- 修改密码 启动与运行 以非root用户运行 每次都以同一个用户身份运行 mysqladmin -p -u root shutdown # 关闭 设置系统变量 # my.ini [mysqld] max_connection=200 # 下划线跟-可以互换 innodb_buffer_pool_size=16M # 单位不填默认为字节 插件 # my.ini [mysqld] plugin-load=xxx,xxx 引擎 SELECT ENGINE, SUPPORT FROM INFORMATION_SCHEMA.ENGINES; -- 查看引擎 配置默认引擎：default_storage_engine 参数 访问控制与安全 维护 备份 复制 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-04 02:31:27 "},"中间件/数据库/mysql/数据库优化.html":{"url":"中间件/数据库/mysql/数据库优化.html","title":"优化","keywords":"","body":"数据库优化 对于优化最重要的事是测量 优化原因 避免网站出现访问错误 低效的查询导致数据库不稳定 优化用户体验 优化方面 硬件 系统配置 数据库表结构 SQL与索引 成本从下到上递增，效果从上到下递减 MYSQL优化 监控 show profile(逐渐淘汰) 使用show profile查询剖析工具，可以指定具体的type show profile cpu; all：显示所有性能信息 block io：显示块io操作的次数 context switches：显示上下文切换次数，被动和主动 cpu：显示用户cpu时间、系统cpu时间 IPC：显示发送和接受的消息数量 memory：内存 page faults：显示页错误数量 source：显示源码中的函数名称与位置 swaps：显示swap的次数 使用performance schema 使用show processlist查看连接的线程个数 开启慢查询 set global slow_query_log=ON; #开启慢查询 set global long_query_time=1.0; #设置记录时长为1秒 set global log_queries_not_using_indexes = ON; #不适用索引 慢查询日志地址： 地址存储在slow_query_log_file变量中 慢查询日志存储格式 # Time: 2019-11-29T06:01:43.909217Z 执行时间 # User@Host: root[root] @ localhost [] Id: 9 主机信息 # Query_time: 0.104442 查询时间 Lock_time: 0.000153 锁定时间 Rows_sent: 1 发送行数 Rows_examined: 16249 锁扫描行数 SET timestamp=1575007303; 执行时间戳 select count(*) from actor,payment; SQL 慢查询分析工具 mysqldumpslow mysqldumpslow -t 10 日志地址 # 分析前10条记录 pt-query-digest wget percona.com/get/pt-query-digest # 下载 chmod u+x pt-query-digest # 添加执行权限 /pt-query-digest 慢查询日志地址 # 分析日志 问题定位 次数多、时间长 IO大 未命中索引 查询执行计划 explain sql id: 1 select_type: SIMPLE # table: staff partitions: NULL type: index possible_keys: NULL key: idx_fk_store_id key_len: 1 ref: NULL rows: 2 filtered: 100.00 Extra: Using index id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符. select_type: SELECT 查询的类型. SIMPLE, 表示此查询不包含 UNION 查询或子查询 PRIMARY, 表示此查询是最外层的查询 UNION, 表示此查询是 UNION 的第二或随后的查询 DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT, UNION 的结果 SUBQUERY, 子查询中的第一个 SELECT DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果. table: 查询的是哪个表 partitions: 匹配的分区 type: join 类型 通常来说, 不同的 type 类型的性能关系:ALL possible_keys: 此次查询中可能选用的索引 key: 此次查询中确切使用到的索引 key_len:表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到 rows:估算 SQL 要查找到结果集需要扫描读取的数据行数，这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好 extra:EXplain 中的很多额外的信息会在 Extra 字段显示 Using filesort:表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果，一般有 Using filesort, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大 Using index：\"覆盖索引扫描\", 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错 Using temporary：查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化 索引优化 索引 创建索引 ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引 ALTER TABLE table_name ADD INDEX index_name (column_list) ALTER TABLE table_name ADD UNIQUE (column_list) ALTER TABLE table_name ADD PRIMARY KEY (column_list) CREATE INDEX可对表增加普通索引或UNIQUE索引 CREATE INDEX index_name ON table_name (column_list) CREATE UNIQUE INDEX index_name ON table_name (column_list) 获取索引 show keys from table_name 何时使用索引 主键列中创建索引 多表连接时连接列创建索引 where子句查询的列 需要经常GROUP BY和ORDER BY的列 索引优化 找出重复冗余索引 索引不包含NULL 短索引 排序的索引问题 like语句前%不会使用索引 列上运算问题 NOT IN会进行全表扫描 数据库结构优化 选择合适的数据类型 范式化 反范式化 垂直拆分 使用垂直切分将按数据库中表的密集程度部署到不同的库中 切分后部分表无法join，只能通过接口方式解决，提高了系统复杂度，存在分布式事务问题 水平拆分 当一个表的数据不断增多时，水平拆分是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力 分库分表 同上面的水平拆分，每张表或者每个库只存储一定量的数据，当需要进行数据读写时，根据唯一ID取模得到数据的位置 为什么分库分表能提高性能 将一张表的数据拆分成多个n张表进行存放，然后使用第三方中间件（MyCat或者Sharding-JDBC）可以并行查询 一些分库分表中间件 cobar，tddl，atlas，sharing-jdbc，my-cat 系统迁移到分库分表 如何将一个单裤单表的系统动态迁移到分库分表上去 停机迁移 禁止全部数据写入，编写一个程序，将单库单表的数据写到分库分表上 双写迁移 新系统部署后，每条数据都会在老库和新库写一遍 后台开启一个数据库迁移工具，这个工具负责把老库的数据写到新库去 写到新库的条件是，老库有的数据新库的没用或者是 老库的数据更新时间比新库的新 工具会比较新库与老库的每一条数据，只有每条数据都一致，才算完成，否则继续新一轮迁移 这样工具几轮操作过去后，新老库的数据就一致了 动态扩容缩容的分库分表方案 停机扩容 同上，只不过上面那是从单个数据库到多个数据库，这次这个是多个数据库到多个数据库 但是不推荐这种做法，原因是数据量很大，数据很难在短时间内转移完毕 第一次分库分表，就一次性给他分个够 32 个库，每个库 32 个表 这里可以多个库都在同一台机器上，当不够用的时候，可以将这些库转移到新机器上 这样，数据的逻辑位置没有发生改变，也避免扩容缩容带来的数据迁移问题 分库分表后的ID 使用一个系统来做自增ID的获取 redis、数据库自带的自增 多个节点的ID获取无法并行 不同的数据自增ID设置相同的步长不同的初始值，这样就能保证这些节点ID不会重复 但这种方式注定了数据库节点数量不能变化 uuid UUID组成部分:当前日期和时间+时钟序列+随机数+全局唯一的IEEE机器识别号 比较长，无法保证趋势递增，做索引时查询效率低 系统时间 可以使用业务字段来拼接避免重复 雪花算法 一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号 单个节点内无法并行 多个节点可以并行 可以支撑每秒几万的情况 拆分策略 使用水平拆分时，操作一条数据，要在哪张表找到它 哈希取模 范围，ID范围，时间范围 映射表 拆分后的问题 事务 使用分布式事务 连接 原来的连接需要分解成多个单表查询，在应用层进行连接 ID唯一性 全局唯一ID（GUID） 每个分片指定ID范围 分布式ID生成器，雪花算法 数据访问优化 减少请求的数据量 SELECT 只返回必要的列 使用LIMIT只返回必要的行 在内存缓存数据避免查询数据库 减少扫描行数 使用索引覆盖来覆盖查询 查询方式优化 分解大查询 一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源 分解大连接查询 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联 可以有效利用缓存 减少锁竞争 应用层拼接数据，数据库拆分更容易，从而做到高性能和可伸缩 单表查询效率可能比连接高 配置优化 设置文件最大打开数 设置最大连接数 设置back_log 存放等待连接的堆栈大小 interactive_timeout 缓冲区 key_buffer_size query_cache_size record_buffer_size read_rnd_buffer_size sort_buffer_size join_buffer_size tmp_table_size table_cache max_heap_table_size thread_cache_size thread_concurrency wait_timeout 关于InnoDB 执行顺序 FORM: 对FROM的左边的表和右边的表计算笛卡尔积。产生虚表VT1 ON: 对虚表VT1进行ON筛选，只有那些符合的行才会被记录在虚表VT2中。 JOIN： 如果指定了OUTER JOIN（比如left join、 right join），那么保留表中未匹配的行就会作为外部行添加到虚拟表VT2中，产生虚拟表VT3, rug from子句中包含两个以上的表的话，那么就会对上一个join连接产生的结果VT3和下一个表重复执行步骤1~3这三个步骤，一直到处理完所有的表为止。 WHERE： 对虚拟表VT3进行WHERE条件过滤。只有符合的记录才会被插入到虚拟表VT4中。 GROUP BY: 根据group by子句中的列，对VT4中的记录进行分组操作，产生VT5. CUBE | ROLLUP: 对表VT5进行cube或者rollup操作，产生表VT6. HAVING： 对虚拟表VT6应用having过滤，只有符合的记录才会被 插入到虚拟表VT7中。 SELECT： 执行select操作，选择指定的列，插入到虚拟表VT8中。 DISTINCT： 对VT8中的记录进行去重。产生虚拟表VT9. ORDER BY: 将虚拟表VT9中的记录按照进行排序操作，产生虚拟表VT10. LIMIT：取出指定行的记录，产生虚拟表VT11, 并将结果返回。 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-24 07:34:56 "},"中间件/数据库/mysql/performance.html":{"url":"中间件/数据库/mysql/performance.html","title":"performance schema","keywords":"","body":"MYSQL performance schema详解 0、performance_schema的介绍 ​ MySQL的performance schema 用于监控MySQL server在一个较低级别的运行过程中的资源消耗、资源等待等情况。 ​ 特点如下： ​ 1、提供了一种在数据库运行时实时检查server的内部执行情况的方法。performance_schema 数据库中的表使用performance_schema存储引擎。该数据库主要关注数据库运行过程中的性能相关的数据，与information_schema不同，information_schema主要关注server运行过程中的元数据信息 ​ 2、performanceschema通过监视server的事件来实现监视server内部运行情况， “事件”就是server内部活动中所做的任何事情以及对应的时间消耗，利用这些信息来判断server中的相关资源消耗在了哪里？一般来说，事件可以是函数调用、操作系统的等待、SQL语句执行的阶段（如sql语句执行过程中的parsing 或 sorting阶段）或者整个SQL语句与SQL语句集合。事件的采集可以方便的提供server中的相关存储引擎对磁盘文件、表I/O、表锁等资源的同步调用信息。 ​ 3、performance_schema中的事件与写入二进制日志中的事件（描述数据修改的events）、事件计划调度程序（这是一种存储程序）的事件不同。performance_schema中的事件记录的是server执行某些活动对某些资源的消耗、耗时、这些活动执行的次数等情况。 ​ 4、performance_schema中的事件只记录在本地server的performance_schema中，其下的这些表中数据发生变化时不会被写入binlog中，也不会通过复制机制被复制到其他server中。 ​ 5、 当前活跃事件、历史事件和事件摘要相关的表中记录的信息。能提供某个事件的执行次数、使用时长。进而可用于分析某个特定线程、特定对象（如mutex或file）相关联的活动。 ​ 6、PERFORMANCE_SCHEMA存储引擎使用server源代码中的“检测点”来实现事件数据的收集。对于performance_schema实现机制本身的代码没有相关的单独线程来检测，这与其他功能（如复制或事件计划程序）不同 ​ 7、收集的事件数据存储在performance_schema数据库的表中。这些表可以使用SELECT语句查询，也可以使用SQL语句更新performance_schema数据库中的表记录（如动态修改performance_schema的setup*开头的几个配置表，但要注意：配置表的更改会立即生效，这会影响数据收集） ​ 8、performance_schema的表中的数据不会持久化存储在磁盘中，而是保存在内存中，一旦服务器重启，这些数据会丢失（包括配置表在内的整个performance_schema下的所有数据） ​ 9、MySQL支持的所有平台中事件监控功能都可用，但不同平台中用于统计事件时间开销的计时器类型可能会有所差异。 1、performance schema入门 ​ 在mysql的5.7版本中，性能模式是默认开启的，如果想要显式的关闭的话需要修改配置文件，不能直接进行修改，会报错Variable 'performance_schema' is a read only variable。 --查看performance_schema的属性 mysql> SHOW VARIABLES LIKE 'performance_schema'; +--------------------+-------+ | Variable_name | Value | +--------------------+-------+ | performance_schema | ON | +--------------------+-------+ 1 row in set (0.01 sec) --在配置文件中修改performance_schema的属性值，on表示开启，off表示关闭 [mysqld] performance_schema=ON --切换数据库 use performance_schema; --查看当前数据库下的所有表,会看到有很多表存储着相关的信息 show tables; --可以通过show create table tablename来查看创建表的时候的表结构 mysql> show create table setup_consumers; +-----------------+--------------------------------- | Table | Create Table +-----------------+--------------------------------- | setup_consumers | CREATE TABLE `setup_consumers` ( `NAME` varchar(64) NOT NULL, `ENABLED` enum('YES','NO') NOT NULL ) ENGINE=PERFORMANCE_SCHEMA DEFAULT CHARSET=utf8 | +-----------------+--------------------------------- 1 row in set (0.00 sec) ​ 想要搞明白后续的内容，同学们需要理解两个基本概念： ​ instruments: 生产者，用于采集mysql中各种各样的操作产生的事件信息，对应配置表中的配置项我们可以称为监控采集配置项。 ​ consumers:消费者，对应的消费者表用于存储来自instruments采集的数据，对应配置表中的配置项我们可以称为消费存储配置项。 2、performance_schema表的分类 ​ performance_schema库下的表可以按照监视不同的纬度就行分组。 --语句事件记录表，这些表记录了语句事件信息，当前语句事件表events_statements_current、历史语句事件表events_statements_history和长语句历史事件表events_statements_history_long、以及聚合后的摘要表summary，其中，summary表还可以根据帐号(account)，主机(host)，程序(program)，线程(thread)，用户(user)和全局(global)再进行细分) show tables like '%statement%'; --等待事件记录表，与语句事件类型的相关记录表类似： show tables like '%wait%'; --阶段事件记录表，记录语句执行的阶段事件的表 show tables like '%stage%'; --事务事件记录表，记录事务相关的事件的表 show tables like '%transaction%'; --监控文件系统层调用的表 show tables like '%file%'; --监视内存使用的表 show tables like '%memory%'; --动态对performance_schema进行配置的配置表 show tables like '%setup%'; 3、performance_schema的简单配置与使用 ​ 数据库刚刚初始化并启动时，并非所有instruments(事件采集项，在采集项的配置表中每一项都有一个开关字段，或为YES，或为NO)和consumers(与采集项类似，也有一个对应的事件类型保存表配置项，为YES就表示对应的表保存性能数据，为NO就表示对应的表不保存性能数据)都启用了，所以默认不会收集所有的事件，可能你需要检测的事件并没有打开，需要进行设置，可以使用如下两个语句打开对应的instruments和consumers（行计数可能会因MySQL版本而异)。 --打开等待事件的采集器配置项开关，需要修改setup_instruments配置表中对应的采集器配置项 UPDATE setup_instruments SET ENABLED = 'YES', TIMED = 'YES'where name like 'wait%'; --打开等待事件的保存表配置开关，修改setup_consumers配置表中对应的配置项 UPDATE setup_consumers SET ENABLED = 'YES'where name like '%wait%'; --当配置完成之后可以查看当前server正在做什么，可以通过查询events_waits_current表来得知，该表中每个线程只包含一行数据，用于显示每个线程的最新监视事件 select * from events_waits_current\\G *************************** 1. row *************************** THREAD_ID: 11 EVENT_ID: 570 END_EVENT_ID: 570 EVENT_NAME: wait/synch/mutex/innodb/buf_dblwr_mutex SOURCE: TIMER_START: 4508505105239280 TIMER_END: 4508505105270160 TIMER_WAIT: 30880 SPINS: NULL OBJECT_SCHEMA: NULL OBJECT_NAME: NULL INDEX_NAME: NULL OBJECT_TYPE: NULL OBJECT_INSTANCE_BEGIN: 67918392 NESTING_EVENT_ID: NULL NESTING_EVENT_TYPE: NULL OPERATION: lock NUMBER_OF_BYTES: NULL FLAGS: NULL /*该信息表示线程id为11的线程正在等待buf_dblwr_mutex锁，等待事件为30880 属性说明： id:事件来自哪个线程，事件编号是多少 event_name:表示检测到的具体的内容 source:表示这个检测代码在哪个源文件中以及行号 timer_start:表示该事件的开始时间 timer_end:表示该事件的结束时间 timer_wait:表示该事件总的花费时间 注意：_current表中每个线程只保留一条记录，一旦线程完成工作，该表中不会再记录该线程的事件信息 */ /* _history表中记录每个线程应该执行完成的事件信息，但每个线程的事件信息只会记录10条，再多就会被覆盖，*_history_long表中记录所有线程的事件信息，但总记录数量是10000，超过就会被覆盖掉 */ select thread_id,event_id,event_name,timer_wait from events_waits_history order by thread_id limit 21; /* summary表提供所有事件的汇总信息，该组中的表以不同的方式汇总事件数据（如：按用户，按主机，按线程等等）。例如：要查看哪些instruments占用最多的时间，可以通过对events_waits_summary_global_by_event_name表的COUNT_STAR或SUM_TIMER_WAIT列进行查询（这两列是对事件的记录数执行COUNT（*）、事件记录的TIMER_WAIT列执行SUM（TIMER_WAIT）统计而来） */ SELECT EVENT_NAME,COUNT_STAR FROM events_waits_summary_global_by_event_name ORDER BY COUNT_STAR DESC LIMIT 10; /* instance表记录了哪些类型的对象会被检测。这些对象在被server使用时，在该表中将会产生一条事件记录，例如，file_instances表列出了文件I/O操作及其关联文件名 */ select * from file_instances limit 20; 4、常用配置项的参数说明 1、启动选项 performance_schema_consumer_events_statements_current=TRUE 是否在mysql server启动时就开启events_statements_current表的记录功能(该表记录当前的语句事件信息)，启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新setup_consumers配置表中的events_statements_current配置项，默认值为TRUE performance_schema_consumer_events_statements_history=TRUE 与performance_schema_consumer_events_statements_current选项类似，但该选项是用于配置是否记录语句事件短历史信息，默认为TRUE performance_schema_consumer_events_stages_history_long=FALSE 与performance_schema_consumer_events_statements_current选项类似，但该选项是用于配置是否记录语句事件长历史信息，默认为FALSE 除了statement(语句)事件之外，还支持：wait(等待)事件、state(阶段)事件、transaction(事务)事件，他们与statement事件一样都有三个启动项分别进行配置，但这些等待事件默认未启用，如果需要在MySQL Server启动时一同启动，则通常需要写进my.cnf配置文件中 performance_schema_consumer_global_instrumentation=TRUE 是否在MySQL Server启动时就开启全局表（如：mutex_instances、rwlock_instances、cond_instances、file_instances、users、hostsaccounts、socket_summary_by_event_name、file_summary_by_instance等大部分的全局对象计数统计和事件汇总统计信息表 ）的记录功能，启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新全局配置项 默认值为TRUE performance_schema_consumer_statements_digest=TRUE 是否在MySQL Server启动时就开启events_statements_summary_by_digest 表的记录功能，启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新digest配置项 默认值为TRUE performance_schema_consumer_thread_instrumentation=TRUE 是否在MySQL Server启动时就开启 events_xxx_summary_by_yyy_by_event_name表的记录功能，启动之后也可以在setup_consumers表中使用UPDATE语句进行动态更新线程配置项 默认值为TRUE performance_schema_instrument[=name] 是否在MySQL Server启动时就启用某些采集器，由于instruments配置项多达数千个，所以该配置项支持key-value模式，还支持%号进行通配等，如下: # [=name]可以指定为具体的Instruments名称（但是这样如果有多个需要指定的时候，就需要使用该选项多次），也可以使用通配符，可以指定instruments相同的前缀+通配符，也可以使用%代表所有的instruments ## 指定开启单个instruments --performance-schema-instrument= 'instrument_name=value' ## 使用通配符指定开启多个instruments --performance-schema-instrument= 'wait/synch/cond/%=COUNTED' ## 开关所有的instruments --performance-schema-instrument= '%=ON' --performance-schema-instrument= '%=OFF' 注意，这些启动选项要生效的前提是，需要设置performance_schema=ON。另外，这些启动选项虽然无法使用show variables语句查看，但我们可以通过setup_instruments和setup_consumers表查询这些选项指定的值。 2、系统变量 show variables like '%performance_schema%'; --重要的属性解释 performance_schema=ON /* 控制performance_schema功能的开关，要使用MySQL的performance_schema，需要在mysqld启动时启用，以启用事件收集功能 该参数在5.7.x之前支持performance_schema的版本中默认关闭，5.7.x版本开始默认开启 注意：如果mysqld在初始化performance_schema时发现无法分配任何相关的内部缓冲区，则performance_schema将自动禁用，并将performance_schema设置为OFF */ performance_schema_digests_size=10000 /* 控制events_statements_summary_by_digest表中的最大行数。如果产生的语句摘要信息超过此最大值，便无法继续存入该表，此时performance_schema会增加状态变量 */ performance_schema_events_statements_history_long_size=10000 /* 控制events_statements_history_long表中的最大行数，该参数控制所有会话在events_statements_history_long表中能够存放的总事件记录数，超过这个限制之后，最早的记录将被覆盖 全局变量，只读变量，整型值，5.6.3版本引入 * 5.6.x版本中，5.6.5及其之前的版本默认为10000，5.6.6及其之后的版本默认值为-1，通常情况下，自动计算的值都是10000 * 5.7.x版本中，默认值为-1，通常情况下，自动计算的值都是10000 */ performance_schema_events_statements_history_size=10 /* 控制events_statements_history表中单个线程（会话）的最大行数，该参数控制单个会话在events_statements_history表中能够存放的事件记录数，超过这个限制之后，单个会话最早的记录将被覆盖 全局变量，只读变量，整型值，5.6.3版本引入 * 5.6.x版本中，5.6.5及其之前的版本默认为10，5.6.6及其之后的版本默认值为-1，通常情况下，自动计算的值都是10 * 5.7.x版本中，默认值为-1，通常情况下，自动计算的值都是10 除了statement(语句)事件之外，wait(等待)事件、state(阶段)事件、transaction(事务)事件，他们与statement事件一样都有三个参数分别进行存储限制配置，有兴趣的同学自行研究，这里不再赘述 */ performance_schema_max_digest_length=1024 /* 用于控制标准化形式的SQL语句文本在存入performance_schema时的限制长度，该变量与max_digest_length变量相关(max_digest_length变量含义请自行查阅相关资料) 全局变量，只读变量，默认值1024字节，整型值，取值范围0~1048576 */ performance_schema_max_sql_text_length=1024 /* 控制存入events_statements_current，events_statements_history和events_statements_history_long语句事件表中的SQL_TEXT列的最大SQL长度字节数。 超出系统变量performance_schema_max_sql_text_length的部分将被丢弃，不会记录，一般情况下不需要调整该参数，除非被截断的部分与其他SQL比起来有很大差异 全局变量，只读变量，整型值，默认值为1024字节，取值范围为0~1048576，5.7.6版本引入 降低系统变量performance_schema_max_sql_text_length值可以减少内存使用，但如果汇总的SQL中，被截断部分有较大差异，会导致没有办法再对这些有较大差异的SQL进行区分。 增加该系统变量值会增加内存使用，但对于汇总SQL来讲可以更精准地区分不同的部分。 */ 5、重要配置表的相关说明 ​ 配置表之间存在相互关联关系，按照配置影响的先后顺序，可添加为 /* performance_timers表中记录了server中有哪些可用的事件计时器 字段解释： timer_name:表示可用计时器名称，CYCLE是基于CPU周期计数器的定时器 timer_frequency:表示每秒钟对应的计时器单位的数量,CYCLE计时器的换算值与CPU的频率相关、 timer_resolution:计时器精度值，表示在每个计时器被调用时额外增加的值 timer_overhead:表示在使用定时器获取事件时开销的最小周期值 */ select * from performance_timers; /* setup_timers表中记录当前使用的事件计时器信息 字段解释： name:计时器类型，对应某个事件类别 timer_name:计时器类型名称 */ select * from setup_timers; /* setup_consumers表中列出了consumers可配置列表项 字段解释： NAME：consumers配置名称 ENABLED：consumers是否启用，有效值为YES或NO，此列可以使用UPDATE语句修改。 */ select * from setup_consumers; /* setup_instruments 表列出了instruments 列表配置项，即代表了哪些事件支持被收集： 字段解释： NAME：instruments名称，instruments名称可能具有多个部分并形成层次结构 ENABLED：instrumetns是否启用，有效值为YES或NO，此列可以使用UPDATE语句修改。如果设置为NO，则这个instruments不会被执行，不会产生任何的事件信息 TIMED：instruments是否收集时间信息，有效值为YES或NO，此列可以使用UPDATE语句修改，如果设置为NO，则这个instruments不会收集时间信息 */ SELECT * FROM setup_instruments; /* setup_actors表的初始内容是匹配任何用户和主机，因此对于所有前台线程，默认情况下启用监视和历史事件收集功能 字段解释： HOST：与grant语句类似的主机名，一个具体的字符串名字，或使用“％”表示“任何主机” USER：一个具体的字符串名称，或使用“％”表示“任何用户” ROLE：当前未使用，MySQL 8.0中才启用角色功能 ENABLED：是否启用与HOST，USER，ROLE匹配的前台线程的监控功能，有效值为：YES或NO HISTORY：是否启用与HOST， USER，ROLE匹配的前台线程的历史事件记录功能，有效值为：YES或NO */ SELECT * FROM setup_actors; /* setup_objects表控制performance_schema是否监视特定对象。默认情况下，此表的最大行数为100行。 字段解释： OBJECT_TYPE：instruments类型，有效值为：“EVENT”（事件调度器事件）、“FUNCTION”（存储函数）、“PROCEDURE”（存储过程）、“TABLE”（基表）、“TRIGGER”（触发器），TABLE对象类型的配置会影响表I/O事件（wait/io/table/sql/handler instrument）和表锁事件（wait/lock/table/sql/handler instrument）的收集 OBJECT_SCHEMA：某个监视类型对象涵盖的数据库名称，一个字符串名称，或“％”(表示“任何数据库”) OBJECT_NAME：某个监视类型对象涵盖的表名，一个字符串名称，或“％”(表示“任何数据库内的对象”) ENABLED：是否开启对某个类型对象的监视功能，有效值为：YES或NO。此列可以修改 TIMED：是否开启对某个类型对象的时间收集功能，有效值为：YES或NO，此列可以修改 */ SELECT * FROM setup_objects; /* threads表对于每个server线程生成一行包含线程相关的信息， 字段解释： THREAD_ID：线程的唯一标识符（ID） NAME：与server中的线程检测代码相关联的名称(注意，这里不是instruments名称) TYPE：线程类型，有效值为：FOREGROUND、BACKGROUND。分别表示前台线程和后台线程 PROCESSLIST_ID：对应INFORMATION_SCHEMA.PROCESSLIST表中的ID列。 PROCESSLIST_USER：与前台线程相关联的用户名，对于后台线程为NULL。 PROCESSLIST_HOST：与前台线程关联的客户端的主机名，对于后台线程为NULL。 PROCESSLIST_DB：线程的默认数据库，如果没有，则为NULL。 PROCESSLIST_COMMAND：对于前台线程，该值代表着当前客户端正在执行的command类型，如果是sleep则表示当前会话处于空闲状态 PROCESSLIST_TIME：当前线程已处于当前线程状态的持续时间（秒） PROCESSLIST_STATE：表示线程正在做什么事情。 PROCESSLIST_INFO：线程正在执行的语句，如果没有执行任何语句，则为NULL。 PARENT_THREAD_ID：如果这个线程是一个子线程（由另一个线程生成），那么该字段显示其父线程ID ROLE：暂未使用 INSTRUMENTED：线程执行的事件是否被检测。有效值：YES、NO HISTORY：是否记录线程的历史事件。有效值：YES、NO * THREAD_OS_ID：由操作系统层定义的线程或任务标识符（ID）： */ select * from threads 注意：在performance_schema库中还包含了很多其他的库和表，能对数据库的性能做完整的监控，大家需要参考官网详细了解。 6、performance_schema实践操作 ​ 基本了解了表的相关信息之后，可以通过这些表进行实际的查询操作来进行实际的分析。 --1、哪类的SQL执行最多？ SELECT DIGEST_TEXT,COUNT_STAR,FIRST_SEEN,LAST_SEEN FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC --2、哪类SQL的平均响应时间最多？ SELECT DIGEST_TEXT,AVG_TIMER_WAIT FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC --3、哪类SQL排序记录数最多？ SELECT DIGEST_TEXT,SUM_SORT_ROWS FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC --4、哪类SQL扫描记录数最多？ SELECT DIGEST_TEXT,SUM_ROWS_EXAMINED FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC --5、哪类SQL使用临时表最多？ SELECT DIGEST_TEXT,SUM_CREATED_TMP_TABLES,SUM_CREATED_TMP_DISK_TABLES FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC --6、哪类SQL返回结果集最多？ SELECT DIGEST_TEXT,SUM_ROWS_SENT FROM events_statements_summary_by_digest ORDER BY COUNT_STAR DESC --7、哪个表物理IO最多？ SELECT file_name,event_name,SUM_NUMBER_OF_BYTES_READ,SUM_NUMBER_OF_BYTES_WRITE FROM file_summary_by_instance ORDER BY SUM_NUMBER_OF_BYTES_READ + SUM_NUMBER_OF_BYTES_WRITE DESC --8、哪个表逻辑IO最多？ SELECT object_name,COUNT_READ,COUNT_WRITE,COUNT_FETCH,SUM_TIMER_WAIT FROM table_io_waits_summary_by_table ORDER BY sum_timer_wait DESC --9、哪个索引访问最多？ SELECT OBJECT_NAME,INDEX_NAME,COUNT_FETCH,COUNT_INSERT,COUNT_UPDATE,COUNT_DELETE FROM table_io_waits_summary_by_index_usage ORDER BY SUM_TIMER_WAIT DESC --10、哪个索引从来没有用过？ SELECT OBJECT_SCHEMA,OBJECT_NAME,INDEX_NAME FROM table_io_waits_summary_by_index_usage WHERE INDEX_NAME IS NOT NULL AND COUNT_STAR = 0 AND OBJECT_SCHEMA <> 'mysql' ORDER BY OBJECT_SCHEMA,OBJECT_NAME; --11、哪个等待事件消耗时间最多？ SELECT EVENT_NAME,COUNT_STAR,SUM_TIMER_WAIT,AVG_TIMER_WAIT FROM events_waits_summary_global_by_event_name WHERE event_name != 'idle' ORDER BY SUM_TIMER_WAIT DESC --12-1、剖析某条SQL的执行情况，包括statement信息，stege信息，wait信息 SELECT EVENT_ID,sql_text FROM events_statements_history WHERE sql_text LIKE '%count(*)%'; --12-2、查看每个阶段的时间消耗 SELECT event_id,EVENT_NAME,SOURCE,TIMER_END - TIMER_START FROM events_stages_history_long WHERE NESTING_EVENT_ID = 1553; --12-3、查看每个阶段的锁等待情况 SELECT event_id,event_name,source,timer_wait,object_name,index_name,operation,nesting_event_id FROM events_waits_history_longWHERE nesting_event_id = 1553; MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-29 08:41:48 "},"中间件/数据库/mysql/schema与数据类型优化.html":{"url":"中间件/数据库/mysql/schema与数据类型优化.html","title":"schema与数据类型优化","keywords":"","body":"schema与数据类型优化 数据类型 更小的通常更好（保证范围够用的情况下） 简单就好 整型比字符串操作更低 尽量避免使用null 对mysql来说很难优化，因为可为null的列使得索引、索引统计和值比较都更加复杂 实际细则 字符串 按照查询速度：char>varchar>text varchar根据实际内容长度保存数据 char固定长度的字符串 最大长度：255 会自动删除末尾的空格 BLOB与TEXT 两者都是为了存储很大数据而设计的字符串类型，分别采用二进制和字符方式存储。 日期时间 datetime 与时区无关，数据库底层时区配置，对datetime无效 可保存到毫秒 timestamp 时间范围：1970-01-01到2038-01-19 date date类型用于保存1000-01-01到9999-12-31之间的日期 使用枚举替代字符串 特殊数据类型 IP使用整数表示 范式与反范式 范式化的更新通常比反范式要快 好的范式可以减少冗余 通常需要进行关联 而反范式所有的数据都在同一张表中，可以避免关联 可以设计有效的索引 表格内的冗余较多，删除数据时候会造成表有些有用的信息丢失 主键 代理主键：与业务无关的，无意义的数字序列 不与业务耦合，因此更容易维护 通用的键策略能够减少需要编写的源码数量，减少系统的总体拥有成本 自然主键：事物属性中的自然唯一标识 字符集 纯拉丁字符能表示的内容，没必要选择 latin1 之外的其他字符编码，因为这会节省大量的存储空间 如果我们可以确定不需要存放多种语言，就没必要非得使用UTF8或者其他UNICODE字符类型 MySQL的数据类型可以精确到字段，可以通过对不同表不同字段使用不同的数据类型来较大程度减小数据存储量 数据冗余 (物化视图) 被频繁引用且只能通过 Join 2张(或者更多)大表的方式才能得到的独立小字段 可以将这些字段独立出一张表 冗余的同时需要确保数据的一致性不会遭到破坏，确保更新的同时冗余字段也被更新 适当拆分 对于一些如TEXT 大VARCHAR 数据时 可以将这些大数据字段拆分到另一个表 降低IO压力 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-30 03:14:22 "},"中间件/数据库/mysql/执行计划.html":{"url":"中间件/数据库/mysql/执行计划.html","title":"执行计划","keywords":"","body":"执行计划 ​ 在企业的应用场景中，为了知道优化SQL语句的执行，需要查看SQL语句的具体执行过程，以加快SQL语句的执行效率。 ​ 可以使用explain+SQL语句来模拟优化器执行SQL查询语句，从而知道mysql是如何处理sql语句的。 ​ 官网地址： https://dev.mysql.com/doc/refman/5.5/en/explain-output.html 1、执行计划中包含的信息 Column Meaning id The SELECT identifier select_type The SELECT type table The table for the output row partitions The matching partitions type The join type possible_keys The possible indexes to choose key The index actually chosen key_len The length of the chosen key ref The columns compared to the index rows Estimate of rows to be examined filtered Percentage of rows filtered by table condition extra Additional information id select查询的序列号，包含一组数字，表示查询中执行select子句或者操作表的顺序 id号分为三种情况： ​ 1、如果id相同，那么执行顺序从上到下 explain select * from emp e join dept d on e.deptno = d.deptno join salgrade sg on e.sal between sg.losal and sg.hisal; ​ 2、如果id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行 explain select * from emp e where e.deptno in (select d.deptno from dept d where d.dname = 'SALES'); ​ 3、id相同和不同的，同时存在：相同的可以认为是一组，从上往下顺序执行，在所有组中，id值越大，优先级越高，越先执行 explain select * from emp e join dept d on e.deptno = d.deptno join salgrade sg on e.sal between sg.losal and sg.hisal where e.deptno in (select d.deptno from dept d where d.dname = 'SALES'); select_type 主要用来分辨查询的类型，是普通查询还是联合查询还是子查询 select_type Value Meaning SIMPLE Simple SELECT (not using UNION or subqueries) PRIMARY Outermost SELECT UNION Second or later SELECT statement in a UNION DEPENDENT UNION Second or later SELECT statement in a UNION, dependent on outer query UNION RESULT Result of a UNION. SUBQUERY First SELECT in subquery DEPENDENT SUBQUERY First SELECT in subquery, dependent on outer query DERIVED Derived table UNCACHEABLE SUBQUERY A subquery for which the result cannot be cached and must be re-evaluated for each row of the outer query UNCACHEABLE UNION The second or later select in a UNION that belongs to an uncacheable subquery (see UNCACHEABLE SUBQUERY) --sample:简单的查询，不包含子查询和union explain select * from emp; --primary:查询中若包含任何复杂的子查询，最外层查询则被标记为Primary explain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ; --union:若第二个select出现在union之后，则被标记为union explain select * from emp where deptno = 10 union select * from emp where sal >2000; --dependent union:跟union类似，此处的depentent表示union或union all联合而成的结果会受外部表影响 explain select * from emp e where e.empno in ( select empno from emp where deptno = 10 union select empno from emp where sal >2000) --union result:从union表获取结果的select explain select * from emp where deptno = 10 union select * from emp where sal >2000; --subquery:在select或者where列表中包含子查询 explain select * from emp where sal > (select avg(sal) from emp) ; --dependent subquery:subquery的子查询要受到外部表查询的影响 explain select * from emp e where e.deptno in (select distinct deptno from dept); --DERIVED: from子句中出现的子查询，也叫做派生类， explain select staname,ename supname from (select ename staname,mgr from emp) t join emp on t.mgr=emp.empno ; --UNCACHEABLE SUBQUERY：表示使用子查询的结果不能被缓存 explain select * from emp where empno = (select empno from emp where deptno=@@sort_buffer_size); --uncacheable union:表示union的查询结果不能被缓存：sql语句未验证 table 对应行正在访问哪一个表，表名或者别名，可能是临时表或者union合并结果集 1、如果是具体的表名，则表明从实际的物理表中获取数据，当然也可以是表的别名 ​ 2、表名是derivedN的形式，表示使用了id为N的查询产生的衍生表 ​ 3、当有union result的时候，表名是union n1,n2等的形式，n1,n2表示参与union的id type type显示的是访问类型，访问类型表示我是以何种方式去访问我们的数据，最容易想的是全表扫描，直接暴力的遍历一张表去寻找需要的数据，效率非常低下，访问的类型有很多，效率从最好到最坏依次是： system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL 一般情况下，得保证查询至少达到range级别，最好能达到ref --all:全表扫描，一般情况下出现这样的sql语句而且数据量比较大的话那么就需要进行优化。 explain select * from emp; --index：全索引扫描这个比all的效率要好，主要有两种情况，一种是当前的查询时覆盖索引，即我们需要的数据在索引中就可以索取，或者是使用了索引进行排序，这样就避免数据的重排序 explain select empno from emp; --range：表示利用索引查询的时候限制了范围，在指定范围内进行查询，这样避免了index的全索引扫描，适用的操作符： =, <>, >, >=, possible_keys ​ 显示可能应用在这张表中的索引，一个或多个，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用 explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; key ​ 实际使用的索引，如果为null，则没有使用索引，查询中若使用了覆盖索引，则该索引和查询的select字段重叠。 explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; key_len 表示索引中使用的字节数，可以通过key_len计算查询中使用的索引长度，在不损失精度的情况下长度越短越好。 explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; ref 显示索引的哪一列被使用了，如果可能的话，是一个常数 explain select * from emp,dept where emp.deptno = dept.deptno and emp.deptno = 10; rows 根据表的统计信息及索引使用情况，大致估算出找出所需记录需要读取的行数，此参数很重要，直接反应的sql找了多少数据，在完成目的的情况下越少越好 explain select * from emp; extra 包含额外的信息。 --using filesort:说明mysql无法利用索引进行排序，只能利用排序算法进行排序，会消耗额外的位置 explain select * from emp order by sal; --using temporary:建立临时表来保存中间结果，查询完成之后把临时表删除 explain select ename,count(*) from emp where deptno = 10 group by ename; --using index:这个表示当前的查询时覆盖索引的，直接从索引中读取数据，而不用访问数据表。如果同时出现using where 表名索引被用来执行索引键值的查找，如果没有，表面索引被用来读取数据，而不是真的查找 explain select deptno,count(*) from emp group by deptno limit 10; --using where:使用where进行条件过滤 explain select * from t_user where id = 1; --using join buffer:使用连接缓存，情况没有模拟出来 --impossible where：where语句的结果总是false explain select * from emp where empno = 7469; MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-30 03:14:22 "},"中间件/数据库/mysql/查询优化.html":{"url":"中间件/数据库/mysql/查询优化.html","title":"查询优化","keywords":"","body":"查询优化 查询慢的原因 网络 CPU IO 上下文切换 系统调用 生成统计信息 锁等待 优化数据访问 查询性能低下的主要原因是访问的数据太多 需要避免检索、传输大量数据 执行过程优化 查询缓存 查询优化处理 计算的依据 每个表或者索引的页面个数 索引的基数 索引和数据行的长度 索引的分布情况 很多情况下mysql会选择错误的执行计划 优化策略 静态优化 直接对解析树进行分析，并完成优化 动态优化 动态优化与查询的上下文有关，也可能跟取值、索引对应的行数有关 优化类型 重新定义关联表的顺序 将外连接转化成内连接，内连接的效率要高于外连接 使用等价变换规则，mysql可以使用一些等价变化来简化并规划表达式 优化count(),min(),max() 预估并转化为常数表达式，当mysql检测到一个表达式可以转化为常数的时候，就会一直把该表达式作为常数进行处理 索引覆盖扫描，当索引中的列包含所有查询中需要使用的列的时候，可以使用覆盖索引 子查询优化 等值传播 排序优化 优化特定类型查询 count 查询 只有没有任何where条件的count(*)才是比较快的 不需要完全精确的值，可以参考使用近似值来代替，比如可以使用explain来获取近似的值 实际操作的时候可以考虑使用索引覆盖扫描，或者增加汇总表，或者增加外部缓存系统 关联查询 确保on或者using子句中的列上有索引 确保任何的groupby和order by中的表达式只涉及到一个表中的列 子查询优化 使用关联查询替代 limit 分页优化 优化此类查询的最简单的办法就是尽可能地使用覆盖索引，而不是查询所有的列 优化union查询 除非确实需要服务器消除重复的行，否则一定要使用union all 使用用户自定义变量 使用索引 索引的原理： MySQL 使用索引的方式： WHERE ORDER BY GROUP PY子句 对于使用MIN MAX函数的查询直接使用索引就可完成 对于某些查询 只使用索引的数据就可返回 无需回表查询 索引的代价： 降低了大部分写操作的速度 占用磁盘空间 挑选索引： 用于搜索 排序 分组的列 列的基数(列的值不重复的个数)越高 索引效果越好 索引尽量选择较小的数据类型 IO 操作更快 降低存储空间需求 可以在缓存中缓存更多数据 加快速度 字符串索引指定前缀长度 大多数字符串前n个字符就足以是唯一的 当成索引 最左索引 对于(a,b,c)这种类型的复合索引 利用其排列顺序进行操作 能有效利用索引 不要过多的索引 保持参与比较的索引类型匹配 散列 B+树 查询优化程序 EXPLAIN SELECT * FROM person WHERE FALSE 有助于优化程序对索引充分利用： 分析表 ANALYZE TABLE 生成键值分析 使用 EXPLAIN 验证哪些索引会被使用到 必要时给予 EXPLAIN提示 表名后面加上FORE INDEX, USE INDEX, IGNORE INDEX STRAIGHT_JOIN要求按特定顺序使用表 比较的列数据类型相同 索引列不要参与运算 LIKE 语句开始位置不要使用通配符 将子查询转换为连接 尝试查收的各种替代形式 避免过多类型的自动转换 数据类型高效查询 多用数字运算 少用字符串运算 ENUM SET 优先使用较小数据类型 加快操作速度 节省存储空间 数据列声明NOT NULL 避免 MySQL 运行时检查 NULL 考虑使用ENUM 输出MySQL对数据类型的建议 SELECT * FROM tb PROCEDURE ANALYSE() 整理表碎片 OPTIMIZE TABLE tb 某些存储引擎不支持 使用mysqldump导出再导入来整理 使用BLOB TEXT存储非结构化数据 注意删除更新时留下的碎片 避免过大 抽离到一张独立的表 合成索引 计算一个散列值存放到一个列 表存储格式高效查询 MyISAM: 默认使用固定长度的行 当某个列长度可变时 则行也会变成可变 固定长度的行比变长行处理速度比较快 MEMORY: 使用都是固定长度的行 InnoDB： 默认情况是COMPACT行格式 对于包含重复数据表 使用 COMPRESSED航格式 占用空间较少 带有TEXT 或 BLOB 使用 DYNAMIC CREATE TABLE tb (...) ROW_FORMAT = xxx; 高效加载数据 LOAD DATA 比 INSERT 效率更高 数据加载时磁盘IO操作越少 效率越高 调度 锁定 并发 调度策略： 写入优先级比读取优先级高 写入操作一次只能执行一个 写入操作时公平的 可以同时处理多个对同一个表的读取 InnoDB: 行级锁 更精细 并发度更高 MyISAM: 表级锁 不会出现死锁问题 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-27 03:11:55 "},"中间件/数据库/mysql/分区表.html":{"url":"中间件/数据库/mysql/分区表.html","title":"分区表","keywords":"","body":"分区表 mysql> CREATE TABLE tr (id INT, name VARCHAR(50), purchased DATE) -> PARTITION BY RANGE( YEAR(purchased) ) ( -> PARTITION p0 VALUES LESS THAN (1990), -> PARTITION p1 VALUES LESS THAN (1995), -> PARTITION p2 VALUES LESS THAN (2000), -> PARTITION p3 VALUES LESS THAN (2005), -> PARTITION p4 VALUES LESS THAN (2010), -> PARTITION p5 VALUES LESS THAN (2015) -> ); 应用场景 表非常大以至于无法全部都放在内存中，或者只在表的最后部分有热点数据，其他均是历史数据 分区表的数据更容易维护 批量删除大量数据可以使用清除整个分区的方式 对一个独立分区进行优化、检查、修复等操作 分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备 可以使用分区表来避免某些特殊的瓶颈 innodb的单个索引的互斥访问 ext3文件系统的inode锁竞争 可以备份和恢复独立的分区 分区表的限制 一个表最多只能有1024个分区，在5.7版本的时候可以支持8196个分区 在早期的mysql中，分区表达式必须是整数或者是返回整数的表达式，在mysql5.5中，某些场景可以直接使用列来进行分区 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来 分区表无法使用外键约束 原理 select查询 ​ 当查询一个分区表的时候，分区层先打开并锁住所有的底层表，优化器先判断是否可以过滤部分分区，然后再调用对应的存储引擎接口访问各个分区的数据 ​ insert操作 ​ 当写入一条记录的时候，分区层先打开并锁住所有的底层表，然后确定哪个分区接受这条记录，再将记录写入对应底层表 ​ delete操作 ​ 当删除一条记录时，分区层先打开并锁住所有的底层表，然后确定数据对应的分区，最后对相应底层表进行删除操作 ​ update操作 ​ 当更新一条记录时，分区层先打开并锁住所有的底层表，mysql先确定需要更新的记录再哪个分区，然后取出数据并更新，再判断更新后的数据应该再哪个分区，最后对底层表进行写入操作，并对源数据所在的底层表进行删除操作 分区表类型 范围分区 根据列值在给定范围内将行分配给分区 列表分区 类似于按range分区，区别在于list分区是基于列值匹配一个离散值集合中的某个值来进行选择 列分区 mysql从5.5开始支持column分区，可以认为i是range和list的升级版，在5.5之后，可以使用column分区替代range和list，但是column分区只接受普通列不接受表达式 hash分区 基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含myql中有效的、产生非负整数值的任何表达式 key分区 类似于hash分区，区别在于key分区只支持一列或多列，且mysql服务器提供其自身的哈希函数，必须有一列或多列包含整数值 子分区 在分区的基础之上，再进行分区后存储 分区表使用 全量扫描数据，不需要任何索引 根据分区规则大致定位需要的数据为止，通过使用where条件将需要的数据限制在少数分区中，这种策略适用于以正常的方式访问大量数据 索引数据，并分离热点 如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将这部分热点数据单独放在一个分区中，让这个分区的数据能够有机会都缓存在内存中 注意问题 null值会使分区过滤无效 分区列和索引列不匹配，会导致查询无法进行分区过滤 选择分区的成本可能很高 打开并锁住所有底层表的成本可能很高 维护分区的成本可能很高 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-05 03:54:19 "},"中间件/数据库/Oracle.html":{"url":"中间件/数据库/Oracle.html","title":"Oracle","keywords":"","body":"体系结构 基本操作 创建表空间 create tablespace test datafile 'd:\\test.dbf' size 100m autoextend on next 10m 删除表空间 drop tablespace test 创建用户 create user root identified by root default tablespace test 角色 CONNECT角色： --是授予最终用户的典型权利，最基本的 RESOURCE角色： --是授予开发人员的 DBA角色：拥有全部特权，是系统最高权限，只有DBA才可以创建数据库结构，并且系统权限也需要DBA授出，且DBA用户可以操作全体用户的任意基表，包括删除 授权 grant dba to root 数据类型 数据类型 描述 Varchar， varchar2 表示一个字符串 NUMBER NUMBER(n)表示一个整数，长度是n,NUMBER(m,n):表示一个小数，总长度是m，小数是n，整数是m-n DATA 表示日期类型 CLOB 大对象，表示大文本数据类型，可存4G BLOB 大对象，表示二进制数据，可存4G 序列 创建序列 create sequence s_person 使用 select s_person.nextval from dual; insert into person values(s_person.nextval,'123'); 查询 单行函数 upper lower ROUND:四舍五入 trunc MONTHS_BETWEEN TO_CHAR nvl 条件表达式 select t.empno, t.ename, case when t.job = 'CLERK' then '业务员' when t.job = 'MANAGER' then '经理' when t.job = 'ANALYST' then '分析员' when t.job = 'PRESIDENT' then '总裁' when t.job = 'SALESMAN' then '销售' else '无业' end from emp t 多行函数 聚合函数 分页查询 select * from (select rownum r ,emp.* from emp) b where b.r >5 and b.r 视图 索引 PLSQL MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-24 07:38:37 "},"中间件/数据库/redis/Redis.html":{"url":"中间件/数据库/redis/Redis.html","title":"Redis","keywords":"","body":"redis redis是一款高性能的NOSQL系列的非关系型数据库 应用场景 缓存 实时性要求高的数据 消息队列 热点数据 计数器 数据过期处理（可以精确到毫秒） 分布式集群架构中的session分离 分布式锁 redis不可以做什么 不适合冷数据 大量的数据 作为缓存 简单使用 redis-server # 默认配置启动 redis-server --port 6379 # 指定配置 redis-cli -h 主机名 -p 连接端口 redis-cli get key # 直接执行get命令 redis-cli shutdown # 关闭redis server 慢查询分析 一条客户端命令的生命周期： 慢查询阈值设置： slowlog-log-slower-than：超过xx微秒则记录为慢查询 slowlog-max-len config set slowlog-log-slower-than 2 # 设置阈值 slowlog get [n] # 获取慢查询日志 n 指定条数 slowlog len # 获取慢查询日志列表长度 slowlog reset # 清空慢查询日志 慢查询日志结构： id time duration command 参数.. ip:port 最佳实践： 线上建议调大慢查询列表 根据qps来配置slowlog-log-slower-than 及时转储slowlog redis shell redos-cli redis-cli -r 3 ping # 重复执行3次ping命令 redis-cli -r 3 -i 1 ping # 每隔1秒发一次ping 重复3此 echo \"world\" | redis-cli -x set hello # 从stdin读入 作为redis的最后一个参数 redis-cli --scan # scan命令 redis-cli --rdb ./bak.rdb # 生成rdb文件 echo -en '*3\\r\\n$3\\r\\nSET\\r\\n$5\\r\\nhello\\r\\n$5\\r\\nworld\\r\\n*2\\r\\n$4\\r\\nincr\\r\\n$7\\r\\ncounter\\r\\n' | redis-cli --pipe # 直接发送命令给redis执行 redis-cli --bigkeys # 分析内存占用比较大的键值对 redis-cli --latency # 查看客户端到目标redis的网络延时 redis-cli --latency-history -i 10 # 每隔10秒查看一次网络延时 redis-cli --latency-dist # 以统计图表的方式输出 redis-cli --stat # 获取redis的统计信息 redis-cli --raw get name # 返回数据不进行格式化(\\xexxx) redis-server redis-server --test-memory 1024 # 测试是否有足够的内存 redis-benchmark redis-benchmark -c 100 -n 20000 # 100个客户 共请求20000次 redis-benchmark -c 100 -n 20000 -q # 只显示 requests per second redis-benchmark -c 100 -n 20000 -r 10000 # -r选项会在key、counter键上加一个12位的后缀，-r10000代表只对后四位做随机处理 redis-benchmark -c 100 -n 20000 -P 10 # 每隔请求的pipline数据量 redis-benchmark -c 100 -n 20000 -q -k 1 # k为1代表启用客户端连接keepalive redis-benchmark -t get,set -q # 只对指定的命令测试 redis-benchmark -t get,set -q --csv # 按照csv文件格式输出 Pipeline Pipeline（流水线）机制能将一组Redis命令进行组装，通过一次RTT传输给Redis，再将这组Redis命令的执行结果按顺序返回给客户端 redis-cli 的--pipeline选项 各种语言客户端的pipeline 客户端和服务端的网络延时越大，Pipeline的效果越明显 如果pipeline传递的数据过大 也会增加客户端的等待时间及网络阻塞 vs. 原生批量命令： 原生批量命令是原子的，Pipeline是非原子的 原生批量命令是一个命令对应多个key，Pipeline支持多个命令 原生批量命令是Redis服务端支持实现的，而Pipeline需要服务端和客户端的共同实现 事件 文件事件 时间事件 Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器 发布订阅 新开启的订阅客户端，无法收到该频道之前的消息 pubsub channels # 查看活跃的频道(至少一个订阅者) pubsub numsub chat # 查看频道订阅数 pubsub numpat # 查看模式订阅数 消费者 SUBSCRIBE redisChat # 订阅 unsubscribe redisChat # 取消订阅 psubscribe pattern # 按照给定模式订阅 punsubscribe pattern # 按照给定模式取消订阅 生产者向频道发送数据 PUBLISH redisChat \"Redis is a great caching technique\" GEO 地理信息定位功能 geoadd locations 116.38 39.55 beijing # 添加成员 geopos locations beijing # 获取 geodist locations beijing tianjin [m|km|mi|ft] # 计算两地距离 georadiusbymember locations beijing 150 km # 获取北京方圆150km内的成员 geohash locations beijing # 将二维经纬度转换为一维字符串 关于geohash： 字符串越长，表示的位置更精确 两个字符串越相似，它们之间的距离越近，Redis利用字符串前缀匹配 算法实现相关的命令 Redis正是使用有序集合并结合geohash的特性实现了GEO的若干命令 分布式 通用集群方案： 主备集群 全量数据同步 分片集群 AKF X：全量，镜像 Y：业务，功能 Z：优先级，逻辑再拆分 线程模型 redis采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理 Redis 单线程模型指的是只有一条线程来处理命令 单线程对每个命令的执行时间是有要求的 某个命令执行过长 就会造成其他命令的阻塞 发现阻塞 当Redis阻塞时，线上应用服务应该最先感知到，这时应用方会收到大量Redis超时异常，比如Jedis客户端会抛出JedisConnectionException异常 此时可以进行日志记录 监控系统通过日志来进行监控报警 需要注意的是要改造Redis客户端 使其记录具体的Redis实例 开源的监控系统：CacheCloud 阻塞原因 内在原因 API或数据结构使用不合理 有些操作的时间复杂度为O(n) 这在高并发场景是不能接受的 这种情况需要重点注意慢查询以及大对象 针对它们进行优化 CPU饱和 请求量很大 需要进行水平扩容来降低单实例的压力 持久化阻塞 fork阻塞：如避免使用过大的内存实例和规避fork缓慢的操作系统等 AOF刷盘阻塞：当硬盘压力过大 fsync命令可能会导致阻塞 HugePage写阻塞：对于开启Transparent HugePages的操作系统，每次写命令引起的复制内存页单位由4K变为2MB 会拖慢写操作的速度 外在原因 CPU竞争 进程竞争：当其他进程过度消耗CPU时，将严重影响Redis吞吐量 CPU绑定：如果将Redis绑定在某个核上 那么在持久化的时候子进程与父进程共存 会导致父进程可用CPU不足 内存交换 内存与硬盘读写速度差几个数量级，会导致发生交换后的Redis性能急剧下降 网络问题： 连接拒绝：网络闪断 连接数超过redis的最大连接数 linux文件符限制或者back_log限制导致的连接溢出 网络延迟：避免物理具体过远 网卡软中断：单个网卡队列只能使用一个CPU，高并发下网卡数据交互都集中在同一个CPU，导致无法充分利用多核CPU的情况 单线程模型也能高效率的原因 纯内存操作 C语言实现 基于非阻塞IO多路复用 单线程避免了频繁上下文切换带来的性能损失以及多线程的锁竞争问题 Redis的内存 内存消耗 内存使用统计：info memory命令 内存消耗划分： 对象内存 内存占用最大的一块 简单理解为sizeof（keys）+sizeof（values） 应当避免使用过长的键 缓冲内存 客户端缓存 复制积压缓冲 AOF缓冲等 内存碎片 默认的内存分配器采用jemalloc，可选的分配器还有：glibc、tcmalloc 频繁更新以及过期键的删除会使碎片率上升 使用整齐的是数据结构减少碎片 或者使用高可用架构重启服务器来整理内存碎片 子进程内存消耗： Redis产生的子进程并不需要消耗1倍的父进程内存，实际消耗根据期间写入命令量决定，但是依然要预留出一些内存防止溢出 内存管理 Redis默认无限使用服务器内存 设置内存上限：maxmemory配置项 限制的是Redis实际使用的内存量，也就是used_memory统计项对应的内存 动态调整内存上限：config set maxmemory 内存回收 删除过期键对象： 惰性删除 当客户端读取带有超时属性的键时，如果已经超过键设置的过期时间，会执行删除操作并返回空 虽然节省CPU 但存在过期对象无法及时回收 内存泄漏的问题 定时任务删除 Redis内部维护一个定时任务，默认每秒运行10次 循环执行指的是执行回收逻辑 直到不足25%或运行超时为止 内存溢出淘汰策略： 设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略 策略 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰（最常用） volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 noeviction 禁止驱逐数据，当内存不足时，写入操作会被拒绝 内存溢出淘汰策略可以采用config set maxmemory-policy{policy}动态配置 内存优化 redisObject： Redis存储的所有值对象在内部定义为redisObject结构体 struct { type // 表示当前对象使用的数据类型 encoding // 代表当前对象内部采用哪种数据结构实现 lru // 记录对象最后一次被访问的时间 refcount // 记录当前对象被引用的次数 Redis可以使用共享对象的方式来节省内存 *ptr // 如果是整数，直接存储数据；否则表示指向数据的指针 3.0之后对值对象是字符串且长度 缩减键值对象 设计键时，在完整描述业务情况下，键值越短越好 值对象尽量选择更高效的序列化工具进行压缩 共享对象池 当数据大量使用[0-9999]的整数时，共享对象池可以节约大量内存 当启用LRU相关淘汰策略如：volatile-lru，allkeys-lru时，Redis禁止使用共享对象池 字符串优化 字符串结构： struct { int len; // 已用字节长度 int free; // 未用字节长度 char buf[]; // 字节数组 } 内部实现空间预分配机制，降低内存再分配次数，字符串缩减后的空间不释放，作为预分配空间保留 这就导致如果对字符串进行 append setrange等操作 就会有内存碎片的产生 可以使用hash来代替字符串类型存储json 不仅支持部分存取 数据量一大时也更节省内存 编码优化 通过不同编码实现效率和空间的平衡 编码转换的流程： 控制键的数量 对于存储相同的数据内容利用Redis的数据结构降低外层键的数量，也可以节省大量内存 对于需要对如hash的内部数据进行过期处理 就必须通过外部定时任务扫描的方式来进行过期处理 整合Lua redis-cli eval \"return 1+1\" 0 在redis-cli中 EVAL \"local msg='hello world' return msg..KEYS[1]\" 1 AAA BBB 独立文件 local count = redis.call(\"get\", \"count\") redis.call(\"incr\",\"count\") return count redis-cli --eval test.lua 0 部署 加载到redis redis-cli script load \"$(cat test.lua)\" 得到sha1值 执行 redis-cli evalsha \"7a2054836e94e19da22c13f160bd987fbc9ef146\" 0 lua脚本管理 script load script exists script flush script kill redis运维 Linux配置优化 vm.overcommit_memory：内存分配策略 swappiness：值越大，说明操作系统可能使用swap的概率越高 THP特性：支持大内存页（2MB）分配，默认开启。当开启时可以降低fork子进程的速度，但fork操作之后，每个内存页从原来4KB变为2MB，会大幅增加重写期间父进程内存消耗 建议关闭 OOM killer会在可用内存不足时选择性地杀掉用户进程 会为每个用户进 程设置一个权值，这个权值越高，被“下手”的概率就越高 使用NTP（网络时间协议）来避免异常情况下的日志排查困难 ulimit 设置同时打开的最大文件个数 TCP backlog 删库补救 持久化文件是恢复数据的媒介 误操作之后大AOF重写参数auto-aof-rewrite-percentage和auto-aof-rewrite-min-size，让Redis不能产生AOF自动重写 以及拒绝手动bgrewriteaof 安全 requirepass配置为Redis提供密码功能 rename-command伪装危险命令 bind指定的Redis和哪个网卡进行绑定 bigkey处理 bigkey是指key对应的value所占的内存空间比较大 可能造成内存倾斜 大key会造成操作阻塞或者网络阻塞 使用redis-cli --bigkeys统计bigkey 热点key 客户端计数 代理端计数 服务端monitor命令输出统计 高并发情况下会有性能问题 通过TCP网络抓包进行统计 redis vs memcached redis支持复杂的数据结构 redis支持原生集群 redis 只使用单核，而 memcached 可以使用多核 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-05 08:53:44 "},"中间件/数据库/redis/数据结构.html":{"url":"中间件/数据库/redis/数据结构.html","title":"数据结构","keywords":"","body":"数据结构 二进制安全：底层没有类型概念，只有byte数组 所以客户端需要将数据序列化成字节数组 string 字符串、数值、bit位图 内部编码： int：8个字节的长整型 embstr：小于等于39个字节的字符串 raw：大于39个字节的字符串 应用场景： 做简单的KV缓存 设计合理的键名，有利于防止键冲突和项目的可维护性，比较推荐的方式是使用业务名：对象名：id：[属性]作为键名 incr（计数）：抢购，秒杀，详情页，点赞，评论 session服务器 限速 通过对key设置过期时间的方式限制用户请求频率 使用位图来处理海量数据 哈希类型 hash 做对象属性读写 列表类型 list 可以做消息队列或者可以来存储列表信息，进行分页查询 集合类型 set 自动去重 推荐系统：数据交集 有序集合类型 sortedset 排序 内部数据结构 字典 typedef struct dictht { dictEntry **table; unsigned long size; unsigned long sizemask; unsigned long used; } dictht; typedef struct dictEntry { void *key; union { void *val; uint64_t u64; int64_t s64; double d; } v; struct dictEntry *next; } dictEntry; redis使用了两张哈希表来方便扩容时的rehash操作 在进行rehash时，为避免给服务器带来过大负担，并不是一次性将所有值rehash到另外一张表，而是通过渐进的方式，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式 rehash。 跳跃表 查找时，从上层开始查找，找到对应的区间后再到下一层继续查找，类似于二分查找 这种查找数据结构跟红黑树相比： 插入非常快，因为不需要在插入后进行旋转 实现容易 支持无锁操作 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-05 08:53:44 "},"中间件/数据库/redis/API.html":{"url":"中间件/数据库/redis/API.html","title":"API","keywords":"","body":"API 通用 keys * : 查看所有的键(生产环境应禁用，原因：正则表达式可能会占用大量资源) dbsize 返回当前数据库中建的总数 type key ： 获取键对应的value的类型 del key：删除指定的key(可以是多个) exists key：判断指定的key是否存在 expire key time：指定key的生存时间，单位：秒 ttl key 查看键的剩余过期时间 字符串类型 set key value [ex seconds] [px milliseconds] [nx|xx] # 设置值 # ex 以秒为单位的过期时间 # px 毫秒单位的过期时间 # nx：set if not exists # xx set if exists get key # 获取值 mset name cxk age 18 # 批量设置值 mget name age # 批量获取值 incr a # 自增1 incrby a 15 # 自增指定值 decrby a 15 # 自减指定值 incrbyfloat a 10.5 # 自增浮点数 append name jntm # 字符串追加值 strlen name # 获取字符串长度 set name 蔡徐坤 strlen name # redis将中文序列化为byte数组 中文的长度取决于终端的编码集 getset name world # 设置新值并返回旧值 setrange name 2 kd # 从指定位置设置字符串 getrange name 0 -1 # 获取指定范围的字符串 在redis中 自增操作都是原子的 不用担心被别的客户端修改 bitmap 这个数据类型适合用来处理海量数据 setbit map 5 1 # 将偏移量为5的bit设置为1 在第一次初始化Bitmaps时，假如偏移量非常大，那么整个初始化过程执行会比较慢，可能会造成Redis的阻塞 getbit map 5 # 获取偏移量为5的值 bitcount map 0 -1 # 获取指定范围内1的个数 bitop and|or|not|xor ret map map1 # bitmap 集合运算 bitpos map 1 # bitmap 第一个值为1的bit的偏移量 例子： 统计某个时间窗口内的登录天数 setbit cxk 1 1 # 第一天登录 setbit cxk 364 1 # 第364天登录 bitcount cxk 0 10 # 0 - 10天这个时间窗口登录了几天 统计某个时间窗口活跃用户数 setbit 200618 1 1 # 18号1号用户登录 setbit 200619 1 1 # 19号1号用户登录 setbit 200619 7 1 # 19号7号用户登录 bitop or ret 200618 200619 # 使用或运算合并bit bitcount ret 0 0 # 统计有多少位1 HyperLogLog 通过HyperLogLog可以利用极小的内存空间完成大量元素的独立总数的统计 用小空间来估算如此巨大的数据，其中一定存在误差率（类似于布隆过滤器） 使用这个来估算数据 可以容忍一定的误差率 pfadd users user1 user2 user3 user4 # 添加元素 pfcount users # 统计个数 哈希类型 hset user:1 name cxk age 18 # 设置field hsetnx user:1 name cxk # set if not exists hget user:1 name # 获取field hdel user:1 name age # 删除field hlen user:1 # 计算field个数 hmget user:1 name age # 批量获取field hexists user:1 name # 判断field是否存在 hkeys user:1 # 获取所有field名称 hvals user:1 # 获取所有field value hgetall user:1 # 获取全部kv对 hincrby user:1 age 1 # 对指定field自增 hincrbyfloat user:1 age 1.5 # 浮点数自增 内部编码： ziplist 压缩列表 这种类型使用更加紧凑的结构实现多个元素的连续存储 节省内存 hashtable 读写效率比ziplist高 使用场景： 哈希类型是稀疏的，而关系型数据库是完全结构化的，哈希类型每个键可以有不同的field，而关系型数据库一旦添加新的列，所有行都要为其设置值 关系型数据库可以做复杂的关系查询，而Redis去模拟关系型复杂查询开发困难 列表类型 将元素加入列表左边：lpush key value 将元素加入列表右边：rpush key value 元素插入：linsert key before|after pivot value 范围获取：lrange key start end 获取指定下标：lindex key i 获取列表长度:llen key 删除列表最左边的元素，并将元素返回:lpop key 删除列表最右边的元素，并将元素返回:rpop key 删除指定元素 从左到右 最多删除一个：lrem list 1 java 从右到左 最多删除一个：lrem list -1 java 删除全部：lrem list 0 java 索引范围内的元素：ltrim list 0 1 修改指定下标的元素：lset list 0 java 阻塞操作 3秒内获取不到就返回:brpop list 3 内部编码： ziplist linkedlist quicklist 结合了ziplist和linkedlist两者的优势 使用场景： 消息队列 户端使用lrpush从列表左侧插入元素 多个消费者客户端使用brpop命令阻塞式的“抢” 分页列表 使用lrange实现 其他： ·lpush+lpop=Stack ·lpush+rpop=Queue ·lpsh+ltrim=Capped Collection ·lpush+brpop=Message Queue 集合类型 sadd set a b c # 添加元素 srem set b # 删除元素 scard set # 计算元素个数(维护一个变量得到) sismember set c # 判断元素是否在集合内 srandmember set 2 # 随机从集合返回指定个数元素 # 正数：取出一个去重的结果集（不能超过已有集） # 负数：取出一个带重复的结果集，一定满足你要的数量 # 如果：0，不返回 spop set 1 # 随机弹出元素 smembers set # 获取所有元素 sinter s1 s2 # 求交集 sunion s1 s2 # 求并集 sdiff s1 s2 # 求差集 sinterstore s3 s1 s2 # 交集结果存储到s3 # ... 内部编码： intset 占用内存小 hashtable 例子：用户标签 sadd user1 food movie sport music sadd user2 food music network sinter user1 user2 # 计算用户共同感兴趣的标签 例子：抽奖 sadd k 1 2 3 4 5 6 7 8 9 # 9个用户 SRANDMEMBER k 3 # 抽取三个不重复用户 SRANDMEMBER k -3 # 抽取三个可能会重复的用户 sadd=Tagging（标签） spop/srandmember=Random item（生成随机数，比如抽奖） sadd+sinter=Social Graph（社交需求） 有序集合类型 help @sorted_set 物理内存左小右大 zadd users 251 tom # 添加成员 分数251 zcard users # 计算成员个数 zscore users tom # 获取某个成员分数 zrank users tom # 计算某个成员排名 zrem users tom # 删除成员 zincrby users 8 jerry # 增加某个成员的分数 zrange users 0 10 # 正序返回指定排名范围的成员 zrevrange users 0 10 # 倒序返回指定排名范围的成员 zrangebyscore users 0 255 # 正序返回指定分数范围的成员 zrevrangebyscore users 0 255 # 正序返回指定分数范围的成员 zcount users 0 255 # 计算指定分数范围的成员个数 zremrangebyrank users 0 1 # 删除指定排名范围内的成员 zremrangebyscore users 0 10 # 删除指定分数范围内的成员 zinterstore user:ranking:1_inter_2 2 user:ranking:1 user:ranking:2 weights 1 0.5 aggregate max # 并集 内部数据结构： ziplist skiplist 例子：点赞 zadd video 0 cxk # cxk发布了一个视频 0赞 zincrby video 1 cxk # 有人给cxk视频点了一个赞 zrem video cxk # 清空cxk的视频点赞 zrevrange video 0 9 # 获取点赞排行榜 键管理 单键管理： rename name newname # 键重命名 randomkey # 随机返回数据库里的一个键 expire name 10 # 设置键10秒后过期 expireat name timestamp # 设置键在指定时间戳后过期 # 对于字符串 set 会清除其过期时间 # Redis不支持二级数据结构（例如哈希、列表）内部元素的过期功能 persist name # 去除键的过期时间 键迁移： move 同一redis内 dump restre 通过RDB文件的方式 migrate 自动通过网络传输数据 遍历键： keys * # 获取所有键 如果Redis包含了大量的键，执行keys命令很可能会造成Redis阻塞 scan 0 # 渐进式遍历 该命令返回两个部分：1. 下一个游标 2. 遍历结果 # 如果要继续遍历 下一次scan后面接的就是返回的游标 数据库管理： select 2 # 切换到2号数据库 flushdb # 清空数据库 如果当前数据库键值数量比较多，flushdb/flushall存在阻塞Redis的可能 flushall Redis3.0后已经逐渐弱化多数据库这个功能 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-05 08:53:44 "},"中间件/数据库/redis/持久化.html":{"url":"中间件/数据库/redis/持久化.html","title":"持久化","keywords":"","body":"持久化 通用持久化方案： 快照 日志 不要只使用某一持久化机制 要充分利用两种持久化机制的优点并避免它们的缺点 RDB 将某个时间点的所有数据都存放到硬盘上, 是对 redis 中的数据执行周期性的持久化 bgsave命令：使用的fork系统调用创建一个子进程来持久化数据, 由于fork出来的子进程是写时复制，所以这达到了一个性能的平衡 可以在redis-cli执行config set dir{newDir}和config set dbfilename{newFileName} 来改变持久化文件位置 配置文件 after 60 sec if at least 10000 keys changed save 60 10000 默认开启，保存在dump.rdb save 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 优缺点 是某个时刻的全部数据，非常适合做冷备 全量备份等 恢复比较迅速 bgsave每次运行都要执行fork操作创建子进程，属于重量级操作 会丢失一定数据 AOF 以日志的形式保存每次操作 对每条写入命令作为日志 为什么使用AOF缓冲：Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载 载 appendonly yes 开启aof appendfsync always 每一次操作都进行持久化 （每次写操作都执行fsync 性能极差） appendfsync everysec 每隔一秒进行一次持久化 (折中的方案) appendfsync no 让操作系统来决定何时同步 （让操作系统决定何时写到磁盘 数据不安全） Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。 如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点 优缺点 更好地保护数据不丢失 append-only没有磁盘寻址开销 适合做灾备 aof文件比rdb大 aof对性能有一定的影响 AOF重写 随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的 手动触发：bgrewriteaof 自动触发：根据auto-aof-rewrite-min-sizeauto-aof-rewrite-percentage参数确定自动触发时机 执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有写命令。 当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致 重启恢复流程 如果aof文件损坏 可以尝试使用redis-check-aof --fix进行修复 问题定位与优化 fork的问题： 重量级操作 如果使用虚拟化技术 fork会比物理机更耗时 fork虽然是写时复制 但是还是需要复制内存页表 持久化时各类资源的消耗： CPU：子进程负责把进程内的数据分批写入文件，这个过程 属于CPU密集操作 内存：子进程通过fork操作产生，占用内存大小等同于父进程，理论上需要两倍的内存来完成持久化操作，但Linux有写时复制机制 （copy-on-write） 磁盘：写入时硬盘压力很大 避免将redis和其他高硬盘负载的服务部署在一起 AOFfsync策略： 使用everysec这种同步策略 当一个命令写入缓冲区后发现上次同步到磁盘的时间大于2秒 就会阻塞住 直至同步磁盘完成 这意味着使用这种策略至多会丢失2秒的数据 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-05 08:53:44 "},"中间件/数据库/redis/客户端.html":{"url":"中间件/数据库/redis/客户端.html","title":"客户端","keywords":"","body":"客户端 RESP(redis 序列化协议) 发送命令 * CRLF $ CRLF CRLF ... $ CRLF CRLF 返回结果 状态回复：在RESP中第一个字节为\"+\"。 错误回复：在RESP中第一个字节为\"-\"。 整数回复：在RESP中第一个字节为\"：\"。 字符串回复：在RESP中第一个字节为\"$\"。 多条字符串回复：在RESP中第一个字节为\"*\"。 java 客户端 Jedis 基本使用 Jedis jedis = new Jedis(\"127.0.0.1\"); jedis.set(\"name\",\"my\"); System.out.println(jedis.get(\"name\")); jedis.close(); 连接池 JedisPoolConfig config = new JedisPoolConfig(); config.setMaxIdle(15); config.setMaxTotal(30); JedisPool pool = new JedisPool(config); Jedis resource = pool.getResource(); System.out.println(resource.ping()); resource.close(); pool.close(); Spring Data Redis RedisTemplate基本操作 redisTemplate.opsForValue() ：操作字符串 redisTemplate.opsForHash() ：操作hash redisTemplate.opsForList()：操作list redisTemplate.opsForSet()：操作set redisTemplate.opsForZSet()：操作zset StringRedisTemplate是K,V均为String的RedisTemplate 使用 template.opsForValue().set(\"name\",\"hello,bitch\"); 事务 multi # 开启事务 set name hello set hello world exec # 提交事务 # discard 停止事务执行 命令语法错误导致的错误整个事务会回滚 set key java watch key multi set key cxk exec # 如果key在这个事务过程中别其他客户端修改 这个事务就不会执行 // 开启事务支持 template.setEnableTransactionSupport(true); try{ // begin template.multi(); // 事务中的多个命令被一次性发送给服务器 template.opsForValue().set(\"java\",\"langeuage\"); template.opsForValue().set(\"python\",\"langeuage\"); // commit template.exec(); }catch (Exception e){ template.discard(); } 客户端管理 client list id=10733 addr=127.0.0.1:42158 fd=9 name= age=84021 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client user=default 标识： id addr fd name 输入缓冲区： Redis为每个客户端分配了输入缓冲区，它的作用是将客户端发送的命令临时保存，同时Redis从会输入缓冲区拉取命令并执行 qbuf 缓冲区的总容量 qbuf-free 剩余容量 如果Redis的处理速度跟不上输入缓冲区的输入速度 机会造成缓冲区十分大 输出缓冲区： Redis为每个客户端分配了输出缓冲区，它的作用是保存命令执行的结果返回给客户端 输出缓冲区由两部分组成：固定缓冲区（16KB）和动态缓冲区，其中固定缓冲区返回比较小的执行结果，而动态缓冲区返回比较大的结果。 固定缓冲区使用的是字节数组，动态缓冲区使用的是列表 obl 固定缓冲区的长度 oll 动态缓冲区列表的长度 omem 代表使用的字节数 客户端存活状态： 单位为秒 age 客户端已经连接的时间 idle 最近一次的空闲时间 客户端类型： flag setName getName 设置名称方便管理 client setName cxk client getName 杀掉客户 client kill ip:port 阻塞客户 client pause timeout # 阻塞当前客户端指定毫秒数 监控客户端命令执行 monitor 客户端相关配置 timeout 检测客户端空闲连接的超时时间，一旦idle时间达到了 timeout，客户端将会被关闭，如果设置为0就不进行检测 maxclients 客户端最大连接数 tcp-keepalive 检测TCP连接活性的周期 tcp-backlog TCP三次握手后，会将接受的连接放入队列中，tcp-backlog就是队列的大小 客户端统计 info clients connected_clients：代表当前Redis节点的客户端连接数 client_recent_max_input_buffer：当前所有输出缓冲区中队列对象个数的最大值 client_recent_max_output_buffer: 前所有输入缓冲区中占用的最大容量 locked_clients：正在执行阻塞命令（例如blpop、brpop、brpoplpush）的客户端个数 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-05 08:53:44 "},"中间件/数据库/redis/复制.html":{"url":"中间件/数据库/redis/复制.html","title":"复制","keywords":"","body":"复制 slaveof命令建立复制 slaveof no one命令断开复制 redis的复制功能是支持多个数据库之间的数据同步。一类是主数据库（master）一类是从数据库（slave），主数据库可以进行读写操作，当发生写操作的时候自动将数据同步到从数据库，而从数据库一般是只读的，并接收主数据库同步过来的数据，一个主数据库可以有多个从数据库，而一个从数据库只能有一个主数据库 拓扑结构 一主一从 用于主节点出现宕机时从节点提供故障转移支持 一主多从 对于读占比较大的场景，可以把读命令发送到从节点来分担主节点压力 或者从节点用来执行一些如keys 等比较耗时的命令 对于写并发量较高的场景，多个从节点会导致主节点写命令的多次发送从而过度消耗网络带宽 主从链 通过引入复制中间层，可以有效降低主节点负载和需要传送给从节点的数据量 原理 复制过程 执行slaveof后从节点只保存主节点的地址信息便直接返回 从节点会建立一个socket套接字 门用于接受主节点发送的复制命令 连接建立成功后从节点发送ping请求进行首次通信用于检测主从之间网络套接字是否可用以及节点当前是否可接受处理命令 如果主节点设置了requirepass参数，则需要密码验证 主从复制连接正常通信后，主节点会把持有的数据全部发送给从节点 接下来主节点会持续地把写命令发送给从节点，保证主从 数据一致性 数据同步 全量复制： 一般用于初次复制场景，会把主节点全部数据一次性发送给从节点 部分复制： psync命令 异步复制： 写命令的发送过程是异步完成，也就是说主节点自身处理完写命令后直接返回给客户端，并不等待从节点复制完成 问题 读写分离带来的问题： 数据延迟 写入master的数据无法马上在salve上读到 读到过期数据 Redis在3.2版本从节点读取数据之前会检查键的过期时间来决定是否返回数据 从节点故障 需要在客户端维护可用从节点列表，当从节点故障时立刻切换到其他从节点或主节点上 主从配置不一致的问题： 如最大限制内存如果不一致 导致从节点部分数据被淘汰 造成从节点数据与主节点不一致 避免全量复制： 从节点启动后会进行一次全量复制 这个无法避免 如果主节点重启 会导致运行ID改变 此时从节点也会进行一次全量复制 主从节点网络断开 如果连接后复制挤压缓冲区不足 也会触发全量复制 避免复制风暴： 复制风暴指大量从节点对同一主节点或者对同一台机器的多个主节点短时间内发起全量复制的过程 单主节点复制风暴 使用主从链代替一主多从来解决这个问题 单机器复制风暴 避免将所有主节点放在同一台机器 如果此时机器A网络挂掉 那么重新启动时 就会导致其他机器的流量全部压向机器A 配置 主服务配置(6379) # 设置主服务器密码 requirepass 123 # 或者需要设置master bind address bind 0.0.0.0 从服务器配置(6380) # 设置访问主服务器得我密码 masterauth 123 # 设置主服务器地址端口 slaveof 127.0.0.1 6379 # 新版本 replicaof 127.0.0.1 6379 只能对主服务器进行写操作，从服务器只能读操作 一些主从配置项 replica-serve-stale-data yes replica-read-only yes # 从节点的任何修改主节点都无法感知 repl-diskless-sync no repl-disable-tcp-nodelay #用于控制是否关闭TCP_NODELAY，默认关闭 repl-backlog-size 1mb #增量复制 min-replicas-to-write 3 min-replicas-max-lag 10 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-05 08:53:44 "},"中间件/数据库/redis/哨兵.html":{"url":"中间件/数据库/redis/哨兵.html","title":"哨兵","keywords":"","body":"哨兵 集群监控：负责监控 redis master 和 slave 进程是否正常工作。 消息通知：Sentinel节点会将故障转移的结果通知给应用方。 故障转移：如果 master node 挂掉了，sentinel会自动选出一个新的redis master node 配置中心：客户端在初始化的时候连接的是Sentinel节点集合，从中获取主节点 信息如果故障转移发生了，通知 client 客户端新的 master 地址 哨兵至少需要 3 个实例，来保证自己的健壮性 当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方 哨兵(sentinel) 是一个分布式系统,你可以在一个架构中运行多个哨兵(sentinel) 进程,这些进程使用流言协议(gossip protocols)来接收关于Master是否下线的信息,并使用投票协议(agreement protocols)来决定是否执行自动故障迁移,以及选择哪个Slave作为新的Master 高可用读写分离： 原理 三个定时任务： 每隔10秒，每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构 每隔2秒，每个Sentinel节点会向Redis数据节点的sentinel：hello频道上发送该Sentinel节点对于主节点的判断以及当前Sentinel节点的信息 每个Sentinel节点也会订阅该频道 每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点 发送一条ping命令做一次心跳检测 sdown与odown： sdown：主观宕机，某一哨兵发现无法连接master odown，一定数量的哨兵发现无法连接master sentinel领导节点选举：通过raft算法 由sentienl领导节点进行故障转移的操作 故障转移 选择一个新主节点 Sentinel领导者节点会对第一步选出来的从节点执行slaveof no one命 令让其成为主节点 Sentinel领导者节点会向剩余的从节点发送命令，让它们成为新主节点的从节点 Sentinel节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复后命令它去复制新的主节点 数据丢失 主备切换时，master异步向salve同步的命令丢失导致数据丢失 网络异常，导致master暂时失联，当master重新连接上网络时，变成了slave，数据丢失 解决：拒绝客户端的写请求 哨兵集群的自动发现 通过 redis 的 pub/sub 系统实现的，每个哨兵都会往 __sentinel__:hello 这个 channel 里发送一个消息，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置,这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在 哨兵配置 # sentinel.conf port 26379 sentinel monitor mymaster 172.17.0.5 6379 2 这个配置代表需要监控127.0.0.1：6379这个主节点，2代表判断主节点失败至少需要2个Sentinel节点同意，mymaster是主节点的别名 # 启动哨兵 redis-sentinel sentinel.conf 哨兵的一些配置项： # 如果超过了down-after-milliseconds配置的时间且没有有效的回复，则判定节点不可达 sentinel down-after-milliseconds # 用来限制在一次故障转移之后，每次向新的主节点发起复制操作的从节点个数 sentinel parallel-syncs # slaveof no one一直失败（例如该从节点此时出现故障），当此过程超过failover-timeout时，则故障转移失败 sentinel failover-timeout # 主节点通信密码 sentinel auth-pass # 当一些警告级别的Sentinel事件发生（指重要事件，例如-sdown：客观下线、-odown：主观下线）时，会触发对应路径的脚本 sentinel notification-script # 故障转移结束后，会触发对应路径的脚本 sentinel client-reconfig-script 动态调整配置：sentinel set 命令 监控多个主节点 sentinel monitor master-business-1 10.10.xx.1 6379 2 sentinel monitor master-business-2 10.16.xx.2 6380 2 部署 Sentinel节点不应该部署在一台物理机器上 部署至少三个且奇数个的Sentinel节点 一套sentinel还是多套sentinel 一套Sentinel，很明显这种方案在一定程度上降低了维护成本 但如果这套Sentinel节点集合出现异常，可能会对多个Redis数据节点造成影响 多套Sentinel会造成资源浪费。但是优点也很明显，每套Redis Sentinel都是彼此隔离的 运维 节点下线： 主节点下线 使用sentienl failover命令选出一个新主节点 将原来的主节点下线 从节点或者sentienl节点下线 保证客户端能感受到从节点的变化 避免发送无效请求 节点上线： 添加从节点 添加slaveof配置启动即可 添加sentienl节点 添加sentienl monitor配置启动即可 API # 查看所有被监控的主节点状态以及相关的统计信息 sentinel masters # 查看指定主节点 sentinel master # 查看指定主节点的从节点 sentinel slaves # 列出指定的主从集群sentinel节点（不包含本节点） sentinel sentinels # 返回指定的主节点地址和端口 sentinel get-master-addr-by-name # 对符合（通配符风格）主节点的配置进行重置 sentinel reset # 强制对集群进行故障转移 sentinel failover # 检测当前可达的Sentinel节点总数是否达到的个数 sentinel ckquorum # 将Sentinel节点的配置强制刷到磁盘上 sentinel flushconfig # 取消当前sentinel节点对指定master的监控那个 sentinel remove # 监控指定master sentinel monitor # Sentinel节点之间用来交换对主节点是否下线的判断 sentinel is-master-down-by-addr 客户端连接 1）遍历Sentinel节点集合获取一个可用的Sentinel节点 2）通过sentinel get-master-addr-by-name master-name这个API来获取对应主节点的相关信息 3）验证当前获取的“主节点”是真正的主节点，这样做的是为了防止获取之后主节点又发生了变化 4）保持和Sentinel节点集合的“联系”，时刻获取关于主节点的相关“信息” Java 客户端： JedisSentinelPool pool = new JedisSentinelPool(\"mymaster\", Set.of(\"192.168.1.101:26379\",\"192.168.1.101:26380\",\"192.168.1.101:26381\")); Jedis resource = pool.getResource(); System.out.println(resource.ping()); resource.close(); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-05 08:53:44 "},"中间件/数据库/redis/集群.html":{"url":"中间件/数据库/redis/集群.html","title":"集群","keywords":"","body":"集群 自动将数据进行分片，每个 master 上放一部分数据 提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的 6379：对外服务 16379：节点间通信 数据分布方案： 节点取余分区 根据key进行取模 得到其存放的节点ID 一致性哈希分区 使用哈希环实现多个虚拟槽点 避免节点数量改变带来的大量键重映射问题 虚拟槽分区 定义大量虚拟槽 让物理节点负责一定量的槽 Redis集群使用了虚拟槽分区： 使用这种方案带来的特点： 解耦数据和节点之间的关系，简化了节点扩容和收缩难度 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据 支持节点、槽、键之间的映射查询 由于数据分布于不同的节点, 所以集群功能相比单机有如下限制： 批量操作支持有限 如mget只能获取在同一个节点上的键 事务支持有限 同理只能支持同一个节点上上的事务 key是数据分区的最小粒度 如一个list 或者hash上的内容都会在同一个节点上 集群模式下只能使用一个数据库空间 复制结构只支持一层，从节点只能复制主节点，不支持主从链结构 集群方案 根据业务拆分，不同的业务数据存放到不同的redis 官方方案redis-cluster搭建(虚拟槽分区) 客户端分片技术（不推荐），扩容/缩容时，必须手动调整分片程序，出现故障不能自动转移 主从复制方式：数据冗余 集群搭建 节点准备： # 节点端口 port 6379 # 开启集群模式 cluster-enabled yes # 节点超时时间，单位毫秒 cluster-node-timeout 15000 # 集群内部配置文件 cluster-config-file \"nodes-6379.conf\" 节点握手： cluster meet 127.0.0.1 6380 ... 节点建立握手之后集群还不能正常工作 需要为各个节点分配slot： redis-cli -h 127.0.0.1 -p 6379 cluster addslots {0..5461} ... 作为一个完整的集群，每个负责处理槽的节点应该具有从节点，保证当它出现故障时可以自动进行故障转移: 使用cluster nodes命令查看集群节点 让其他节点做复制： cluster replicate 41f2232cc928fb61c8a201b7d1cc1e57f029752e ... 使用redis-cli: redis-cli --cluster create 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6380 127.0.0.1:6379 --cl uster-replicas 1 redis-cluster原理 客户端直接访问集群 代理访问集群 redis cluster 有固定的 16384 个 hash slot，集群中的每个node平均分配得到一定的slot 使用一致性哈希实现 优点： 增加节点，的确可以分担其他节点的压力，不会造成全局洗牌 缺点： 新增节点造成一小部分数据不能命中 1，问题，击穿，压到mysql 2，方案：每次取离我最近的2个物理节点 更倾向于 作为缓存，而不是数据库用！！！！ 节点间的通信 节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息 redis 维护集群元数据采用了gossip协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点 但是元数据的更新有延时，可能导致集群中的一些操作会有一些滞后 gossip协议 meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信 ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据 pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新 fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机了 节点选择 集群伸缩 数据槽点迁移： 扩容: 启动新节点 执行redis-cli --cluster add-node 127.0.0.1:6386 127.0.0.1:6379 添加节点 执行redis-cli --cluster reshard 127.0.0.1:6379来重新分配槽点 收缩： ... 请求路由 请求重定向： 当的ket的CRC16结果不是本节点时 集群节点就会返回一个MOVED错误 提供实际节点 127.0.0.1:6379> set hello2 value1 (error) MOVED 7486 127.0.0.1:6380 使用redis-cli时 加上-c参数支持自动重定向 ASK重定向： 例如当一个slot数据从源节点迁移到目标节点时，期间可能出现一部分数据在源节点，而另一部分在目标节点 客户端需要自行处理这种情况 ASK重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移 完成，因此只能是临时性的重定向，客户端不会更新slots缓存 故障转移 主观下线与客观下线 故障恢复：故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它的从节点中选出一个替换它 集群运维 集群完整性： 为了保证集群完整性，默认情况下当集群16384个槽任何一个没有指派到节点时整个集群不可用 当持有槽的主节点下线时，从故障发现到自动完成转移期间整个集群是不可用状态 为了避免这种情况 可以设置cluster-require-full-coverage为no 带宽： 集群带宽消耗主要分为：读写命令消耗+Gossip消息消耗 在满足业务需要的情况下尽量避免大集群 适度提高 设置cluster-node-timeout降低消息发送频率节省带宽 避免集中部署 否则机器消耗带宽非常严重 PUB/SUB问题：Pub/Sub功能应该避免在大量节点的集群内使用，否则会严重消耗集群内网络带宽 集群倾斜： 数据倾斜 比如有些槽键数量差异大 或者有些节点上的键值很大 请求倾斜 如热点key问题 集群读写分离： 只读连接 通过readonly命令来指定从节点可以处理读请求 读写分离 需要自行开发 手动故障转移： cluster failover命令 数据迁移（从单机导入集群）： redis-cli --cluster import命令 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-05 08:53:44 "},"中间件/数据库/MongoDB.html":{"url":"中间件/数据库/MongoDB.html","title":"MongoDB","keywords":"","body":"mongodb MongoDB 是一个跨平台的，面向文档的数据库，是当前 NoSQL 数据库产品中最热 门的一种。它介于关系数据库和非关系数据库之间，是非关系数据库当中功能最丰富，最 像关系数据库的产品。它支持的数据结构非常松散，是类似 JSON 的 BSON 格式，因此可以 存储比较复杂的数据类型。 基础概念 SQL术语/概念 MongoDB术语/概念 解释/说明 database database 数据库 table collection 数据库表/集合 row document 数据记录行/文档 column ﬁeld 数据字段/域 index index 索引 table joins 表连接（MongoDB不支持） primary key primary key 主键,MongoDB自动在每个集合中添加_id的主键 数据类型 null：用于表示空值或者不存在的字段，{“x”:null} 布尔型：布尔类型有两个值true和false，{“x”:true} 数值：shell默认使用64为浮点型数值。{“x”：3.14}或{“x”：3} 对于整型值，可以使用 NumberInt（4字节符号整数）或NumberLong（8字节符号整数）， {“x”:NumberInt(“3”)}{“x”:NumberLong(“3”)} 字符串：UTF-8字符串都可以表示为字符串类型的数据，{“x”：“呵呵”} 日期：日期被存储为自新纪元依赖经过的毫秒数，不存储时区，{“x”:new Date()} 正则表达式：查询时，使用正则表达式作为限定条件，语法与JavaScript的正则表达式相 同，{“x”:/[abc]/} 数组：数据列表或数据集可以表示为数组，{“x”： [“a“，“b”,”c”]} 内嵌文档：文档可以嵌套其他文档，被嵌套的文档作为值来处理，{“x”:{“y”:3 }} 对象Id：对象id是一个12字节的字符串，是文档的唯一标识，{“x”: objectId() } 二进制数据：二进制数据是一个任意字节的字符串。它不能直接在shell中使用。如果要 将非utf-字符保存到数据库中，二进制数据是唯一的方式。 代码：查询和文档中可以包括任何JavaScript代码，{“x”:function(){/…/}} 操作 show dbs #列出所有数据库 use test #使用数据库（不存在会自动创建，新创建的数据库不显示（至少包含一个集合）） db.dropDatabase() #删除当前数据库 db.createCollection(\"student\") # 创建集合 db.collection.drop() #删除集合 db.student.insert({\"name\":\"cxk\",\"age\":25}) # 插入文档 db.student.update({\"name\":\"cxk\"},{\"name\":\"xkc\"}) #更新文档（替换文档） db.student.find() # 查询全部 db.student.find({\"name\":\"cxk\"}) # 按条件查询 db.student.find({\"name\":\"cxk\"},{name:1,age:1,_id:0}) # 投影 # 创建用户 db.createUser( { user:\"root\", pwd:\"root\", roles:[ {role:\"root\",db:\"admin\"} ] } ) JAVA操作 依赖 org.mongodb mongo-java-driver 3.11.0 使用 MongoClient client = new MongoClient(\"my-pc\"); MongoDatabase db = client.getDatabase(\"db\"); MongoCollection spit = db.getCollection(\"spit\"); Document d = new Document(); d.append(\"name\",\"jntm\"); spit.insertOne(d); for (Document document : spit.find()) { System.out.println(document.getString(\"name\")); } client.close(); Spring data mongodb node操作 连接 const mongoose = require('mongoose') mongoose.connect('mongodb://localhost/db1', { useNewUrlParser: true, useUnifiedTopology: true }) .then(() => { console.log('连接成功') }) .catch(e => console.log(e)) 创建集合 const userSchema = new mongoose.Schema({ name: String, age: Number }) // 返回一个构造函数 const User = mongoose.model('User',userSchema) 插入文档 const user = new User({ name:'cxk',age:18 }) user.save() User.create({name:'gdf',age:15},(err,doc)=>{ if (!err){ console.log('插入成功',doc) } }) 查询 // 查询全部 User.find().then(result=>console.log(result)) // 根据ID查询 User.findById('5c09f236aeb04b22f8460967').then(result=>console.log(result)) // 根据条件查询 User.find({password:'123456'}).then(result=>console.log(result)) User.find({ age: { $gt: 20, $lt: 40 } }).then(result => console.log(result)) User.find({ hobbies: { $in: ['打豆豆'] } }).then(result => console.log(result)) // 投影 User.find().select('name password -_id').then(result => console.log(result)) // 排序 User.find().sort('age').then(result => console.log(result)) User.find().sort('-age').then(result => console.log(result)) // 降序 // 分页 User.find().skip(2).limit(5).then(result => console.log(result)) 删除 // 删除符合条件的第一个文档 User.findOneAndDelete({name:'cxk'}).then(res=>console.log(res)) // 删除符合条件的全部文档 User.deleteMany({name:'gdf'}).then(res=>console.log(res)) 更新 // 更新符合条件中的第一个 User.updateOne({ name: 'gdf' }, { name: 'cxk' }).then(res => console.log(res)) // 更新全部符合调价你的 User.updateMany({ password: '123456' }, { name: 'cxk' }).then(res => console.log(res)) 验证 const userSchema = new mongoose.Schema({ // name必传，否则会报错 name: { type: String, required: true }, age: Number }) 其他的验证规则 required: true 必传字段 minlength：3 字符串最小长度 maxlength: 20 字符串最大长度 min: 2 数值最小为2 max: 100 数值最大为100 enum: ['html', 'css', 'javascript', 'node.js'] trim: true 去除字符串两边的空格 validate: 自定义验证器 default: 默认值 集合关联 // 用户集合 const User = mongoose.model('User', new mongoose.Schema({ name: { type: String } })); // 文章集合 const Post = mongoose.model('Post', new mongoose.Schema({ title: { type: String }, // 使用ID将文章集合和作者集合进行关联 author: { type: mongoose.Schema.Types.ObjectId, ref: 'User' } })); Post.find().populate('author').then(r => console.log(r)) GridFS MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-11 01:30:14 "},"中间件/消息队列/消息队列.html":{"url":"中间件/消息队列/消息队列.html","title":"消息队列","keywords":"","body":"消息队列 消息模型 点对点 只能被一个消费者消费一次 发布订阅 消息生产者向频道发送一个消息之后，多个消费者可以从该频道订阅到这条消息并消费 使用场景 异步处理 发送者发送消息之后无需等待，可以直接返回 流量削峰 高并发的情况下，将请求发送到消息队列，服务器按照处理能力对请求进行处理 应用解耦 如果模块之间不直接进行调用，模块之间耦合度就会很低 可靠性 发送端的可靠性 通过本地消息表实现 接收端的可靠性 保证消费幂等性 保证消息具有唯一编号 消息堆积 如果消费端出现问题，可能就会造成队列的消息堆积 此时，处理方案只需要恢复消费端的处理能力即可 但是如果消息队列即将被写满，就必须将快要满的这个队列的消息分发到其他消息队列，临时加派消费者加快处理这些消息 消息失效 消息失效导致的大量消息丢失，只能写程序慢慢将丢失的那些消息补回来 消息中间件带来的好处 解耦 异步 横向扩展 安全可靠 顺序保证 中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源。 中间件位于客户机/ 服务器的操作系统之上，管理计算机资源和网络通讯。 消息中间件是指一种在需要进行网络通信的系统进行通道的建立，数据或文件发送的中间件。消息中间件的一个重要作用是可以跨平台操作，为不同操作系统上的应用软件集成提供便利。 JMS Java消息服务（Java Message Service，JMS）应用程序接口是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。 Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。 队列模型 主题模型 JMS编码接口之间的关系 AMQP 高级消息队列协议即Advanced Message Queuing Protocol（AMQP）是一个用于统一面向消息中间件实现的一套标准协议，其设计目标是对于消息的排序、路由（包括点对点和订阅-发布）、保持可靠性、保证安全性。 对比 消息队列设计 从几个方面考虑： 可伸缩性 也就是能根据系统负载动态增减节点 持久化 持久化的开销 高可用 主节点的选举，主从之间的数据复制 消息可靠性保证 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-18 12:35:26 "},"中间件/消息队列/activeMQ.html":{"url":"中间件/消息队列/activeMQ.html","title":"ActiveMQ","keywords":"","body":"ActiveMQ 使用 初始化 // 创建连接 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(url); Connection connection = connectionFactory.createConnection(); connection.start(); // 创建会话 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 创建目的 Destination destination = session.createQueue(queueName); 队列模式 生产消息 MessageProducer producer = session.createProducer(destination); for (int i = 0; i 消费消息 MessageConsumer consumer = session.createConsumer(destination); consumer.setMessageListener(new MessageListener() { public void onMessage(Message message) { System.out.println(message); } }); 在队列模式下，消费者会平均消费生产者生产的消息 主题模式 Destination destination = session.createTopic(topicName); 主题模式下，订阅之后才能收到消息 生产者生产消息会推送给所有消费者 消息持久化 PERSISTENT：指示JMS provider持久保存消息，以保证消息不会因为JMS provider的失败而丢失 NON_PERSISTENT:不要求JMS provider持久保存消息 producer.setDeliveryMode(DeliveryMode.PERSISTENT); 可靠数据传输 JMS消息只有在被确认之后，才认为已经被成功的消费了 Session.AUTO_ACKNOWLEDGE：当客户成功的从receive方法返回的时候，或者从MessageListener.onMessage方法成功返回的时候，会话自动确认客户收到的消息 Session.CLIENT_ACKNOWLEDGE:客户通过调用消息的acknowledge方法确认消息 Session.DUPS_ACKNOWLEDGE:该选择只是会话迟钝的确认消息的提交 集成Spring jms 配置 @Bean public ConnectionFactory connectionFactory(){ return new ActiveMQConnectionFactory(\"tcp://127.0.0.1:61616\"); } @Bean public Destination destination(){ return new ActiveMQQueue(\"queue\"); } @Bean public JmsTemplate jmsTemplate(ConnectionFactory connectionFactory){ return new JmsTemplate(connectionFactory); } 使用 jmsTemplate.send(destination,new MessageCreator() { public Message createMessage(Session session) throws JMSException { TextMessage msg = session.createTextMessage(); msg.setText(message); return msg; } }); 配置消费者 @Bean public MessageListener messageListener(){ return new ConsumerMessageListener(); } @Bean public DefaultMessageListenerContainer defaultMessageListenerContainer(Destination destination, ConnectionFactory connectionFactory, MessageListener messageListener){ DefaultMessageListenerContainer container = new DefaultMessageListenerContainer(); container.setConnectionFactory(connectionFactory); container.setMessageListener(messageListener); container.setDestination(destination); return container; } SpringBoot整合 依赖 org.springframework.boot spring-boot-starter-activemq 配置 spring: activemq: broker-url: tcp://127.0.0.1:61616 user: admin password: admin queue: myQueue @Value(\"${queue}\") private String queueName; @Bean public Queue queue(){ return new ActiveMQQueue(queueName); } 使用 生产者 @Component public class Producer { @Autowired private JmsMessagingTemplate template; @Autowired private Queue queue; @Scheduled(fixedDelay = 5000) public void send() { String payload = UUID.randomUUID().toString(); System.out.println(\"producer send:\" + payload); template.convertAndSend(queue, payload); } } 消费者 @Component public class Consumer { @JmsListener(destination = \"myQueue\") public void receive(String msg){ System.out.println(\"consumer receive:\"+msg); } } 集群 高可用 负载均衡 集群方式 客户端集群 Broker集群 Master Slave 企业开发需要解决的问题 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-10 07:45:52 "},"中间件/消息队列/rabbitMQ.html":{"url":"中间件/消息队列/rabbitMQ.html","title":"RabbitMQ","keywords":"","body":"rabbitmq RabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的，而集群和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。 性能非常高 对比 安装 安装erlang 安装rabbitmq-server 以上操作均可以使用包管理工具完成 使用docker docker run -d --hostname my-rabbit --name some-rabbit -p 15672:15672 -p 5672:5672 rabbitmq:3-management 核心概念 Server Connection Channel （信道）：它建立在上述的TCP连接中 Message Virtual host 权限控制的基本单位（类似于数据库中的database），一个VirtualHost里面有若干Exchange和 MessageQueue，以及指定被哪些user使用 Exchange 生产者将消息发送到Exchange（交换机），由Exchange将消息路由到一个 或多个Queue中（或者丢弃）。Exchange并不存储消息 Binding Routing key 生产者在将消息发送给Exchange的时候，一般会指定一个routing key， 来指定这个消息的路由规则，而这个routing key需要与Exchange Type及binding key联 合使用才能最终生效 Queue （队列）是RabbitMQ的内部对象，用于存储消息 使用 JAVA客户端 获取连接 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"192.168.182.129\"); factory.setUsername(\"my\"); factory.setPassword(\"123\"); factory.setPort(5672); factory.setVirtualHost(\"/\"); Connection connection = factory.newConnection(); 创建队列/绑定队列 Channel channel = connection.createChannel(); channel.queueDeclare(\"queue1\",false,false,false,null); 生产者发送消息 String msg = UUID.randomUUID().toString(); channel.basicPublish(\"\",\"queue1\",null,msg.getBytes()); 消费者监听 DefaultConsumer consumer = new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(\"接收到消息:\"+new String(body)); } }; channel.basicConsume(\"queue1\",true,consumer); SpringBoot 引入依赖 org.springframework.boot spring-boot-starter-amqp 配置（生产者、消费者） spring: rabbitmq: addresses: 192.168.182.129 username: my password: 123 virtual-host: / 生产者发送消息 @Autowired private RabbitTemplate rabbitTemplate; public void sendUser(User user) throws Exception{ CorrelationData correlationData = new CorrelationData(user.getUsername()); rabbitTemplate.convertAndSend(\"user-exchange\",\"user.abcd\",user,correlationData); } 消费端配置 spring.rabbitmq.listener.simple.concurrency=5 spring.rabbitmq.listener.simple.acknowledge-mode=auto spring.rabbitmq.listener.simple.max-concurrency=10 spring.rabbitmq.listener.simple.prefetch=1 消费 @RabbitListener(bindings = @QueueBinding( value = @Queue(value = \"user-queue\"), exchange = @Exchange(name = \"user-exchange\",type = \"topic\"), key = \"user.#\" )) @RabbitHandler public void onMessage(@Payload User user){ // 当这里抛出异常，会自动进行重试 log.info(\"on message:{}\",user); } 消息模型 点对点 当有多个消费端时，mq会把消息公平分发到每个消费端（轮询） 工作队列 消息转发机制是平均分配，这样就会出现俩个消费者，由于每个消费者处理任务的效率不一，可以通过设置qos的方式来决定消费者的消费能力，从而达到资源的充分利用 channel.basicQos(1); 手动ack后的消费端，mq会继续发消息给它，这样就能达到消费速度更快的客户端消费更多数据 订阅模型-Fanout Fanout exchange（扇型交换机）将消息路由给绑定到它身上的所有队列 生产者 String exchangeName = \"exchange1\"; channel.exchangeDeclare(exchangeName,\"fanout\"); String msg = UUID.randomUUID().toString(); channel.basicPublish(exchangeName,\"\",null,msg.getBytes()); 消费者 端a String queueName = \"queue1\"; String exchangeName = \"exchange1\"; channel.queueDeclare(queueName, false, false, false, null); channel.queueBind(queueName, exchangeName, \"\"); DefaultConsumer consumer = new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(\"消费者接收到消息:\" + new String(body)); } }; channel.basicConsume(queueName,true,consumer); 端b ... String queueName = \"queue2\"; ... 订阅模型-Direct Direct exchange（直连交换机）是根据消息携带的路由键（routing key）将消息投递给对应队列 生产端 ... channel.basicPublish(exchangeName,\"routing_key\",null,msg.getBytes()); 消费端 ... channel.queueBind(queueName, exchangeName, \"routing_key\"); ... 订阅模型-Topic Topic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符 端a channel.queueBind(queueName, exchangeName, \"#.sms\"); 端b channel.queueBind(queueName, exchangeName, \"#.email\"); 当生产者的routingKey为log.sms时，消息会发送到端a # 可以匹配一个或多个词 *只能匹配一个词 消息确认机制（ACK） ACK：消费者通知RabbitMQ消息已经接收并且处理完毕了。RabbitMQ就可以删除该条消息了 自动ACK：消息一旦被接收，消费者自动发送ACK 手动ACK：消息接收后，不会发送ACK，需要手动调用 DefaultConsumer consumer = new DefaultConsumer(channel){ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { System.out.println(\"接收到消息:\"+new String(body)); channel.basicAck(envelope.getDeliveryTag(),false); } }; channel.basicConsume(\"queue1\",false,consumer); 事务 try{ channel.txSelect(); String msg = UUID.randomUUID().toString(); channel.basicPublish(exchangeName,\"log.email\",null,msg.getBytes()); channel.txCommit(); }catch (Exception e){ channel.txRollback(); } 保证幂等性 当引入异常重试机制时，如何保证同一条消息不被重复消费 重试配置 spring: rabbitmq: listener: simple: retry: initial-interval: 100ms enabled: true max-attempts: 3 解决这个问题，需要根据业务的具体情况来分析，可以： 全局消息ID redis的天然幂等性 数据库的唯一约束 全局消息ID 当消费者处理完一条消息之后，将这个消息ID记录下来，当一条新消息到来之后，要判断是否记录过这条消息的ID，如果是，不再继续往下处理 死信队列 当由于一些诸如队列满或者消息被拒绝等原因，这些消息将被移入到一个备胎队列，死信队列就是专门用来存放这些消息的队列 普通队列绑定私信队列 Map args = new HashMap<>(2); // 死信队列交换机与死信队列路由键 args.put(\"deadExchangeName\", deadExchangeName); args.put(\"deadRoutingKey\", deadRoutingKey); Queue queue = new Queue(\"user_queue\", true, false, false, args); 消息可靠投递方案 生产者弄丢数据 可能由于网络原因，数据没有到MQ，就在半路没了 这可以使用confirm机制，confirm机制当MQ接收到消息后，会给生产者回传一个ack，如果MQ没能处理这个消息，会回传nack，整个过程都是异步的 MQ弄丢数据 只要开启数据持久化，消息丢失的可能性很小 消费端弄丢数据 使用消息确认机制，处理完消息手动ack 高可用 镜像集群模式 创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上 顺序性 当多个consumer同时消费一个queue时，很有可能造成消费的顺序和存入的顺序不一致，解决方法是： 拆分多个 queue，每个 queue 一个 consumer MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-21 02:23:20 "},"中间件/消息队列/RocketMQ.html":{"url":"中间件/消息队列/RocketMQ.html","title":"RocketMQ","keywords":"","body":" Apache RocketMQ是一个采用Java语言开发的分布式的消息系统，由阿里巴巴团队开发，于2016年底贡献给Apache 核心概念 Producer 消息生产者，负责产生消息，一般由业务系统负责产生消息 Producer Group 一类 Producer 的集合名称，这类 Producer 通常发送一类消息，且发送逻辑一致 Consumer 消息费者，负责消费消息，一般是后台系统负责异步消费 Push Consumer 服务端向消费者端推送消息 Pull Consumer 消费者端向服务定时拉取消息 Consumer Group 一类 Consumer 的集合名称，这类 Consumer 通常消费一类消息，且消费逻辑一致 NameServer 集群架构中的组织协调员 收集broker的工作情况 不负责消息的处理 Broker 是RocketMQ的核心负责消息的发送、接收、高可用等（真正干活的） 需要定时发送自身情况到NameServer，默认10秒发送一次，超时2分钟会认为该broker失效。 Topic 不同类型的消息以不同的Topic名称进行区分，如User、Order等 是逻辑概念 Message Queue 消息队列，用于存储消息 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"中间件/消息队列/Kafka.html":{"url":"中间件/消息队列/Kafka.html","title":"Kafka","keywords":"","body":"kafka Kafka 是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域 特点 多生产者 多消费者 基于磁盘的数据存储 伸缩性 broker可以不断扩展 高性能 基础概念 消息和批次 消息是kafka的数据单元 批次是一组消息 模式 schema 使用额外的结构定义消息内容 主题和分区 消息通过主题分类 主题被分为若干个分区 通过分区来实现数据冗余和伸缩性 生产者和消费者 生产者创建消息 消费者读取消息 一个分区只能由一个组内消费者消费 通过偏移量记录消息消费位置 broker 和集群 broker 独立的 kafka 服务器 每个集群都有一个broker 充当集群控制器 对于消息 kafka会保留一段时间或者达到一定大小的字节数 旧的消息会被删除 多集群 使用场景 活动跟踪 生产者产生事件 消费者读取事件进行统计 传递消息 度量指标 日志记录 收集系统度量指标和日志 日志系统 流处理 架构 Partition ：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上， 一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列； Replica： ：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本， 一个 leader 和若干个 follower。 leader ：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对 象都是 leader。 生产者和消费者只与 leader 副本交互,当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选 follower ：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据 的同步。leader 发生故障时，某个 follower 会成为新的 follower。 分区与副本机制 各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡） 副本极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间 zk的作用 主要为 Kafka 提供元数据的管理的功能 Broker 注册 ：在 Zookeeper 上会有一个专门用来进行 Broker 服务器列表记录的节点 Topic 注册：分区信息及与 Broker 的对应关系也都是由 Zookeeper 在维护 应用场景 消息队列 行为跟踪 日志收集 流处理 事件源 持久性日志 搭建 安装java zookeeper 下载二进制包 ./kafka-server-start.sh 配置 broker 配置 broker.id 在集群中唯一 需要多少个broker 需要多少磁盘空间保留数据 集群处理请求的能力 port zookeeper.connect log.dirs 消息保存在磁盘上的位置 num.recovery.threads.per.data.dir 使用指定的线程池来处理日志 auto.create.topics.enable 自动创建主题 当一个生产者开始往主题写入消息时 当一个消费者开始读取 客户端向主题发送元数据请求 主题配置 num.partitions 默认分区数量 log.retention.ms 数据保留多久 log.retention.bytes 主题保留的数据大小 log.segment.bytes 一个日志片段的最大大小 log.segment.ms 日志片段的最长打开时间 message.max.bytes 消息最大大小 命令操作 列出topic ./kafka-topics.sh --list --zookeeper 172.17.0.1:2181 创建topic /opt/kafka/bin/kafka-topics.sh --create --zookeeper 172.17.0.1:2181 --replication-factor 1 --partitions 2 --topic my_log 生产者 ./kafka-console-producer.sh --topic first --broker-list 172.17.0.1:9092 消费者 ./kafka-console-consumer.sh --topic first --bootstrap-server 172.17.0.1:9092 工作流程 Kafka 中消息是以 topic 进行分类的，生产者生产消息，消费者消费消息，都是面向 topic的 每个 partition 对应于一个 log 文件，该 log 文件中存储的就是 producer 生产的数据 Producer 生产的数据会被不断追加到该log 文件末端，且每条数据都有自己的 offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费 index与log文件的作用： 生产者 发送消息： Properties props = new Properties(); //kafka 集群，broker-list props.put(\"bootstrap.servers\", \"172.24.211.140:9092\"); props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); Producer producer = new KafkaProducer<>(props); for (int i = 0; i (\"test\", \"Precision Products\", \"France\"); producer.send(record, new Callback() { @Override public void onCompletion(RecordMetadata metadata, Exception exception) { System.out.println(metadata); } }); } producer.close(); 配置 acks 定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的 acks=0 ，生产者在成功写入消息之前不会等待任何来自服务器的响应 当 broker 故障时有可能 丢失数据 acks=1 ，只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应 如果在 follower同步成功之前 leader 故障，那么将会丢失数据 acks=all ，只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应 如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成 数据重复 buffer.memory 设置生产者内存缓冲区的大小 compression.type 设置消息压缩算法 retries 决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误 batch.size 指定了一个批次可以使用的内存大小 linger.ms KafkaProducer 会在批次填满或 linger.ms 达到上限时把批次发送出去。默认情况下，只要有可用的线程，生产者就会把消息发送出去 client.id max.in.flight.requests.per.connection 指定了生产者在收到服务器响应之前可以发送多少个消息 timeout.ms、request.timeout.ms 和 metadata.fetch.timeout.ms max.block.ms 调用send时最长的阻塞时间 max.request.siz receive.buffer.bytes 和 send.buffer.bytes 分别指定了 TCP socket 接收和发送数据包的缓冲区大小 顺序保证 将max.in.flight.requests.per.connection设置为1 保证顺序的方法就是： 每个主题只分为一个区 每次发送的消息发送到同一个分区 序列化器 自定义序列化器：实现Serializer接口 不推荐使用 其他序列化 avro：一种将shcema嵌入在数据里的序列化方式 分区策略 分区的原因： 方便扩展 提高并发 分区原则： 指明 partition 的情况下，直接将指明的值直接作为 partiton 值 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition数进行取余得到 partition 值 否则就是随机取一个值 然后再这个值的基础上进行轮询 自定义分区器： 实现Partitioner接口 数据可靠性保证 Ecactly Once 将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据，即 AtLeast Once 语义 At Least Once + 幂等性 = Exactly Once 消费者 分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡 消费者通过向被指派为群组协调器的 broker（不同的群组可以有不同的协调器）发送心跳来维持它们和群组的从属关系以及它们对分区的所有权关系 Properties props = new Properties(); //kafka 集群，broker-list props.put(\"bootstrap.servers\", \"172.24.211.140:9092\"); props.put(\"group.id\", \"consumer1\"); props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); KafkaConsumer consumer = new KafkaConsumer(props); consumer.subscribe(List.of(\"test\")); while(true){ ConsumerRecords records = consumer.poll(Duration.ofMillis(1000)); for (ConsumerRecord record : records) { System.err.println(record); } } 消费方式: 采用 pull（拉）模式从 broker 中读取数据 配置 fetch.min.bytes 指定了消费者从服务器获取记录的最小字节数 fetch.max.wait.ms 指定 broker 的等待时间 max.partition.fetch.bytes 指定了服务器从每个分区里返回给消费者的最大字节数 session.timeout.ms 指定了消费者在被认为死亡之前可以与服务器断开连接的时间 auto.offset.reset 指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长时间失效，包含偏移量的记录已经过时并被删除）该作何处理 enable.auto.commit 指定了消费者是否自动提交偏移量 partition.assignment.strategy 决定哪些分区应该被分配给哪个消费者 range:该策略会把主题的若干个连续的分区分配给消费者 轮询：该策略把主题的所有分区逐个分配给消费者 client.id max.poll.records 控制单次调用 call() 方法能够返回的记录数量 receive.buffer.bytes 和 send.buffer.bytes 读写数据时用到的 TCP 缓冲区也可以设置大小 偏移量 更新分区当前偏移量的操作叫作提交 Kafka 0.9 版本之前，consumer 默认将 offset 保存在 Zookeeper 中，从 0.9 版本开始，consumer 默认将 offset 保存在 Kafka 一个内置的 topic 中，该 topic为__consumer_offsets。 自动提交： 如果 enable.auto.commit 被设为 true ，那么每过 5s，消费者会自动把从 poll() 方法接收到的最大偏移量提交上去 手动提交： 把 auto.commit.offset 设为 false ，使用 commitSync() 异步提交 commitAsync() , 但该方法在发生错误时不会进行重试 再均衡监听： 订阅的时候传入 ConsumerRebalanceListener 实现相关接口 从特定偏移量开始处理：seekToBeginning(..) 读取特定偏移量：seek(..) 退出 其他线程调用consumer.wakeup() 会使consumer在poll抛出异常 然后进行close即可 没有群组的消费者 调用assign为其设置消费的分区 深入 集群成员关系 broker通过创建临时节点把自己的 ID 注册到 Zookeeper 控制器：一个特殊的broker 通过在zk创建临时节点进行选举 控制器负责在节点加入或离开集群时进行分区首领选举。控制器使用epoch 来避免“脑裂” 复制 首领副本 所有生产者请求和消费者请求都会经过这个副本 跟随者副本 从首领那里复制消息，保持与首领一致的状态 请求处理 生产请求： 在消息被写入分区的首领之后，broker 开始检查 acks 配置参数——如果 acks 被设为 0 或 1 ，那么 broker 立即返回响应；如果 acks 被设为 all ，那么请求会被保存在一个叫作炼狱的缓冲区里，直到首领发现所有跟随者副本都复制了消息，响应才会被返回给客户端 获取请求： broker 将按照客户端指定的数量上限从分区里读取消息，再把消息返回给客户端。Kafka 使用零复制技术向客户端发送消息(直接从文件系统缓存复制到网卡) 所有同步副本复制了这些消息，才允许消费者读取它们 物理存储 文件管理： 分区分成若干个片段 当前正在写入数据的片段叫作活跃片段 可靠数据传递 kafka 的保证： 分区消息的顺序 只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是“已提交”的 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失 消费者只能读取已提交的消息 副本的同步保证： 与 Zookeeper 之间有一个活跃的会话，也就是说，它在过去的 6s（可配置）内向Zookeeper 发送过心跳 过去的 10s 内（可配置）从首领那里获取过消息 过去的 10s 内从首领那里获取过最新的消息 broker 复制系数： 主题级别 replication.factor broker级别 default.replication.factor 如果复制系数为 N，那么在 N-1 个 broker 失效的情况下，仍然能够从主题读取数据或向主题写入数据，同时 它们也会占用N倍的磁盘空间、 不完全首领选举： 如果把 unclean.leader.election.enable 设为 true ，就是允许不同步的副本成为首领 就要承担丢失数据和出现数据不一致的风险 最少同步副本： min.insync.replicas 如果要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置为大一点 生产者 发送确认： acks：0 能够通过网络把消息发送出去，那么就认为消息已成功写入 1 ：意味着首领在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时 会返回确认或错误响应 all： 首领在返回确认或错误响应之前，会等待所有同步副本都收到消息 重试参数： 对于一些错误 可以通过重试来解决 如： LEADER_NOT_AVAILABLE 消费者 显示提交偏移量： 处理完事件再提交 批量提交 重试 维护状态 避免对消息处理时间过程 否则会造成无法及时发送心跳 仅一次传递 暂时支持不了 使用幂等性写入来实现 数据管道 需要考虑的问题： 及时性 可靠性 至少一次传递 仅一次传递 吞吐量要求 高 动态调整 数据格式与转换问题 安全性 传输安全 权限安全 故障处理 数据管道与上下游的耦合 Connect 启动 connect: ./bin/connect-distributed.sh ./config/connect-distributed.properties 文件数据源: POST localhost:8083/connectors {\"name\":\"load-kafka-config\", \"config\":{\"connector.class\":\"FileStreamSource\",\"file\":\"config/server.properties\",\"topic\":\"kafka-config-topic\"}} 传递文件数据源到主题上 深入 连接器 任务 worker进程 转换器 偏移量管理 集群镜像 使用场景： 区域集群 中心集群 数据冗余 云迁移 多集群架构 跨数据中心通信： 高延迟 带宽有限 高成本 中心架构： 主从架构： 双活架构： 主备架构： MirrorMaker 如果有可能，尽量让 MirrorMaker 运行在目标数据中心里 监控 所有度量指标都可以通过 Java Management Extensions（JMX）接口来访问 broker 非同步分区数量： 如果集群里多个 broker 的非同步分区数量一直保持不变，那说明集群中的某个 broker 已经离线了 如果非同步分区的数量是波动的，或者虽然数量稳定但并没有 broker 离线，说明集群出现了性能问题 集群问题： 不均衡的负载 资源过度消耗 主机问题： 硬件 进程冲突 配置问题 流式处理 数据流:无边界数据集的抽象表示 数据流是有序的, 不可变的, 可重播的 流式处理是持续地从一个无边界的数据集读取数据，然后对它们进行处理并生成结果 概念 时间： 事件时间 所追踪事件的发生时间和记录的创建时间 处理时间 收到事件之后要对其进行处理的时间 状态： 内部状态 只能被单个应用程序实例访问 外部状态 使用外部的数据存储来维护 时间窗口： 设计模式 单事件处理： 本地状态事件处理： 多阶段处理： 外部数据源填充： 连接流： 对乱序事件重排序 重新处理： 使用新处理程序从头读取数据流生成结果流 Kafka Streams 架构 拓扑结构： 对拓扑结构伸缩： MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-24 01:26:07 "},"中间件/web中间件/web中间件.html":{"url":"中间件/web中间件/web中间件.html","title":"web容器/服务器","keywords":"","body":"Web 中间件 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"中间件/web中间件/Tomcat.html":{"url":"中间件/web中间件/Tomcat.html","title":"Tomcat","keywords":"","body":"Tomcat 目录结构 部署方式 直接将项目放到webapps目录下 配置conf/server.xml文件 在标签体中配置 docBase:项目存放的路径 path：虚拟目录 在conf\\Catalina\\localhost创建任意名称的xml文件。在文件中编写 虚拟目录：xml文件的名称 JAVA WEB项目目录结构 项目的根目录 WEB-INF目录： web.xml：web项目的核心配置文件 classes目录：放置字节码文件的目录 lib目录：放置依赖的jar包 架构 整体设计： Connector负责连接的建立以及数据返回 Container(Engine)负责请求的具体处理 Service 负责维护Conenctor与Container之间的映射关系 Container设计： Engine：Container的具体实现 Host：以域名为主的一个虚拟主机 Wrapper：代表Servlet实例 Context：代表一个独立的web应用 PipeLine：各个组件之间传递消息的管道 Connector设计： Endpoint负责监听连接，将连接交给Processor处理 Processor再将请求映射到Container Executor： 共享线程池由Service维护 外部依赖 Bootstrap和Catalina： Bootstrap启动Cataina Catalina启动Server 实现了Bootstrap 与 Server进行解耦 启动流程 请求处理 总体流程： CoyoteAdapter.service 请求映射：CoyoteAdapter.postParseRequest 调用容器：connector.getService().getContainer().getPipeline().getFirst().invoke(request, response) Catalina请求处理： 类加载器 通过每个app使用自己的类加载器来达到： 隔离：不同的app依赖类库不会相互影响 灵活：重新部署时的问题 对于Web 应用类加载器，它的加载顺序： 从缓存加载 如果缓存没有 从JVM的Bootstrap类加载器加载 （防止JAVA SE核心类被覆盖） 如果还是没有 从当前类加载器加载 （如果开启委托 则会遵循JVM双亲委托模型） 还没有 再从父类加载器加载 Catalina Servlet容器 Digester : XML解析工具 Server 创建 解析Server：Catalina.createStartDigester 解析Engine：EngineRuleSet.addRuleInstances 解析Host：HostRuleSet.addRuleInstances 解析Context：ContextRuleSet.addRuleInstances Web应用启动流程 StandardHost： 从server.xml配置加载 或者扫描webapps目录加载 HostConfig： START_EVENT事件：会根据context描述文件或者对webapps目录下war包目录等部署应用 调用deployApps() PERIODIC_EVENT事件：检查文件是否发生变更 是则重新部署(之前不存在的应用)或者重新加载(之前存在的应用) StandardContext： 应用初始化及启动 ContextConfig： AFTER_INIT_EVENT事件：加载Context配置文件 BEFORE_START_EVENT事件：处理docBase(应用所在文件夹)问题 CONFIGURE_START_EVENT：初始化操作, 解析XML配置文件(或者扫描目录 使用注解的方式) 创建 Servlet Filter等组件 StandardWrapper： 根据配置load servlet 以及对 servlet 初始化 Context的命名与请求路径映射 Catalina 自带的 Servlet DefaultServlet：处理静态资源 处理目录请求 可配参数：https://tomcat.apache.org/tomcat-7.0-doc/default-servlet.html JspServlet:编译jsp文件 处理jsp请求 Coyote 请求连接器的实现 支持的传输协议： HTTP1.1 HTTP2.0 AJP1.3 支持的IO方案： NIO NIO2 APR HTTP 配置： 概念 Endpoint 通信端点 负责Socekt接收处理 Porcessor 负责创建请求和响应 将请求转发到Catalina ProtocolHandler 封装Endpoint Processor UpgradeProtocol 处理HTTP协议的升级协议 请求流程 AJP AJP（Apache JServ Protocol）是定向包协议。因为性能原因，使用二进制格式来传输可读性文本。WEB服务器通过 TCP连接 和 SERVLET容器连接 包结构： 有效载荷的前一个字节代表类型 请求处理： Jasper 使用单独的类加载器 编译方式 运行时编译： 编译结果： 首选存放在 context-param 的scratchdir 否则是 $CATALINA_BASE/work/Engine名称/Host名称/Context名称 再否则在系统临时文件目录下 预编译： jspc 编译原理 // 继承该类 class index_jsp extends HttpJspBase private static final JspFactory _jspxFactory = JspFactory.getDefaultFactory(); private static Map _jspx_dependants; // 依赖的外部资源 private static final Set _jspx_imports_packages = new HashSet(); // 导入的包 private static final Set _jspx_imports_classes; // 导入的类 _jspService 处理请求： 定义了out pageContext session application config page 等局部变量 对于静态内容调用out.write 处理jsp标签 配置管理 JVM配置 :: JVM启动参数 set \"JAVA_OPTS=%JAVA_OPTS% %JSSE_OPTS%\" 系统属性：略 服务器配置 catalina.properties: 容器启动阶段的配置 server.xml: 服务器核心配置 Server Service Executor 线程池配置 默认其他组件会创建自己的线程池 Connector 默认配置了两个 HTTP 和 AJP Engine 可以指定虚拟主机 Host name 域名 appBase 存放应用的目录 unpackWARs 是否解压war包 autoDeploy 定期检测 自动部署 Alias 可以配置新的域名 Context docBase 具体应用的目录 path Context路径 CookieProcessor 指定cookie处理器 Loader 用于管理 web 应用的类加载器 delegate 属性可以打破双亲委派模型 reloadable 属性会监控资源变化后重新加载应用 loaderClass 指定类加载器的具体实现 Manger 会话管理器 Standard和Presistent Resources 资源共享 JarScanner content.xml Web 应用配置 context-param: ServerContext.getInitParameter() 可以获取到的参数 session-config 会话配置 三种追踪模式 COOKIE URL SSL servlet 声明servlet及其映射 listener filter mime-mapping 映射文件类型与对应的content-type welcome-file-list error-page locale-encoding-mapping-list 本地化与响应编码的关系 安全配置 jndi配置 内置的 Filter CorsFilter：解决跨域问题 CsrfPreventionFilter：防止CSRF攻击 ExpiresFilter：控制缓存过期与否 FailedRequestFilter：解析参数失败就返回错误 RemoteAddrFilter：只放行符合特定表达式的IP地址 RemoteHostFilter：只放行符合特定表达式的主机 RemoteIpFilter：前方有负载均衡器的情况下 将getRemoteAddr()替换为 X-Forwarded-For 中的IP RequestDumperFilter：以日志形式输出请求和响应对象 主要用于调试 SetCharacterEncodingFilter：设置请求编码 Tomcat 管理 /host-manager/html 集群 Tomcat 本身就不适合配置集群 一种通用的解决方案是 接入层为 Nginx Nginx 对后端的Tomcat进行负载均衡 Tomcat上的Web应用最好是设计成无状态的 如果仍然需要保持会话 最好使用一台独立的服务器来存储会话 比如 Redis 而不要使用Tomcat的会话同步功能 安全 安装部署：下载安全 移除自带的几个Web应用 server.xml: 删除不必要的连接器 删除UserDatabase 修改关键配置：8005管理端口 避免恶意web应用的自动启动：autoDeploy 允许有限的客户端访问 避免将异常堆栈打印到客户端 listing会导致目录泄漏以及DoS攻击 应用安全 传输安全(SSL) JAVA安全策略 优化 JVM 优化 Tomcat 配置优化 server.xml: 链接器maxConnections 属性：超过该属性的连接会被阻塞 tcpNoDelay：禁止TCP缓存并发送 maxKeepAliveRequest socketBuffer enableLookups 网络传输优化： 静态文件压缩 高性能链接器(NIO NIO2) 禁用自动部署 JSP页面配置(web.xml): development 设置为false 不自动检测JSP页面变动 ... 继承 web 服务器： 动静分离 负载均衡 应用优化 减少通信次数 减少通信数据流 推迟会话创建 不在会话存储大对象 合理定义对象作用域 使用连接池提高性能 使用缓存提高性能 最小化日志 附加功能 嵌入式启动 websocket MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-05 02:16:46 "},"中间件/web中间件/Nginx.html":{"url":"中间件/web中间件/Nginx.html","title":"Nginx","keywords":"","body":"Nginx Nginx (\"engine x\") 是一个高性能的 HTTP 和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器 vs apache 最核心的区别在于apache是同步多进程模型，一个连接对应一个进程 nginx是异步的，多个连接（万级别）可以对应一个进程 主要功能 http服务器 反向代理 负载均衡 动态路由 请求过滤 配置文件 worker_processes 6;，工作线程数，建议设置为CPU核数 worker_connections 10240;,每个工作线程最大支持连接 include mime.types; 文件扩展名与文件类型映射表 sendfile on; 开启高效文件传输模式,直接由内核读取文件发送给网卡 tcp_nopush 在linux/Unix系统中优化tcp数据传输，仅在sendfile开启时有效 autoindex on;开启目录列表访问，合适下载服务器，默认关闭。 keepalive_timeout 120;#长连接超时时间，单位是秒 gzip on; 开启gzip压缩输出 虚拟主机 基于端口的虚拟主机 server { listen 80; ... } 基于域名的虚拟主机 server { listen 80; server_name www.itmayiedu.com; ... } location语法 =开头表示精确匹配 ^~ 开头表示uri以某个~字符串开头，不是正则匹配 ~ 开头表示区分大小写的正则匹配 ~* 开头表示不区分大小写的正则匹配 / 通用匹配, 如果没有其它匹配,任何请求都会匹配到 “普通location ”与“正则 location ”之间的匹配顺序是: 先匹配普通 location ，再“考虑”匹配正则 location 访问状态监控： location /basic_status { stub_status on; } 反向代理 正向代理：通过客户机的配置，实现让一台服务器代理客户机，客户的所有请求都交给代理服务器处理。正向代理隐藏真实客户端 反向代理：用一台服务器，代理真实服务器，用户访问时，不再是访问真实服务器，而是代理服务器。反向代理隐藏真实服务端 反向代理隐藏真实内部ip地址，请求先访问nginx代理服务器,nginx服务器再转发到真实服务器中 nginx反向代理配置 http{ ... server { listen 80; server_name hostname; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; location / { proxy_pass http://127.0.0.1:8080; proxy_connect_timeout 600; proxy_read_timeout 600; } } } 负载均衡 所有请求先到负载均衡器，在由负载均衡器采用负载均衡算法（轮训、IP绑定、权重）分发到不同实际的服务器中 四层负载均衡：基于IP+端口的负载均衡（传输层），此种负载均衡不理解应用协议（如HTTP/FTP/MySQL等等）。例子：LVS（软负载），F5硬件负载 七层负载均衡：基于应用层的信息决定如何转发（应用层） 带来的问题 分布式Session一致性问题 分布式定时任务调度幂等性问题 分布式生成全局ID Upstream Server 上游服务器，就是被nginx代理最后真实访问的服务器 nginx配置负载均衡 upstream so { server www.baidu.com:80; server www.163.com:80; } server { listen 8080; location / { proxy_pass http://so/; } } 轮询算法 轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务，如果后端某台服务器死机，自动剔除故障系统，使用户访问不受影响。 weight（轮询权值） weight的值越大分配到的访问概率越高，主要用于后端每台服务器性能不均衡的情况下。或者仅仅为在主从的情况下设置不同的权值，达到合理有效的地利用主机资源。 # 设置权重 server www.baidu.com:80 weight=2; # 设置最大连接数 server 127.0.0.1:8050 weight=5 max_conns=800; server www.163.com:80 weight=8; max_fails:失败多少次 认为主机已挂掉则，踢出 max_fails=3 fail_timeout=30s代表在30秒内请求某一应用失败3次，认为该应用宕机，后等待30秒，这期间内不会再把新请求发送到宕机应用 ip_hash 每个请求按访问IP的哈希结果分配，使来自同一个IP的访客固定访问一台后端服务器，并且可以有效解决动态网页存在的session共享问题。俗称IP绑定。 server { ... ip_hash; } fair（第三方） 比 weight、ip_hash更加智能的负载均衡算法，fair算法可以根据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间 来分配请求，响应时间短的优先分配 url_hash(第三方) 按访问的URL的哈希结果来分配请求，使每个URL定向到一台后端服务器，可以进一步提高后端缓存服务器的效率 动态负载均衡 Consul Consul是一款开源的分布式服务注册与发现系统，通过HTTP API可以使得服务注册、发现实现起来非常简单 双机主从热备 LVS 可以实现传输层四层负载均衡。LVS是Linux Virtual Server的缩写，意思是Linux虚拟服务器。目前有三种IP负载均衡技术（VS/NAT、VS/TUN和VS/DR）；八种调度算法（rr,wrr,lc,wlc,lblc,lblcr,dh,sh） Keepalived Keepalived是基于vrrp协议的一款高可用软件。Keepailived有一台主服务器和多台备份服务器，在主服务器和备份服务器上面部署相同的服务配置，使用一个虚拟IP地址对外提供服务，当主服务器出现故障时，虚拟IP地址会自动漂移到备份服务器 故障转移 当上游服务器,一旦出现故障或者是没有及时响应的话，应该直接轮训到下一台服务器，保证服务器的高可用 配置超时时间，超时进行故障转移 location / { proxy_pass http://so/; proxy_connect_timeout 1s; proxy_send_timeout 1s; proxy_read_timeout 1s; } 动静分离 动静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态资源的速度，降低对后台应用访问的频次。这里我们将静态资源放到nginx中，动态资源转发到tomcat服务器中 nginx实现方式 通过对URL或者域名的判断，进行转发 浏览器缓存 对于静态文件，例如：CSS、图片，服务器会自动完成 Last Modified 和 If Modified Since 的比较，完成缓存或者更新 SSI 服务端嵌入 ssi包含类似于jsp页面中的incluce指令，ssi是在web服务端将include指定 的页面包含在网页中，渲染html网页响 应给客户端 。nginx、apache等多数web容器都支持SSI指令。 配置 server{ listen 80; server_name www.edu.com; ssi on; ssi_silent_errors on; ..... oprenresty 整合lua location /lua { default_type text/html; content_by_lua ' ngx.say(\"Hello, World!\") '; } 外部文件 location /lua { default_type text/html; content_by_lua_file /hello.lua; MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-22 01:56:50 "},"中间件/全文检索/全文检索.html":{"url":"中间件/全文检索/全文检索.html","title":"全文检索","keywords":"","body":"全文检索 数据分类 结构化数据 非结构化数据 数据查询 结构化查询 非结构化查询 顺序扫描法 全文检索 应用场景 数据量大 数据结构不固定 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"中间件/全文检索/Lucene.html":{"url":"中间件/全文检索/Lucene.html","title":"Lucene","keywords":"","body":"Lucene实现全文检索的流程 创建索引库 // 创建directory指定索引存放位置 Directory directory = FSDirectory.open(new File(\"./index\").toPath()); IndexWriter indexWriter = new IndexWriter(directory,new IndexWriterConfig()); File dir = new File(\"./res\"); File[] files = dir.listFiles(); assert files != null; // 遍历文件 for (File file : files) { String fileName = file.getName(); String filePath = file.getPath(); String content = FileUtils.readFileToString(file, \"utf8\"); long fileSize = FileUtils.sizeOf(file); // 根据文件内容生成成员 Field fieldName = new TextField(\"name\",fileName, Field.Store.YES); Field fieldPath = new TextField(\"path\",filePath,Field.Store.YES); Field fieldContent = new TextField(\"content\",content,Field.Store.YES); Field fieldSize = new TextField(\"size\", String.valueOf(fileSize),Field.Store.YES); // 将成员添加到文档中 Document document = new Document(); document.add(fieldName); document.add(fieldPath); document.add(fieldContent); document.add(fieldSize); // 将文档写入索引库 indexWriter.addDocument(document); } indexWriter.close(); 搜索 // 创建directory指定索引存放位置 Directory directory = FSDirectory.open(new File(\"./index\").toPath()); IndexReader indexReader = DirectoryReader.open(directory); IndexSearcher indexSearcher = new IndexSearcher(indexReader); Query query = new TermQuery(new Term(\"content\",\"spring\")); TopDocs docs = indexSearcher.search(query, 10); System.out.println(\"总记录数:\"+docs.totalHits); ScoreDoc[] scoreDocs = docs.scoreDocs; for (ScoreDoc scoreDoc : scoreDocs) { int id = scoreDoc.doc; Document document = indexSearcher.doc(id); System.out.println(document.get(\"name\")); System.out.println(document.get(\"path\")); System.out.println(document.get(\"size\")); // System.out.println(document.get(\"content\")); System.out.println(\"--------------\"); } indexReader.close(); 分析 Analyzer analyzer = new StandardAnalyzer(); TokenStream tokenStream = analyzer.tokenStream(\"\", \"Learn how to create a web page with Spring MVC.\"); CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class); tokenStream.reset(); while (tokenStream.incrementToken()){ System.out.println(charTermAttribute.toString()); } 使用别的分析器 Analyzer analyzer = new IKAnalyzer(); 维护 删除 Directory directory = FSDirectory.open(new File(\"./index\").toPath()); IndexWriter indexWriter = new IndexWriter(directory,new IndexWriterConfig()); //indexWriter.deleteAll(); indexWriter.deleteDocuments(new Term(\"content\",\"name\")); indexWriter.close(); 更新 indexWriter.updateDocument(new Term(\"content\",\"name\"),document); QueryParser MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-13 14:21:31 "},"中间件/全文检索/ElasticSearch.html":{"url":"中间件/全文检索/ElasticSearch.html","title":"ElasticSearch","keywords":"","body":"ElasticSearch ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口 Near Realtime 从写入数据到数据可以被搜索到有一个小延迟，大概是 1s 基于 es 执行搜索和分析可以达到秒级 优势 横向可扩展 分片机制提供更好的分布性 高可用 安装 使用 docker docker run elasticsearch:7.3.1 docker network create somenetwork; docker run -d --name elasticsearch --net somenetwork -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:7.3.1 9300端口： ES节点之间通讯使用 9200端口： ES节点 和 外部 通讯使用 图形化管理界面 head 概念 集群(cluster) 多个节点组成 节点(node) 服务器实例 索引（index） Databases 数据库 ​类型（type） Table 数据表 ​文档（Document） Row 行 ​字段（Field） Columns 列 shard es 可以将一个索引中的数据切分为多个 shard，分布在多台服务器上存储 replica 任何一个服务器随时可能故障或宕机，此时 shard 可能就会丢失，因此可以为每个 shard 创建多个replica 副本。replica 可以在 shard 故障时提供备用服务，所以同一片shard跟replica不能存放在同一节点 映射 mapping 索引结构 倒排索引：根据词找文章 DocId Doc 1 谷歌地图之父跳槽 Facebook 2 谷歌地图之父加盟 Facebook 3 谷歌地图创始人拉斯离开谷歌加盟 Facebook 4 谷歌地图之父跳槽 Facebook 与 Wave 项目取消有关 5 谷歌地图之父拉斯加盟社交网站 Facebook 对这些doc进行分词之后，以词为主键，记录哪些doc出现了这些词 WordId Word DocIds 1 谷歌 1,2,3,4,5 2 地图 1,2,3,4,5 3 之父 1,2,4,5 4 跳槽 1,4 5 Facebook 1,2,3,4,5 6 加盟 2,3,5 7 创始人 3 8 拉斯 3,5 9 离开 3 10 与 4 .. .. .. 正排索引：根据文章找词 操作 创建索引 PUT /blog { \"settings\": { \"number_of_shards\": 3, \"number_of_replicas\": 2 } } 获取索引库信息 GET /blog 删除索引库 DELETE /blog 添加映射 PUT /索引库名/_mapping/类型名称 { \"properties\": { \"字段名\": { \"type\": \"类型\", \"index\": true, \"store\": true, \"analyzer\": \"分词器\" } } } 数据类型 text：该类型被用来索引长文本，在创建索引前会将这些文本进行分词，转化为词的组合，建立索引；允许es来检索这些词，text类型不能用来排序和聚合。 keyword：该类型不需要进行分词，可以被用来检索过滤、排序和聚合，keyword类型自读那只能用本身来进行检索（不可用text分词后的模糊检索） 数值型：long、integer、short、byte、double、float 日期型：date 布尔型：boolean 二进制型：binary 查看映射关系 GET /索引库名/_mapping 更新索引 POST http://my-pc:9200/blog/{indexName} 添加文档 POST /索引库名/类型名 { \"key\":\"value\" } 自定义id POST /索引库名/类型/id值 {...} 删除文档 DELETE http://my-pc:9200/blog/hello/1 修改文档 UPDATE http://my-pc:9200/blog/hello/1 查询 基本查询 GET /索引库名/_search { \"query\":{ \"查询类型\":{ \"查询条件\":\"查询条件值\" } } } 根据ID查询 GET http://my-pc:9200/blog/hello/1 根据字段查询 Term Query为精确查询，在搜索时会整体匹配关键字，不再将关键字分词。 GET /shop/_search { \"_source\": [\"title\",\"price\"], \"query\": { \"term\": { \"price\": 2699 } } } queryString查询 { \"query\":{ \"query_string\":{ \"default_field\":\"content\", \"query\":\"内容\" } } } 过滤 includes：来指定想要显示的字段 excludes：来指定不想要显示的字段 GET /shop/_search { \"_source\": { \"includes\":[\"title\",\"price\"] }, \"query\": { \"term\": { \"price\": 2699 } } } 排序 GET /shop/_search { ... \"sort\": [ { \"price\": { \"order\": \"desc\" } } ] } 模糊查询 GET /heima/_search { \"query\": { \"fuzzy\": { \"title\": { \"value\":\"appla\", \"fuzziness\":1 } } } } 分词 内置的分词器 Standard Analyzer Simple Analyzer Whitespace Analyzer Stop Analyzer Keyword Analyzer Pattern Analyzer Language Analyzers Fingerprint Analyzer 测试分词 GET /_analyze { \"analyzer\": \"standard\", \"text\": \"中文测试分词\" } 中文分词器 下载 docker run --name elasticsearch --net somenetwork -v /root/plugin:/usr/share/elasticsearch/plugins -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:7.3.1 GET http://my-pc:9200/_analyze { \"analyzer\": \"ik_max_word\", \"text\": \"中文测试分词\" } ik 的两种模式： max：会将文本做最细粒度的拆分 会穷尽所有的可能 smart：最最粗粒度的划分 聚合 桶 ES集群 采用ES集群，将单个索引的分片到多个不同分布式物理机器上存储，从而可以实现高可用、容错性 架构 es 集群多个节点，会自动选举一个节点为 master 节点 master 节点宕机了，那么会重新选举一个节点为 master 节点 非 master节点宕机了，那么会由 master 节点，让那个宕机节点上的 primary shard 的身份转移到其他机器上的 replica shard 可以使用三个节点，将索引分成三份，每个节点存放一份primary shard，两份replica，这样就算只剩下一台节点，也能保证服务可用 搭建 配置 # 集群名称，必须保持一致 cluster.name: elasticsearch # 节点的名称 node.name: node-1 # 监听网段 network.host: 0.0.0.0 # 本节点rest服务端口 http.port: 9201 # 本节点数据传输端口 transport.tcp.port: 9301 # 集群节点信息 discovery.seed_hosts: [\"127.0.0.1:9301\",\"127.0.0.1:9302\",\"127.0.0.1:9303\"] cluster.initial_master_nodes: [\"node-1\",\"node-2\",\"node-3\"] 另外两个节点配置省略... JAVA客户端 依赖 org.elasticsearch elasticsearch 7.3.1 org.elasticsearch.client transport 7.3.1 连接 Settings settings = Settings.builder() .put(\"cluster.name\",\"docker-cluster\") .build(); TransportClient client = new PreBuiltTransportClient(settings); client.addTransportAddress( new TransportAddress(InetAddress.getByName(\"my-pc\"),9300)); 创建索引 client.admin().indices().prepareCreate(\"index\").get(); 设置映射 XContentBuilder builder = XContentFactory.jsonBuilder() .startObject() .startObject(\"article\") .startObject(\"properties\") .startObject(\"id\") .field(\"type\", \"long\") .field(\"store\", true) .endObject() .startObject(\"title\") .field(\"type\", \"text\") .field(\"store\", true) .field(\"analyzer\", \"ik_smart\") .endObject() .startObject(\"content\") .field(\"type\", \"text\") .field(\"store\", true) .field(\"analyzer\", \"ik_smart\") .endObject() .endObject() .endObject() .endObject(); client.admin().indices().preparePutMapping(\"index\") .setType(\"article\") .setSource(builder) .get(); 添加文档 XContentBuilder builder = XContentFactory.jsonBuilder() .startObject() .field(\"id\",1L) .field(\"title\",\"央视快评：勇做敢于斗争善于斗争的战士\") .field(\"content\",\"9月3日，习近平总书记在中央党校（国家行政学院）中青年干部培训班开班式上发表重要讲话强调，广大干部特别是年轻干部要经受严格的思想淬炼、政治历练、实践锻炼，发扬斗争精神，增强斗争本领，为实现“两个一百年”奋斗目标、实现中华民族伟大复兴的中国梦而顽强奋斗。\") .endObject(); client.prepareIndex(\"index\",\"article\",\"1\") .setSource(builder) .get(); POJO添加文档 Article article = new Article(); article.setId(3L); article.setTitle(\"3央视快评：勇做敢于斗争善于斗争的战士\"); article.setContent(\"9月3日3333，（国家行政学院）中青年干部培训班开班式上发表重要讲话强调，广大干部特别是年\"); String json = new ObjectMapper().writeValueAsString(article); client.prepareIndex(\"index\",\"article\",\"3\") .setSource(json, XContentType.JSON) .get(); 查询 根据ID QueryBuilder queryBuilder = QueryBuilders.idsQuery().addIds(\"1\",\"2\"); SearchResponse response = client.prepareSearch(\"index\") .setTypes(\"article\") .setQuery(queryBuilder) .get(); SearchHits hits = response.getHits(); System.out.println(\"总记录:\"+hits); SearchHit[] ret = hits.getHits(); for (SearchHit documentFields : ret) { Map map = documentFields.getSourceAsMap(); System.out.println(\"id:\"+map.get(\"id\")); System.out.println(\"title:\"+map.get(\"title\")); System.out.println(\"content:\"+map.get(\"content\")); System.out.println(\"-------------------\"); } 根据term QueryBuilder queryBuilder = QueryBuilders.termQuery(\"title\",\"斗争\"); 根据queryString QueryBuilder queryBuilder = QueryBuilders.queryStringQuery(\"青年强调\") .defaultField(\"content\"); 分页查询 SearchResponse response = client.prepareSearch(\"index\") .setTypes(\"article\") .setQuery(queryBuilder) .setFrom(10) .setSize(5) .get(); 高亮显示结果 HighlightBuilder highlightBuilder = new HighlightBuilder(); highlightBuilder.field(highlight); highlightBuilder.preTags(\"\"); highlightBuilder.postTags(\"\"); SearchResponse response = client.prepareSearch(\"index\") .setTypes(\"article\") .setQuery(queryBuilder) .highlighter(highlightBuilder) .get(); SearchHits hits = response.getHits(); System.out.println(\"总记录:\"+hits.getTotalHits()); SearchHit[] ret = hits.getHits(); for (SearchHit documentFields : ret) { Map map = documentFields.getSourceAsMap(); System.out.println(\"id:\"+map.get(\"id\")); System.out.println(\"content:\"+map.get(\"content\")); Map highlightFields = documentFields.getHighlightFields(); System.out.println(highlightFields.get(highlight).getFragments()[0]); System.out.println(\"-------------------\"); } es操作过程 写过程 客户端选择一个协调节点（coordinating node）发送请求，协调节点将请求转发给对应的node 对应的node在primary shard上处理请求，并同步到replica shard上 写过程原理 数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到 每隔 5s，将数据写入 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中 读过程 客户端选择一个协调节点（coordinating node）发送根据ID查询请求，协调节点会根据id进行哈希，得到doc所在的分片，将请求转发到对应的node 这个node然后会在primary shard与replica中使用随机轮询，进行负载均衡，返回document给协调节点 协调节点再把document返回给客户端 搜索过程 客户端发送搜索请求给协调节点，协调节点将这个请求发送给所有的shard 每个shard将自己的搜索结构返回给协调节点 由协调节点进行数据的合并、排序、分页等操作，产出最终结果 接着协调节点根据id再去查询对应的document的数据，返回给客户端 删除/更新过程 删除操作，会生成一个对应document id的.del文件，标识这个document被删除 如果是更新操作，就是将原来的 doc 标识为 deleted 状态，然后新写入一条数据 每refresh一次，会生成一个segment file，系统会定期合并这些文件，合并这些文件的时候，会物理删除标记.del的document 性能优化 杀手锏：filesystem cache 在es中，doc的字段尽量只存储要被搜索的字段，这样可以节省内存，存放更多数据，做缓存效果更好 数据预热 对于一些热点数据，也要通过一些方式让它在缓存中 冷热分离 保证热点数据都在缓存里，提高系统性能 doc模型设计 对于一些复杂的关联，最好在应用层面就做好，对于一些太复杂的操作，比如 join/nested/parent-child 搜索都要尽量避免，性能都很差的 分页性能优化 由于分页操作是由协调节点来完成的，所以翻页越深，性能越差 解决： 不允许深度翻页 将翻页设计成不允许跳页，只能一页一页翻 kibana Kibana是一个基于Node.js的Elasticsearch索引库数据统计工具，可以利用Elasticsearch的聚合功能，生成各种图表，如柱形图，线状图，饼图等。 而且还提供了操作Elasticsearch索引数据的控制台，并且提供了一定的API提示，非常有利于我们学习Elasticsearch的语法。 安装 docker docker pull kibana:5.6.8 # 拉取镜像 docker run -d --name kibana --net somenetwork -p 5601:5601 kibana:5.6.8 # 启动 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-21 02:06:44 "},"中间件/缓存/缓存.html":{"url":"中间件/缓存/缓存.html","title":"缓存中间件","keywords":"","body":"缓存中间件 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-17 07:36:37 "},"中间件/缓存/EhCache.html":{"url":"中间件/缓存/EhCache.html","title":"EhCache","keywords":"","body":"EhCache Ehcache是​​一个标准的开源缓存，可提高性能，减轻数据库负载并简化可伸缩性。 因为它健壮，可靠，功能齐全并可以与其他流行的库和框架集成,所以是最广泛使用的基于Java的缓存。 Ehcache可以从进程内缓存扩展到具有TB级缓存的混合进程内/进程外部署 基本架构 Ehcache是用来管理缓存的一个工具，其缓存的数据可以是存放在内存里面的，也可以是存放在硬盘上的。 其核心是CacheManager，一切Ehcache的应用都是从CacheManager开始的。它是用来管理Cache（缓存）的，一个应用可以有多个CacheManager，而一个CacheManager下又可以有多个Cache。 Cache内部保存的是一个个的Element，而一个Element中保存的是一个key和value的配对，相当于Map里面的一个Entry 缓存过期策略 当缓存需要被清理时（比如空间占用已经接近临界值了），需要使用某种淘汰算法来决定清理掉哪些数据 FIFO：First In First Out，先进先出。判断被存储的时间，离目前最远的数据优先被淘汰。 LRU：Least Recently Used，最近最少使用。判断最近被使用的时间，目前最远的数据优先被淘汰。 LFU：Least Frequently Used，最不经常使用。在一段时间内，数据被使用次数最少的，优先被淘汰。 Spring Boot整合EhCache 引入依赖 org.springframework.boot spring-boot-starter-cache net.sf.ehcache ehcache 2.10.6 配置 spring: cache: type: ehcache # 配置缓存类型 ehcache: config: classpath:ehcache.xml # ehcache的配置文件 编写ehcache配置文件 缓存注解配置 @CacheConfig(cacheNames ={\"userCache\"}) // 设置缓存的标志 @Service public class UserService { // 这个方法的返回值会被缓存 @Cacheable public String username(){ return UUID.randomUUID().toString(); } // 这个方法会清除缓存 @CacheEvict public void update(){ } } 开启缓存 @SpringBootApplication @EnableCaching public class EhcacheApplication { public static void main(String[] args) { SpringApplication.run(EhcacheApplication.class, args); } } Redis+EhCache分布式缓存架构 这里要注意的是以及缓存的过期时间要比二级缓存早 同时，由于查询redis要走网络，所以可以把ehcahe作为一级缓存，redis作为二级缓存 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-25 01:04:34 "},"中间件/缓存/Memcached.html":{"url":"中间件/缓存/Memcached.html","title":"Memcached","keywords":"","body":"Memcached 免费 开源 高性能 分布式内存对象缓存系统 设计理念 简单KV存储 服务器不关心数据结构 需要程序前序列化再存储到服务器 一半一半 缓存逻辑一半在客户端 一半在服务器 客户端知道找哪台服务器读写 服务器知道如何存储item 如何淘汰内存 简单的集群 集群服务器之间无法通信 没有同步 没有广播 没有复制 O(1) 所有命令操作很快 并且是锁友好的 过期是常态 memcached 是一种LRU缓存 缓存失效 客户端对集群服务器的操作时按需访问 而非直接向所有服务器广播 硬件需求 低CPU需求：默认使用4条工作线程 大多时候只需要一条缓存线程 内存需求：内存越多越好 集群节点内存大小最好一致 方便扩容缩容时不考虑权重问题 避免内存交换 是否为高速内存不重要 网络需求： 取决于实际使用情况 如果具有非常高的带宽 使用多个memcached比较好 硬件布局 缓存web服务器 缓存数据库 不是好主意 应该将内存留给数据库的索引优化 使用专用的服务器 好处是专用 扩展方便 容量规划 搭建集群前容量规划好 运行期扩展十分困难 服务器配置 -m 参数告诉memcached可以使用多少内存 这个并非限制memcached实际内存使用 而是memcached存储缓存的最大限制 -d 参数 后台启动 -v 控制标准输入输出的打印 -p 指定端口号 可以指定不同的端口号启动多个实例 -l 绑定指定网卡或者IP -U UDP端口 -s 使用unix socket 连接限制：默认连接数量限制为1024 查过这个限制的连接会被挂起 每个连接的内存开销很低 线程：memcached默认使用4个线程 采取了类似nginx的线程模型 打印memcached状态： echo \"stats settings\" | nc localhost 11211 客户端配置 哈希算法：根据key来选择服务器 一致性哈希：减少服务器数量变动带来的重哈希问题 服务器配置要一致 避免在不同的服务器上哈希得到不同的结果 权重：有时候 一些机器资源更多 我们就给他更多的权重 处理更多的请求 失败还是故障转移：转移的一个问题在于可能会使请求返回旧数据 更多的情况下 对于缓存 直接让其失败就好 压缩：客户端都支持压缩大数据 小数据压缩得不偿失 管理连接对象：注意连接的管理 如果不注意 每次操作都打开一个连接 会造成连接泄漏 Java 客户端 com.googlecode.xmemcached xmemcached 2.4.6 MemcachedClient client = new XMemcachedClient(\"192.168.1.101\", 11211); //同步存储value到memcached，缓存超时为1小时，3600秒。 client.set(\"key\", 3600, \"jntm\"); //从memcached获取key对应的value Object someObject = client.get(\"key\"); System.out.println(someObject); //从memcached获取key对应的value,操作超时2秒 someObject = client.get(\"key\", 2000); //更新缓存的超时时间为10秒。 boolean success = client.touch(\"key\", 10); System.out.println(success); //删除value client.delete(\"key\"); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-11 07:36:40 "},"中间件/分布式/分布式.html":{"url":"中间件/分布式/分布式.html","title":"分布式中间件","keywords":"","body":"分布式中间件 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-04-05 10:55:35 "},"中间件/分布式/Zookeeper.html":{"url":"中间件/分布式/Zookeeper.html","title":"Zookeeper","keywords":"","body":"Zookeeper 提供了协调分布式应用的基本服务，它提供了以下通用服务： 分布式同步（Distributed Synchronization） 命名服务（Naming Service） 集群维护（Group Maintenance） 应用场景 命名服务 通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息 数据发布与订阅（配置中心） 发布者将数据发布到ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新 分布式通知/协调 watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理 分布式事务 分布式事务中最重要的就是要有一个协调者，ZK就充当了这个角色 分布式锁 保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁 控制时序，就是所有试图来获取这个锁的客户端，最会按获取锁的顺序来获得锁 集群管理与Master选举 能够快速对集群中机器变化作出响应并将变化推送给客户端 有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行，其余机器可以共享这个结果 负载均衡 在分布式环境中，为了保证高可用性，通常同一个应用或同一个服务的提供方都会部署多份，达到对等服务。而消费者就须要在这些对等的服务器中选择一个来执行相关的业务逻辑 基础 数据结构 层次化的目录结构，命名符合常规文件系统规范(类似文件系统） 每个节点在zookeeper中叫做znode,并且其有一个唯一的路径标识 znode有4种类型： 临时节点（ephemeral），客户端断开连接zk会删除ephemeral类型节点 持久节点（persistent），客户端断开连接zk不删除persistent类型节点 PERSISTENT_SEQUENTIAL 持久且有序的节点 发生重复会自增 EPHEMERAL_SEQUENTIAL 临时且有序的节点 发生重复会自增 节点Znode可以包含数据和子节点（但是EPHEMERAL类型的节点不能有子节点） 如果一个znode节点包含任何数据，那么数据存储为字节数组 监视与通知 监视点会触发一个通知。为了接收多个通知，客户端必须在每次通知后设置一个新的监视点 客户端可以设置多种监视点： 监控znode的数据变化 监控znode子节点的变化 监控znode的创建或删除 版本号 每一个znode都有一个版本号，它随着每次数据变化而自增 使用版本号有效避免并发写问题 特征/保障 顺序一致性 - 客户端的更新将按发送顺序应用。 原子性 - 更新成功或失败。没有部分结果。 统一视图 - 无论服务器连接到哪个服务器，客户端都将看到相同的服务视图。 可靠性 - 一旦应用了更新，它将从那时起持续到客户端覆盖更新。 及时性 - 系统的客户视图保证在特定时间范围内是最新的。 架构 独立模式：单机 仲裁模式：集群 在集群模式下 最多能容忍服务器挂掉的数量为 总服务器/2 +1 会话 zk客户端的会话可以透明地在多台服务器上转移 同一个会话中的请求遵循FIFO 会话状态： 网络分区时的CONNECTING： 如果因网络分区问题导致客户端与ZooKeeper集群被隔离而发生连接断开，那么其CONNECTING状态将会一直保持，直到显式地关闭这个会话，或者分区问题修复后，客户端能够获悉ZooKeeper服务器发送的会话已经过期 设置了超时时间t 果经过时间t之后服务接收不到这个会话的任何消息，服务就会声明会话过期 客户端如果经过t/3的时间未收到任何消息，客户端将向服务器发送心跳消息。在经过2t/3时间后，ZooKeeper客户端开始寻找其他的服务器 重连： 客户端重连时根据zxid来判断服务器数据是否最新 来决定是否连接 JAVA操作 依赖 org.apache.zookeeper zookeeper 3.5.7 新增节点 CountDownLatch latch = new CountDownLatch(1); // 连接zk ZooKeeper zk = new ZooKeeper(\"localhost:2181\", 5000, new Watcher() { @Override public void process(WatchedEvent watchedEvent) { // 监听节点变化 latch.countDown(); } }); latch.await(); // 创建节点 String ret = zk.create(\"/test\", \"jntm\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); System.out.println(ret); zk.close(); 实现负载均衡 使用Zookeeper实现负载均衡原理，服务器端将启动的服务注册到，zk注册中心上，采用临时节点。客户端从zk节点上获取最新服务节点信息，本地使用负载均衡算法，随机分配服务器 使用zkclient com.101tec zkclient 0.11 服务端在启动之后注册到zk public void registerServer() { // 将当前服务器ip 端口作为一个节点value注册到/service节点下 ZkClient zkClient = new ZkClient(\"127.0.0.1:2181\", 5000); // 先创建父节点 String root = \"/service\"; if (!zkClient.exists(root)) { zkClient.createPersistent(root); } String nodeName = root+\"/service_\"+port; String nodeValue = \"127.0.0.1:\"+port; if (zkClient.exists(nodeName)){ zkClient.delete(nodeName); } zkClient.createEphemeral(nodeName,nodeValue); System.out.println(\"服务注册成功\"); } 客户端启动之后获取服务器列表 public static void initServer() { // 连接zk获取/service节点下注册的所有节点，并且获取这些节点的value listServer.clear(); ZkClient zkClient = new ZkClient(\"127.0.0.1:2181\", 5000); String root = \"/service\"; List children = zkClient.getChildren(root); for (String s : children) { String path = root + \"/\" + s; String readData = zkClient.readData(path); listServer.add(readData); } System.out.println(\"获取服务器成功:\"+listServer); // 监听节点变化，当新增服务或者服务下线之后都会得到通知 zkClient.subscribeChildChanges(root, new IZkChildListener() { @Override public void handleChildChange(String rootPath, List list) throws Exception { listServer.clear(); for (String s : list) { String path = root + \"/\" + s; String readData = zkClient.readData(path); listServer.add(readData); } System.out.println(\"服务器列表发生改变:\"+listServer); } }); } 客户端可以通过一些负载均衡算法选择服务器 public static String getServer() { // 简单轮询 count++; return listServer.get(count%2); } master选举 原理 多个服务器在启动的时候，会在Zookeeper上创建相同的临时节点，谁如果能够创建成功，谁就为主(因为节点保证唯一)，如果主服务宕机之后，会话连接也会失效，其他服务器有开始重新选举。 实现 // 创建节点成功就代表自己选举为主节点 if (createNode()){ log.info(\"{}选举为主节点成功\",serverPort); }else { log.info(\"{}成为从节点\",serverPort); } // 增加监听，当节点被删除（主节点挂掉了），重新竞争 zkClient.subscribeDataChanges(path, new IZkDataListener() { @Override public void handleDataChange(String dataPath, Object data) throws Exception { } @Override public void handleDataDeleted(String dataPath) throws Exception { log.info(\"重新选举\"); if (createNode()){ log.info(\"{}选举为主节点成功\",serverPort); }else { log.info(\"{}成为从节点\",serverPort); } } }); private boolean createNode() { try { zkClient.createEphemeral(path); return true; } catch (Exception e) { return false; } } 集群 为了保证高可用，如果某个服务实现宕机的话，实现故障转移 整个集群可用节点数量必须大于一半，否则无法正常使用 脑裂问题：当由于网络故障 整个网络被分裂成几个独立的小岛 各个小岛之间的服务器还能通信 它们就会进行自己选举 后对外提供服务 导致整个大集群被分裂成几个小集群 从而导致数据不一致 服务器的构成 在独立服务器模式下： PrepRequestProcessor接受客户端的请求并执行这个请求，处理结果则是生成一个事务 SyncRequestProcessor负责将事务持久化到磁盘上 在FinalRequestProcessor 如果Request对象包含事务数据，该处理器将会接受对ZooKeeper数据树的修改，否则，该处理器会从数据树中读取数据并返回给客户端 集群模式下的leader： ProposalRequestProcessor会准备一个提议，并将该提议发送给跟随者 对于写操作请求，还会将请求转发给SyncRequestProcessor SyncRequestProcessor执行完之后会触发AckRequestProcessor处理器，这个处理器是一个简单请求处理器，它仅仅生成确认消息并返回给自己 CommitRequestProcessor会将收到足够多的确认消息的提议进行提交 oBeAppliedRequestProcessor会做好commit消息的确认处理 集群模式下的跟随者： FollowerRequestProcessor处理器之后转发请求给CommitRequestProcessor，同时也会转发写请求到群首服务器 commit处理器在得到leader的commit消息之前会一直阻塞 SendRequestProcessor会向leader发送确认消息 存储 日志 服务器通过事务日志来持久化事务 服务器会时不时地滚动日志，即关闭当前文件并打开一个新的文件 服务器只有在强制将事务写入事务日志之后才确认对应的提议 快照 每一个服务器会经常以序列化整个数据树的方式来提取快照 因为服务器在进行快照时还会继续处理请求，所以当快照完成时，数据树可能又发生了变化，我们称这样的快照是模糊的（fuzzy） 为了解决这个问题 需要记录序列化开始到序列化结束这段时间的操作 并将它重放到结果中 会话 会话状态由 leader 维护 为了保证会话的存活，服务器需要接收会话的心跳信息 心跳可以是消息请求或者ping消息 leader发送一个PING消息给它的追随者们，追随者们返回自从最新一次PING消息之后的一个session列表 群首服务器每半个tick就会发送一个ping消息 使用过期队列来管理会话的过期 通过一个叫bucket的数据结构批量管理会话 每次会将一批过期的会话清理掉 监视点 一个WatchManager类的实例负责管理当前已被注册的监视点列表，并负责触发它们 每种类型的服务器管理监视点的方法都是一样的 监视点只会保存在内存 zk的角色 角色 说明 Leader(领导者) 为客户端提供读和写的服务，负责投票的发起和决议，更新系统状态。 Follower（跟随者） 为客户端提供读服务，如果是写服务则转发给Leader。在选举过程中参与投票。 Observe（观察者） 为客户端提供读服务器，如果是写服务则转发给Leader。观察者只获取一条包含已提交提议的内容的INFORM消息。不参与选举过程中的投票，也不参与“过半写成功”策略。在不影响写性能的情况下提升集群的读性能。 client（客户端） 连接zookeeper服务器的使用着，请求的发起者。独立于zookeeper服务器集群之外的角色。 zab协议 zab的事务保障： 如果leader按顺序广播了事务T1和事务T2，那么每个服务器在提交T2事务前保证事务T1已经提交完成 如果某个服务器按照事务T1、事务T2的顺序提交事务，所有其他服务器也必然会在提交事务T2前提交事务T1 zab的领导保障： 一个被选举的leader确保在提交完所有之前需要提交的事务，之后才开始广播新的事务 在任何时间点，都不会出现两个leader 读写数据 写Leader 客户端向Leader发起写请求 Leader将写请求 (对于这个请求的事务包括了两个重要字段：节点中新的数据字段值和该节点新的版本号) 以Proposal的形式发给所有Follower并等待ACK Follower收到Leader的Proposal后返回ACK Leader得到过半数的ACK（Leader对自己默认有一个ACK）后向所有的Follower和Observer发送Commmit (如果一条消息没有接收到commit 那么这条消息对客户端不可见) Leader将处理结果返回给客户端 这里需要注意到的是请求的事务具有两个特性： 原子性 幂等性 每个事务都有一个zxid(事务ID), 这个id是保证事务按序执行的关键与集群选举的重要依据 写Follower/Observer 多了一步跟随者转发请求到领导者 读操作 Leader/Follower/Observer都可直接处理读请求，从本地内存中读取数据并返回给客户端即可， 所以ZooKeeper在处理以只读请求为主要负载时，性能会很高 同步数据 当leader发生变化时 有两种方式来更新跟随者： DIFF 发送缺失的事务点 SNAP 发送数据的完整快照 选举过程 服务器启动阶段的Leader选举： 每台服务器启动时，都会给自己投票。 投完票之后，会把自己的投票结果广播给集群中的每一台服务器。 这样每台服务器都有集群所有服务器的投票，会优先比较zxid zxid最大的就是为leader 如果zxid都相同 则leader 就是myid最大的那台服务器 服务器运行期间的Leader选举： 运行期间leader挂了 重复上面操作 搭建 在zk配置文件配置服务器集群 server.0=192.168.182.128:2888:3888 server.1=192.168.182.129:2888:3888 server.2=192.168.182.130:2888:3888 修改zk myid 启动各个zk 连接集群 ZkClient zkClient = new ZkClient(\"192.168.182.128:2181,192.168.182.129:2181,192.168.182.130:2181\"); zkClient.createPersistent(\"/lock\"); zkClient.close(); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-22 06:56:41 "},"中间件/分布式/xxl-job.html":{"url":"中间件/分布式/xxl-job.html","title":"xxl-job","keywords":"","body":"xxl-job 传统定时任务 单机（无集群） 定时任务的问题 高并发下 请求量大的情况下，独立的job服务器宕机之后如何处理未完成的任务 分布式下 分布式集群的情况下，怎么保证定时任务不被重复执行 分布式定时任务解决方案 集群节点读入一个全局共享变量来决定是否运行任务 分布式锁 数据库 配置文件 分布式任务调度平台 架构 工作原理 执行器 依赖 com.xuxueli xxl-job-core 2.1.2 配置 xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin xxl.job.executor.appname=xxl-job-executor-sample xxl.job.executor.ip= xxl.job.executor.port=7777 ### xxl-job, access token xxl.job.accessToken= ### xxl-job log path xxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler ### xxl-job log retention days xxl.job.executor.logretentiondays=30 @Configuration public class XxlJobConfig { private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class); @Value(\"${xxl.job.admin.addresses}\") private String adminAddresses; @Value(\"${xxl.job.executor.appname}\") private String appName; @Value(\"${xxl.job.executor.ip}\") private String ip; @Value(\"${xxl.job.executor.port}\") private int port; @Value(\"${xxl.job.accessToken}\") private String accessToken; @Value(\"${xxl.job.executor.logpath}\") private String logPath; @Value(\"${xxl.job.executor.logretentiondays}\") private int logRetentionDays; @Bean public XxlJobSpringExecutor xxlJobExecutor() { logger.info(\">>>>>>>>>>> xxl-job config init.\"); XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor(); xxlJobSpringExecutor.setAdminAddresses(adminAddresses); xxlJobSpringExecutor.setAppName(appName); xxlJobSpringExecutor.setIp(ip); xxlJobSpringExecutor.setPort(port); xxlJobSpringExecutor.setAccessToken(accessToken); xxlJobSpringExecutor.setLogPath(logPath); xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays); return xxlJobSpringExecutor; } } 编写处理器 @XxlJob(\"demoJobHandler\") public ReturnT demoJobHandler(String param) throws Exception { XxlJobLogger.log(\"XXL-JOB, Hello World.\"); for (int i = 0; i 执行器集群 可以配置多个同appname的执行器，来实现定时任务执行器负载均衡 路由策略 分片广播 集群多台机器同时进行 调度中心集群 需要注意的是，调度中心是一主多备的关系，只有一台调度中心进行调度任务 启动多台调度中心 执行器配置多个调度中心地址 xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin,http://127.0.0.1:8079/xxl-job-admin MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-02 07:41:55 "},"中间件/分布式/Apollo.html":{"url":"中间件/分布式/Apollo.html","title":"Apollo","keywords":"","body":"Apollo Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景 分布式配置中心 将配置文件信息注册到配置中心平台上，可以使用分布式配置中心实时更新配置文件信息，统一管理配置文件，不需要重新打包发布。 流程 安装 拉取代码:https://github.com/nobodyiam/apollo-build-scripts 创建数据库,导入sql文件 配置demo.sh数据库连接信息 执行 demo.sh start Spring boot整合 修改/opt/settings/server.properties（Mac/Linux）或C:\\opt\\settings\\server.properties（Windows）文件，设置env 引入依赖 com.ctrip.framework.apollo apollo-client 1.5.1 配置注册中心 server.port=8081 spring.application.name=service eureka.client.service-url.defaultZone=http://127.0.0.1:8080/eureka apollo.properties local.meta=http://127.0.0.1:8080 dev.meta=http://127.0.0.1:8080 fat.meta=${fat_meta} uat.meta=${uat_meta} lpt.meta=${lpt_meta} pro.meta=${pro_meta} META-INF/app.properties app.id=app_id MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-03 08:02:43 "},"中间件/数据库中间件/数据库中间件.html":{"url":"中间件/数据库中间件/数据库中间件.html","title":"数据库中间件","keywords":"","body":"数据库中间件 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-22 00:33:18 "},"中间件/数据库中间件/MyCat.html":{"url":"中间件/数据库中间件/MyCat.html","title":"MyCat","keywords":"","body":"MyCat MyCAT是一款由阿里Cobar演变而来的用于支持数据库，读写分离、分表分库的分布式中间件 MyCAT原理MyCAT主要是通过对SQL的拦截，然后经过一定规则的分片解析、路由分析、读写分离分析、缓存分析等，然后将SQL发给后端真实的数据块，并将返回的结果做适当处理返回给客户端 使用 server.xml 123 mycat_testdb --> 123 mycat_testdb true schema.xml S1，M2->S2，并且M1与 M2互为主备)，正常情况下，M2,S1,S2都参与select语句的负载均衡； 2，所有的readHost与writeHost都参与select语句的负载均衡，也就是说，当系统的写操作压力不大的情况下，所有主机都可以承担负载均衡； --> select user() 分片枚举 分片枚举算法就是根据不同的枚举(常量)，分类存储。 schema.xml rule.xml name hash-int partition-hash-int.txt 1 1 partition-hash-int.txt wuhan=0 shanghai=1 suzhou=2 取模 使用根据ID对节点数量取余，得到存放节点 这种方式数据库节点一开始就是固定的，如果节点数量发生变更，需要迁移数据rehash 查询原理 如果含有分片字段，则根据字段计算出数据所在DB，向DB发送查询请求并返回给客户端 否则向所有DB节点发送查询请求，汇总结果后拼接返回给客户端 所以如果没有排序，会发现同样的条件查询，会有不同的顺序 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-22 12:58:19 "},"中间件/数据库中间件/ShardingJDBC.html":{"url":"中间件/数据库中间件/ShardingJDBC.html","title":"ShardingJDBC","keywords":"","body":"ShardingJDBC 一个客户端数据库分片库 原理 简单使用 io.shardingjdbc sharding-jdbc-core 2.0.3 #shardingjdbc配置 sharding: jdbc: data-sources: ###配置第一个从数据库 ds_slave_0: password: 123 jdbc-url: jdbc:mysql://192.168.182.132:3306/test?useUnicode=true&characterEncoding=utf-8&useSSL=true driver-class-name: com.mysql.jdbc.Driver username: root ###主数据库配置 ds_master: password: 123 jdbc-url: jdbc:mysql://192.168.182.131:3306/test?useUnicode=true&characterEncoding=utf-8&useSSL=true driver-class-name: com.mysql.jdbc.Driver username: root ###配置读写分离 master-slave-rule: ###配置从库选择策略，提供轮询与随机，这里选择用轮询 load-balance-algorithm-type: round_robin ####指定从数据库 slave-data-source-names: ds_slave_0 name: ds_ms ####指定主数据库 master-data-source-name: ds_master @Configuration @EnableConfigurationProperties(ShardingMasterSlaveConfig.class) @Log4j2 // 读取ds_master主数据源和读写分离配置 @ConditionalOnProperty({ \"sharding.jdbc.data-sources.ds_master.jdbc-url\", \"sharding.jdbc.master-slave-rule.master-data-source-name\" }) public class ShardingDataSourceConfig { @Autowired private ShardingMasterSlaveConfig shardingMasterSlaveConfig; @Bean public DataSource masterSlaveDataSource() throws SQLException { final Map dataSourceMap = Maps.newHashMap(); dataSourceMap.putAll(shardingMasterSlaveConfig.getDataSources()); final Map newHashMap = Maps.newHashMap(); // 创建 MasterSlave数据源 DataSource dataSource = MasterSlaveDataSourceFactory.createDataSource(dataSourceMap, shardingMasterSlaveConfig.getMasterSlaveRule(), newHashMap); log.info(\"masterSlaveDataSource config complete\"); return dataSource; } } @Data @ConfigurationProperties(prefix = \"sharding.jdbc\") public class ShardingMasterSlaveConfig { // 存放本地多个数据源 private Map dataSources = new HashMap<>(); private MasterSlaveRuleConfiguration masterSlaveRule; } 分表 private DataSource buildDataSource() { // 1.设置分库映射 Map dataSourceMap = new HashMap<>(2); dataSourceMap.put(\"ds_0\", createDataSource(\"ds_0\")); // dataSourceMap.put(\"ds_1\", createDataSource(\"ds_1\")); // 设置默认db为ds_0，也就是为那些没有配置分库分表策略的指定的默认库 // 如果只有一个库，也就是不需要分库的话，map里只放一个映射就行了，只有一个库时不需要指定默认库， // 但2个及以上时必须指定默认库，否则那些没有配置策略的表将无法操作数据 DataSourceRule rule = new DataSourceRule(dataSourceMap, \"ds_0\"); // 2.设置分表映射，将t_order_0和t_order_1两个实际的表映射到t_order逻辑表 TableRule orderTableRule = TableRule.builder(\"t_order\").actualTables(Arrays.asList(\"t_order_0\", \"t_order_1\")) .dataSourceRule(rule).build(); // 3.具体的分库分表策略 ShardingRule shardingRule = ShardingRule.builder().dataSourceRule(rule) .tableRules(Arrays.asList(orderTableRule)) // 根据userid分片字段 .tableShardingStrategy(new TableShardingStrategy(\"user_id\", new TableShardingAlgorithm())).build(); // 创建数据源 DataSource dataSource = ShardingDataSourceFactory.createDataSource(shardingRule); return dataSource; } private DataSource createDataSource(String dataSourceName) { // 使用druid连接数据库 DruidDataSource druidDataSource = new DruidDataSource(); druidDataSource.setDriverClassName(className); druidDataSource.setUrl(String.format(url, dataSourceName)); druidDataSource.setUsername(username); druidDataSource.setPassword(password); return druidDataSource; } public class TableShardingAlgorithm implements SingleKeyTableShardingAlgorithm { // sql 中关键字 匹配符为 =的时候，表的路由函数 @Override public String doEqualSharding(Collection availableTargetNames, ShardingValue shardingValue) { for (String tableName : availableTargetNames) { if (tableName.endsWith(shardingValue.getValue() % 2 + \"\")) { return tableName; } } throw new IllegalArgumentException(); } ... } spring boot快速整合 io.shardingsphere sharding-jdbc-spring-boot-starter 3.0.0.M3 sharding: jdbc: ####ds1 datasource: names: ds0 ds0: password: 123 type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://192.168.182.131:3306/ds_0 username: root config: sharding: tables: t_order: table-strategy: inline: #### 根据userid 进行分片 sharding-column: user_id algorithm-expression: ds_0.t_order_$->{user_id % 2} actual-data-nodes: ds0.t_order_$->{0..1} props: sql: ### 开启分片日志 show: true MY all right reserved，powered by Gitbook该页面最后修改于： 2020-03-24 11:26:25 "},"中间件/文件服务器/文件服务器.html":{"url":"中间件/文件服务器/文件服务器.html","title":"文件服务器","keywords":"","body":"文件服务器 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-01 07:09:06 "},"中间件/文件服务器/FastDFS.html":{"url":"中间件/文件服务器/FastDFS.html","title":"FastDFS","keywords":"","body":"FastDFS 分布式文件系统 分布式文件系统（Distributed File System）是指文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点(可简单的理解为一台计算机)相连 NFS GFS HDFS 架构 Tracker：负责调度 Storage：负责存储 group：组，也称为卷。同组内服务器上的文件是完全相同的 上传流程 安装 docker pull delron/fastdfs 安装Tracker docker run -d --network=host --name tracker -v /docker/fastdfs/tracker:/var/fdfs delron/fastdfs tracker 安装Storage docker run -d --network=host --name storage -e TRACKER_SERVER=192.168.1.56:22122 -v /docker/fastdfs/storage:/var/fdfs -e GROUP_NAME=group1 delron/fastdfs storage JAVA API 依赖 com.github.tobato fastdfs-client ${fastDFS.client.version} 配置 fdfs: so-timeout: 1501 # 超时时间 connect-timeout: 601 # 连接超时时间 thumb-image: # 缩略图 width: 60 height: 60 tracker-list: # tracker地址 - my-pc:22122 image: adress: http://my-pc:8888/ 使用 StorePath storePath = storageClient.uploadImageAndCrtThumbImage(file.getInputStream(), file.getSize(),\"扩展名\", null); MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-01 07:09:06 "},"移动开发/nav.html":{"url":"移动开发/nav.html","title":"移动开发","keywords":"","body":"移动开发 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 12:40:15 "},"移动开发/安卓/nav.html":{"url":"移动开发/安卓/nav.html","title":"安卓","keywords":"","body":"安卓 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 12:40:15 "},"移动开发/安卓/Activity.html":{"url":"移动开发/安卓/Activity.html","title":"Activity","keywords":"","body":"目录 [toc] Activity 介绍 Activity 是一个应用组件，用户可与其提供的屏幕进行交互，以执行拨打电话、拍摄照片、发送电子邮件或查看地图等操作。 每个 Activity 都会获得一个用于绘制其用户界面的窗口。窗口通常会充满屏幕，但也可小于屏幕并浮动在其他窗口之上。 一个应用通常由多个彼此松散联系的 Activity 组成。 一般会指定应用中的某个 Activity 为“主”Activity，即首次启动应用时呈现给用户的那个 Activity。 而且每个 Activity 均可启动另一个 Activity，以便执行不同的操作。 每次新 Activity 启动时，前一 Activity 便会停止，但系统会在堆栈（“返回栈”）中保留该 Activity。 当新 Activity 启动时，系统会将其推送到返回栈上，并取得用户焦点。 返回栈遵循基本的“后进先出”堆栈机制，因此，当用户完成当前 Activity 并按“返回”按钮时，系统会从堆栈中将其弹出（并销毁），然后恢复前一 Activity。 （任务和返回栈文档中对返回栈有更详细的阐述。） 当一个 Activity 因某个新 Activity 启动而停止时，系统会通过该 Activity 的生命周期回调方法通知其这一状态变化。Activity 因状态变化—系统是创建 Activity、停止 Activity、恢复 Activity 还是销毁 Activity— 而收到的回调方法可能有若干种，每一种回调都会为您提供执行与该状态变化相应的特定操作的机会。 例如，停止时，您的 Activity 应释放任何大型对象，例如网络或数据库连接。 当 Activity 恢复时，您可以重新获取所需资源，并恢复执行中断的操作。 这些状态转变都是 Activity 生命周期的一部分。 生命周期 onCreate:系统在创建Activity时调用，必须在此方法内调用 setContentView() onPause：作为用户离开 Activity 的第一个信号（但并不总是意味着 Activity 会被销毁）进行调用 onRestart：在 Activity 已停止并即将再次启动前调用 onResume:在 Activity 即将开始与用户进行交互之前调用 onStop：在 Activity 对用户不再可见时调用 onDestory:在 Activity 被销毁前调用 Activity创建 manifest: ```xml class: ```java public class Main2Activity extends AppCompatActivity { @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main2); } } Activity的启动 显式启动 Intent intent = new Intent(); intent.setClass(MainActivity.this,Main2Activity.class); startActivity(intent); 隐式启动 Intent intent = new Intent(); intent.setAction(Intent.ACTION_VIEW); intent.setData(Uri.parse(\"http://baidu.com\")); startActivity(intent); 隐式启动需要在xml中声明intent-fliter： Activity之间的数据传递 Activity之间通过Intent来传递数据，载体是Bundle: Intent intent = new Intent(); Bundle bundle = new Bundle(); bundle.putInt(\"int\",1); bundle.putString(\"string\",\"adsa\"); bundle.putSerializable(\"ser\",new HashMap<>()); bundle.putParcelable(); （也可以选择不适用Bundle，直接通过Intent进行put）Bundle除了能传递基本类型与String外，还支持Serializable，可序列化对象，也能存放实现了Parcelable接口的对象，这是安卓自己的一个接口。 接收方则是通过调用getIntent()这个方法获取传递过来的Intent，如果不为空，则就可以通过Intent来获取数据 Intent intent = getIntent(); if (intent != null){ Log.i(\"test\",String.valueOf(intent.getExtras().getInt(\"int\"))); } 获取返回数据 当一个Activity返回到上一个Activity时，要如何进行数据交互？ 使用回调： Activity1: @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); Button btn = findViewById(R.id.button); btn.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View v) { startActivityForResult(new Intent(),1); } }); } @Override protected void onActivityResult(int requestCode, int resultCode, @Nullable Intent data) { Log.i(\"test\",data.getStringExtra(\"name\")); super.onActivityResult(requestCode, resultCode, data); } Activity2: @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main2); Intent intent = getIntent(); if (intent != null){ Log.i(\"test\",String.valueOf(intent.getExtras().getInt(\"int\"))); } Intent intent1 = new Intent(); intent1.putExtra(\"name\",\"my\"); setResult(1,intent1); } 需要注意的是，如果要求Activity返回结果，需要使用startActivityForResult这个函数 传输大数据对象异常 在传输数据时，数据量不能大于0.25m，否则将会出现异常 Activity与Task Task简介 android任务栈又称为Task，它是一个栈结构，具有后进先出的特性，用于存放我们的Activity组件。 我们每次打开一个新的Activity或者退出当前Activity都会在一个称为任务栈的结构中添加或者减少一个Activity组件，因此一个任务栈包含了一个activity的集合, android系统可以通过Task有序地管理每个activity，并决定哪个Activity与用户进行交互:只有在任务栈栈顶的activity才可以跟用户进行交互。 在我们退出应用程序时，必须把所有的任务栈中所有的activity清除出栈时,任务栈才会被销毁。当然任务栈也可以移动到后台, 并且保留了每一个activity的状态. 可以有序的给用户列出它们的任务, 同时也不会丢失Activity的状态信息。 需要注意的是，一个App中可能不止一个任务栈，某些特殊情况下，单独一个Actvity可以独享一个任务栈。还有一点就是一个Task中的Actvity可以来自不同的App，同一个App的Activity也可能不在一个Task中。Activity的四种启动模式 Standard 模式 在这样模式下，每启动一个Activity都会重新创建一个Activity的新实例，并且将其加入任务栈中 singleTop 模式 在这种模式下，如果有新的Activity已经存在任务栈的栈顶，那么此Activity就不会被重新创建新实例，而是复用已存在任务栈栈顶的Activity 如果Activity在顶层，那么不会新建新的实例： 如果不在顶层，那么仍会创建新的实例： singleTask 模式 又称为栈内复用模式。这是一种单例模式，与singTop点类似，只不过singTop是检测栈顶元素是否有需要启动的Activity，而singTask则是检测整个栈中是否存在当前需要启动的Activity，如果存在就直接将该Activity置于栈顶，并将该Activity以上的Activity都从任务栈中移出销毁 singleInstance 模式 在singleInstance模式下，该Activity在整个android系统内存中有且只有一个实例，而且该实例单独尊享一个Task 设置Activity的启动模式 设置启动模式只需在清单文件的activity节点中增加android:launchMode即可。BackTask Task可以分为foreground task和background task. 当用户按下home键时, 当前task就会从foreground task变成background task. 如果一个task变为background task, 那么栈中的所有activity都将处于stopped状态 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-05-27 04:03:18 "},"移动开发/安卓/Intent.html":{"url":"移动开发/安卓/Intent.html","title":"Intent","keywords":"","body":"[toc] Intent 与 Intent过滤器 Intent 是一个消息传递对象，您可以使用它从其他应用组件请求操作 其基本用例主要包括以下三个： 启动 Activity 启动服务 传递广播Intent类型 显式 Intent：按名称（完全限定类名）指定要启动的组件 隐式 Intent ：不会指定特定的组件，而是声明要执行的常规操作，从而允许其他应用中的组件来处理它 从 Android 5.0（API 级别 21）开始，如果使用隐式 Intent 调用 bindService()，系统会引发异常 　构建 Intent Intent 中包含的主要信息如下： 组件名称 操作 数据 类别 Extra 标志显式 Intent 示例 // 在 Activity 中执行, 所以 'this' 就是当前的上下文 // fileUrl 是一个URL, 类似 \"http://www.example.com/image.png\" Intent downloadIntent = new Intent(this, DownloadService.class); downloadIntent.setData(Uri.parse(fileUrl)); startService(downloadIntent); 隐式 Intent 示例 ```java // 创建一条文本消息 Intent sendIntent = new Intent(); sendIntent.setAction(Intent.ACTION_SEND); sendIntent.putExtra(Intent.EXTRA_TEXT, textMessage); sendIntent.setType(\"text/plain\"); // 确定这个Intent可以匹配到Activity if (sendIntent.resolveActivity(getPackageManager()) != null) { startActivity(sendIntent); } 设置选择框标题： ```java Intent chooser = Intent.createChooser(sendIntent, title); 接收隐式 Intent 以下是一个使用包含 Intent 过滤器的 Activity 声明，当数据类型为文本时，系统将接收 ACTION_SEND Intent ： 限制对组件的访问 --- 如果必须确保只有您自己的应用才能启动您的某一组件，请针对该组件将 exported 属性设置为 \"false\" MY all right reserved，powered by Gitbook该页面最后修改于： 2019-05-31 03:31:37 "},"移动开发/安卓/RecyclerView.html":{"url":"移动开发/安卓/RecyclerView.html","title":"RecyclerView","keywords":"","body":"RecyclerView A flexible view for providing a limited window into a large data set. 基本使用 定义一个Adapter，其用来控制数据与Item的绑定关系 ```java public class MyAdapter extends RecyclerView.Adapter { LayoutInflater layoutInflater; Context context; List data; public MyAdapter(Context context, List data) { this.context = context; this.data = data; layoutInflater = LayoutInflater.from(context); } @NonNull @Override public MyViewHolder onCreateViewHolder(@NonNull ViewGroup viewGroup, int i) { View view = layoutInflater.inflate(R.layout.single_view,viewGroup,false); return new MyViewHolder(view); } @Override public void onBindViewHolder(@NonNull MyViewHolder myViewHolder, int i) { myViewHolder.textView.setText(data.get(i)); } @Override public int getItemCount() { return data.size(); } } ``` 其中，ViewHolder则是控制单条Item的显示 public class MyViewHolder extends RecyclerView.ViewHolder { TextView textView; public MyViewHolder(@NonNull View itemView) { super(itemView); textView = itemView.findViewById(R.id.tv); } } 在使用时，只要指定布局管理器以及适配器，就可以自定义数据的显示方式 RecyclerView.LayoutManager manager = new GridLayoutManager(this,3); rw.setAdapter(adapter); rw.setLayoutManager(manager); 也就是说，RecyclerView提供了一种插拔式的体验，类似于模板方法模式，只要修改一下细节，就可以重新定义数据的显示方式 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-06-08 17:40:05 "},"移动开发/安卓/handler.html":{"url":"移动开发/安卓/handler.html","title":"Handler","keywords":"","body":"Handler [toc] Handler 是一个消息分发对象。handler是Android给我们提供用来更新UI的一套机制，也是一套消息处理机制，我们可以发消息，也可以通过它处理消息 由于非UI线程无法修改界面（主要的原因是防止数据不一致） 那么，如果直接创建一个线程，进行UI更新操作，程序会崩掉： new Thread(new Runnable() { @Override public void run() { try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } Toast.makeText(MainActivity.this,\"获取到消息\",Toast.LENGTH_SHORT).show(); } }).start(); 发送消息 // 成员变量 private Handler handler = new Handler(new Handler.Callback() { @Override public boolean handleMessage(Message msg) { Toast.makeText(MainActivity.this,\"获取到消息\"+msg.what,Toast.LENGTH_SHORT).show(); return true; } }); // 创建一个发送消息给Handler new Thread(new Runnable() { @Override public void run() { try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } Toast.makeText(MainActivity.this,\"获取到消息\",Toast.LENGTH_SHORT).show(); Message message = new Message(); message.what=0x123; handler.sendMessage(message); } }).start(); 直接让Handler执行一段代码 new Thread(new Runnable() { @Override public void run() { try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } handler.post(new Runnable() { @Override public void run() { Toast.makeText(MainActivity.this,\"获取到消息\",Toast.LENGTH_SHORT).show(); } }); } }).start(); Callback 这个类是Handler的一个内部类，作用主要是回调，在上面的例子我们已经认识到它的作用了 UI线程与子线程通信 Looper：类似一个消息泵。它本身是一个死循环，不断地从MessageQueue中提取Message或者Runnable MessageQueue：一个消息队列，可以看作是一个容器，用来存放消息 而Handler可以看做是一个Looper的暴露接口，向外部暴露一些事件，并暴露sendMessage()和post()函数 除了UI线程/主线程以外，普通的线程(先不提HandlerThread)是不自带Looper的 更新UI的四种方式 使用Handler消息传递 Handler的post AsyncTask Activity.runOnUiThread View.post 后两种本质上也是使用了Handler 非UI线程更新UI 在oncreate方法中开启子线程更新ui，在thread没有休眠的情况下，因为ViewRootImp在activity的onresume方法中创建，在ViewRootImp方法中判断当前线程是否为主线程，oncreate在onresume之前执行，所以这种情况下，可以进行更新ui操作 @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); new Thread(new Runnable() { @Override public void run() { handler.post(new Runnable() { @Override public void run() { Toast.makeText(MainActivity.this,\"获取到消息\",Toast.LENGTH_SHORT).show(); } }); } }).start(); } 以上代码可以正确运行 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-06-04 09:22:12 "},"移动开发/安卓/IPC机制.html":{"url":"移动开发/安卓/IPC机制.html","title":"IPC机制","keywords":"","body":"IPC机制 IPC:进程间通信 安卓中的多进程模式 开启多进程 在清单文件中添加：android:process 代表该activity以包名.p1作为进程名进行运行 多线程造成的问题 静态成员、单例模式完全失效 线程同步机制失效 SharedPrerences可靠性下降 Application多次创建 IPC Serializable接口 java当中自带的序列化接口 Parceable接口 实现接口： ```java public class User implements Parcelable { private String name; private int age; protected User(Parcel in) { name = in.readString(); age = in.readInt(); } // 省略构造器 public static final Creator CREATOR = new Creator() { @Override public User createFromParcel(Parcel in) { return new User(in); } @Override public User[] newArray(int size) { return new User[size]; } }; @Override public int describeContents() { return 0; } @Override public void writeToParcel(Parcel dest, int flags) { dest.writeString(name); dest.writeInt(age); } //省略toString } 这样，就可以直接在Intent中传送User类型的对象了： ```java Intent intent = new Intent(); intent.setClass(MainActivity.this,Main2Activity.class); intent.putExtra(\"user\",new User(\"小明\",15)); startActivity(intent); 安卓中的IPC方式 Bundle 文件共享 SharedPreferences本质：XML Messenger AIDL ContentProvider MY all right reserved，powered by Gitbook该页面最后修改于： 2019-06-05 14:10:00 "},"移动开发/安卓/通知栏.html":{"url":"移动开发/安卓/通知栏.html","title":"通知栏","keywords":"","body":"MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-11 13:41:49 "},"移动开发/安卓/数据绑定.html":{"url":"移动开发/安卓/数据绑定.html","title":"数据绑定","keywords":"","body":"概念 与MVVM 配置 android { ... dataBinding{ enabled = true } } UI绑定 ActivityMainBinding binding = DataBindingUtil.setContentView(MainActivity.this,R.layout.activity_main); binding.setTitle(\"avcd\"); 事件绑定 @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); ActivityMainBinding binding = DataBindingUtil.setContentView(MainActivity.this,R.layout.activity_main); binding.setPresenter(new Presenter()); } public class Presenter{ public void onClick(){ Toast.makeText(MainActivity.this,\"click\",Toast.LENGTH_SHORT).show(); } } presenter.onClick()}\" /> 数据绑定原理 编译 - 处理layout文件 - 解析表达式 - java编译 - 解析依赖 运算符 空指针避免 数组越界 include viewstub 观察者模式 public class UserInfo extends BaseObservable { private String name; private String password; private Integer age; public void setName(String name) { this.name = name; notifyChange(); } public void setPassword(String password) { this.password = password; notifyChange(); } public void setAge(Integer age) { this.age = age; notifyChange(); } } private UserInfo userInfo = new UserInfo(); @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); ActivityMainBinding binding = DataBindingUtil.setContentView(MainActivity.this,R.layout.activity_main); binding.setPresenter(new Presenter()); binding.setUser(userInfo); } public class Presenter implements TextWatcher { @Override public void beforeTextChanged(CharSequence charSequence, int i, int i1, int i2) { } @Override public void onTextChanged(CharSequence charSequence, int i, int i1, int i2) { userInfo.setName(charSequence.toString()); } @Override public void afterTextChanged(Editable editable) { } } 高级绑定 列表绑定 创建适配器 public class UserAdapter extends RecyclerView.Adapter { private final LayoutInflater layoutInflater; private List userInfoList = new ArrayList<>(); public UserAdapter(Context context) { layoutInflater = (LayoutInflater) context.getSystemService(Context.LAYOUT_INFLATER_SERVICE); } @Override public int getItemViewType(int position) { return super.getItemViewType(position); } @NonNull @Override public BindingViewHolder onCreateViewHolder(@NonNull ViewGroup parent, int viewType) { ViewDataBinding binding = DataBindingUtil.inflate(layoutInflater,R.layout.item_user,parent,false); return new BindingViewHolder(binding); } @Override public void onBindViewHolder(@NonNull BindingViewHolder holder, int position) { final UserInfo userInfo = userInfoList.get(position); holder.getBinding().setVariable(wang.ismy.databinding.BR.item,userInfo); holder.getBinding().executePendingBindings(); } @Override public int getItemCount() { return userInfoList.size(); } public void addAll(List list){ userInfoList.addAll(list); } public void add(UserInfo userInfo){ userInfoList.add(userInfo); notifyItemInserted(userInfoList.size()); } public void remove(){ if (userInfoList.size() == 0) return; userInfoList.remove(0); notifyItemRemoved(0); } } 创建holder public class BindingViewHolder extends RecyclerView.ViewHolder { private T binding; public BindingViewHolder(@NonNull T itemView) { super(itemView.getRoot()); binding = itemView; } public T getBinding() { return binding; } } 使用 binding = DataBindingUtil.setContentView(MainActivity.this,R.layout.activity_main); binding.recyclerView.setLayoutManager(new LinearLayoutManager(this)); userAdapter = new UserAdapter(getApplicationContext()); binding.setPresenter(new Presenter()); binding.recyclerView.setAdapter(userAdapter); userAdapter.addAll(Arrays.asList(new UserInfo(\"1\"), new UserInfo(\"2\"),new UserInfo(\"3\"), new UserInfo(\"4\"))); 自定义属性 @BindingAdapter({\"app:imageUrl\",\"app:placeholder\"}) public static void loadImage(ImageView view, String url, Drawable drawable ){ Glide.with(view.getContext()) .load(url) .placeholder(drawable) .into(view); } binding.setUrl(url); 双向绑定 表达式链 隐式更新 Lambda表达式 presenter.click()}\" /> 动画 Transition binding.addOnRebindCallback(new OnRebindCallback() { @Override public boolean onPreBind(ViewDataBinding binding) { ViewGroup viewGroup = (ViewGroup) binding.getRoot(); TransitionManager.beginDelayedTransition(viewGroup); return true; } }); MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-22 09:20:26 "},"移动开发/安卓/屏幕适配.html":{"url":"移动开发/安卓/屏幕适配.html","title":"屏幕适配","keywords":"","body":" 屏幕尺寸 屏幕对角线的长度 屏幕分辨率 横纵向上的像素点数 px 屏幕像素密度 每英寸上的像素点数 dpi 单位 px dp、dip 密度无关像素 sp 根据文字大小首选项进行收缩 mdpi、hdpi、xdpi、xxdip 解决方案 使用wrap_content、match_parent、weight weight宽度=原来宽度+剩余空间所占百分比宽度 使用相对布局 使用限定符 使用自动拉伸位图 .9图 屏幕密度问题 屏幕宽度问题 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-24 09:11:56 "},"移动开发/安卓/Fragment.html":{"url":"移动开发/安卓/Fragment.html","title":"Fragment","keywords":"","body":" 复用 使用 创建继承Fragment的类 重写onCreateView方法 绑定xml View view = inflater.inflate(R.layout.fragment_title,null); return view; 静态使用 在xml中使用 动态使用 老版本 button.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { FragmentManager manager = getFragmentManager(); FragmentTransaction transaction = manager.beginTransaction(); transaction.add(R.id.title_layout,new TitleFragment()); transaction.commit(); } }); 新版本 getSupportFragmentManager() .beginTransaction() .add(R.id.title_layout,new TitleFragment()) .commit(); V4包 动态切换 Random random = new Random(); if (random.nextBoolean()){ getSupportFragmentManager() .beginTransaction() .replace(R.id.title_layout,new TitleFragment()) .commit(); }else{ getSupportFragmentManager() .beginTransaction() .replace(R.id.title_layout,new ContentFragment()) .commit(); } 生命周期 通信 Activity 向 Fragment传值 // Activity 端 TitleFragment titleFragment = new TitleFragment(); Bundle bundle = new Bundle(); bundle.putString(\"id\", UUID.randomUUID().toString()); titleFragment.setArguments(bundle); getSupportFragmentManager() .beginTransaction() .replace(R.id.title_layout,titleFragment) .commit(); // Fragment端 if (getArguments() != null){ textView.setText(getArguments().getString(\"id\")); } Fragment 向 Activity 传值 回调接口 linearLayout.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { if (listener != null){ listener.onClick(); } } }); /////////////// public interface TitleFragmentClickListener{ void onClick(); } public void setListener(TitleFragmentClickListener listener) { this.listener = listener; } titleFragment.setListener(new TitleFragment.TitleFragmentClickListener() { @Override public void onClick() { Toast.makeText(getApplicationContext(),\"click 111\",Toast.LENGTH_SHORT).show(); } }); Fragment 向 Fragment 传值 getFragmentManager().findFragmentById() ListFragment MY all right reserved，powered by Gitbook该页面最后修改于： 2019-07-31 03:59:41 "},"移动开发/移动web开发.html":{"url":"移动开发/移动web开发.html","title":"移动web开发","keywords":"","body":"移动web开发 流式布局 视口（viewport）就是浏览器显示页面内容的屏幕区域。 视口可以分为布局视口、视觉视口和理想视口 布局视口 layout viewport 一般移动设备的浏览器都默认设置了一个布局视口，用于解决早期的PC端页面在手机上显示的问题。 iOS, Android基本都将这个视口分辨率设置为 980px，所以PC上的网页大多都能在手机上呈现，只不过元素看上去很小，一般默认可以通过手动缩放网页 视觉视口 visual viewport 它是用户正在看到的网站的区域，我们可以通过缩放去操作视觉视口，但不会影响布局视口，布局视口仍保持原来的宽度 理想视口 ideal viewport 布局视口的宽度应该与理想视口的宽度一致，简单理解就是设备有多宽，我们布局的视口就多宽 meta标签 标准设置 视口宽度和设备保持一致 视口的默认缩放比例1.0 不允许用户自行缩放 最大允许的缩放比例1.0 最小允许的缩放比例1.0 二倍图 物理像素&物理像素比 物理像素点指的是屏幕显示的最小颗粒，是物理真实存在的。这是厂商在出厂时就设置好了,比如苹果6 是 750* 1334 我们开发时候的1px 不是一定等于1个物理像素的 一个px的能显示的物理像素点的个数，称为物理像素比或屏幕像素比 lRetina（视网膜屏幕）是一种显示技术，可以将把更多的物理像素点压缩至一块屏幕里，从而达到更高的分辨率，并提高屏幕显示的细腻程度 按照刚才的物理像素比会放大倍数，这样会造成图片模糊 在标准的viewport设置中，使用倍图来提高图片质量，解决在高清设备中的模糊问题 背景缩放background-size background-size: 背景图片宽度 背景图片高度; 单位： 长度|百分比|cover|contain; cover把背景图像扩展至足够大，以使背景图像完全覆盖背景区域。 contain把图像图像扩展至最大尺寸，以使其宽度或高度完全适应内容区域 移动开发选择和技术解决方案 单独制作移动端页面（主流） 响应式页面兼容移动端（其次） 解决方案 移动端浏览器基本以 webkit 内核为主，因此我们就考虑webkit兼容性问题 移动端公共样式Normalize.css 移动端大量使用 CSS3盒子模型box-sizing CSS3盒子模型：盒子的宽度= CSS中设置的宽度width 里面包含了 border 和 padding /*CSS3盒子模型*/ box-sizing: border-box; /*传统盒子模型*/ box-sizing: content-box; 移动端特殊样式 /*CSS3盒子模型*/ box-sizing: border-box; -webkit-box-sizing: border-box; /*点击高亮我们需要清除清除 设置为transparent 完成透明*/ -webkit-tap-highlight-color: transparent; /*在移动端浏览器默认的外观在iOS上加上这个属性才能给按钮和输入框自定义样式*/ -webkit-appearance: none; /*禁用长按页面时的弹出菜单*/ img,a { -webkit-touch-callout: none; } 移动端常见布局 移动端单独制作 流式布局（百分比布局） flex 弹性布局（强烈推荐） less+rem+媒体查询布局 混合布局 响应式 媒体查询 bootstarp 流式布局： 流式布局，就是百分比布局，也称非固定像素布局。 通过盒子的宽度设置成百分比来根据屏幕的宽度来进行伸缩，不受固定像素的限制，内容向两侧填充。 流式布局方式是移动web开发使用的比较常见的布局方式。 width:100%; max-width: 1200px; min-width: 320px; flex布局 pc端浏览器支持情况比较差 如果是移动端或者是不考虑兼容的pc则采用flex 原理 flex 是 flexible Box 的缩写，意为\"弹性布局\"，用来为盒状模型提供最大的灵活性，任何一个容器都可以指定为 flex 布局 通过给父盒子添加flex属性，来控制子盒子的位置和排列方式 父项常见属性 flex-direction设置主轴的方向 flex-direction: value; justify-content 设置主轴上的子元素排列方式 flex-wrap设置是否换行 nowrap 不换行 wrap 换行 align-items 设置侧轴上的子元素排列方式（单行 ） flex-start 从头部开始 flex-end 从尾部开始 center 居中显示 stretch 拉伸 align-content 设置侧轴上的子元素的排列方式（多行） flex-flow 属性是 flex-direction 和 flex-wrap 属性的复合属性 flex-flow:row wrap; flex布局子项常见属性 flex 属性 定义子项目分配剩余空间，用flex来表示占多少份数 align-self控制子项自己在侧轴上的排列方式 align-self 属性允许单个项目有与其他项目不一样的对齐方式，可覆盖 align-items 属性 order 属性定义项目的排列顺序 数值越小，排列越靠前，默认为0 rem布局 rem rem (root em)是一个相对单位，类似于em，em是父元素字体大小。 不同的是rem的基准是相对于html元素的字体大小 媒体查询 使用 @media查询，可以针对不同的媒体类型定义不同的样式 @media 可以针对不同的屏幕尺寸设置不同的样式 当你重置浏览器大小的过程中，页面也会根据浏览器的宽度和高度重新渲染页面 目前针对很多苹果手机、Android手机，平板等设备都用得到多媒体查询 @media mediatype and|not|only (media feature) { CSS-Code; } mediatype 查询类型 关键字 关键字将媒体类型或多个媒体特性连接到一起做为媒体查询的条件 媒体特性 为了防止混乱，媒体查询我们要按照从小到大或者从大到小的顺序来写,但是我们最喜欢的还是从小到大来写，这样代码更简洁 媒体特性也可以加在css引用中，来达到不同的屏幕加载不同的css文件 rem适配方案 1.less+rem+媒体查询 2.lflexible.js+rem MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"移动开发/小程序开发/nav.html":{"url":"移动开发/小程序开发/nav.html","title":"小程序开发","keywords":"","body":"小程序开发 什么软件适合做小程序 业务逻辑简单 使用频率低 性能要求低 开发者工具界面 v1.02 目录结构 主文件 文件 必填 作用 app.js 是 小程序逻辑 app.json 是 小程序公共设置 app.wxss 否 小程序公共样式表 页面文件组成 文件类型 必填 作用 js 是 页面逻辑 ( 微信小程序没有window和document对象 ) wxml 是 页面结构 ( WeiXin Markup Language，不是HTML语法 ) wxss 否 页面样式表 (WeiXin Style Sheets 拓展了rpx尺寸单位，微信专属响应式像素 ) json 否 页面配置 分包 整个小程序所有分包大小不超过 8M 单个分包/主包大小不能超过 2M 移动设备的分辨率与rpx rpx（responsive pixel）: 可以根据屏幕宽度进行自适应。规定屏幕宽为750rpx。如在 iPhone6 上，屏幕宽度为375px，共有750个物理像素，则750rpx = 375px = 750物理像素，1rpx = 0.5px = 1物理像素 配置 全局配置app.json控制整个程序的行为 页面配置page.json控制单个页面 组件 swiper 页面注册 生命周期 生命周期回调 Page({ // 启动页面后弹出消息 onLoad: function () { wx.showToast({ title: '鸡你太美', }); } }) 视图 数据绑定 在小程序中，在js的data中定义变量 Page({ // .. data: { msg: 'msg' } //... 可以在WXML中进行绑定，跟VUE一样，但是需要注意的是，这种绑定是单向绑定 {{message}} 需要使用setData来设置或者更新数据 this.setData({msg:'abc'}); 更复杂的用法 Hidden 条件渲染 True WEBVIEW APP MINA 列表渲染 {{item}} 事件 在WXML中绑定事件 Page({ onTap(){ console.log('hello') } }) bind与catch bind是冒泡，事件会往上传递 catch会阻止事件向上冒泡 模块化 模块导出 function method1(){ console.log(\"123\"); } module.exports.method1 = method1; 模块使用 const common = require('common.js') 模板template 定义模板 FirstName: {{firstName}}, LastName: {{lastName}} 引入模板 使用模板 页面间参数传递 页面跳转 wx.navigateTo({ url: './post-detail/post-detail?id='+id, }) onLoad: function (options) { // 这里可以拿到url的参数 console.log(options.id); }, 缓存 // 设置缓存 wx.setStorage({ key: '', data: '', }) // 获取缓存 wx.getStorage({ key: , success: function(res) {}, }) 全局变量 在app.js中定义 App({ globalData: { flag:false } //... } 使用 var app =getApp(); app.globalData.flag= true; 路由 三种路由方式 navigateTo redirectTo switchTab 组件 视图组件 view 类似div 基础组件 icon text 一段文本 progress 表单组件 button 默认尺寸按钮 form image switch slider checkbox 场景值 代表是怎么来的 视图层 WXML import 的依赖无法传递 嵌入 WXSS 单位 rpx（responsive pixel）: 可以根据屏幕宽度进行自适应 样式导入 @import \"common.wxss\"; 内联样式 style与class 选择器 .class id element element,element ::after ::before 全局样式与局部样式 app.wxss 是全局样式，定义在page目录下的是局部样式 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-18 01:51:39 "},"移动开发/uniapp.html":{"url":"移动开发/uniapp.html","title":"uniapp","keywords":"","body":"uniapp 目录结构 ┌─components uni-app组件目录 │ └─comp-a.vue 可复用的a组件 ├─hybrid 存放本地网页的目录，详见 ├─platforms 存放各平台专用页面的目录，详见 ├─pages 业务页面文件存放的目录 │ ├─index │ │ └─index.vue index页面 │ └─list │ └─list.vue list页面 ├─static 存放应用引用静态资源（如图片、视频等）的目录，注意：静态资源只能存放于此 ├─wxcomponents 存放小程序组件的目录，详见 ├─main.js Vue初始化入口文件 ├─App.vue 应用配置，用来配置App全局样式以及监听 应用生命周期 ├─manifest.json 配置应用名称、appid、logo、版本等打包信息，详见 └─pages.json 配置页面路由、导航条、选项卡等页面类信息，详见 生命周期 应用生命周期 函数名 说明 onLaunch 当uni-app 初始化完成时触发（全局只触发一次） onShow 当 uni-app 启动，或从后台进入前台显示 onHide 当 uni-app 从前台进入后台 onError 当 uni-app 报错时触发 onUniNViewMessage 对 nvue 页面发送的数据进行监听，可参考 nvue 向 vue 通讯 路由 handleClick () { uni.navigateTo({ url:'home/home' }) } MY all right reserved，powered by Gitbook该页面最后修改于： 2020-04-14 12:13:16 "},"开发工具/nav.html":{"url":"开发工具/nav.html","title":"开发工具","keywords":"","body":"开发工具 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 12:40:15 "},"开发工具/linux/Linux.html":{"url":"开发工具/linux/Linux.html","title":"Linux","keywords":"","body":"Linux 基本概念及操作 求助 man man 是 manual 的缩写，将指令的具体信息显示出来 man date 代号 类型 1 用户在 shell 环境中可以操作的指令或者可执行文件 2 内核可调用的函数与工具库 3 函数库 4 设备文件说明 5 配置文件 6 游戏 7 协议 8 系统管理员可以使用的管理指令 doc /usr/share/doc目录下存放了软件的使用说明 关机 who who # 查看在线的用户 sync sync # 关机之前需要强制内存中的数据同步到磁盘 shutdown # shutdown [-krhc] 时间 [信息] -k ： 不会关机，只是发送警告信息，通知所有在线的用户 -r ： 将系统的服务停掉后就重新启动 -h ： 将系统的服务停掉后就立即关机 -c ： 取消已经在进行的 shutdown 重启 reboot PATH 环境变量，用来声明可执行文件的路径，路径之间用 : 分隔 /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin sudo 允许一般用户执行只有root用户才能执行的命令，只有在/etc/sudoers中配置的用户才能执行 包管理工具 RPM：Redhat Package Manager，YUM基于RPM DPKG：基于 Debian 操作系统的 DEB 软件包管理工具 发行版 Linux发行版指的Linux内核及各种应用软件的集成版本 VIM 三个模式 一般指令模式（Command mode）：VIM 的默认模式，可以用于移动游标查看内容 编辑模式（Insert mode）：按下 \"i\" 等按键之后进入，可以对文本进行编辑 指令列模式（Bottom-line mode）：按下 \":\" 按键之后进入，用于保存退出等操作 GNU GNU的目标是创建一套完全自由的操作系统，称为 GNU，其内容软件完全以 GPL 方式发布 以任何目的运行此程序的自由 再复制的自由 改进此程序，并公开发布改进的自由 磁盘 磁盘接口 IDE （ATA）全称 Advanced Technology Attachment，接口速度最大为 133MB/s，因为并口线的抗干扰性太差，且排线占用空间较大，不利电脑内部散热，已逐渐被 SATA 所取代 SATA 全称 Serial ATA，也就是使用串口的 ATA 接口，抗干扰性强，且对数据线的长度要求比 ATA 低很多，支持热插拔等功能。SATA-II 的接口速度为 300MiB/s，而 SATA-III 标准可达到 600MiB/s 的传输速度。SATA 的数据线也比 ATA 的细得多，有利于机箱内的空气流通，整理线材也比较方便 SCSI 全称是 Small Computer System Interface（小型机系统接口），SCSI 硬盘广为工作站以及个人电脑以及服务器所使用，因此会使用较为先进的技术，如碟片转速 15000rpm 的高转速，且传输时 CPU 占用率较低，但是单价也比相同容量的 ATA 及 SATA 硬盘更加昂贵 SAS Serial Attached SCSI是新一代的 SCSI 技术，和 SATA 硬盘相同，都是采取序列式技术以获得更高的传输速度，可达到 6Gb/s。此外也通过缩小连接线改善系统内部空间等 磁盘文件名 在Linux，硬件都被当成一个文件 IDE 磁盘：/dev/hd[a-d] SATA/SCSI/SAS 磁盘：/dev/sd[a-p] 分区 分区表 MBR MBR 中，第一个扇区最重要，里面有主要开机记录（Master boot record, MBR）及分区表（partition table），其中主要开机记录占 446 bytes，分区表占 64 bytes 分区表只有 64 bytes，最多只能存储 4 个分区，这 4 个分区为主分区（Primary）和扩展分区（Extended）。其中扩展分区只有一个，它使用其它扇区来记录额外的分区表，因此通过扩展分区可以分出更多分区，这些分区称为逻辑分区 Linux把分区当成文件，分区文件的命名方式为：磁盘文件名 + 编号，例如 /dev/sda1。注意，逻辑分区的编号从 5 开始 GPT 扇区是磁盘的最小存储单位，旧磁盘的扇区大小通常为 512 bytes，而最新的磁盘支持 4 k。GPT 为了兼容所有磁盘，在定义扇区上使用逻辑区块地址（Logical Block Address, LBA），LBA 默认大小为 512 bytes 开机检测程序 BIOS是开机的时候计算机执行的第一个程序，这个程序知道开机的磁盘，读取磁盘的第一个扇区的开机记录（MBR），通过MBR执行开机管理程序，开机管理程序加载操作系统的核心文件 MBR提供以下功能：选单、载入核心文件以及转交其它开机管理程序。转交这个功能可以用来实现多重引导，只需要将另一个操作系统的开机管理程序安装在其它分区的启动扇区上，在启动开机管理程序时，就可以通过选单选择启动当前的操作系统或者转交给其它开机管理程序从而启动另一个操作系统 文件系统 一个分区通常只能格式化成一个文件系统，但使用磁盘阵列技术可以将一个分区格式化为多个文件系统 组成 inode：一个文件占用一个inode，记录文件的属性和此文件占用的block编号 具体包含：权限、拥有者、容量、时间、文件特性等信息 每个 inode 大小均固定为 128 bytes (新的 ext4 与 xfs 可设定到 256 bytes) block：用来存放文件内容，一个文件可以占用多个block 不同block大小会限制单个文件和文件系统的最大大小 superblock：记录文件系统的整体信息，如容量、格式 block bitmap：一个记录block占用情况的图 文件读取 Ext2 先根据inode查询出所有block，然后再把block里的文件内容读出来 FAT 这种文件系统没有inode，每个block就像一个链表，存储着下一个block的编号 磁盘碎片 指一个文件的block过于分散，磁盘读取时磁头移动距离过大 目录 一个目录最少分配一个inode与一个block，block记录了目录下所有文件的inode以及文件名 日志 ext3/ext4 文件系统引入了日志功能，可以利用日志来修复文件系统 挂载 利用目录作为文件系统的进入点 目录配置 Filesystem Hierarchy Standard (FHS) 规定了 Linux 的目录结构： /：root，根目录 /usr：unix software resource，所有系统默认软件都会安装到这个目录 /var：variable，存放系统或者程序运行过程中的数据文件 文件 文件属性 drwxr-xr-x 4 my my 4096 Mar 4 12:04 ./ drwxr-xr-x：文件类型及权限，第一位为文件类型自动，后9位位文件权限自动 d：目录 -：文件 l：链接文件 9 位的文件权限字段中，每 3 个为一组，共 3 组，每一组分别代表对文件拥有者、所属群组以及其它人的文件权限 rwx分布表示可读(readable),可写(writeable),可执行(executeable) 3：链接数 my：文件拥有者 my：所属群组 4096：文件大小 Mar 4 12:04：最后修改时间 modification time (mtime)：文件的内容更新就会更新； status time (ctime)：文件的状态（权限、属性）更新就会更新； access time (atime)：读取文件时就会更新。 文件与目录的基本操作 ls 列出文件或者目录的信息，目录的信息就是其中包含的文件 # ls [-aAdfFhilnrRSt] file|dir -a ：列出全部的文件 -d ：仅列出目录本身 -l ：以长数据串行列出，包含文件的属性与权限等等数据 cd 更换当前目录 cd [相对路径或绝对路径，如果不填默认是~] mkdir # mkdir [-mp] 目录名称 -m ：配置目录权限 -p ：递归创建目录 rmdir 删除空目录 rmdir [-p] 目录名称 -p ：递归删除目录 touch 更新文件时间或者建立新文件 # touch [-acdmt] filename -a ： 更新 atime -c ： 更新 ctime，若该文件不存在则不建立新文件 -m ： 更新 mtime -d ： 后面可以接更新日期而不使用当前日期，也可以使用 --date=\"日期或时间\" -t ： 后面可以接更新时间而不使用当前时间，格式为[YYYYMMDDhhmm] cp 复制文件 cp [-adfilprsu] source destination -a ：相当于 -dr --preserve=all -d ：若来源文件为链接文件，则复制链接文件属性而非文件本身 -i ：若目标文件已经存在时，在覆盖前会先询问 -p ：连同文件的属性一起复制过去 -r ：递归复制 -u ：destination 比 source 旧才更新 destination，或 destination 不存在的情况下才复制 --preserve=all ：除了 -p 的权限相关参数外，还加入 SELinux 的属性, links, xattr 等也复制了 rm 删除文件 # rm [-fir] 文件或目录 -r ：递归删除 -i: 删除前询问 -f：强制删除 mv 移动文件 # mv [-fiu] source destination # mv [options] source1 source2 source3 .... directory -f ： force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 修改权限 # chmod [ugoa] [+-=] [rwx] dirname/filename - u：拥有者 - g：所属群组 - o：其他人 - a：所有人 - +：添加权限 - -：移除权限 - =：设定权限 # 为所有人添加可执行权限 chmod a+x test.sh 默认权限 文件的默认权限是-rw-rw-rw- ，没有可执行权限 目录的默认权限是drwxrwxrwx 目录权限 文件名不是存储在一个文件的内容中，而是存储在一个文件所在的目录中。因此，拥有文件的 w 权限并不能对文件名进行修改 目录存储文件列表，一个目录的权限也就是对其文件列表的权限。因此，目录的 r 权限表示可以读取文件列表；w 权限表示可以修改文件列表，具体来说，就是添加删除文件，对文件名进行修改；x 权限可以让该目录成为工作目录，x 权限是 r 和 w 权限的基础，如果不能使一个目录成为工作目录，也就没办法读取文件列表以及对文件列表进行修改了 链接 # ln [-sf] source_filename dist_filename -s ：默认是实体链接，加 -s 为符号链接 -f ：如果目标文件存在时，先删除目标文件 实体链接 实体链接直接链接了源文件的inode 不能跨越文件系统、不能对目录进行链接 ln my.link test.sh 符号链接 符号链接指向的是文件，如果原始文件被删除，符号链接就打不开了 ln -s test.sh symbol.link 获取内容 cat 取得文件内容 # cat [-AbEnTv] filename -n ：打印出行号，连同空白行也会有行号，-b 不会 tac 从最后一行开始打印 more 可以一页一页查看文件内容 less 比more多了一个向前翻页的功能 head 取得文件的前几行 # head [-n number] filename -n ：后面接数字，代表显示几行的意思 tail head的反向操作，取得后几行 od 以字符或者十六进制的形式显示二进制文件 指令与文件搜索 which # which [-a] command -a ：将所有指令列出，而不是只列第一个 which -a ssh whereis 文件搜索，只搜索几个特定的目录 # whereis [-bmsu] dirname/filename locate 可以用关键字或者正则表达式进行搜索文件 locate 使用 /var/lib/mlocate/ 这个数据库来进行搜索，它存储在内存中，并且每天更新一次，所以无法用 locate 搜索新建的文件。可以使用 updatedb 来立即更新数据库 # locate [-ir] keyword -r：正则表达式 find 可以使用文件的属性和权限进行搜索 # find [basedir] [option] example: find . -name \"shadow*\" 与时间有关的选项： -mtime n ：列出在 n 天前的那一天修改过内容的文件 -mtime +n ：列出在 n 天之前 (不含 n 天本身) 修改过内容的文件 -mtime -n ：列出在 n 天之内 (含 n 天本身) 修改过内容的文件 -newer file ： 列出比 file 更新的文件 与文件拥有者和所属群组有关的选项： -uid n -gid n -user name -group name -nouser ：搜索拥有者不存在 /etc/passwd 的文件 -nogroup：搜索所属群组不存在于 /etc/group 的文件 与文件权限和名称有关的选项： -name filename -size [+-]SIZE：搜寻比 SIZE 还要大 (+) 或小 (-) 的文件。这个 SIZE 的规格有：c: 代表 byte，k: 代表 1024bytes。所以，要找比 50KB 还要大的文件，就是 -size +50k -type TYPE -perm mode ：搜索权限等于 mode 的文件 -perm -mode ：搜索权限包含 mode 的文件 -perm /mode ：搜索权限包含任一 mode 的文件 压缩与打包 压缩指令 gzip 使用 zcat、zmore、zless 来读取压缩文件的内容 $ gzip [-cdtv#] filename -c ：将压缩的数据输出到屏幕上 -d ：解压缩 -t ：检验压缩文件是否出错 -v ：显示压缩比等信息 -# ： # 为数字的意思，代表压缩等级，数字越大压缩比越高，默认为 6 bzip2 使用bzcat、bzmore、bzless、bzgrep读取压缩文件的内容 $ bzip2 [-cdkzv#] filename -k ：保留源文件 xz 查看命令：xzcat、xzmore、xzless、xzgrep 打包 压缩指令只能对一个文件进行压缩，打包能够将多个文件打包成一个大文件 tar -z ：使用 zip； -j ：使用 bzip2； -J ：使用 xz； -c ：新建打包文件； -t ：查看打包文件里面有哪些文件； -x ：解打包或解压缩的功能； -v ：在压缩/解压缩的过程中，显示正在处理的文件名； -f : filename：要处理的文件； -C 目录 ： 在特定目录解压缩。 一些范例 使用方式 命令 打包压缩 tar -jcv -f filename.tar.bz2 要被压缩的文件或目录名称 查 看 tar -jtv -f filename.tar.bz2 解压缩 tar -jxv -f filename.tar.bz2 -C 要解压缩的目录 Bash 通过Shell来请求内核提供服务，Bash是Shell的一种 特性 命令历史 命令文件补全 命令别名 shell脚本 通配符 变量操作 # 变量赋值 x=abc # 输出变量 echo $x # 输出 abc x=\"环境变量 = $PATH\" # 输出 环境变量 = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin x='x$PATH' # 单引号内不会进行变量替换 它会输出 x$PATH version=$(uname -r) # 将指令执行结果赋值给变量 $ declare [-aixr] variable -a ： 定义为数组类型 -i ： 定义为整数类型 -x ： 定义为环境变量 -r ： 定义为 readonly 类型 指令搜索顺序 以绝对或相对路径来执行指令，例如 /bin/ls 或者 ./ls ； 由别名找到该指令来执行； 由 Bash 内置的指令来执行； 按 $PATH 变量指定的搜索路径的顺序找到第一个指令来执行。 数据流重定向 重定向指的是使用文件代替标准输入、标准输出和标准错误输出 有一个箭头的表示以覆盖的方式重定向，而有两个箭头的表示以追加的方式重定向 1 代码 运算符 标准输入 (stdin) 0 标准输出 (stdout) 1 > 或 >> 标准错误输出 (stderr) 2 2> 或 2>> ls &> result # 将ls的所有输出都定向到result文件 管道指令 将一个命令的标准输出作为另一个命令的标准输入 ll | cat -n # 将ll的结果作为cat的输入 提取指令 cut $ cut -d ：使用分隔符对每行进行分割 -f ：经过 -d 分隔后，使用 -f n 取出第 n 个区间 -c ：以字符为单位取出区间 last | cut -d ' ' -f 1 # 取出登录的用户 排序指令 sort $ sort [-fbMnrtuk] [file or stdin] -f ：忽略大小写 -b ：忽略最前面的空格 -M ：以月份的名字来排序，例如 JAN，DEC -n ：使用数字 -r ：反向排序 -u ：相当于 unique，重复的内容只出现一次 -t ：分隔符，默认为 tab -k ：指定排序的区间 last | cut -d ' ' -f 1 | sort # 对登录用户进行排序 uniq 去除重复数据 $ uniq [-ic] -i ：忽略大小写 -c ：进行计数 last | cut -d ' ' -f 1 | sort |uniq -c # 统计用户登录次数 双向输出重定向 tee cat my.link |tee result # 同时将输出输出到屏幕和result文件 字符转换指令 tr 对字符替换 last | tr '[0-9]' '*' # 把数字替换成* col 将tab转换为空格 expand 将 tab 转换一定数量的空格，默认是 8 个 正则表达式 grep globally search a regular expression and print，使用正则表示式进行全局查找并打印。 $ grep [-acinv] [--color=auto] 搜寻字符串 filename -c ： 统计匹配到行的个数 -i ： 忽略大小写 -n ： 输出行号 -v ： 反向选择，也就是显示出没有 搜寻字符串 内容的那一行 --color=auto ：找到的关键字加颜色显示 last |grep 'pts/[0-9]' # 找出pts登录的 printf printf '%10s \\n' $(last |grep 'pts/[0-9]') # 格式化输出，非管道命令，需要通过$()进行数据传递 awk awk 每次处理一行，处理的最小单位是字段，每个字段的命名方式为：$n，n 为字段号，从 1 开始，$0 表示一整行 last -n 5 | awk '{print $1 \"\\t\" $3}' # 最近5个登录的用户及ip 进程管理 查看进程 ps ps -l # 查看自己的进程 ps aux # 查看系统所有进程 pstree pstree -A # 查看所有进程树 top top -d 2 # 2秒刷新一次查看进程 进程状态 状态 说明 R running or runnable (on run queue) 正在执行或者可执行，此时进程位于执行队列中。 D uninterruptible sleep (usually I/O) 不可中断阻塞，通常为 IO 阻塞。 S interruptible sleep (waiting for an event to complete) 可中断阻塞，此时进程正在等待某个事件完成。 Z zombie (terminated but not reaped by its parent) 僵死，进程已经终止但是尚未被其父进程获取信息。 T stopped (either by a job control signal or because it is being traced) 结束，进程既可以被作业控制信号结束，也可能是正在被追踪。 SIGCHLD 子进程改变了它的状态时（停止运行，继续运行或者退出），有两件事会发生在父进程中： 得到 SIGCHLD 信号； 子进程发送的 SIGCHLD 信号包含了子进程的信息，比如进程 ID、进程状态、进程使用 CPU 的时间等 waitpid() 或者 wait() 调用会返回 在子进程退出时，它的进程描述符不会立即释放，这是为了让父进程得到子进程信息，父进程通过 wait() 和 waitpid() 来获得一个已经退出的子进程的信息。 wait 父进程调用 wait() 会一直阻塞，直到收到一个子进程退出的 SIGCHLD 信号，之后 wait() 函数会销毁子进程并返回 waitpid 作用和 wait() 完全相同，但是多了两个可由用户控制的参数 pid 和 options。 pid 参数指示一个子进程的 ID，表示只关心这个子进程退出的 SIGCHLD 信号。如果 pid=-1 时，那么和 wait() 作用相同，都是关心所有子进程退出的 SIGCHLD 信号。 options 参数主要有 WNOHANG 和 WUNTRACED 两个选项，WNOHANG 可以使 waitpid() 调用变成非阻塞的，也就是说它会立即返回，父进程可以继续执行其它任务 孤儿进程 父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程 孤儿进程将被 init 进程（进程号为 1）所收养，并由 init 进程对它们完成状态收集工作 僵尸进程 一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程 如果产生大量僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-14 02:49:04 "},"开发工具/vim/vim.html":{"url":"开发工具/vim/vim.html","title":"Vim","keywords":"","body":"目录 [toc] VIM vim的四种模式 正常模式：启动vim后默认处于正常模式。不论位于什么模式，按下键(有时需要按两下）都会进入正常模式 w：跳到下一个单词 b：跳到上一个单词 0：跳到行首 $：跳到行尾 gg：跳到文档开头 G：跳到文档末尾 ctrl + u :上翻页 ctrl + f ：下翻页 zz：将光标移到屏幕中间 dt{char} : delete to char (删除到char) ct{char} : delete to char and into insert(删除到char然后进入insert ctrl+u：向前滚动半页 模式) 插入模式：i:进入插入模式 o：新起一行进行添加 a：在光标后进行追加 在插入模式中，可以使用```ctrl + h``` 或者 ```ctrl + w```来删除上一个单词 ctrl + u ：undo操作 命令模式：在正常模式中，按下:（英文冒号）键，会进入命令模式。在命令模式中可以执行一些输入并执行一些vim或插件提供的指令，就像在shell里一样。这些指令包括设置环境、文件操作、调用某个功能等等 %s s/{a}/{b}/g：全局把a替换成b vs:垂直分割屏幕 sp：水平分割屏幕 ctrl + w:移动到上一个屏幕 可视模式：在正常模式中按下v, V, +v，可以进入可视模式。可视模式中的操作有点像拿鼠标进行操作，选择文本的时候有一种鼠标选择的即视感，有时候会很方便 y：复制 p：粘贴宏的使用 录制宏： 回放宏：自动补全 单词自动补全 ctrl + n：下一个单词 ctrl + p: 上一个单词 文件自动补全 ctrl + f修改VIM的配色 : colorscheme xx 其中xx为配色名称持久化配置 在~/.vimrc中可以输入一些命令，以此来保存配置：set nu set autoindent set background=dark colorscheme hybrid syntax on 按键映射 map： 其中可以为i(insert),c(command),n(normal),v(visual) noremap: 的取值同上 nore的区别在于这种按键映射是非递归的。 举例：imap jj 这么样一条命令代表在insert模式下按下jj会自动切换到normal模式插件的安装 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-05-28 06:47:26 "},"开发工具/git.html":{"url":"开发工具/git.html","title":"Git","keywords":"","body":"GIT Git属于分布式版本控制系统 整体流程 初始化仓库 git init 配置信息 git config --global user.name my git config --global user.email 715711877@qq.com 配置默认编辑器 git config core.editor vim 查看状态 git status 工作流 把文件的修改添加到暂存区 git add . 把暂存区的修改提交到当前分支，提交之后暂存区就被清空了 git commit 使用当前分支上的修改覆盖暂存区 git reset -- files 将某个分支的操作添加到某个分支 git rebase branch1 branch2 # 1 添加的分支 2 被添加的分支 使用暂存区的修改覆盖工作目录 git checkout -- file 直接把所有文件的修改添加到暂存区然后执行提交 git commit -a 取出最后一次修改，可以用来进行回滚操作 git checkout HEAD -- files 将一些提交添加到当前分支 git cheery-pick hash1 hash2 hash3... 交互式rebase git rebase -i HEAD~4 # 通过UI界面的方式调整提交记录顺序 查看提交日志 git log 回滚到某一次提交 git reset --hard 33ea7586bfe2d14e9ddbe9b07c5653159541338c # 通过将HEAD指向某一提交记录实现 git revert ... # 通过创建一个新提交记录实现 添加远程仓库 $ git remote add origin https://github.com/cjp715711877/test.git 推送到远程仓库 $ git push -u origin master 克隆仓库 $ git clone https://github.com/996icu/996.ICU.git 分支 HEAD 指针指向当前分支指针 新建分支 新建一个指针指向时间线的最后一个节点，并让 HEAD 指针指向新分支 git branch x 切换分支 git checkout x 每次提交只会让当前分支指针向前移动，而其它分支指针不会移动 分支合并 合并分支也只需要改变指针即可 git merge x 冲突 两个分支都对同一个文件的同一行进行了修改，在分支合并时就会产生冲突 Git 会使用 >>>>>> 标记出不同分支的内容，只需要把不同分支中冲突部分修改成一样就能解决冲突 Fast forward 快进式合并\"（fast-farward merge），会直接将 master 分支指向合并的分支，这种模式下进行分支合并会丢失分支信息，也就不能在分支历史上看出分支信息 储藏（Stashing） 在一个分支上操作之后，如果还没有将修改提交到分支上，此时进行切换分支，那么另一个分支上也能看到新的修改。这是因为所有分支都共用一个工作区的缘故 使用 git stash 这个命令将当前分支的修改储藏起来，此时工作区就是干净的，可以切换到其他分支 推送到远程仓库 生成ssh密钥 ssh-keygen -t rsa 添加远程仓库地址 git remote add origin git@github.com:0xcaffebabe/repo1.git 推送 git push -u origin master 搭建Git私服 安装git 初始化服务器本地仓库 git --bare init /home/git/first 设置远程仓库地址 git remote add origin ssh://root@my-pc/home/git/first 推送 git push --set-upstream origin master 从远程仓库下载源码 git clone ssh://root@my-pc/home/git/first 一些坑 检出错误 ssh: connect to host xxx.com port 22: Connection refused 确定是否有权限 切换邮箱提交错误 新的账户没有提交权限，然而你在新的账户上有了一次提交，此时代码推不上去，切换回原邮箱依然提示推不上去 此时，需要回滚撤销此次提交，切回有权限的邮箱重新提交并推送 切分支错误 拉取新分支时，一定要注意检查父分支 提前合并到master 如果相关代码没有准备好，提前将代码合并到master，会引发错误 merge冲突 此时一定要慎之又慎，来处理冲突 一个分支干多件事 如果一个分支干多件事，测试代码没有覆盖，很容易出bug 及时合并到master 开发周期较长时，要及时合并到master，避免最后大量冲突 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-06 06:27:10 "},"开发工具/SVN.html":{"url":"开发工具/SVN.html","title":"SVN","keywords":"","body":"SVN 概念 repository（源代码库）:源代码统一存放的地方 Checkout（检出）:当你手上没有源代码的时候，你需要从repository checkout一份 Commit（提交）:当你已经修改了代码，你就需要Commit到repository Update (更新):当你已经Checkout了一份源代码， Update一下你就可以和Repository上的源代码同步，你手上的代码就会有最新的变更 生命周期 创建版本库：一个集中的空间，用于存放开发者所有的工作成果 检出（checkout）：类似于git clone 更新（update）:git push 提交(commit) 复查变化(status) 回滚提交(revert) 解决冲突(merge) 启动 svnadmin create /opt/svn/rp1 # 创建版本库 配置 # /opt/svn/rp1/conf/authz [/] admin = rw # /opt/svn/rp1/conf/passwd [users] admin = admin # /opt/svn/rp1/conf/svnserver.conf [general] anon-access = none auth-access = write password-db = passwd authz-db = authz 检出 svn checkout svn://localhost/ --username=admin 提交 svn status # 检查目前版本跟踪文件情况 svn add readme.md # 添加文件到暂存区 svn commit -m \"first commit\" 冲突解决 当发生冲突时 无法进行commit 必须进行update解决冲突后再次commit root@my-win:~/svn# svn commit -m \"kkk commit\" Sending readme.md Transmitting file data .done Committing transaction... svn: E160028: Commit failed (details follow): svn: E160028: File '/readme.md' is out of date root@my-win:~/svn# svn update Updating '.': C readme.md Updated to revision 2. Summary of conflicts: Text conflicts: 1 Conflict discovered in file 'readme.md'. Select: (p) postpone, (df) show diff, (e) edit file, (m) merge, (mc) my side of conflict, (tc) their side of conflict, (s) show all options: mc Resolved conflicted state of 'readme.md' Summary of conflicts: Text conflicts: 0 remaining (and 1 already resolved) 版本回退 svn revert readme.md # 回退某一文件 查看 svn log # 输出历史日志信息 svn diff -r 1 readme.md # 输出与版本号为1diff的文件内容 svn cat -r 1 readme.md # 查看某一特定版本的文件内容 svn list svn://localhost/ # 输出版本库文件列表 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-11-09 06:39:31 "},"开发工具/idea.html":{"url":"开发工具/idea.html","title":"Idea","keywords":"","body":"安装 https://www.jetbrains.com/idea/download/#section=windows 项目目录 .idea 目录和 demo.iml 和我们开发无关，是IDEA工具自己使用的 out 目录是存储编译后的.class文件 src 目录是存储我们编写的.java源文件 常用快捷键 键位 说明 Alt+Enter 导入包，自动修正代码 Ctrl+Y 删除光标所在行 Ctrl+D 复制光标所在行的内容，插入光标位置下面 Ctrl+Alt+L 格式化代码 Ctrl+/ 单行注释 Ctrl+Shift+/ 选中代码注释，多行注释，再按取消注释 Alt+Ins 自动生成代码，toString，get，set等方法 Alt+Shift+上下箭头 移动当前代码行 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-08-01 09:04:39 "},"开发工具/构建工具/gradle.html":{"url":"开发工具/构建工具/gradle.html","title":"Gradle","keywords":"","body":"Gradle Gradle 的核心在于基于 Groovy 的丰富而可扩展的域描述语言(DSL) 目录结构 ├── build.gradle 用于配置当前项目的Gradle构建脚本 ├── gradle │ └── wrapper │ ├── gradle-wrapper.jar Gradle Wrapper可执行jar 文件 │ └── gradle-wrapper.properties Gradle Wrapper 配置 ├── gradlew 类unix下的Gradle Wrapper启动脚本 ├── gradlew.bat windows下的Gradle Wrapper启动脚本 └── settings.gradle 用于配置Gradle构建的Gradle设置脚本 构建基础 project：我们的应用 task：每个 project 都由多个 tasks 组成。每个 task 都代表了构建执行过程中的一个原子性操作。如编译，打包，生成 第一个构建脚本 // build.gradle task copy(type: Copy, group: \"Custom\", description: \"从一个地方复制到另一个地方\") { from \"src\" into \"dest\" } # 执行任务 ./gradlew copy 使用插件定义任务 plugins { id \"base\" } task zip(type: Zip, group: \"Archive\", description: \"Archives sources in a zip file\") { from \"src\" archiveName \"basic-demo-1.0.zip\" } 查看可用任务 .\\gradlew tasks 构建java项目 ├── build.gradle ├── gradle │ └── wrapper │ ├── gradle-wrapper.jar │ └── gradle-wrapper.properties ├── gradlew ├── gradlew.bat ├── settings.gradle └── src ├── main │ ├── java │ │ └── demo │ │ └── App.java │ └── resources └── test ├── java │ └── demo │ └── AppTest.java └── resources // settings.gradle rootProject.name = 'gradle-java' // 项目名 // build.gradle plugins { // 使用java插件 id 'java' // application插件 id 'application' } repositories { // 远程仓库 jcenter() } // 一些依赖 dependencies { implementation 'com.google.guava:guava:28.2-jre' testImplementation 'org.junit.jupiter:junit-jupiter-api:5.6.0' testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.6.0' } application { // 定义main类 mainClassName = 'gradle.java.App' } test { // 使用junit5测试 useJUnitPlatform() } # 构建项目 ./gradlew build 构建JAVA库文件 plugins { // 使用java-library插件 id 'java-library' } repositories { jcenter() } dependencies { // 这个依赖会暴露给消费者，也就是说，这个依赖可以在消费者的classpath下找到 api 'org.apache.commons:commons-math3:3.6.1' // 内部使用的依赖 不会暴露给消费者 implementation 'com.google.guava:guava:28.2-jre' testImplementation 'org.junit.jupiter:junit-jupiter-api:5.6.0' testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.6.0' } test { useJUnitPlatform() } 自定义 // build.gradle version = '0.1.0' // 定义jar包版本 // 自定义manifest属性 jar { manifest { attributes('Implementation-Title': project.name, 'Implementation-Version': project.version) } } repositories { // 自定义仓库 ivy { // URL可以是一个本地目录 url \"../local-repo\" } // 可以指定多个仓库 jcenter() } 多项目 // 查看子项目任务 gradlew :service:tasks // 执行子任务测试 gradle :service:test 构建spring boot项目 plugins { id 'java' id 'org.springframework.boot' version '2.2.6.RELEASE' id 'io.spring.dependency-management' version '1.0.9.RELEASE' } repositories { maven { url 'https://maven.aliyun.com/repository/jcenter/'} maven { url 'https://maven.aliyun.com/repository/spring/'} } dependencies { implementation 'org.springframework.boot:spring-boot-dependencies:2.2.6.RELEASE' implementation 'org.springframework.boot:spring-boot-starter-web' testImplementation 'org.springframework.boot:spring-boot-starter-test' components { withModule('org.springframework:spring-beans') { allVariants { withDependencyConstraints { // Need to patch constraints because snakeyaml is an optional dependency it.findAll { it.name == 'snakeyaml' }.each { it.version { strictly '1.19' } } } } } } } bootJar { // Define the main class for the application. mainClassName = 'gradle.spring.boot.App' } Groovy Groovy 是JVM 的一个替代语言—替代是指可以用Groovy 在Java 平台上进行Java 编程，使用方式基本与使用Java 代码的方式相同 程序示例： class Foo { doSomething() { data = [\"name\": \"James\", \"location\": \"London\"] for (e in data) { println(\"entry ${e.key} is ${e.value}\") } } closureExample(collection) { collection.each { println(\"value ${it}\") } } static void main(args) { values = [1, 2, 3, \"abc\"] foo = new Foo() foo.closureExample(values) foo.doSomething() } } 生命周期 初始化->配置->执行 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-04-16 12:38:14 "},"开发工具/构建工具/maven.html":{"url":"开发工具/构建工具/maven.html","title":"Maven","keywords":"","body":"Maven 简介 项目管理工具。 基于项目对象模型（POM）， 可以通过一小段描述信息管理项目的构建。 下载与安装 下载地址'https://maven.apache.org/' 配置环境变量 新增'M2_HOME' 将%M2_HOME%\\bin添加到Path环境变量下 目录结构 src main java package resources test java package resources 一些喜欢忘记的知识点 指定JDK版本： UTF-8 UTF-8 12 12 12 常用命令 mvn clean # 清理target目录下的类文件 mvn install # 将本项目安装到本地仓库 mvn compile # 编译 mvn test # 执行测试 mvn package #打包 添加依赖 junit junit 4.12 test 自动生成目录结构 mvn archetype:generate 坐标与构件 仓库 本地仓库 修改本地仓库地址 远程仓库 镜像仓库 配置镜像仓库 生命周期 clean 清理项目 pre-clean clean post-clean default 构件项目 compile test package install deploy site 生成项目站点 pre-site site post-site site-deploy 打包插件 org.apache.maven.plugins maven-source-plugin 3.0.0 true compile jar-no-fork POM元素 pom版本 反写的网址+项目名 项目名+模块名 1.0-SNAPSHOT 项目描述名 项目地址 项目描述 证书信息 组织信息 UTF-8 UTF-8 12 12 12 junit junit 4.12 test org.apache.maven.plugins maven-source-plugin 3.0.0 true compile jar-no-fork 依赖范围 依赖传递 A->B(compile) 第一关系: a依赖b compile B->C(compile) 第二关系: b依赖c compile 依赖冲突 短路优先 A->B->C->X(1.0) A->D->X(2.0) 由于只能引入一个版本的包，此时Maven按照最短路径选择导入x(2.0) A->B->X(1.0) A->D->X(2.0) 路径长度一致，则优先选择第一个，此时导入x(1.0) B B 0.1 C C 聚合与继承 聚合 study-common study-plugin study-blog study-web 继承 com.tiantian.mavenTest projectA 1.0-SNAPSHOT 创建web项目 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"开发工具/构建工具/maven/分模块构建.html":{"url":"开发工具/构建工具/maven/分模块构建.html","title":"分模块构建","keywords":"","body":"继承 继承是为了消除重复，如果将dao、service、web分开创建独立的工程则每个工程的pom.xml文件中的内容存在重复，比如：设置编译版本、锁定spring的版本的等，可以将这些重复的配置提取出来在父工程的pom.xml中定义 聚合 项目开发通常是分组分模块开发，每个模块开发完成要运行整个工程需要将每个模块聚合在一起运行，比如：dao、service、web三个工程最终会打一个独立的war运行。 同级模块添加依赖 wang.ismy service 1.0-SNAPSHOT compile 私服 使用docker docker pull sonatype/nexus3 docker run -d -p 8081:8081 --name nexus sonatype/nexus3 上传 releases http://192.168.1.102:8081/content/repositories/releases/ snapshots http://192.168.1.102:8081/repository/maven-snapshots/ snapshots admin admin 下载 nexus local private nexus http://192.168.1.102:8081/repository/maven-public/ true true 安装第三方jar到本地 mvn install:install-file -DgroupId=com.alibaba -DartifactId=fastjson -Dversion=1.1.37 -Dfile= fastjson-1.1.37.jar -Dpackaging=jar 上传jar到私服 mvn deploy:deploy-file -DgroupId=com.alibaba -DartifactId=fastjson -Dversion=1.1.37 -Dpackaging=jar -Dfile=fastjson-1.1.37.jar -Durl=http://localhost:8081/nexus/content/repositories/thirdparty/ -DrepositoryId=thirdparty MY all right reserved，powered by Gitbook该页面最后修改于： 2019-08-25 12:39:25 "},"开发工具/构建工具/NPM.html":{"url":"开发工具/构建工具/NPM.html","title":"NPM","keywords":"","body":" npm（全称 Node Package Manager，即“node包管理器”）是Node.js默认的、以JavaScript编写的软件包管理系统 初始化工程 npm init 安装模块 本地安装 npm install xxx 获取模块全局目录 npm root -g 全局安装 npm install xxx -g 批量安装 npm install # npm会根据package.json下载依赖 使用淘宝镜像 npm install -g cnpm --registry=http://registry.npm.taobao.org 运行 在package.json中定义 dev：开发阶段 build：构建编译 lint：运行js代码检测 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-14 13:53:58 "},"运维/nav.html":{"url":"运维/nav.html","title":"运维","keywords":"","body":"运维 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 12:40:15 "},"运维/持续集成.html":{"url":"运维/持续集成.html","title":"持续集成","keywords":"","body":" 持续集成是一种软件开发实践，即团队开发成员经常集成他们的工作，通常每个成员每天至少集成一次，也就意味着每天可能会发生多次集成。每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误。 Jenkins https://jenkins-ci.org/ 好处 自动化集成部署，提高了集成效率。 更快的修复问题。 更快的进行交付。 提高了产品质量。 特点 它是一个自动化的周期性的集成测试过程，从检出代码、编译构建、运行测试、结果 记录、测试统计等都是自动完成的，无需人工干预 需要有专门的集成服务器来执行集成构建 需要有代码托管工具支持 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-11-22 06:20:36 "},"运维/Docker.html":{"url":"运维/Docker.html","title":"Docker","keywords":"","body":"Docker Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux或Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口 使用场景 持续集成 可伸缩的云服务 微服务架构 容器与虚拟机 虚拟机最大的缺点就是依赖其专用的操作系统 Docker架构 镜像与容器 容器是镜像的实例 安装 安装脚本 wget https://get.docker.com 引擎 Docker引擎由如下主要的组件构成：Docker客户端（Docker Client）、Docker守护进程（Docker daemon）、containerd以及runc。它们共同负责容器的创建和运行 LXC提供了对诸如命名空间（Namespace）和控制组（CGroup）等基础工具的操作能力，它们是基于Linux内核的容器虚拟化技术 Docker公司开发了名为Libcontainer的自研工具，用于替代LXC runc： 创建容器 containerd： 容器的生命周期管理 启动容器的过程： 容器运行时与Docker daemon是解耦的,对Docker daemon的维护和升级工作不会影响到运行中的容器 shim： 保持所有STDIN和STDOUT流是开启状态 将容器的退出状态反馈给daemon 镜像 镜像使用 搜索镜像 docker search name 拉取镜像 docekr pull name 删除镜像 docker rmi 镜像ID docker image rm $(docker image ls -q) -f 标签 在镜像名后面的:xxx 代表标签 没有标签的镜像被称为悬虚镜像 分层 docker 会复用已存在的镜像层 镜像仓库 搭建 docekr pull registry docker run -di --name=registry 5000:5000 registry 上传镜像到私服 docker tag nginx 127.0.0.1:5000/nginx docker push 127.0.0.1:5000/nginx 容器 持久化 容器在停止后启动写入的数据仍会存在 但是volume才是持久化的首选 重启策略 在指定事件或者错误后重启来完成自我修复 always unless-stoped on-failed 容器使用 查看容器 docker ps 运行一个容器 docker run -p 8080:80 -d daocloud.io/nginx 复制文件到容器中 docker cp index.html e07dc4e0236a://usr/share/nginx/html 从容器中复制出文件 docker cp name:容器文件路径 宿主路径 停止容器 docker stop name # 优雅关闭并删除：stop rm 启动容器 docker start name 进入容器内部 docker exec -it bash 目录挂载 在启动容器时，使用-v参数 查看容器信息 docker inspect name 查看容器日志 docker logs name 常用软件部署 mysql # 将宿主机33306映射到容器3306，指定root密码为123 docker run -di --name=mysql1 -p 33306:3306 -e MYSQL_ROOT_PASSWORD=123 mysql tomcat docker run -di --name=mytomcat -p 9000:8080 -v /usr/local/webapps:/usr/local/tomcat/webapps tomcat nginx docker run -di --name=mynginx2 -p 8080:80 nginx-update 迁移与备份 保存镜像 docker commit -m 'update' e07dc4e0236a nginx-update 保存为压缩包 docker save -o nginx-update.tar nginx-update 把压缩包恢复成镜像 docker load -i nginx-update.tar 容器化 Dockerfile 编写Dockerfile文件： FROM ubuntu MAINTAINER MY RUN apt-get update RUN apt-get install nginx -y COPY index.html /var/www/html ENTRYPOINT [\"/usr/sbin/nginx\",\"-g\",\"daemon off;\"] EXPOSE 80 每一个RUN指令会新增一个镜像层。因此，通过使用&& 连接多个命令以及使用反斜杠（\\ ）换行的方法，将多个命令包含在一个RUN指令中，通常来说是一种值得提倡的方式 根据文件构建镜像： docker build -t='name' . DockerMaven插件 开启docker接受远程操作 添加maven插件 com.spotify docker-maven-plugin 0.4.12 my-pc:5000/${project.artifactId}:${project.version} java [\"java\", \"-jar\", \"/${project.build.finalName}.jar\"] / ${project.build.directory} ${project.build.finalName}.jar http://my-pc:2375 JDK8以上的版本需要添加如下依赖 javax.activation activation 1.1.1 构建并推送 mvn clean package docker:build -DpushImage 推送到仓库 docker images push 多阶段构建 FROM xxx AS T1 FROM xxx AS T2 COPY --from=T1 ... 最佳实践 利用构建缓存： 执行命令时，Docker会检查构建缓存中是否存在基于同一基础镜像，并且执行了相同指令的镜像层 合并镜像： 执行docker image build 命令时，可以通过增加--squash 参数来创建一个合并的镜像 no-install-recommends： 若使用的是APT包管理器，则应该在执行apt-get install 命令时增加no-install-recommends 参数。这能够确保APT仅安装核心依赖（Depends 中定义）包 不要安装MSI包（Windows） Compose 编写docker-compose.yml: version: \"3.5\" services: redis: image: \"redis:alpine\" networks: my-net: nginx: image: \"nginx\" networks: my-net: networks: my-net: volumes: my-net: 启动： docker-compose up Docker 网络 CNM: 定了Docker网络架构的基础组成要素 Libnetwork是CNM标准的实现 docker network ls # 列出可用网络 docker run -d --network my-net # 指定容器网络 如果在相同网络中继续接入新的容器，那么在新接入容器中是可以通过的容器名称来进行网络通信的 网络类型 Bridge：: 单机桥接网络 Docker设计的NAT网络模型（默认类型） 只能在单个Docker主机上运行，并且只能与所在Docker主机上的容器进行连接 docker network create -d bridge localnet Host：与主机共享Network Namespace，--net=host overlay：多机覆盖网络 接入现有网络 None：:不为容器配置任何网络功能，没有网络 --net=none Container：与另一个运行中的容器共享Network Namespace，--net=container:containerID 端口映射 # 将本机8080端口映射到容器80端口 docker run -p 8080:80 # 将本机端口随机与容器端口映射 docker run -P 持久化 每个Docker容器都有自己的非持久化存储。非持久化存储自动创建，从属于容器，生命周期与容器相同 持久化是将数据存储在卷上。卷与容器是解耦的 卷类型： 块存储 适用于对小块数据的随机访问负载 文件存储 包括NFS和SMB协议的系统 对象存储 适用于较大且长期存储的、很少变更的二进制数据存储。通常对象存储是根据内容寻址 卷操作 docker volume create myv docker volume inspect myv docker run ... --mount source=bizvol,target=/vol # 指定容器存储卷 安全 Docker 平台安全技术： Swarm模式 加密节点ID。 基于TLS的认证机制。 安全准入令牌。 支持周期性证书自动更新的CA配置。 加密集群存储（配置DB）。 加密网络 内容信任 通过 Docker Hub 信任内容 密钥 使用docker secret管理密钥 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-08-25 08:07:21 "},"运维/K8s.html":{"url":"运维/K8s.html","title":"K8s","keywords":"","body":"Kubernetes Kubernetes（常简称为K8s）是用于自动部署、扩展和管理容器化（containerized）应用程序的开源系统 架构 master：用于控制集群 API服务器：外部访问入口 Scheduler：调度应用（为应用分配工作节点） Controller Manager：执行集群级别的功能 etcd：存储集群配置的分布式数据存储 工作节点：运行用户部署应用的节点 容器运行时：Docker 或者其他容器 Kubelet：与API服务器通信 管理当前节点的容器 kube-proxy:负责组件之间的负载均衡 分布式 Kubenetes系统组件间只能通过API服务器通信 为了保证高可用性， master的每个组件可以有多个实例 etcd 只有API服务器才能直接与etcd通信 数据在etcd中存储的是一个层次级目录结构 末端节点存储的json数据 集群一致性保证：raft算法 API 服务器 认证授权 通知客户端资源变更 安全防护 pod 使用 service accounts机制进行认证 kubectl get sa # 获取服务账户 kubectl create serviceaccount foo # 创建 使用sa: spec: serviceAccountName: foo RBAC控制：使用插件 调度器 利用 API 服务器的监听机制等待新创建的 pod, 然后给每个新的、 没有节点集的 pod 分配节点 调度过程是很复杂的： 选择可用节点 选择最佳节点 高级调度 如何保证节点副本分布尽可能均匀 控制管理器 确保系统真实状态朝 API 服务器定义的期望的状态收敛 rc rs控制器 deployment控制器... Kubelet 在 API 服务器中创建Node 资源, 等待pod分配给它并启动pod 向API服务器提供监控 当pod从 API服务器删除, kubelet也会删除pod kube-proxy 确保用户可以访问后端的pod 两种模式： 控制器协作 pod 到底是什么 网络 相同节点的pod通信： 不同节点的pod通信： 只有当所有节点连接到相同网关的时候 上述方案才有效 服务的实现 服务暴露的外部ip与端口通过每个节点上的kube-proxy实现 暴露的这个ip是虚拟的 主要是用来做映射用的 当kube-proxy接收到这个ip的请求 就会查找映射 转发请求 高可用集群 应用高可用： 水平扩展 主从架构 master高可用： etcd自身会进行数据同步 API 服务器是无状态的 控制器与调度器会进行主从选举 只有leader才会进行调度控制工作 优点 简化部署 充分利用硬件 健康检查 自修复 自动扩容 在K8S中运行应用 根据描述信息生成对应的pod 在pod中运行容器 K8S会保证集群中的容器数量实例 在容器死亡时 会启动新容器替补 K8S 在运行时可根据需求动态调整副本数量 通过kube-proxy能进行服务连接动态切换 本地运行K8S 安装minikube 安装kubectl minikube start \\ --image-mirror-country=cn \\ --registry-mirror='https://t9ab0rkd.mirror.aliyuncs.com' \\ --image-repository='registry.cn-hangzhou.aliyuncs.com/google_containers' 部署第一个应用 kubectl run kubia --image=luksa/kubia --port=8080 # 创建容器运行 kubectl get pods # 获取pod kubectl get rc kubectl port-forward kubia 8080:8080 # 开启端口转发 kubectl get pods -o wide # 查看应用在哪个节点 kubectl scale rc kubia --replicas=3 # 水平扩容 逻辑架构： RC用来确保始终有pod运行 使用http服务来完成外部请求到pod的映射 pod 一组紧密相关的容器 独立的逻辑机器 一 个 pod 中的所有容器都在相同的 network 和 UTS 命名空间下运行 每个 pod 都有自己的 IP 地址， 并且可以通过这个专门的网络实现 pod 之间互相访问 pod的使用： 倾向于单个pod单个容器 使用yml创建pod apiVersion: v1 kind: Pod metadata: name: kubia-manual labels: env: test # 指定一个标签 spec: nodeSelector: # 选择特定标签的节点 super: \"true\" containers: - image: luksa/kubia name: kubia ports: - containerPort: 8080 protocol: TCP kubectl create -f kubia-manual.yaml kubectl logs kubia-manual # 查看日志 标签 kubectl get po --show-labels kubectl label po kubia-manual createtion_method=manual # 修改标签 kubectl label node minikube super=true kubectl get po -l createtion_method=manual # 根据标签筛选 注解 注解也是键值对 kubectl annotate pod kubia-manual wang.ismy/name=\"cxk\" 命名空间 命名空间简单为对象划分了一个作用域 kubectl get ns kubectl get po -n kube-system # 获取命名空间下的pod kubectl create namespace custom-namespace # 创建命名空间 kubectl create -f kubia-manual.yaml -n custom-namespace # 指定命名空间 停止与移除 kubectl delete po kubia-manual # 根据名字删除 副本机制 k8s 会保证 pod 以及 容器的健康运行 存活探针 当存活探针探测失败 容器就会重启 创建 apiVersion: v1 kind: Pod metadata: name: kubia-liveness spec: containers: - image: luksa/kubia-unhealthy name: kubia livenessProbe: # 存活探针 httpGet: # 返回2xx 或者 3xx就代表活着 path: / port: 8080 ReplicationController 创建和管理一个pod的多个副本 创建 apiVersion: v1 kind: ReplicationController metadata: name: kubia spec: replicas: 3 selector: app: kubia template: metadata: labels: app: kubia spec: containers: - name: kubia image: luksa/kubia ports: - containerPort: 8080 控制器通 过 创建 一 个新的替代pod来响应pod的删除操作 通过更改标签的方式来实现rc与pod的关联 扩容 kubectl scale rc kubia --replicas=10 删除 kubectl delete rc kubia ReplicaSet ReplicaSet 会 替代 rc rs 的pod 选择器的表达能力更强 创建 apiVersion: apps/v1 kind: ReplicaSet metadata: name: kubia spec: replicas: 3 selector: matchLabels: app: kubia template: metadata: labels: app: kubia spec: containers: - name: kubia image: luksa/kubia DaemonSet 由DaemonSet 创建的pod 会绕过调度程序 会在所有集群节点上运行（或者也可以通过指定nodeSelector在其他节点运行） 创建 apiVersion: apps/v1 kind: DaemonSet metadata: name: ssd-monitor spec: selector: matchLabels: app: ssd-monitor template: metadata: labels: app: ssd-monitor spec: nodeSelector: disk: ssd containers: - name: main image: luksa/ssd-monitor Job 允许运行 一 种 pod, 该 pod 在内部进程成功结束时， 不重启容器。 创建 apiVersion: batch/v1 kind: Job metadata: name: batch-job spec: completions: 5 # 运行pod数 parallelism: 2 # 并行运行数 template: metadata: labels: app: batch-job spec: restartPolicy: OnFailure containers: - name: main image: luksa/batch-job CronJob 创建 apiVersion: batch/v1beta1 kind: CronJob metadata: name: cron-job spec: schedule: \"0,15,30,45 * * * *\" jobTemplate: spec: template: metadata: labels: app: batch-job spec: restartPolicy: OnFailure containers: - name: main image: luksa/batch-job 服务 是一种为一组功能相同的 pod 提供单一不变的接入点的资源 创建 apiVersion: v1 kind: Service metadata: name: kubia spec: ports: - port: 80 targetPort: 8080 selector: app: kubia 服务间的发现 通过环境变量 kubectl exec kubia-9knkg -- env 通过DNS 域名：kubia.default.svc.cluster.local 如果在同一命名空间下 直接使用 kubia即可 Endpoint 暴露一个服务的 IP 地址和端口的列表 kubectl get endpoints kubia 暴露服务给外部 NodePort：每个集群节点都会在节点上打开一个端口 将在该端口上接收到的流量重定向到基础服务 apiVersion: v1 kind: Service metadata: name: kubia-nodeport spec: type: NodePort ports: - port: 80 targetPort: 8080 nodePort: 30123 selector: app: kubia 通过nodeip:30123 访问 负载均衡器将流量重定向到跨所有节点的节点端口。客户端通过负载均衡器的 IP 连接到服务 apiVersion: v1 kind: Service metadata: name: kubia-loadbalancer spec: type: LoadBalancer ports: - port: 80 targetPort: 8080 selector: app: kubia 通过externalip:一个随机端口访问 Ingress 只需要 一 个公网 IP 就能为许多服务提供访问 启用： minikube addons enable ingress 就绪探针 创建 # kubia-rc.yaml spec: containers: - name: kubia image: luksa/kubia readinessProbe: exec: command: - ls - /var/ready # 该文件存在 容器才被认为就绪 服务故障排除 确保从集群内连接到服务的集群IP 服务的集群IP 是虚拟IP, 是无法ping通的 如果已经定义了就绪探针， 请确保 它返回成功；否则该pod不会成为服务的一部分 确认某个容器是服务的 一 部分 检查是否连接到服务公开的端口，而不是目标端口 尝试直接连接到podIP以确认pod正在接收正确端口上的 连接 法通过pod的IP 访问应用， 请确保应用不是仅绑定 到本地主机 卷 卷是 pod 的 一 个组成部分， 因此像容器 一 样在 pod 的规范中定义 在容器之间共享数据 emptyDir：pod被删除时 卷的内容就会丢失 创建 apiVersion: v1 kind: Pod metadata: name: fortune spec: containers: - image: luksa/fortune name: html-genrator volumeMounts: - name: html mountPath: /var/htdocs - image: nginx:alpine name: web-server volumeMounts: - name: html # 使用html卷 mountPath: /usr/share/nginx/html # 挂载到容器的位置 readOnly: true ports: - containerPort: 80 protocol: TCP volumes: # 创建一个卷 - name: html emptyDir: {} gitRepo：以git仓库文件填充目录文件 apiVersion: v1 kind: Pod metadata: name: gitrepo-volume-pod spec: containers: - image: nginx:alpine name: web-server volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 protocol: TCP volumes: - name: html gitRepo: repository: https://github.com/luksa/kubia-website-example.git revision: master directory: . 访问工作节点文件 hostPath 卷指向节点文件系统上的特定文件或目录 持久化存储 gce持久盘 aws弹性块存储 nfs卷 持久卷 创建持久卷 apiVersion: v1 kind: PersistentVolume metadata: name: mongodb-pv spec: capacity: storage: 1Gi accessModes: - ReadWriteOnce - ReadOnlyMany persistentVolumeReclaimPolicy: Retain hostPath: path: /tmp/mongodb 创建持久卷声明 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: mongodb-pvc spec: resources: requests: storage: 1Gi accessModes: - ReadWriteOnce storageClassName: \"\" # 动态持久卷 容器使用持久卷 # ... volumes: - name: mongodb-data persistentVolumeClaim: claimName: mongodb-pvc 动态持久卷 创建StorageClass apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: fast provisioner: k8s.io/minikube-hostpath parameters: type: pd-ssd 声明是通过名称引用它的 方便之处主要是在不同集群之间移植 参数配置 通过定义传递参数： - image: luksa/fortune:args args: [\"2\"] 使用环境变量： - image: luksa/fortune:env env: - name: INTERVAL value: \"30\" ConfigMap 类似于配置中心： 创建 kubectl create configmap fortunes-config --from-literal=sleep-interval=25 单个环境变量使用 - image: luksa/fortune:env env: - name: INTERVAL valueFrom: configMapKeyRef: name: fortunes-config key: sleep-interval 一次传递所有环境变量 - image: luksa/fortune:env env: envFrom: - prefix: CONFIG_ configMapRef: name: fortunes-config args: [\"${CONFIG_xxx}\"] # 传递到命令行 挂载到卷 volumes: - name: config configMap: name: configmap 更新配置 kubectl edit configmap xxx Secret 存储与分发敏感信息 创建 kubectl create secret generic fortune-https --from-file=https.key 挂载卷使用 - image: xxx volumeMounts: - name: keys mountPath: /etc/nginx/keys/ volumes: - name: keys secret: secretName: fortune-https 环境变量使用 env: - name: FOO_SECRET valueFrom: secretKeyRef: name: fortune-https key: name pod 元数据访问 Downward API 通过环境变量： env: - name: POD IP valueFrom: fieldRef: fieldPath: status.podIP - name: CONTAINER CPU REQUEST MILLICORES valueFrom: resourceFieldRef: resource: requests.cpu divisor: lm 通过卷： volumes: - name: downward downwardAPI: items: - path: \"podName\" fieldRef: fieldPath: metadata.name 使用 K8S API 服务器 REST API： 启动kubectl proxy curl http://localhost:8001/apis/batch/v1/jobs 在 pod 内部使用 客户端API Deployment 更新应用： 删除旧版本pod 启动新版本pod 会造成短暂的服务不可用 启动新版本pod 删除旧版本pod 使用rc进行滚动升级 书上通过rolling-update的方法已经过时 使用 Deployment 声明式升级 创建 apiVersion: apps/v1 kind: Deployment metadata: name: kubia spec: replicas: 3 selector: matchLabels: app: kubia template: metadata: name: kubia labels: app: kubia spec: containers: - image: luksa/kubia:v1 name: nodejs kubectl create -f kubia-dep-v1.yaml --record # 加上该参数会记录历史版本号 更新版本 kubectl set image deployment kubia nodejs=luksa/kubia:v2 回滚 kubectl rollout undo deployment kubia 使用 - -to-revision=xxx 回滚到特定版本 升级速率控制 rollingUpdate : maxSurge: 1 # 最多允许超过的副本数 maxunavailable: 0 # 最多允许多少百分比pod不可用 使用rollout pause 暂停滚动升级 部分软件版本就不一样 金丝雀发布 minReadySeconds属性指定新创建的pod至少要成功运行多久之后 ， 才能 将其视为可用 如果 一 个新的pod 运行出错， 并且在minReadySeconds时间内它的就绪探针出现了失败， 那么新版本的滚动升级将被阻止 使用kubectl apply升级Deployment StatefulSet 如何复制有状态的pod？ Statefulset 保证了pod在重新调度后保留它们的标识和状态 每个pod都有专属于它的持久卷 K8S保证不会有两个相同标识和持久卷的pod同时运行 使用 创建持久卷 创建控制 Service apiVersion: v1 kind: Service metadata: name: kubia spec: clusterIP: None selector: app: kubia ports: - name: http port: 80 创建StatefulSet apiVersion: apps/v1 kind: StatefulSet metadata: name: kubia spec: serviceName: kubia replicas: 2 selector: matchLabels: app: kubia # has to match .spec.template.metadata.labels template: metadata: labels: app: kubia spec: containers: - name: kubia image: luksa/kubia-pet ports: - name: http containerPort: 8080 volumeMounts: - name: data mountPath: /var/data volumeClaimTemplates: - metadata: name: data spec: resources: requests: storage: 1Mi accessModes: - ReadWriteOnce 使用一个 Service 来访问 Pod apiVersion: v1 kind: Service metadata: name: kubia-public spec: selector: app: kubia ports: - port: 80 targetPort: 8080 发现伙伴节点 容器内部通过DNS SRV 记录 安全 pod 使用宿主节点的Linux命名空间 使用宿主节点的网络命名空间 spec: hostNetwork: true 使用宿主节点的端口而不使用宿主节点的网络命名空间 如果使用hostport 一个节点只能有一个相同的pod 使用宿主的PID与IPC空间 spec: hostPID: true hostIPC: true 开启后 相同节点的pod的进程之间就是可见的 可通信的 安全上下文 spec: securityContext: # ... pod 级别的 containers: securityContext: runAsUser: 405 # 以指定用户运行 runAsNonRoot: true # 禁止以root运行 privileged: true # 在特权模式下允许 capabilities: add: - SYS_TIME # 开放硬件时间修改权限 drop: - CHOWN # 禁用文件所有者修改权限 readOnlyRootFilesystem: true # 禁止在根目录写文件 pod 网络隔离 网络策略 apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: postgres-netpolicy spec: podSelector: matchLabels: app: database # 对该标签的pod生效 ingress: # 只允许来自匹配下面标签的pod请求 - from: - podSelector: matchLabels: app: webserver ports: - port: 5432 计算资源管理 申请资源 spec: containers: - image: busybox command: [\"dd\", \"if=/dev/zero\", \"of=/dev/null\"] name: main resources: requests: cpu: 200m # 申请200毫核 也就说20%CPU memory: 10Mi # 申请10M内存 添加了requests对调度的影响： 通过设置资源requests我们指定了pod对资源需求的最小值。 调度器不关心资源的实际使用了 而是关心各pod所定义的requests资源量 限制资源 resources: limits: cpu: 1 # 允许最大使用1核 memory: 20Mi # 内存允许最大 20M 超过limits的情况： cpu：进程分配到的CPU不会超过指定的 内存：如果内存超过limit 则容器会被杀掉 QoS 等级 通过定义优先级决定资源不足时杀谁 BestEffort 优先级最低 没有设置requess和limits都属于这个级别 Guaranteed 优先级最高 cpu和内存都要设置requests 和 limits 所有容器都要设置资源量 requests 与 limits必须相等 Burstable 其他的pod都属于这个等级 限制命名空间中的pod LimitRange插件 ResourceQuota 监控 pod Heapster 自动伸缩与集群 基于CPU使用率的自动伸缩 kubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5 纵向扩容 自动修改CPU与内存大小 集群节点扩容 新节点启动后，其上运行的Kubelet会联系API服务器，创建 一 个Node资源以注册该节点 当一 个节点被选中下线，它首先会被标记为不可调度， 随后运行其上的pod 将被疏散至其他节点 高级调度 污点和容忍度 限制哪些pod可以被调度到某 一 个节点 kubectl describe node minikube | grep Taints # 查看节点污点 NoSchedule 表示如果 pod 没有容忍这些污点， pod 则不能被调度到包含这些污点的节点上 PreferNoSchedule 是 NoSchedule 的 一 个宽松的版本， 表示尽量阻止pod 被调度到这个节点上， 但是如果没有其他节点可以调度， pod 依然会被调度到这个节点上 NoExecute会影响正在节点上运行着的 pod 。 如果在 一 个节点上添加了 NoExecute 污点， 那些在该节点上运行着的pod, 如果没有容忍这个 NoExecute 污点， 将会从这个节点去除 添加污点 kubectl taint node minikube node-type=production:NoSchedule pod添加容忍度 spec: replicas: 5 template: spec: ... tolerations: - key: node-type operator: Equal value: production effect: NoSchedule 节点亲缘性 这种机制允许你通知 Kubemetes将 pod 只调度到某个几点子集上面 spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: gpu operator: In values: - \"true\" 最佳实践 pod 的生命周期 应用必须意识到会被杀死或者重新调度 ip与主机名会发生变化 使用卷解决数据写入问题 不断重启的pod不会被重新调度 固定顺序启动pod 使用init容器 应用要处理好其他依赖没有准备好的情况 生命周期钩子 postStart preStop pod的关闭 客户端请求处理 pod启动时避免客户端连接断开 使用一个就绪探针来探测pod是否准备好接受请求了 pod关闭时避免请求断开 停止接受新连接 等待所有请求完成 关闭应用 让应用方便运行与管理 可管理的容器镜像 镜像太大难以传输 镜像太小会缺失很多工具 合理给镜像打标签 不要使用latest 使用具体版本号 使用多维度的标签 使用注解描述额外信息 使用/dev/termination-log 写入失败信息 日志 将日志打印到标准输出方便查看 集中式日志系统 应用扩展 CRD对象 创建 apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: websites.extensions.example.com spec: scope: Namespaced group: extensions.example.com version: v1 names: kind: Website singular: website plural: websites 创建CRD实例 apiVersion: extensions.example.com/v1 kind: Website metadata: name: kubia spec: gitRepo: https://github.com/luksa/kubia-website-example.git 服务目录 服务目录就是列出所有服务的目录。 用户可以浏览目录并自行设置目录中列出的服务实例 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-19 07:47:46 "},"运维/容器管理.html":{"url":"运维/容器管理.html","title":"容器管理","keywords":"","body":"Rancher 可以对容器进行分类、分环境管理，以图形化界面操作docker Rancher是一个开源的企业级全栈化容器部署及管理平台。Rancher为容器提供一揽 子基础架构服务：CNI兼容的网络服务、存储服务、主机管理、负载均衡、防护墙…… Rancher让上述服务跨越公有云、私有云、虚拟机、物理机环境运行，真正实现一键式应 用部署和管理 主机 应用 容器 服务 扩容缩容 influxDB InfluxDB是一个由InfluxData开发的开源时序型数据库。它由Go写成，着力于高性能地查询与存储时序型数据。InfluxDB被广泛应用于存储系统的监控数据，IoT行业的实时数据等场景 cAdvisor CAdvisor是Google开源的一款用于展示和分析容器运行状态的可视化工具。通过在主机上运行CAdvisor用户可以轻松的获取到当前主机上容器的运行统计信息，并以图表的形式向用户展示 Grafana grafana 是一款采用 go 语言编写的开源应用，主要用于大规模指标数据的可视化展现，是网络架构和应用分析中最流行的时序数据展示工具，目前已经支持绝大部分常用的时序数据库 MY all right reserved，powered by Gitbook该页面最后修改于： 2019-11-22 08:59:23 "},"通识/nav.html":{"url":"通识/nav.html","title":"通识","keywords":"","body":"通识 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 12:40:15 "},"通识/技术与世界.html":{"url":"通识/技术与世界.html","title":"技术与世界","keywords":"","body":"技术与世界 软件开发永远不止是写代码那么简单 技术人员，很容易就陷入到“技术就是一切”的极端中，往往是只见树木，不见森林 仅仅是技术好，是不够的。必须有更大的视野，必须看更大的世界 编程语言的发展趋势 现代编程语言，可以说是抽象程度更高了，更符合人类的思维 领域特定语言(DSL) 做特定领域的事情，而不用纠结与太多的底层细节 GPPL(通用目标语言) 算法 所以说，想要用算法来审查违规内容，并非一件轻松之事 人类创建了这些算法，却无法控制这些算法。 算法只是会忠实履行它自己应尽的责任，它没有人类的精神世界，主观。作恶还是作善都是取决人 大多数人都不会，也不可能使用工程师的视角，去看待技术 归根到底，算法只是一个工具 机器学习的算法 机器学习算法与传统算法的区别在于传统算法所执行的，都是一系列定义好的逻辑规则 而现如今的机器学习，都是通过输入数据与答案，让机器找到这中间的联系，从而识别新数据 现在的机器学习算法，就像是个黑盒子，我们就只知道它做了什么，至于为什么这样做，一概不知 安全 素数与安全 学习与智力 勤学如春起之苗，不见其增，日有所长 完美主义与囫囵吞枣 学习的境界 了解 关键词 原理 实践 应用 创造 遗忘 对于遗忘的知识，重新捡起来，是很容易的 学习的最佳时期 不要忽视时间的力量 或许学习的时长远比接触的时间重要的多 估算 费米估算，关键在于对问题的拆解和转换 因素越多，得到的估算就会越靠谱 信息 从文字到图片，再到音视频，下一种媒体形式，会是什么？ 语言的表现能力是否过于苍白 5G的真正优势是什么？只是传输信息更快？ Iot 两个时代的交替，就会催生出新的机会 人体 有时候身体某一地方出了毛病，不代表就真的是这个地方出了毛病，也许是其他地方出了毛病所产生的并发症 头痛医头脚痛医脚，在大部分情况下，是有问题的 机器 在自动化某一个过程之前，你必须知道手动完成这件事情的全过程 在最开始，自动化是需要付出一定的成本的，但随着时间的推移，越往后面，就越能享受到自动化带来的好处 虽然自动化的不断应用，人肯定是要被慢慢替换下来的，但是自动化的增加可能会增加出新岗位出来，只不过这些岗位，肯定没有之前轻松 商业 做信息的生意，是互联网创业的核心 订阅服务 真的更便宜吗？ 消费心理 支付意愿与接受意愿 技术 对于有一些技术领域，一个社会完全可以跳过某一个技术阶段，直接达到下一个技术阶段 大多数人不会觉得现在自己使用的，是落后的技术 人类的大脑好像也有类似的这样一种“关闭”机制。一旦一种熟悉的，可以解决问题的方式进入了，我们的大脑就会自然地抗拒第二种方式的进入 走出舒适区很容易吗 社会 问题在于，在这个世界上，什么是善，什么是恶，从来不是泾渭分明的 自由的好处 自由的坏处 看再多“只和自己比较，不要顾及别人的眼光”的文章，我们的大脑一样会不由自主地和别人去比较 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-09 06:17:23 "},"通识/专业素养.html":{"url":"通识/专业素养.html","title":"专业素养","keywords":"","body":"专业素养 关心你的技艺 思考你的作为 专业主义 专业主义意味着担当责任 提供各种选择 不要找蹩脚的借口 说明做不到之前 给出所能给出的最好方案以尝试挽回 损害 软件出现bug 就是在损坏软件功能 编写测试 让它自动化跑出起来 测试越多 你对自己的代码越有信心 牺牲结构来修改软件 后果是得不偿失 软件的特点就在于软 如果修改难以进行 就代表设计出现了问题 留着这些破窗户只会导致破窗越来越大 不要容忍破窗户 当软件的熵越来越大时 软件也就越来越无序了 称之为软件腐烂 使用无情重构的方式来避免代码慢慢腐烂 但重构的前提是完备的测试 测试是软件质量的保障 留意环境 警惕那些软件腐败的小细节 职业道德 专业人士应舍得投入时间不断提升自己 变得更加专业 似乎软件开发这个领域出现知识大爆炸 感慨学不过来 但目前这些所谓的流行技术 绝大部分都是来得快去得快 那些来之不易的理念 绝大部分在今天仍然十分有价值 在学习时 应该把重点放在这边 设计模式 设计原则 开发方法 软件工程实践 不会过时的工具 ... 持续学习才不至于落伍 不写代码的架构师必然遭殃 这个行业的知识更新迭代的速度十分快, 你需要像金融投资那样经营你的知识资产： 定期投资让你不至于你的知识一成不变 落伍 多元化 知道的不同的事情越多 越有价值 管理风险 新兴知识的投资高回报高风险 不要把所有的技术鸡蛋放在同一个篮子 需要时 对投资进行重新评估与选择 批判分析读到和听到的 练习能让你的技艺保持熟悉 什么样的练习 刷题? 与他人合作能从彼此身上学到很多东西 费曼学习法 技术人员应付出想当的努力来认识业务领域 站在雇主角度开发软件 使质量称为需求问题, 有时候需要在尽早交付与完美软件之前权衡 编程就像绘画 需要知道何时止步 一昧求精只会导致损毁掉你的程序 不必故作谦逊 摔了跟头大不了一笑了之 说不 面对艰难决定 直接面对是最好的办法 对于非技术人员 ”为什么“只是个技术细节 对它们俩说 并不重要 合适的时机说不 意味着团队精神 意味着对团队负责 客户所要的任何一项功能 一旦写起来 总是远比它刚开始时说的要复杂许多 说是 模糊不清的词是缺乏承诺的征兆 使用具体时间来承诺 那么就要为承诺负起全部责任 只能承诺自己能完全掌握的事情 即使无法完成目标 也该努力前进 离目标更近 如果无法兑现承诺 应及时发布预警 如何说是： 试试看意味着不确定感 对于明确有着不确定的任务 应该表达出不确定感 同时仍需要坚守原则 作为一个专业人士 编码 你不可能写出完美的软件 防御式编程不仅仅防御别人的代码 还要防御自己 传统的瀑布模型一旦进入编码阶段 就是机械地将设计转为可执行语句 这种没有任何创造性的编码或许是造成软件结构糟糕 低效的原因 出错感知能力能帮助你更快速地从错误中学习 准备： 编码前必须要理解解决的是什么问题以及该如何解决 确保代码能解决客户的问题 而非完成需求 新的代码应能完美适应当前系统 写下的代码应该具有可读性 疲劳与心烦意乱下的产出 最终只能回头返工 一味追求速度可能会导致思考角度边狭隘 从而做出一些以后不得不推到再来的决策 编程时被中断再回来会导致上下文成本切换很高： 结对编程的伙伴可以帮助维护上下文 TDD失败的测试也可以快速让你回到状态 心情/精神等因素会阻塞你的创造性输出 相反 一些创造性输入可以激励你产出 调试时间的多少与专业程度成反比 向着零调试时间前进 难以解决的困难不妨放一放 等待灵感的到来 冲刺可以解决进度延迟问题 但不一定会成功 需要准备后备预案 只有通过验收测试 某个特性才能称之为完成 帮助他人 接收他人的帮助 合约式编程 DBC: 前条件：调用程序前 必须为真的条件 后条件：程序保证会做的事 类不变项：确保从调用者的角度看 总是为真的条件 实现方式： 断言 但是无法继承 部分语言内置支持 但是大部分语言不支持 通过使用预处理器来实现它 早崩溃： 通过检查前置条件 早一点暴露错误 调试就会容易许多 尽早崩溃比造成破坏是更好的选择 Java中的运行时异常采用了这一哲学 不变项： 循环不变项：循环的边界很容易出错 通过定义一个不变项来证明结果有效 语义不变项：定义一个合约来表达不可违反的需求 动态合约与代理：合约可以发生变化 断言式编程 如果它不可能发生 用断言确保它不会发生 不要关掉断言 这世界很危险 程序很容易出错 异常的使用 异常不应该是程序正常流程的一部分 而是留给意外事件 不支持异常的编程语言只能使用错误处理器 c语言可以通过使用goto的方式来实现全局异常处理 资源的使用 有始有终 分配资源的程序应该负责回收资源 资源的分配： 以资源分配的反序释放资源 这样就不会造成资源被遗弃 分配同一组资源的时候 总是以相同的顺序进行分配 这可以降低死锁发生的可能性 资源的释放： 递归回收 顶层对象一旦被释放 就递归地释放子资源 顶层回收 就直接遗弃所有子资源 如果顶层含有子资源 在所有子资源释放前 拒绝释放顶层 靠巧合编程 编程时 依赖着许多假定的条件 有时候这些条件也许存在 从而你的程序能偶尔可以工作正确 但更多地 它会在你未来的某一天崩掉 算法速率 使用大O表示法估算你的算法 重构 早重构 常重构 重构必无情 何时重构： 重复 非正交设计 过时的知识 为了性能 易于测试的代码 为测试而设计 使用合约式编程来清晰测试 谨慎代码生成器的使用 不要使用你不理解的代码代码生成器 这些代码未来可能会跟你你编写的代码柔和在一起 如果不理解它们 未来就是一个定时炸弹 注重实效 重复 系统中的每一项知识都必须具有单一 无歧义 权威的表示 不要重复你自己 强加的重复 好像让开发者没得选择 必须写重复的文档 做重复的编码 如根据规约写出代码 但只需要动用一点小才智 就能让这个过程自动化 把低级的知识放在代码中 把注释留给高级的知识 无意的重复 这种重复一般是设计的错误 需要从根源解决问题 无耐性的重复 就跟提到的赶工期取消单元测试一样 编码一时爽 维护火葬场 开发者的重复 这个问题似乎在2020年的今天已经不存在 开源社区的繁荣促使开发者代码复用变得十分容易 正交 消除无关事务之间的影响 正交在几何中表示的是如果两条线称直角 则就称之为正交 对应到计算机世界 就是解耦 一个模块的变化不会影响到另外一个模块 正交的好处： 提高生产率 小模块的编写总比大模块容易 促进复用 降低风险 有问题的代码会被隔离 改动影响的范围有限 测试更容易 在团队中：正交性差的团队成员职责边界不清晰 在设计中：分层的方法是设计正交系统的强大途径 引入第三方库时 是否需要对已有代码进行改动 如果是 那么就不是正交的 每次编写编码 都有系统降低正交性的风险 几个原则来维持正交性： 保持代码解耦 避免不必要的数据暴露 使用OOP来封装 避免全局变量 使用设计模式 正交也适用于文档 正交文档表现形式与内容分离 比如markdown 可撤销 如果某个想法是唯一的想法 那就太危险了 总需要保持代码的灵活性来避免变动带来的返工 不存在最终决策 曳光弹 小步快跑 快速迭代 帮助用户明确需求 小段代码的惯性很小 改变起来很容易 原型与便签 应制作原型的事物： 架构 新功能 外部源 性能问题研究 UI 适当使用原型 节约时间金钱 领域语言 计算机语言会影响思考问题的方式 靠近问题领域进行编程 站在更高的抽象层面 忽略琐碎的细节 基本工具 纯文本 使用纯文本保存知识 二进制数据的问题在于没有第三方对其解析 这些数据毫无意义 文本的威力： 保证不过时 人能阅读的数据 以及自描述的数据 活的更久 杠杆作用 计算机世界的许多工具对文本的支持都不错 unix下的小工具 vcs等 易于测试 文本测试数据更容易修改 并且无需特殊工具 纯文本在异构系统下十分好用 shell shell是不是真的比GUI好 好在哪里？ GUI最要命的一点 那就是使用GUI完成操作受限于GUI设计者 你所做的 都是在设计者给你的条条框框内 利用命令shell的力量 你可以使用组合参数 管道等方式得到一些十分强大的命令 编辑器 用好一种编辑器 这个编辑器应该能横跨所有平台（GUI 与命令行） 我能想到的就只有vim 但是vscode也符合需求 它的确很强大 源码控制 总是使用源码控制 不仅仅是代码 一切一切都可以存入源码控制系统 他给你了你反悔的能力 调试 要修正问题 而非发出指责 不要恐慌 你最容易欺骗的人是你自己 从何开始： 收集更多数据 以清楚bug 策略： 把你的数据可视化 跟踪程序 跟踪数据 橡皮鸭调试法 你的程序出错的可能性比外部程序大 不要假定 要证明 出现了令你惊讶的bug就代表你之前的假设是错的 文本操纵语言 学习一门文本操纵语言可以有效提升效率 代码生成器 编写能生成代码的代码 被动代码生成器：生成结果 结果可以独立使用 主动代码生成器：需要时进行生成结果 结果用完就扔 代码生成器生成的不仅仅可以是代码 练习 用自己的时间练习 保持自己的技能不落伍是自己的责任 验收测试 需求 过早精细化带来的问题： 每次向业务放展示一项功能 他们就获得比之前更多的信息 这些信息又会影响他们的看法 提出新的观点 需求一定会变化 过于精确的评估无效 但是拒绝过早精细化又会带来模糊性 验收测试 其目的确定需求已经完成 何为已经完成：代码都写完了 测试都通过了 QA和需求方都认可 通过沟通确保大家都明白要做的什么 验收测试应当自动化进行 手工测试的成本太高 验收测试的进行越晚越好 需求一定会变化 理想情况下 应该由业务方以及QA来编写这些测试 协商并改进测试时专业开发人员的职责 单元测试与验收测试的区别在单元测试时白盒 验收是黑盒 对于GUI测试 进行时必须使用GUI背后文档的抽象元素 但是GUI测试还是应尽可能减少 设计时做到GUI与业务逻辑的解耦 GUI测试时不稳定的 使用持续集成确保新增的代码不会导致测试失败 否则修复失败是第一重要任务 测试策略 开发人员与QA携手保障系统质量 自动化测试金字塔： 单元测试作为持续集成的一部分来运行 组件测试需要使用合适的模拟 输入数据 收集输出 验证是否符合预期 集成测试主要测试组件装配在一起是否协调 系统测试测试系统是否已正确组装完毕 各个组件之间是否能正确交互 最后使用人工探索式测试尽可能找出多的古怪之处 时间管理 离开没必要的会议 按照真实的紧急程度来执行任务 进入死胡同或者泥潭时 你可以回头修正设计 也可以继续向死路走下去 但走回头路是最简单的办法 预估 估算，以避免发生意外 根据实际情况来调整你的估算 使用的单位会对结果的解读造成影响 承诺是关乎确定性的 预估是一种猜测 尽可能说明预估的概率分布 三元分析法： 乐观预估 标称预估 悲观预估 压力 保持冷静的最好方式 便是规避会导致压力的处境 尽力为其他人的承诺找到解决方法 但并非要为别人的承诺付出代价 保持整洁 不能因压力而破坏原则 快而脏是矛盾的 遵循那些仍会在危机时刻遵循的原则 这些原则是避免陷入危机的最好途径 避免产生孤注一掷的想法 仓促鲁莽只会把你代入更深的深渊 协作 程序员的工作职责就是要让业务免于陷入困顿 代码共有比代码私有带来的好处要更加多 结对编程不仅促进知识传播 同时也是复查代码的一种手段 说什么与怎么说同样重要 做变化的催化剂 解耦 迪米特法则 该法则试图使各个模块的耦合降至最低 工程需要平衡各种证明因素和负面因素 带来解耦的好处 就会带来其他代价 元程序设计 元数据是描述数据的数据 那么元程序就是元数据驱动的引用 将抽象放进代码 细节放进元数据 好处： 耦合更低 推迟细节决定 无需重新编译 更接近于领域模型 可以通过调整元数据实现不同的应用 可配置的应用 配置度越高 就代表程序越抽象 越抽象的程序越容易复用 时间耦合 相较于并发程序 顺序程序更符合人的逻辑 如果容许并发 就代表与时间的耦合度降低了 并再设计上予以支持 虽然不符合人的正常思维 但可以获得更强的灵活性 分析工作流 以改善并发性 用定义良好的 接口一致的服务来进行设计 为并发而设计能促使你设计更加简洁的接口 一旦具有了并发的要素 部署起来更加容易 因为不会有强依赖的情况产生 所谓强依赖就是部署a之前必须部署b 只是视图 发布订阅模式 MVC中的视图与模型分离 这条原则不仅适用于GUI 而是一条通用的编码准则 用来降低耦合 项目 需求 不要收集需求 而是挖掘它 深刻明白客户所提的需求可能是表象 要通过表象洞察其本质 建立需求文档：不管是形式化还是非形式化 不管是用例还是普通流程图 避免过度：文档比代码的好处就是可以模糊不清 文档不必过于具体 保持适当抽象 抽象比细节获得更加长久 追踪需求：通过建立一系列跟踪计划来避免特性膨胀 维护一张词汇表：建立业务领域与技术领域之间的映射 这些需求文档的分发可以借助于VCS以及Web 又厚又大的打印文档不仅费时费力而且容易过时 解决问题 一个难题的最终解决方案是一个刚开始看起来不太适用的方案 尝试思考被排除的方案 准备好了吗 对于反复出现的焦虑 需要重视它 准备好再开始 如使用原型来验证想法是否可行 规范陷阱 不应该将需求分析以及编码分裂成不同的过程 这些过程相辅相成 也不应该将规约设计到编码时毫无发挥技巧的余地 圆圈与箭头 不要做形式化方法的奴隶 编码是一个创造性过程 昂贵的工具不一定能制作出更好的设计 团队 不要留破窗户 破窗户最终只会越来越破 不要做温水里的青蛙 警惕那些使项目失败的小细节 交流失败的团队注定会失败 DRY:团队成员的工作重复不仅带来浪费 而且维护还可能是噩梦 围绕功能而非工作职务进行组织人员 就像围绕业务而非技术 抵抗不断画下去的诱惑 自动化 手工流程是不可靠的 构建自动化 自动化管理 网站生成 批准流程 无情的测试 早测试 常测试 测试必无情 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-13 11:19:01 "},"通识/设计.html":{"url":"通识/设计.html","title":"设计","keywords":"","body":"设计 什么是设计： MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-18 11:19:14 "},"通识/编程思想.html":{"url":"通识/编程思想.html","title":"编程思想","keywords":"","body":"编程思想 编程语言 语法 数据结构 编程模型 面向对象 面向过程 编程思想 契约编程 设计模式 OOP 封装继承多态 AOP 静态接口 动态代理 字节码 面向元数据编程 metadata 泛型 反射 注解 函数式编程 函数式接口 默认方法 方法引用 契约编程 语义 设计模式 最基本：23设计模式 面向对象设计模式,面向切面设计模式... 模式驱动 接口驱动 配置驱动 注解驱动 函数驱动 模块驱动 领域驱动 解决的问题：系统规模日益变大 领域 业务问题模块 驱动 驱动设计 关注领域，而非细节 驱动代码实现 实施 理解领域 领域专家 拆分领域 细化子域 标准 业务规则 业务场景 业务流程 约束领域 划分边界 调试 第一步：重现问题 第二步：思考原因 第三步：验证假设 如果无法确定问题，可以缩小范围 修复bug应了解其产生原因 抽象 抽象更接近问题的本质 寻找共性 提升抽象层次 分治 函数分解 优雅的代码不是一次写成的 分治模式 pipline 分层设计 垂直拆分/水平拆分 编程珠玑 灵光一现的算法 数据结构决定程序 使用更合适的数据结构能减少代码量 正确的程序 断言 测试 性能分析 问题定义 系统结构 算法与数据结构 代码调优 系统软件 硬件 估算 使用小实验获取关键参数 任何事都应尽量简单 但不宜过于简单 算法设计 保存状态 避免重复计算 动态规划 对信息进行预处理至数据结构中 分治算法 扫描算法 还是动态规划 代码调优 不成熟的优化是大量编程灾害的根源 需要有一个度量工具 注意代码调优是一把双刃剑 一些优化方案： 缓存 等价的代数表达式 内联函数避免函数调用开销 循环展开 修改数据结构 节省空间 调整数据结构 使用计算代替存储 稀疏数据结构 关键字索引 数据压缩 动态废品 垃圾回收 自描述数据 KV对 注释文档 源代码描述 技巧 明白用户的真实需求 评估成本与收益 正确评估问题的难度 正确的工具 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-07-26 06:58:51 "},"通识/测试与思维.html":{"url":"通识/测试与思维.html","title":"测试与思维","keywords":"","body":"测试与思维 优秀的测试思维 敏感：能敏锐地透过现象看本质 好奇心：对于一件事情，不应该只浅尝表面，而应该朝着探索未知、探索深入的方向 乐观：要记住，编程不是全部，技术不是全部，试着空出一点时间，放松你的身心 学习 拿来主义 ≠ 懒惰主义 方式 在一个能让你沉浸式学习的环境 听课 预习 听课 实践 复习 记忆 各种所谓的记忆技巧，归根到底终是死记硬背，能真正掌握一件东西最好的方式就是你每时每刻都会接触它，应用它 测试全流程 需求阶段 头脑风暴 需求分析 设计阶段 测试模块划分 测试计划&测试用例 执行阶段 冒烟测试 执行测试 测试总结 项目上线 自动化测试 监控 测试用例 测试用例是通过使用在测试计划中确定的测试技术，对于已确定的测试条件进行逐步推敲，精炼而设计出来的重点说明如何具体操作产生何种结果的文档 等价类划分法 是把所有的输入数据，即程序的输入域划分为若干部分（子集），然后从每一个子集中选取少数具有代表性的数据作为测试用例 边值法 通常边界值分析法是作为对等价类划分法的补充，这种情况下，其测试用例来自等价类的边界 场景法 通过运用场景来对系统的功能点或业务流程的描述 错误推测法 根据经验或直觉推测程序中可能存在的各种错误，从而有针对性地编写检查这些错误的测试用例的方法 测试人员懂代码很重要吗 很重要，而且必要 生产问题复现 提升测试效率 问题定位 后续进阶 自动化测试 测试框架 自动化测试 自动化测试的目的是什么？ 小项目、项目的早期不适合自动化 自动化测试工具 第一代，录制回放类 开源编程类 测试设计模式 page object 把自动化测试代码以页面进行组织，将同一个页面上的所有信息，相关操作都放到一个类中 分层模式 进行抽象 测试平台 无代码，直接上手 可以完成更多类型的测试 效率 节省硬件资源 移动端测试 安装卸载升级测试 耗电量与发热测试 流量测试 兼容性测试 弱网测试 中断测试 手势测试 权限测试 客户端性能 极限测试 用户体验 移动端自动化 Appium 性能测试 负载测试：通过逐步加压的方式来确定系统的处理能力，确定系统能够承受的各项阀值 压力测试：压力测试则是要看服务的临界点 容量测试：容量测试相反，是在一定性能目标的前提下，系统能够处理的最大能力 配置测试：这是通过对被测试软件的软硬件配置的测试，找到系统各项资源的最优分配原则 性能测试≠性能测试工具的使用 需要前期分析，并且能监控调优 测试与架构设计 如果你的意识里系统架构都不存在的话，那么你怎么知道架构在什么情况下会出现异常呢 精准测试 通过自动化的手段对更新的代码进行范围判断，生成测试用例，自动执行 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-26 02:19:22 "},"通识/学习方法论.html":{"url":"通识/学习方法论.html","title":"学习方法论","keywords":"","body":"学习方法论 主要途径 文档/书籍 越往底层信息密度越大，准确性越高，参考价值越大 视频 视频对初学者来说帮助挺大的。 但到了一些阶段，视频讲解速度对于有基础的人来说过慢，而且进阶的免费视频也较少 到这个时候，看视频就不能再只关注视频本身的知识点，而是多关注诸如作者的编码，作者的思想等内容 源码 以思考为主，从设计者的角度来读源码 目的 读源码之前要确定目的，不然就是走马观花，没有收获 思路 从设计者的角度来读源码 先整体后局部 先手册后源码 如果连使用都不会就直接去学习源码，是一种非常不理智的行为 由易到难 带着问题读源码 了解项目的背景，项目的功能 写代码时遇到问题进行读源码 看issue 看错误堆栈信息 通过源码的单测来学习 通过demo 技巧 自己实现一个简易版的框架，跟着问题去探索源码 寻找源码的入口 阅读时重视变量、函数的命名 阅读时参考源码里的注释 关注类层次结构 调试 通过IDE的调试功能能清除地看到代码运行轨迹，从而更清楚地观察到整个代码 基本方法 设置断点 调试模式运行 单步调试 常见调试功能按钮 1 表示 Step Over 即跳过，执行到下一行； 2 表示 Step Into 即步入，可以进入自定义的函数； 3 表示 Force Step Into 即强制进入，可以进入到任何方法（包括第三方库或 JDK 源码）； 4 表示 Step Out 即跳出，如果当前调试的方法没问题，可以使用此功能跳出当前函数； 5 表示 Drop frame 即移除帧，相当于回退到上一级； 6 表示 Run to Cursor 即执行到鼠标所在的代码行数。 高级技巧 多线程调试 条件断点 运行时修改变量值 对变量执行表达式 功能很强大，比如可以对集合添加数据 watch表达式，可以让表达式显式在变量区 memory查看对象数量 异常断点 设置自定义异常断点 远程调试 被调试代码添加启动参数 -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000 -Xdebug IDEA配置远程主机信息 专栏 专栏相对于博客公众号的好处在于知识的系统性较强 公众号/博客 选择公众号或者博客需要注意甄别，抱着怀疑的态度 思维导图 通过思维导图，可以整理需求，梳理所学知识并构建知识体系 方法 推演验证 根据文档、使用体验来反推实现方式，然后与实际实现作对比 教 费曼学习法 PDAC循环 很多人学习时更喜欢 “做更多试卷” 给自己带来的虚假成就感，而不是珍惜错题给自己带来的价值 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-02-21 05:32:07 "},"通识/区块链.html":{"url":"通识/区块链.html","title":"区块链","keywords":"","body":"区块链 应用场景 资产：支付结算 记账 不可抵赖 点对点 匿名 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-04-22 08:13:28 "},"通识/markdown写作.html":{"url":"通识/markdown写作.html","title":"markdown写作","keywords":"","body":"markdown写作 语法简单 文本格式 网络协作 文章题纲 标题 ## 二级标题 无序列表 - 1 - 2 有序列表 1. a 2. b 完成任务 - [x] 已完成 - [ ] 未完成 [x] 已完成 [ ] 未完成 文本与代码 分段 p1 p2 粗体 **text** 斜体 *text* 删除线 ~~text~~ 引用 > 引用文本 代码块 转移字符 脚注 - cxk[^1] [^1]:知名篮球选手. 表格图形 表格 | 姓名 | 性别 | 年龄 | 婚姻状况 | |-----|-----:|:---:|:--------| | 张三 | 男 | 25 | 未婚 | | 李四 | 女 | 35 | 已婚 | | 王五 | 男 | 45 | 离异 | 可以使用html来呈现复杂表格 流程图 graph LR id1(A) --> id2(B) 序列图 sequenceDiagram cxk ->> server: 给我一台服务器 server ->> cxk : 好的，给你 数学 latex 行内引用：$\\LaTeX$ 单独引用：$$\\LaTeX$$ 上标与下标 $$10^2$$ $$10^{2+i}$$ $$A_i$$ $$A_{i+1}$$ 求和 $$\\sum_{i=0}^n A_i$$ 上划线下划线 $$P(A) = \\overline{A}\\overline{B}$$ $$A = B \\underline{B}$$ 花括号 $$\\underbrace{e,d}_{公钥P_k}$$ 分式 $$\\frac{a}{2}$$ 矩阵 $$ \\begin{matrix} a && b \\ c && d \\ \\end{matrix} $$ MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-10 02:46:50 "},"通识/概率论与数理统计.html":{"url":"通识/概率论与数理统计.html","title":"概率论与数理统计","keywords":"","body":"概率论与数理统计 随机事件 样本空间和随机事件 随机试验 可在相同条件下重复进行（可重复性） 全部结果是已知的（结果已知性） 事前无法预知结果（不可预测性） 随机事件 在随机试验中，对某些现象的陈述 必然事件Ω 不可能事件∅ 基本事件：一次试验中必发生且最简单的事件 复合事件：若干基本事件组成 样本空间 样本点：试验的每一个可能结果 样本点全体称为样本空间 事件关系和运算 包含 A发生必然导致B发生 A ⊂ B 如果 A ⊂ B 且 B ⊂ A,则 A = B 和(并)事件 A ∪ B 积(交)事件 A ∩ B 或者 AB 互不相容(互斥) 事件A,B不可能在一次试验同时发生 对立事件(逆事件) B = {A不发生} B = A 差事件 A-B 或 AB 运算律 事件的概率 事件A发生的可能性大小为P(A) 称为A的概率 A出现的频率 = (A出现的次数/实验总次数) 古典概型 实验结果为有限个 各个结果发生的可能性相等 P(A) = (A出现的次数/实验总次数) 几何概型 允许实验结果为无限个 公理化定义 非负性 ，0 ≤ P(A) ≤ 1 规范性 P（Ω） = 1 完全可加性 n个事件并集概率 = n个事件加起来的概率 性质： P(∅) = 0 不可能事件概率为0 n个事件并集概率 = n个事件加起来的概率 P（A）+P(A） P（B-A）=P(B)-P(AB) P(A∪B)=P(A)+P(B)-P(AB) 条件概率与事件的独立性 条件概率 已知事件B发生的条件下，事件A发生的可能性的客观度量称为条件概率，记为P(A|B)。 P(A|B) = P(AB) / P(B) 乘法定理 P (AB) = P(A)P(B|A) P (AB) = P(B)P(A|B) 全概率公式 用于多个原因导致一个结果发生 有互不相容事件B1 B2 B3 BN B1...BN 概率和为1 A为Ω中的一个事件 则 A = P(AB1) + P(AB2)... 贝叶斯公式 结果为A的事件，求Bi导致其发生的概率 事件的独立性 若P(A|B) = P(A) 或 P(B|A)=P(B) 或 P(AB)=P(A)P(B) 则事件A与B互相独立 随机变量及其分布 随机变量：对于Ω上的每一样本点w，都有一个实数与之对应，则称X(w)的X为随机变量 分布函数F(x)=P(X) 离散型随机变量 有一类随机变量可能的取值是有限个或可列无穷个，称之为离散型随机变量 各个可能的取值组合起来称之为随机变量X的分布律 常用离散型分布 0-1分布 二项分布 几何分布 泊松分布 连续型随机变量 一些随机变量的可能取值可充满一个区间，称之为连续型随机变量 常用连续型分布 均匀分布 指数分布 正态分布 二维随机变量及其分布 对于Ω上的每一样本点w，有两个实数XY与之对应，则（X,Y）为二维随机变量 联合分布函数 二维离散型随机变量 二维连续型随机变量 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-06-19 01:02:22 "},"个人/项目开发.html":{"url":"个人/项目开发.html","title":"项目开发","keywords":"","body":"项目开发 后端 travel 基于servlet与jsp的旅游网站 ssm 使用纯注解配置的ssm项目 pms 基于ssm的多模块权限管理系统 shop 基于Spring Cloud框架的微服务电商网站 edu 基于Spring Cloud框架的微服务在线视频教育网站 soc 基于Spring Cloud框架的微服务社交网站 sell 基于Spring Boot的点餐系统 前端 shop-web 纯HTML CSS实现的电商前端 blogb 基于node的多人博客系统 travel-vue 基于VUE的旅游网站前端 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-09-20 05:44:18 "},"参考文献.html":{"url":"参考文献.html","title":"参考文献","keywords":"","body":"参考文献/文档/书籍 [1] CS-Notes [2] advanced-java [3] Netty 实战 [4] 趣学算法 [5] 编程珠玑 [6] 领域驱动设计：软件核心复杂性应对之道 [7] JAVA EE 7 精粹 [8] InternetArchitect [9] javaguide [10] 敏捷软件开发 [11] Kafka 权威指南 [12] 深入浅出 Docker [13] 高性能 MySQL [14] MySQL 技术内幕 [15] Tomcat 架构解析 [16] 代码整洁之道 程序员的职业素养 [17] Kubernetes.in.Action [18] 代码整洁之道 [19] 码出高效 Java开发手册 [20] Java 解惑 [21] Zookeeper 分布式过程协同技术详解 [22] Redis 开发与运维 [23] Spring Cloud Alibaba 参考文档 [24] Nacos 文档 [25] 深入分析 Java Web 技术内幕 [26] 软件架构设计 大型网站技术架构与业务架构融合之道 [27] Sentinel 文档 [28] 程序员修炼之道 从小工到专家 [29] memcached Wiki [30] 集体智慧编程 [31] 深入理解 Java 虚拟机 [32] 代码之髓 编程语言核心概念 [33] Istio Handbook——Istio 服务网格进阶实战 [34] 软件架构探索：The Fenix Project [35] 七周七语言 理解多种编程范型 MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-29 14:07:16 "},"个人/个人简历.html":{"url":"个人/个人简历.html","title":"个人简历","keywords":"","body":"个人简历 期望职位：Java 开发 联系方式 手机：17359563770 邮箱：cjp1999@foxmail.com 基本资料 陈吉平 / 男 / 1999 泉州师范学院 / 本科 / 软件工程 / 2021届 技术博客：ismy.wang Github：github.com/0xcaffebabe 技能 基础 Java 基础良好. 熟悉数据结构及算法, 计算机网络, 操作系统等基础知识. 熟悉常用设计模式, 设计原则, 系统设计知识. 熟悉持续集成, 重构, 单元测试等实践. 熟悉 Netty, Spring, Mybatis 等主流框架. 熟悉 Java 并发编程. 熟悉 JVM. 中间件 熟悉 ZooKeeper. 熟悉 MySQL, Redis, Elasticsearch. 熟悉 RabbitMQ, Kafka. 熟悉 Nginx, Tomcat. 分布式 熟悉分布式相关内容. 熟悉 Spring Cloud, Dubbo. 其他 拥有英文技术文档阅读能力. 熟悉 Linux 使用, 了解容器技术, 熟悉 Python. 熟悉前端开发. 项目经验 消息推送系统 项目 Github 地址：github.com/0xcaffebabe/distributed-message-push-system 时间：2020年6月 - 2020年7月 职责：系统设计及主要模块开发 该系统预期目标是用作于嵌入在其他系统的子系统, 预期的应用场景是：IM消息推送, APP通知推送, IoT终端状态上报及事件推送等. 系统分为 Gateway, Connector, Dispatcher, Admin 4个子系统. Gateway 负责对到来的连接认证鉴权及分配 Connector 实例. Connector 负责维护与客户端的连接及消息推送接收. Dispatcher 接收消息推送请求, 指挥相应的 Connector 推送消息. Admin 通过注册中心, MQ 等收集各子系统信息, 实现对整个系统的实时监控与运维. 外部系统可以通过 MQ 与 Dispatcher 接入本系统, 实现自己的业务逻辑. 客户端支持 Java, Python, JavaScript, Go 等语言. 各子系统使用 Spring Boot 框架快速开发. Connector 支持水平扩展, 使用 Netty 实现与客户端通信, 使用心跳机制保证连接的有效性, 使用非对称加密保证与对称加密保证了数据传输的安全性, 实现了对 MQ 消息消费幂等性处理, 使用定时任务进行消息重试, 使用 Redis 作为临时存储, 使用 MySQL 持久化客户端消息确认记录. 外卖订餐系统 项目 Github 地址：github.com/0xcaffebabe/blb 时间：2020年4月 - 2020年6月 职责：系统设计, 文档编写, 主要模块开发 该项目采用前后端分离架构, 前端使用 Vue.js 技术栈. 后端使用微服务架构, 整体架构分为四层：基础设施服务层, 业务服务层, 服务聚合层, 网关层. 后端系统使用 SpringCloud 作为微服务框架, 使用 Nacos 作为注册中心, 为服务间发现提供支持, 使用 Feign 进行远程调用, 服务的降级熔断采用 Sentinel. 为提高性能, 引入 Redis 作为缓存支持, 为统一管理, 将缓存管理相关功能拆分到一个独立的服务里. 在商品服务与店铺服务中使用了 Elasticsearch 对商品, 店铺信息分词索引, 为店铺及商品搜索功能提供支持. 在订单服务里, 使用 Rabbit MQ 广播订单事件, 实现了订单服务与下游服务的解耦, 提升了系统的可扩展性. MY all right reserved，powered by Gitbook该页面最后修改于： 2020-10-18 08:31:47 "}}